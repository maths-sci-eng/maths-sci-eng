[["index.html", "Mathematics for Scientists and Engineers Preface Acknowledgements", " Mathematics for Scientists and Engineers Dr Mark Callaway 2023-10-11 Preface These notes have been compiled for use alongside the University of Exeter modules CSM1027, CSM1033, CSM1040 and CSM1041. They are a work in progress – please let me know if you find any errors or have any feedback. Contact: m.callaway@exeter.ac.uk Recommended text: Engineering Mathematics, John Bird. Available online through the UoE library here: https://encore.exeter.ac.uk/iii/encore/record/C__Rb4511752 Acknowledgements Thank you to my colleagues who have contributed to these notes by sharing lecture materials: Dr TJ McKinley, Dr Houry Melkonian, Dr Markus Mueller and Prof Stuart Townley. Thank you to Ed Branford for his contributions to the exercise solutions. "],["foundations.html", "Chapter 1 Foundations 1.1 Numbers 1.2 Algebra 1.3 Equations 1.4 Inequalities 1.5 Common mistakes!", " Chapter 1 Foundations We begin with some foundational material that forms the basis of all applied mathematics. 1.1 Numbers We deal with various number systems in mathematics. The set of natural numbers are the familiar counting numbers: \\[1, 2, 3,\\dotsc\\] We denote these by the symbol \\(\\mathbb{N}\\). The integers are the “whole numbers”, which include zero and negative numbers: \\[\\dots,-2,-1,0,1,2,\\dots\\] We denote these by the symbol \\(\\mathbb{Z}\\). We sometimes want to focus on just the positive integers, which is another name for the natural numbers. The non-negative integers are the numbers: \\[0, 1, 2, 3,\\dotsc\\] (the natural numbers and zero). The negative integers are the numbers: \\[-1, -2, -3,\\dotsc\\] The rational numbers are numbers which can be written in the form \\(\\frac{a}{b}\\) where \\(a\\) and \\(b\\) are integers, with \\(b\\neq 0\\), so numbers like \\[\\frac{1}{2}, \\frac{3}{2}, -\\frac{4}{5}, \\dotsc\\] Note these include the integers since they can be written as \\(\\frac{a}{1}\\). Rational numbers are denoted \\(\\mathbb{Q}\\). The ancient Greeks discovered that there are numbers that are not rational – so-called irrational numbers. For example, \\(\\sqrt{2}, \\pi\\) and \\(e\\) are all irrational numbers. One way of characterising irrational numbers is that they have a decimal representation that never repeats… \\[ \\pi=3.141592653589793238462643383279502884197169399375105820\\dots \\] In contrast, all rational numbers have an eventually repeating decimal expansion (after perhaps some initial jumble of digits, there is a repeating pattern), for example: Rational Number Repeating pattern \\(\\frac{1}{3}=0.333\\dots\\) repeating \\(3\\)’s \\(\\frac{3}{2}=1.5000\\dots\\) repeating \\(0\\)’s after the first decimal digit, which we normally don’t write down! \\(\\frac{219}{1750}=0.125142857142857\\dots\\) repeating sequence \\(142857\\) of length \\(6\\) after the first \\(3\\) decimal digits The real numbers consist of all rational and irrational numbers together. We can think of real numbers as points on a continuous straight line, or as numbers that possibly have a decimal representation requiring an infinite number of digits1. The set of real numbers is denoted by \\(\\mathbb{R}\\). We learn about all of the above numbers early on in our mathematical education. However, there is a further set of numbers that is very useful in science and engineering that you may not have encountered before: the complex numbers, denoted by \\(\\mathbb{C}\\). These are not as intuitive as real numbers and they are explored in section 5. 1.2 Algebra Algebra is the general name given to the rules for manipulating numerical variables. We often use letters as placeholders for numerical values. We can then manipulate these letters as if they were numbers using the rules of algebra, and hence re-arraging formulae or fing the general solution to an equation. We can then “plug-in” specific numbers to get the answer. Being fluent in the notation and manipulations of algebra allows us to progress to higher (more useful and more interesting) areas of mathematics. 1.2.1 BEDMAS Recall that when an expression contains multiple arithmetic operations, there is a certain precedence (they must be carried out in a certain order), so that there is no ambiguity in evaluating the answer. This is usually remembered by the mneumonic BEDMAS: B - Brackets E - Exponents D - Division M - Multiplication A - Addition S - Subtraction Division and Multiplication can be carried out in either order, as can Addition and Subtraction. We’ll recap the rules of Brackets and Exponents in the next sections. Example 1.1 (BEDMAS) We have \\[3+2\\times 4=11,\\] whilst \\[(3+2)\\times 4 = 20.\\] Another example: \\[18\\div 3^2 = 2\\] whilst \\[(18\\div 3)^2 = 36.\\] 1.2.2 Notation for Multiplication and Division Let \\(a,b\\) and \\(c\\) be numerical variables. To simplify our mathematical writing, we shorten the multiplication \\(a\\times b\\) to \\(ab\\) We also write division \\(a\\div c\\) in the “fraction” form \\(\\dfrac{a}{c}\\) Since division and multiplication can be carried out in either order, the following are different ways of writing the same thing: \\[\\dfrac{a}{c}b=\\dfrac{ab}{c}=a\\dfrac{b}{c}\\] and since multiplication of two numbers can be carried out in either order, there are even more ways of writing this expression: \\[\\frac{b}{c}a=\\frac{ba}{c}=b\\frac{a}{c}\\] 1.2.3 Rules of Exponents In their most basic form, we use exponents as a shorthand for multiplication of a number by itself a given number of times. For example: \\(5\\times 5 = 5^2\\) spoken as “5 squared” or “5 to the power 2” \\(5\\times 5\\times 5=5^3\\) spoken as “5 cubed” or “5 to the power 3” and more generally, for any numbers \\(x\\) and \\(a\\), \\(\\underbrace{x\\times \\dotsb \\times x}_{\\text{with }a\\, x\\text{&#39;s}} = x^a\\) spoken as “x to the power \\(a\\)” The number \\(x\\) is known as the base and the number \\(n\\) is known as the power, index or exponent. Next, we look at rules for combining and simplifying exponents. We start by assuming the base \\(x\\) is a positive real number and the exponent \\(a\\) is a postive integer. Now for any positive integers \\(a\\) and \\(b\\), it should be clear that the following rule holds: Theorem 1.1 (Rule 1) Multiplying powers with the same base: \\[x^ax^b=x^{a+b}\\] since we are multiplying \\(a\\) \\(x\\)’s by a further \\(b\\) \\(x\\)’s to give a total of \\(a+b\\) \\(x\\)’s multiplied together \\[\\underbrace{x\\times \\dotsb \\times x}_{\\text{with }a\\, x\\text{&#39;s}}\\times\\underbrace{x\\times \\dotsb \\times x}_{\\text{with }b\\, x\\text{&#39;s}}=\\underbrace{x^{a+b}}_{\\text{with }a+b\\, x\\text{&#39;s}}\\] Example 1.2 (Multiplying powers) Example: \\(2^3 2^4 = 2^7\\) It is also worth seeing a non-example: \\(3^3 4^2=?\\) There is in general no simple way to combine exponents with different bases (3 and 4 here): \\[3^3 4^2=(3\\times 3 \\times 3) \\times (4 \\times 4) = 27 \\times 16=432\\] and this number cannot be written as a power of any whole number. Extending this idea, we also have: Theorem 1.2 (Rule 2) Power of a Power \\[(x^a)^b=x^{ab}\\] This follows from Rule 1 since $\\((x^a)^b=\\underbrace{x^a\\times \\dotsb \\times x^a}_{b\\, \\text{times}}=x^{a+\\dotsb+a}=x^{ab}\\) Example 1.3 (Power of a power) \\((5^3)^4=5^{12}\\) Exercise 1.1 Show that \\((x^a)^b=(x^b)^a\\). The following is a straightforward rule applying when we have powers of products of two different numbers \\(x\\) and \\(y\\). Theorem 1.3 (Rule 3) Power of a product: \\[(xy)^a=x^ay^a\\] Example 1.4 (Power of a product) \\((2\\times 3)^4=(2\\times 3)\\times(2\\times 3)\\times(2\\times 3)\\times(2\\times 3) = 2^4\\times 3^4\\) And we have a similar rule for powers of quotients. Theorem 1.4 (Rule 4) Power of a quotient: \\[\\left(\\frac{x}{y}\\right)^a=\\frac{x^a}{y^a}\\] This follows from the previous rule: \\(\\left(\\frac{x}{y}\\right)^a=\\left(x\\frac{1}{y}\\right)^a=x^a\\left(\\frac{1}{y}\\right)^a=x^a\\frac{1}{y^a}=\\frac{x^a}{y^a}.\\) So far we have allowed the exponents to be positive integers. Can we make sense of negative integers as exponents? Consider for \\(a\\) and \\(b\\) as positive integers the product \\[x^a\\frac{1}{x^b}=\\frac{x^a}{x^b}\\] Let’s start with a concrete example and for arguments sake let’s take \\(a&gt;b\\) with \\(a=5, b=2\\). Then: \\[\\frac{x^5}{x^2}=\\frac{x\\times x \\times x\\times x \\times x}{x \\times x}=x\\times x\\times x=x^3\\] where we have cancelled the 2 common factors of \\(x\\), leaving us with a product of \\(5-2=3\\) \\(x\\)’s. More generally, taking \\(\\frac{x^a}{x^b}\\) for \\(a&gt;b\\) we have \\(a\\) \\(x\\)’s on the top and \\(b\\) \\(x\\)’s on the bottom, so we can cancel the common factors to leave \\(a-b\\) \\(x\\)’s. So, \\[\\begin{equation} \\frac{x^a}{x^b}=x^{a-b} \\tag{1.1} \\end{equation}\\] and following Rule 1 we could think of this as \\(x^{a-b}=x^{a+(-b)}=x^ax^{-b}\\), and therefore using a negative exponent \\(-b\\) gives the reciprocal of \\(x^b\\). Theorem 1.3 (Rule 5) \\[x^{-a}=\\frac{1}{x^a}\\] Example 1.5 (Negative Exponents) Note in particular \\(x^{-1}=\\frac{1}{x}\\), the reciprocal of \\(x\\) Generally, \\(\\frac{x^a}{x^b}=x^a\\frac{1}{x^b}=x^ax^{-b}=x^{a-b}\\) so, for example, \\[\\frac{5^6}{5^2}=5^4\\] and \\[\\frac{7^2}{7^5}=7^{-3}\\] (which is \\(\\dfrac{1}{7^3}\\)) How do negative exponents work in a “power of a power”? \\[(x^2)^{-3}=\\frac{1}{(x^2)^{3}}=\\frac{1}{x^6}=x^{-6}\\] which is compatible with the “multiply exponents” rule \\[(x^2)^{-3}=x^{(2\\times -3)}=x^{-6}\\]. So far we have assumed \\(x\\) is positive. What happens when \\(x=0\\)? Then \\(0^a\\) is multiplying \\(0\\) by itself \\(a\\) times, so the result is obviously \\(0\\). Note this does not hold when \\(a=0\\) since we have \\(0^0\\), which is an indeterminate form. Also when \\(-a&lt;0\\), have \\(0^{-a}=\\frac{1}{0^a}=\\frac{1}{0}\\) which is also an indeterminate form. So we need \\(a&gt;0\\) for this result. Theorem 1.3 (Rule 6) \\[0^{a}=0, \\text{ for }a&gt;0\\] Next, we can consider the the exponent \\(a=0\\), that is the value of \\(x^0\\). In (1.1) with the particular case \\(b=a\\), we have \\[1=\\frac{x^a}{x^a}=x^{a-a}=x^0\\] so we get that for any non-zero2 value of \\(x\\): Theorem 1.5 (Rule 7) \\[x^0=1, \\text{ for } x\\neq 0\\] So far we have only considered exponents that are integers and values of the base that are non-negative real numbers. It turns out that the previous rules actually apply to any real number exponent and non-negative real number base. We’ll start by thinking about fractional exponents, and in particular exponents of the form \\[x^{\\frac{1}{a}}\\] where \\(a\\) is a non-zero integer. Example 1.6 Take \\((9^\\frac{1}{2})^2=9^{(\\frac{1}{2}\\times 2)}=9^1=9\\). This implies \\(9^{\\frac{1}{2}}=3\\), the square root of \\(9\\). More generally, take \\((x^\\frac{1}{a})^a=x^{\\frac{1}{a}a}=x^1=x\\). This means that raising \\(x^\\frac{1}{a}\\) to the power \\(a\\) gets us back to \\(x\\), hence the number \\(x^\\frac{1}{a}\\) is the \\(a^\\text{th}\\) root of \\(x\\). In particular the square root is \\(x^{\\frac{1}{2}}=\\sqrt{x}\\) and the cube root is \\(x^{\\frac{1}{3}}=\\sqrt[3]{x}\\); we tend to use the root notation for expressions containing square or cube roots on their own, and use the power notation when combining different roots. Theorem 1.6 (Rule 8) Reciprocal powers are roots: \\[x^\\frac{1}{a}=\\sqrt[a]{x}.\\] Example 1.7 \\(8^\\frac{1}{3}=\\sqrt[3]{8}=2\\) Now lets try to make sense of a power of the form \\(x^{\\frac{a}{b}}\\) where \\(a\\) is an integer and \\(b\\) is a positive integer. That is, we now allow for any fractional (otherwise known as rational) exponent. Since we have \\(\\frac{a}{b}=a\\frac{1}{b}\\) we can write (using Rule 2): \\[x^{\\frac{a}{b}}=x^{a\\frac{1}{b}}=(x^a)^{\\frac{1}{b}}=\\sqrt[b]{x^a},\\] or, equaivalently \\[x^{\\frac{a}{b}}=x^{\\frac{1}{b}a}=(x^{\\frac{1}{b}})^a=(\\sqrt[b]{x})^a.\\] Theorem 1.7 (Rule 9) Fractional exponents: \\[x^{\\frac{a}{b}}=\\sqrt[b]{x^a}=(\\sqrt[b]{x})^a\\] 1.2.4 More on exponents As we mentioned, an exponent can be any real number. Not all numbers can be written as fractions i.e. rational numbers, such as \\(\\sqrt{2}, \\pi, e\\): these are called irrational numbers, and the above rules still work with irrational exponents. Proving this is beyond the scope of these notes, but your calculator can happily handle calculations with any real number exponent. Another thing we have not mentioned so far is what happens when \\(x\\) is a negative number. This is easy to understand when the exponent \\(a\\) is an integer, since we are just multiplying a negative number by itself multiple times (and taking the reciprocal if \\(a\\) is negative). But how do we interpret something like \\(y=(-1)^\\frac{1}{2}\\)? That is, \\(y\\) must be a number such that when it is multiplied by itself it gives the negative number \\(-1\\), but this is impossible for a real number! Answering this conundrum requires us to invent a new set of numbers, called complex numbers – this is addressed in section 5. A summary of the rules: Theorem 1.8 (Rules of Exponents) \\(x^ax^b=x^{a+b}\\) \\((x^a)^b=x^{ab}\\) \\((xy)^a=x^ay^a\\) \\(\\left(\\frac{x}{y}\\right)^a=\\frac{x^a}{y^a}\\) \\(x^{-a}=\\frac{1}{x^a}\\) \\(0^a=0\\), for \\(a&gt;0\\) \\(x^0=1\\), for \\(x\\neq 0\\) \\(x^{\\frac{1}{a}}=\\sqrt[a]{x}\\) \\(x^{\\frac{a}{b}}=\\sqrt[b]{x^a}=(\\sqrt[b]{x})^a.\\) 1.2.5 Brackets We use brackets to set the precedence (or order) of evaluating the different parts of an expression. We evaluate the innermost brackets first. Note we usually omit the multiplication sign when multiplying a bracketed expression. Example 1.8 (Evaluating brackets) \\[5(((2+4)\\div (5-2))+1)=5((6\\div 3)+1)=5(2+1)=5\\times 3 = 15\\] Sometimes you might find it helpful to add “redundant” brackets to make the calculation clearer. For example, we could write \\[3+2\\times 4=11\\] as \\[3+(2\\times 4)=11.\\] The brackets are not really needed in the second version since we get the same result from following BEDMAS, but adding brackets can make an expression easier to read and evaluate. 1.2.5.1 Expansion Recall that we can expand expressions involving multiplication of brackets by multiplying each term, such as the following: \\[a(b+c)=ab+ac\\] \\[(a+b)(c+d)=ac+ad+bc+bd\\] \\[(a+b)^2=(a+b)(a+b)=a^2+ab+ba+b^2=a^2+b^2+2ab\\] \\[(ab)^2=(ab)(ab)=abab=a^2b^2.\\] We often want to expand expressions in order to simplify them by grouping together like-terms, for example: \\[(a+b)(b+c)+2ac=ab+ac+b^2+bc+2ac=ab+3ac+b^2+bc.\\] With more than two brackets, we do the expansion in two steps: it does not matter which expansion we perform first. For example, we could start by expanding the first two sets of brackets in the following \\[\\underbrace{(a+b)(c+d)}_{\\text{first expand these two}}(e+f)=(ac+ad+bc+bd)(e+f)=ace+ade+bce+bde + acf+adf+bcf+bdf\\] but since the order of multiplication is unimportant, we could have started by expanding any two of the three sets of brackets. In the case of the sum of two numbers (a binomial term) to a postive integer power we have a general formula for the expansion, i.e. something of the form \\[(a+b)^n.\\] which involves multiplying out the brackets \\(n\\) times. We start by looking at a slightly simpler form \\[(1+x)^n.\\] Let’s take a look at the expansion for the first few values of \\(n\\). \\(n=0:\\) \\((1+x)^0 = 1\\) \\(n=1:\\) \\((1+x)^1=1+x\\) \\(n=2:\\) \\((1+x)^2=(1+x)(1+x)=x^2+2x+1\\) \\(n=3:\\) \\((1+x)^3=(1+x)(1+x)^2=(1+x)(x^2+2x+1)=x^3+3x^2+3x+1\\) The coefficients of \\(x\\) form the \\(n^\\text{th}\\) row of Pascal’s triangle. The general formula is: \\[(1+x)^n = \\binom{n}{0}x^0+\\binom{n}{1}x^1+\\binom{n}{2}x^2+\\dotsb+\\binom{n}{n-1}x^{n-1}+\\binom{n}{n}x^n\\] where \\(\\binom{n}{k}\\) is the binomial coefficient \\[\\binom{n}{k}=\\frac{n!}{k!(n-k)!}\\] and \\(n!\\) is the factorial of \\(n\\): \\[n!=n\\times(n-1)\\times(n-2)\\times\\dotsb \\times3\\times 2\\times 1\\]. Given the more general form \\((a+b)^n\\), we can first extract a factor of \\(a\\) to give \\[(a+b)^n=(a(1+\\frac{b}{a}))^n=a^n(1+\\frac{b}{a})^n\\] so we now just need to evaluate \\((1+\\frac{b}{a})^n\\) using the formula and substituting \\(x\\) with \\(\\frac{b}{a}\\). Alternatively, the full formula is: \\[(x+y)^n = \\binom{n}{0}x^ny^0+\\binom{n}{1}x^{n-1}y^1+\\binom{n}{2}x^{n-2}y^2+\\dotsb+\\binom{n}{n-1}x^1y^{n-1}\\binom{n}{n}x^0y^n.\\] 1.2.5.2 Factorisation At other times, we wish to simplify by extracting common factors from an expression, which we call factorisation. In the simplest form, this could just be factorising a single number \\[2x+2y=2(x+y)\\] Or, it could involve extracting more complicated factors, for example \\[2xy+6x^2y=2xy(1+3x)\\] \\[x^2-3x-10=(x+2)(x-5)\\] The second example here is factorising a quadratic which we can do systematically by finding the roots – we will see how to do this later in section 3.1. 1.2.6 Simplifiying Expressions In order to simplify an expression we can carry out the following proceedures: Expand brackets Collect together any like-terms, e.g. \\(2a+3b+a=3a+3b\\), or \\(a^3a^2+b^2=a^5+b^2\\) Simplify any fractions: use common denominators, e.g. \\(\\frac{a}{b}+\\frac{c}{d}=\\frac{da+bc}{bd}\\); cancel any common factors, e.g. \\(\\frac{ab}{ac}=\\frac{b}{c}\\) Factorise Note: these are “rules of thumb”, as there usually does not exist such a thing as a “simplest” form for a given algebraic expression. The meaning of “simple” is dependent on what we want to gain from it. The intention is to put the expression in a form that is easier to understand (in the given context) and which usually uses fewer symbols (but not always). 1.3 Equations An equation indicates the equality of two mathematical expressions: what is on the left of the \\(=\\) sign is the same as what is on the right of the \\(=\\) sign. When manipulating equations, we must perform the same operation to each side in order to maintain equality – think about a traditional mechanical balance scale, where if we were to change the mass on one side of the balance we would need to do the same to the other side in order to maintain balance. We will use the abreviations l.h.s. for left-hand-side and r.h.s. for right-hand-side. There are a few subtly different types of equations; the main two are formulas and conditional equations. 1.3.1 Formulas Equations are often regarded as formulas, which can be used to calculate the value of a mathematical or physical quantity in terms of other known quantities. In this case, we write a single dependent variable on the left hand side and the right hand side will contain independent variables and constants. The value of the dependent variable depends on the values of the independent variables and is obtained by evaluating the right hand side when the values of the independent variables are known. For example, the formula for the area \\(A\\) of a circle is \\[A=\\pi r^2\\] where the independent variable \\(r\\) is the radius of the cirle and \\(\\pi\\) is the mathematical constant \\(3.141...\\). By plugging in a particular value for \\(r\\) we then obtain a value for the area \\(A\\). We often want to re-arrange equations to make a different variable the dependent variable, or subject, of the formula, i.e. to place it alone on the left hand-side. Re-arranging formulae is also known as transposition. For example, if we knew the area of a cirlce and wanted to calculate the corresponding radius, we can re-arrange the equation to make \\(r\\) the subject: \\[r=\\sqrt{\\frac{A}{\\pi}}.\\] In obtaining this, we carry out the “opposite” of the operations on the right hand side to both sides of the equation. These opposites are: addition and subtraction; multiplication and division; powers and roots. Let’s see this step by step in our example. We start with \\[A=\\pi r^2.\\] Then, divide both sides by \\(\\pi\\) \\[\\frac{A}{\\pi}=\\frac{\\pi}{\\pi}r^2=r^2\\] so that \\(r^2\\) is no longer multiplied by \\(\\pi\\). Now, to get from \\(r^2\\) to \\(r\\) we need to take the square root of both sides \\[\\sqrt{\\frac{A}{\\pi}}=\\sqrt{r^2}=r\\] and finally, we put the subject on the left hand side (since we read from left to right it is simply convention to do this, but mathematically it makes no difference since it is still an equality). \\[r=\\sqrt{\\frac{A}{\\pi}}\\] 1.3.2 Conditional equations Another type of equation is a conditional equation. These may not hold true for all values of the variables and we will want to find the values for which equality is true. For example, \\[5x+4=19\\] is only true when \\(x=3\\). We can solve this equation by making \\(x\\) the subject: subract \\(4\\) from both sides \\[5x=15\\] divide both sides by \\(5\\) \\[x=3.\\] Note that an equation may have more than one solution, or perhaps no solutions. For example, \\[x^2=4\\] has two possible solutions, either \\(x=2\\) or \\(x=-2\\). On the other hand, the equation \\[x+2=x+3\\] has no solutions. To see this, subtract \\(x+2\\) from both sides and we obtain \\[0=1\\] which is false, so no value of \\(x\\) can give us equality. 1.4 Inequalities We are familiar with the symbols \\(&lt;, \\leq, &gt;\\) and \\(\\geq\\), (less than, less than or equal to, greater than and greater than or equal to) which are used to define inequalities. Example 1.9 \\[x&lt;5\\] denotes all numbers that are strictly less that \\(5\\) (so not including \\(5\\) itself). \\[-1&lt; x \\leq 1\\] denotes all numbers that are strictly greater than \\(-1\\) but less that or equal to \\(1\\) (so \\(x=1\\) is a possibility). When re-arranging inequalities we need to be a bit more careful with their manipulation than with equalities. If we perform the same operation to both sides in an equality then the equality still holds true, but this is not the case in general for inequalities – in particular we need to be careful with multiplication by negative numbers which “flips” the inequality. For example, if we take all values \\(x\\) such that \\(x&gt;10\\), then an equivalent expression after multiplying by \\(-1\\) is \\(-x&lt;-10\\) (NOT \\(-x&gt;-10\\)). Let \\(a,u,v,x,y,z\\) be real numbers, then some basic relations that hold true are: if \\(x&gt;y\\) and \\(y&gt;z\\), then \\(x&gt;z\\); if \\(x&gt;y\\), then \\(x+z&gt;y+z\\) and \\(x-z&gt;y-z\\); if \\(x&gt;y\\) and \\(u&gt;v\\), then \\(x+u&gt;y+v\\); if \\(x&gt;y\\), then \\(ax&gt;ay\\) if \\(a&gt;0\\), and \\(ax &lt; ay\\) if \\(a&lt;0\\); if \\(x&gt;y\\), then \\(\\dfrac{x}{a}&gt;\\dfrac{y}{a}\\) if \\(a&gt;0\\), and \\(\\dfrac{x}{a}&lt;\\dfrac{y}{a}\\) if \\(a&lt;0\\); if \\(x&gt;y&gt;0\\) and \\(u&gt;v&gt;0\\), then \\(xu&gt;yv\\) and \\(\\dfrac{x}{v}&gt;\\dfrac{y}{u}\\); if \\(x&gt;y&gt;0\\), then \\(\\dfrac{1}{x}&lt;\\dfrac{1}{y}\\). It should not be necessary to memorise all of these, it just requires a little thought when manipulating inequalities: the important ones to be careful with are multiplying or dividing by negative values. 1.5 Common mistakes! We finish this section with some common algebraic errors to watch out for! Invent your own examples to convince yourself that these things are true. Fractions: \\(\\frac{a}{b+c}\\neq \\frac{a}{b}+\\frac{a}{c}\\) and \\(\\frac{a+b}{c+b}\\neq\\frac{a}{c}\\) (can’t “cancel” the \\(b\\)’s.). Inequalities: \\(ab&gt;c\\) does not imply that \\(a&gt;\\frac{c}{b}\\) (what happens if \\(b\\) is negative?). Powers: \\((a+b)^2\\neq a^2+b^2\\). Roots: \\(\\sqrt{a+b}\\neq \\sqrt{a}+\\sqrt{b}\\). Real numbers require quite a bit of work to define in a rigorous mathematical way and we will not do this here; the interested reader should look up “construction of real numbers by Dedekind cuts” or “construction of real numbers by Cauchy sequences”.↩︎ We already know that \\(0^0\\) is an indeterminate form.↩︎ "],["functions-and-graphs.html", "Chapter 2 Functions and Graphs 2.1 Linear Functions 2.2 Polynomials 2.3 Rational functions 2.4 Trigonometric functions 2.5 Exponentials 2.6 Hyperbolic functions 2.7 Inverse Functions", " Chapter 2 Functions and Graphs A function \\(f\\) can be thought of as a machine that takes an input value \\(x\\) and returns an output value \\(y\\). The output value \\(y\\) corresponding to the input \\(x\\) is also denoted by \\(f(x)\\) (read “\\(f\\) of \\(x\\)”). We most commonly encounter functions whose input is a real number and output is a real number, but there are many other types of functions in mathematics. Figure 2.1: A function can be thought of as a machine: we have an input value \\(x\\), the machine is the function \\(f\\), and the output is the value \\(f(x)\\) We are familiar with plotting such functions on a graph, where we draw the coordinates \\((x,f(x))\\), or \\((x,y)\\), against perpendicular axes – this is known as the Cartesian coordinate system. Figure 2.2: A function can be plotted in Cartesian Coordinates: the corresponding inputs \\(x\\) and outputs \\(y=f(x)\\) are plotted as a point; these often form a continuous curve in the plane. In this section we shall take a look at some useful functions, their graphs, and some of their other interesting properties. 2.1 Linear Functions We are familiar with the equation of a straight line: \\[y=mx+d\\] with gradient \\(m\\) and intercepting the \\(y\\)-axis at the value \\(d\\). Figure 2.3: Straight line graph of \\(y=\\frac{1}{2}x+1\\). If we think about such a line as a function with input \\(x\\) and output \\(y\\), then we call this a linear function. If the gradient is positive, \\(m&gt;0\\), then the line slopes upwards with increasing \\(x\\) values; if the gradient is negative, \\(m&lt;0\\), then the line slopes downwards with increasing \\(x\\) values; if the gradient is zero, \\(m=0\\), then the line is a horizontal line. Note that we cannot describe a vertical line with this function: a vertical line has an equation of the form \\(x=A\\), where \\(A\\) is the value at which it intercepts the \\(x\\)-axis. Specifying a single point \\((x_1,y_1)\\) and a gradient \\(m\\) is enough to define a (non-vertical) line and we can write the equation of this line as \\[ y-y_1=m(x-x_1). \\] Also, a line can be defined by specifying any two points \\((x_1,y_1)\\) and \\((x_2,y_2)\\) that lie on the line. We can calculate the gradient of this line from \\[ m=\\frac{y_2-y_1}{x_2-x_1} \\] but there is a problem if \\(x_2=x_1\\) and we have division by \\(0\\) – effectively we have an “infinite” gradient. Since \\(x_1=x_2\\) this, of course, corresponds to a vertical line, which we can write as the equation \\(x=x_1\\). An equation of the form \\(ax+by+c=0\\) is a general way to express any line in the Cartesian plane and includes both vertical and non-vertical lines. In section ?? we will be using this more general form for solving simultaneous linear equations. Figure 2.4: A general line \\(ax+by+c=0\\) (red line) a line specified by a gradient and intercept \\(y=mx+d\\) (blue line), a vertical line \\(x=A\\) (green line) and a horizontal line \\(y=B\\) (orange line). Adjust the sliders to change the constants and check which values of \\(m,d,A,\\) and \\(B\\) correspond to \\(a,b\\) and \\(c\\). [Open graph in browser.] 2.1.1 Parallel lines A line makes an angle \\(\\theta\\) from the positive \\(x\\)-axis, the angle of inclination. This is related to the gradient \\(m\\) by \\[ m=\\frac{\\Delta y}{\\Delta x}=\\tan(\\theta). \\] Two lines are parallel if they have the same angle of inclination \\(\\theta\\), or same gradient \\(m\\). Figure 2.5: The angle of inclination of a line. Hence if two (non-vertical) lines are parallel they are of the form \\[\\begin{align*} y&amp;=mx + d_1\\\\ y&amp;=mx + d_2 \\end{align*}\\] with different \\(y\\)-intercepts \\(d_1\\) and \\(d_2\\). 2.1.2 Perpendicular lines Two lines are perpendicular, or normal, if they meet at a right angle. We have \\[\\begin{align*} m_1&amp;=\\tan(\\theta)\\quad\\text{and,}\\\\ m_2&amp;=\\tan\\Big(\\theta + \\frac{\\pi}{2}\\Big)=\\frac{\\sin(\\theta + \\frac{\\pi}{2})}{\\cos(\\theta + \\frac{\\pi}{2})}\\\\ &amp;=\\frac{\\sin(\\theta)\\cos(\\frac{\\pi}{2}) + \\cos(\\theta)\\sin(\\frac{\\pi}{2})}{\\cos(\\theta)\\cos(\\frac{\\pi}{2}) - \\sin(\\theta)\\sin(\\frac{\\pi}{2})}\\\\ &amp;=\\frac{\\cos(\\theta)}{-\\sin(\\theta)}\\\\ &amp;=-\\cot(\\theta) \\end{align*}\\] Figure 2.6: Perpendicular lines. Thus, two (non-vertical) lines are perpendicular if \\[\\begin{equation*} m_1m_2=-1 \\end{equation*}\\] and hence they have the forms \\[\\begin{align*} y&amp;=mx + d_1,\\\\ y&amp;=-\\frac{1}{m}x + d_2. \\end{align*}\\] with \\(y\\)-intercepts \\(d_1\\) and \\(d_2\\). Alternatively, if we describe a line by \\(ax+by+c=0\\) then \\[\\begin{align*} ax+by+p&amp;=0\\quad\\text{is a parallel line}\\\\ bx+ay+q&amp;=0\\quad\\text{is a perpendicular line} \\end{align*}\\] where \\(p\\) and \\(q\\) are constants. 2.2 Polynomials A polynomial is a function made up of non-negative integer powers of the independent variable \\(x\\) multiplied by constant coefficients, i.e. it has the form \\[f(x)=a_0 + a_1 x + a_2 x^2 + \\dotsb + a_n x^n\\] where the \\(n+1\\) fixed numbers \\(a_0,\\dots,a_n\\) are the coefficients (which could be positive, negative or zero). For example, the following are all polynomials: \\[\\begin{align*} f(x)&amp;=x^2\\\\ g(x)&amp;=2+\\frac{1}{3}x^4 - x^5\\\\ h(x)&amp;=-3.6 + x^2 -2x^{10} \\end{align*}\\] The number \\(n\\) corresponding to the highest power in the polynomial is called the order or degree of the polynomial. For the functions \\(f, g\\) and \\(h\\) above the degrees are \\(2, 5\\) and \\(10\\), respectively. We have a few special names for polynomials of low degree: Degree 1: a linear polynomial, since its graph is a line \\(f(x)=a_0+a_1 x\\) Degree 2: a quadratic polynomial Degree 3: a cubic polynomial Degree 4: a quartic polynomial Degree 5: a quintic polynomial The higher the degree of the polynomial, the more “wavey” its graph can be; in fact, a degree \\(n\\) polynomial can have at most \\(n-1\\) turning points. A polynomial which has only one term is called a monomial, for example \\[f(x)=2\\\\ g(x)=3x^2\\\\ h(x)=-4x^5 \\] are all monomials. Figure 2.7: A plot of a polynomial of at most degree 5, \\(f(x)=a_0 + a_1 x + a_2 x^2 + a_3 x^3 + a_4 x^4 + a_5 x^5\\). Adjust the sliders to change the coefficients \\(a_0\\) to \\(a_5\\) to get a feel for the possible shapes of a degree 5 polynomial; set the higher degree coefficients to \\(0\\) to look at lower degree polynomials; also take a look at the monomials up to degree 5. [Open graph in browser.] 2.3 Rational functions A rational function is one that can be expressed as the quotient of two polynomials, for example \\[f(x)=\\frac{1+x}{2-x+3x^2}\\] is the quotient of a degree 1 polynomial and a degree 2 polynomial. They often have values of \\(x\\) where they are undefined due to the denominator evaluating to zero. Furthermore, they often have asymptotes, which means the graph approaches a straight line. For example, the function \\(f(x)=\\frac{x^{2}}{x^{2}-4}\\) has asmptotes at the vertical lines \\(x=2\\) and \\(x=-2\\) and at the horizontal line \\(y=1\\). Figure 2.8: A plot of the rational function \\(f(x)=\\frac{x^{2}}{x^{2}-4}\\) (solid red line) and its asymptotes (dashed blue lines). [Open graph in browser.] 2.4 Trigonometric functions The three basic trigonometric functions are sine (\\(\\sin\\)), cosine (\\(\\cos\\)) and tangent (\\(\\tan\\)), which we are familiar with from trigonometry for calculations involving angles. We shall explore trigonometry in more detail in section 4. For now, we will just look at some of their properties as functions. Sine and cosine look similar, like “waves”, with one graph shifted along the \\(x\\) axis from the other. They oscillate between their maximum value of \\(1\\) and minimum value of \\(-1\\). Figure 2.9: The functions \\(\\sin(x)\\) (red curve) and \\(\\cos(x)\\) (blue dashed line). [Open graph in browser.] In figure 2.9 we have plotted the functions with the \\(x\\) axis in units of radians. This is the natural mathematical choice of units, but in applications we tend to use degrees. We’ll understand more about radians and see how these units are related to degrees in section 4. Note the graphs repeat every \\(2\\pi\\) radians (or equivalently \\(360^\\circ\\)) – they are periodic functions with period \\(2\\pi\\). The tangent function is defined via sine and cosine as: \\[\\begin{equation} \\tan(x)=\\frac{\\sin(x)}{\\cos(x)} \\tag{2.1} \\end{equation}\\] It’s graph looks rather different to sine and cosine. Figure 2.10: The function \\(\\tan(x)\\) (green curve). [Open graph in browser.] Like sine and cosine it is periodic, but with half the period: it repeats every \\(\\pi\\) radians (or \\(180^\\circ\\)). It is undefined at \\(x=\\frac{\\pi}{2}\\) (and repeatedly at intervals of \\(\\pi\\)) since at this value \\(\\cos(\\frac{\\pi}{2})=0\\) so we have division by zero. Close to these points, the value of \\(\\cos(x)\\) in the denominator of (2.1) is very small, whilst the value of \\(\\sin(x)\\) is close to \\(1\\) or \\(-1\\), which results in very large positive or negative values of \\(\\tan(x)\\) and we have vertical asymptotes at these points. \\[\\begin{gather*} \\sin^2(x)+\\cos^2(x)=1\\\\ \\sin(2x)=2\\sin(x)\\cos(x)\\\\ \\cos(2x)=\\cos^2(x)-\\sin^2(x)\\\\ 1+\\tan^2(x)=\\sec^2(x) \\end{gather*}\\] 2.5 Exponentials An exponential function is one of the form \\[ f(x)=a^x \\] where the positive number \\(a\\) is called the . Figure 2.11: The function \\(f(x)=a^x\\) for varying positive values of \\(a\\). [Open graph in browser.] The term “exponential growth” corresponds to such functions; this is where the instantaneous rate of change of a quantity is proportional to its current magnitude and this is the characteristic property of exponential functions. More mathematically, the instantaneous rate of change is given by the derivative3, so we have \\[\\begin{equation} \\frac{d(a^x)}{dx}=ka^x \\tag{2.2} \\end{equation}\\] where \\(k\\) is the constant of proportionality4 (which we shall find in section ??). Exponential growth is a common occurance in physical systems, at least in the early stages of a process. For example, it can describe the early stages of population growth well, when there are no limits on resources and a constant birth rate; in reality, limits (on food, space, impact of disease etc.) mean that uncurbed exponential growth cannot take place forever. Any exponential function with any base \\(a&gt;1\\) will grow faster than any polynomial; although a polynomial can be larger for some small range of \\(x\\) values, eventually the exponential graph will “overtake” the polynomial. Figure 2.12: The functions \\(f(x)=a^x\\) for varying \\(a&gt;1\\) (red curve) and the monomial \\(g(x)=x^n\\) for varying power \\(n\\) (blue dashed curve); for any value of \\(a\\) and any value of \\(n\\), if you scroll up far enough you will see that the red curve overtakes the dashed blue curve. [Open graph in browser.] There is a special value of the base \\(a\\) for which the constant of proportionality is \\(k=1\\). This is known as Euler’s number and is denoted as \\(e\\). It is an irrational number (has an infinite, never repeating decimal expansion): \\[e=2.71828182846...\\] The function \\(e^x\\) is referred to as the natural exponential function or just the exponential function. It is also commonly denoted by \\(\\exp(x)\\). Since by definition \\(k=1\\) we have: \\[\\frac{de^x}{dx}=1e^x=e^x.\\] 2.6 Hyperbolic functions The hyperbolic functions are defined in terms of the exponential function. They are named after the trigonometric functions due to possessing some similar properties, although their graphs are quite different. Hyperbolic sine, usually spoken as “shine” is defined as \\[\\sinh(x)=\\frac{e^x-e^{-x}}{2}\\] Hyperbolic cosine or “cosh” is defined as \\[\\cosh(x)=\\frac{e^x+e^{-x}}{2}\\] Hyperbolic tangent or “tanch” is defined as \\[{\\tanh(x)=\\dfrac{\\sinh(x)}{\\cosh(x)}=\\dfrac{e^x-e^{-x}}{e^x+e^{-x}}}\\] Figure 2.13: The functions \\(\\sinh(x)\\) (red curve), \\(\\cosh(x)\\) (blue curve) and \\(\\tanh(x)\\) (green curve). [Open graph in browser.] The usual trigonometric identities also hold for the corresponding hyperbolic functions, except that where ever there is a \\(\\sin^2\\) we replace it with a \\(-\\sinh^2\\). For example: \\[\\begin{align*} &amp;\\text{Trigonometric} &amp;\\text{Hyperbolic}\\\\ &amp;\\sin^2(x)+\\cos^2(x)=1 &amp;\\cosh^2(x)-\\sinh^2(x)=1 \\\\ &amp;\\sin(2x)=2\\sin(x)\\cos(x) &amp;\\sinh(2x)=2\\sinh(x)\\cosh(x) \\\\ &amp;\\cos(2x)=\\cos^2(x)-\\sin^2(x) &amp;\\cosh(2x)=\\cosh^2(x)+\\sinh^2(x) \\\\ &amp;1+\\tan^2(x)=\\sec^2(x) &amp;1-\\tanh^2(x)=\\text{sech}^2(x) \\end{align*}\\] As an example of where these functions arise in the real-world, the shape formed by a flexible cable or chain hanging from its ends under its own weight has the general form \\[\\begin{equation*} y=a\\cosh\\left(\\frac{x}{a}\\right) \\end{equation*}\\] and is known as a catenary curve. Figure 2.14: A chain hanging from points forms a catenary. From Wikipedia - Kamel15 2.7 Inverse Functions Thinking of a function again as a machine, we sometimes want to run the machine in reverse: given a certain output, we want to know what the original input was. We call this “reversing function” the inverse. We generally denote the inverse of a function \\(f\\) by \\(f^{-1}\\). This operation is itself a function. For example, if \\[f(x)=2x+1\\] then the inverse is \\[f^{-1}(x)=\\frac{1}{2}x-\\frac{1}{2}.\\] For example, \\(f(3)=2\\times3+1=7\\) and \\(f^{-1}(7)=0.5\\times 7- 0.5 = 3\\). So inverse functions “undo” the action of the original function to return to the original value \\(x\\). If we first apply \\(f\\) and then \\(f^{-1}\\) (known as the composition of \\(f\\) and \\(f^{-1}\\)), or the other way around, then the result is to get back to \\(x\\): \\[f^{-1}(f(x)) = x\\] and \\[f(f^{-1}(x)) = x.\\] WARNING: with exponents the superscript \\({-1}\\) in \\(a^{-1}\\) means \\(a^{-1}=\\frac{1}{a}\\), and in a sense \\(a^{-1}\\) is an inverse: the inverse operation to multiplying a number \\(x\\) by a non-zero number \\(a\\) is to divide by the number \\(a\\): \\[\\text{if we multiply a number $x$ by $a$}\\quad x\\to ax\\quad \\text{ the reverse process is } \\quad ax \\to a^{-1}ax=\\frac{1}{a}ax=x\\] HOWEVER, the inverse function \\(f^{-1}\\) is not generally given by \\(f^{-1}(x)=\\dfrac{1}{f(x)}\\), it is more complicated than that. The notation \\(f^{-1}\\) is used becuase it is similar in spirit to the relationship between multipliction and division. It is not always possible to do this reverse process, as sometimes there is more than one possible input \\(x\\) which gives the output \\(y\\). For example, if the original function is \\[f(x)=x^2\\] and the output is \\(f(x)=4\\), then the input could have been \\(x=2\\) or it could have been \\(x=-2\\). An extreme example is the function \\(f(x)=0\\) for all \\(x\\). This sends all inputs \\(x\\) to the same output value \\(0\\), so any value of \\(x\\) could have been the input. We call such functions “many-to-one” (many inputs give the same output). In order to have an inverse, our function must be “one-to-one” (each output comes from a unique input). Going back to \\(f(x)=x^2\\), we are not completely stuck in finding an inverse. If we only consider non-negative inputs to the function, then the output does have a unique input. The inverse is then the square root function \\(f^{-1}(x)=\\sqrt{x}\\). We sometimes call such an inverse a partial inverse. We are just considering the inverse of half of the \\(y=x^2\\) graph where \\(x\\) is non-negative. We will revisit this particular example in more generality in the Root functions section below. Graphically, the inverse function is the reflection in the line \\(y=x\\) (can you understand why this is true?). Figure 2.15: The function y=2x+1 and its inverse y=0.5x-0.5. 2.7.1 Finding the inverse of a function When we have an algebraic forumula for a function there is a general proceedure for finding the inverse: If necessary, restrict to inputs where the function is one-to-one (to obtain a partial inverse); Re-arrange \\(y=f(x)\\) to give \\(x\\) in terms of \\(y\\); Interchange the variable labels \\(x\\) and \\(y\\) to obtain \\(y=f^{-1}(x)\\). Let’s take a look at some examples. ::: {.example algebraic_inverses} Find the inverse of \\(f(x)=2x+1\\). This function is one-to-one. Re-arraging for \\(x\\) \\[\\begin{align*} y&amp;=2x+1\\\\ y-1&amp;=2x\\\\ \\frac{1}{2}(y-1)&amp;=x\\\\ x&amp;=\\frac{1}{2}y-\\frac{1}{2} \\end{align*}\\] swapping the variable names \\(x\\) and \\(y\\) \\[y=\\frac{1}{2}x-\\frac{1}{2}\\] so the inverse is \\[f^{-1}(x)=\\frac{1}{2}x-\\frac{1}{2}.\\] Find an inverse of \\(g(x)=x^2-1\\), by restricting to suitable inputs. By restricting to non-negative values of \\(x\\), the function is one-to-one. Re-arranging for \\(x\\): \\[\\begin{align*} y&amp;=x^2-1\\\\ y+1&amp;=x^2\\\\ \\sqrt{y+1}&amp;=x\\\\ x&amp;=\\sqrt{y+1}. \\end{align*}\\] swapping the variable names \\(x\\) and \\(y\\) \\[y=\\sqrt{x+1}\\] Therefore \\(g^{-1}(x)=\\sqrt{x+1}\\). (#fig:x2-1_inv)The function \\(g(x)=x^2-1\\) (red curve) and its partial inverse \\(g^{-1}(x)=\\sqrt{x+1}\\) (blue curve) together with the line of symmetry \\(y=x\\). [Open graph in browser.] Find the inverse of \\(h(x)=\\dfrac{x-2}{x-3}\\). Note this function cannot have input \\(x=3\\), since that would result in division by zero. Other than this caveat, we can see from its graph that it is one-to-one. Solving for \\(x\\) gives: \\[\\begin{align*} y&amp;=\\dfrac{x-2}{x-3}\\\\ (x-3)y&amp;=x-2\\\\ xy-3y&amp;=x-2\\\\ xy-x&amp;=3y-2\\\\ x(y-1)&amp;=3y-2\\\\ x&amp;=\\dfrac{3y-2}{y-1} \\end{align*}\\] and swapping the variable names \\(x\\) and \\(y\\) \\[y=\\dfrac{3x-2}{x-1}.\\] Therefore the inverse is \\(h^{-1}(x)=\\dfrac{3x-2}{x-1}\\). (#fig:rational_inv)The function \\(h(x)=\\dfrac{x-2}{x-3}\\) (red curve) and its partial inverse \\(h^{-1}(x)=\\dfrac{3x-2}{x-1}\\) (blue curve) together with the line of symmetry \\(y=x\\). [Open graph in browser.] ::: 2.7.2 Root functions Taking the \\(n^\\text{th}\\) root of a number \\(x\\), \\(\\sqrt[n]{x}\\), returns the answer to the question “what number multiplied by itself \\(n\\) times equals \\(x\\)?”. We saw in section 1.2.3 that this is the same as taking the power \\(x^\\frac{1}{n}\\). Taking the \\(n^\\text{th}\\) root can also be thought of as reversing the operation of taking the \\(n^\\text{th}\\) power (and vice versa). In this sense, the functions \\(f(x)=x^n\\) and \\(g(x)=\\sqrt[n]{x}\\) are inverses of one another. However, when \\(n\\) is even \\(x^n\\) returns the same non-negative number for a non-negative input \\(x\\) and the corresponding negative input \\(-x\\). For example, \\(f(x)=x^2\\) gives \\(f(2)=2\\times 2=4\\) and \\(f(-2)=-2\\times -2 =4\\). More generally, if \\(n\\) is even we are multiplying \\(x\\) by itself an even number of times, and if \\(x\\) is negative then the minus signs all cancel. This means that we cannot find a proper inverse function for \\(x^n\\) with \\(n\\) even. We instead have a so-called partial inverse \\(f^{-1}(x)=x^{\\frac{1}{n}}\\) which only takes non-negative inputs and returns non-negative outputs. Graphically, we are just considering the inverse of half of the \\(x^n\\) graph where \\(x\\) is non-negative. Figure 2.16: The functions \\(f(x)=x^2\\) (red curve) \\(g(x)=\\sqrt{x}\\) (blue curve) are reflections of each other in the line \\(y=x\\) (dashed black line) for non-negative values of \\(x\\). [Open graph in browser.] If \\(n\\) is an odd number then it also makes sense for negative values of \\(x\\) (why?) and we have a full inverse function. Figure 2.17: The functions \\(f(x)=x^3\\) (red curve) \\(g(x)=x^{ rac{1}{3}}\\) (blue curve) are reflections of each other in the line \\(y=x\\) (dashed black line) for all values of \\(x\\). [Open graph in browser.] It is important to keep these facts in mind when re-arranging equations. For example, consider the equation of the area \\(A\\) of a circle of radius \\(r\\): \\[A=\\pi r^2.\\] To find the radius as a function of area, we first re-arrange to give \\[r^2=\\frac{A}{\\pi}\\] and now if we take the square root of both sides, mathematically there are TWO possible solutions, one positive and one negative \\[r=\\pm \\sqrt{\\frac{A}{\\pi}}.\\] However, in this particular context only the positive solution makes sense since a radius must be a positive number, so we take \\[r=\\sqrt{\\frac{A}{\\pi}}.\\] 2.7.3 Inverse Trigonometric Functions Since the trigonometric functions are not one-to-one, we must restrict them if we want to define a partial inverse. Since the input to a trigonometry function is an angle, the output of an inverse trigonometric function is an angle. The inverse sine or “arcsine” function is defined for inputs \\(-1\\le x \\le 1\\) and gives outputs in the range \\(-\\frac{\\pi}{2}\\le y \\le \\frac{\\pi}{2}\\) radians or \\(-90^\\circ \\le y \\le 90^\\circ\\). It is written as \\(\\sin^{-1}(x)\\) or \\(\\arcsin(x)\\). Figure 2.18: The function \\(\\arcsin(x)\\) (blue curve). [Open graph in browser.] The inverse cosine or “arccos” function is defined for inputs \\(-1\\le x \\le 1\\) and gives outputs in the range \\(0\\le y\\le \\pi\\) radians or $0y ^$. It is written as \\(\\cos^{-1}(x)\\) or \\(\\arccos(x)\\). Figure 2.19: The function \\(\\arccos(x)\\) (blue curve). [Open graph in browser.] The inverse tangent or “arctan” function is defined for any real number input \\(x\\), and gives outputs in the range \\(-\\frac{\\pi}{2} &lt; x &lt; \\frac{\\pi}{2}\\) radians or \\(-90^\\circ &lt; y &lt; 90^\\circ\\) degrees. It is written as \\(\\tan^{-1}(x)\\) or \\(\\arctan(x)\\). Figure 2.20: The function \\(\\arctan(x)\\) (blue curve). [Open graph in browser.] 2.7.4 Logarithms The inverse of an exponential function \\(f(x)=a^x\\) is called the logarithm to the base \\(a\\), denoted by \\(\\log_a(x)\\). Since it is the inverse, the exponential and logarithm “undo” the action of each other, so that \\[\\log_a(a^x)=x\\] and \\[a^{\\log_a(x)}=x\\]. For the base \\(a=e\\), we call the logarithm \\(\\log_e(x)\\) the natural logarithm and use the notation \\[\\ln(x)=\\log_e(x)\\] \\(\\ln(x)\\) is usually spoken as lun x or L.N. of x. Figure 2.21: The functions \\(f(x)=a^x\\) for varying \\(a&gt;1\\) (red curve) and the inverse \\(g(x)=\\log_a(x)\\) (blue curve) together with the line \\(y=x\\) to show the symmetry of the function and its inverse. [Open graph in browser.] In engineering applications it is also common to use base \\(2\\) and base \\(10\\). For base \\(10\\), the following notation is sometimes used \\[\\log(x)=\\log_{10}(x)\\] but we should always check what the author intends as sometimes \\(\\log(x)\\) is used to mean \\(\\ln(x)\\). We have the following rules for manipulating logarithms (these follow from the laws of exponents in Theorem ??; try to derive them yourself): Theorem 2.1 (Rules of Logarithms) \\(\\log_a(xy)=\\log_a(x)+\\log_a(y)\\) \\(\\log_a(x^p)=p\\log_a(x)\\) \\(\\log_a(\\frac{x}{y})=\\log_a(x)-\\log_a(y)\\) \\(\\log_a(1)=0\\) \\(\\log_a(a)=1\\) We can also change between bases in logarithms with the following rule Theorem 2.2 (Change of Base Rule) Let \\(y=a^x\\), then \\(x=\\log_a(y)\\). Also, \\(\\log_b(y)=x\\log_b(a)\\), and so \\(x=\\dfrac{\\log_b(y)}{\\log_b(a)}\\). Therefore, \\[\\begin{equation*} \\log_a(y)=\\dfrac{\\log_b (y)}{\\log_b (a)}. \\end{equation*}\\] This allows us to calculate \\(\\log_a\\) of a number in terms of \\(\\log_b\\). An exponential function with base \\(a\\) can be re-written in any other base \\(b\\) with a constant factor in the argument as follows: \\[\\begin{align*} a^x&amp;=b^{\\log_b (a^x)} \\quad \\text{(note that $b^{\\log_b y}=y$)} \\\\ &amp;=b^{x\\log_b (a)}\\\\ &amp;=b^{kx},\\quad \\text{where }k=\\log_b(a). \\end{align*}\\] The “natural” choice of base for mathematical use is \\(b=e\\) and hence we usually only consider exponential functions in the form \\(e^{kx}\\) where \\(k=\\ln(a)\\). 2.7.5 Logarthmic plots When we have quatities that change over a large range of magnitudes, it can be more convenient to plot them on a “logarthmic scale” so that they do not take up so much space on the page. For example, the Ricther Magnitude Scale for measuring earthquakes is a logarthmic scale, which takes the logarithm to the base 10 of the amplitude of waves recorded by seismographs. The following is a “semi-log” plot, where the \\(y\\)-axis is the logarithmic scale and the \\(x\\)-axis is a (normal) linear scale. This means that every unit moved up along the \\(y\\)-axis actually represents a power of 10 increase in the amplitude of the seismograph waves. Figure 2.22: Magnitude of the August 2016 Central Italy earthquake (red dot) and aftershocks (which continued to occur after the period shown here). From Wikipedia - Phoenix7777. The logarithmic nature of the scale is sometimes made clearer by labelling the axis with an exponentially increasing scale and drawing in the minor gridlines. In figure 2.23 the major grid lines on the \\(y\\)-axis increase by a power of \\(10\\). The minor grid lines between \\(1\\) and \\(10\\) represent increments of \\(1\\) unit, then the minor grid lines between \\(10\\) and \\(10^2=100\\) represent increments of \\(10\\) units, and so on. Figure 2.23: Semi log graph paper (base 10). From wikimedia. See section ??.↩︎ The phrase “exponential growth” is sometimes used in a casual way to talk about anything that increases “quickly”, but mathematicians, scientists and engineers are more precise and would only use the term in its strict mathematical sense, as relating to an exponential function!↩︎ "],["solving-equations-and-inequalities.html", "Chapter 3 Solving Equations and Inequalities 3.1 Quadratic equations 3.2 Higher order polynomials 3.3 Simultaneous equations 3.4 Exponentials and Logarithms 3.5 Inequalities", " Chapter 3 Solving Equations and Inequalities In this section we shall look at some solution methods to some forms of commonly encountered equations and inequalities. 3.1 Quadratic equations A particularly common form of equations that arise in science and engineering are quadratic equations. These are equations of the form \\[ax^2+bx+c=0\\] where \\(a\\), \\(b\\) and \\(c\\) are constants and we wish to find the values of \\(x\\) satisfying this equation. Graphically, these are the \\(x\\)-coordinates where the polynomial function \\(f(x)=ax^2+bx+c\\) crossses the \\(x\\)-axis: these values are known as the roots of the polynomial. A quadratic may cross the \\(x\\)-axis either twice, just once, or not at all. Figure 3.1: The displayed quadtratic function has 2 roots. Try changing the sliders to find quadratics with just 1 root and with no roots. [Open graph in browser.] ::: We’ll explore three different methods for finding the roots of a quadratic. 3.1.1 Factorisation by inspection First consider a quadratic where \\(a=1\\), that is \\[x^2+bx+c=0.\\] If we can write a quadratic equation as a product of two simple linear factors in the form5: \\[x^2+bx+c = (x+\\alpha)(x+\\beta)\\] then \\(x=-\\alpha\\) and \\(x=-\\beta\\) are solutions to \\(ax^2+bx+c=0\\), since for \\(x=-\\alpha\\) \\[(-\\alpha+\\alpha)(-\\alpha+\\beta)=0(-\\alpha+\\beta)=0\\] and similarly for \\(x=-\\beta\\). Furthermore, these will be the only two solutions: it is possible there are two different solutions \\(\\alpha\\neq\\beta\\), one “repeated” solution where \\(\\alpha=\\beta\\) so that the quadratic factorises as \\((x+\\alpha)(x+\\alpha)=(x+\\alpha)^2\\), or there may be no solutions6. In many cases it is easy to spot the values of \\(\\alpha\\) and \\(\\beta\\). To see this, let’s work backwards and expand the brackets: \\[(x+\\alpha)(x+\\beta)=x^2+\\beta x +\\alpha x +\\alpha\\beta = x^2 + (\\alpha + \\beta)x + \\alpha\\beta\\] so we just need to find the values of \\(\\alpha\\) and \\(\\beta\\) that sum to \\(b\\) and multiply together to give \\(c\\). Example 3.1 If we have \\[x^2+5x+6=0\\] we are looking for two numbers that sum to make \\(5\\) and multiply to make \\(6\\), so the answer is clearly \\(x=2\\) and \\(x=3\\), giving the factorisation \\[x^2+5x+6=(x+2)(x+3).\\] If we have a more general quadratic where \\(a\\neq1\\), then we could start by taking out a factor of \\(a\\) \\[ax^2+bx+c=a\\left(x^2+\\frac{b}{a}x+\\frac{c}{a}\\right)=0\\] and then dividing both sides by \\(a\\) \\[x^2+\\frac{b}{a}x+\\frac{c}{a}=0\\] The values of \\(x\\) satisfying this new equation will be the same as those for the original, so we can now use the above method to find the solutions. However, sometimes we not only want the solution, but also want to know how to factorise the quadratic. In this case we shall have to keep the factor of \\(a\\). To factorise we just need to find the values of the coefficients in the factorisation that will give the answer we need when we expand the brackets. Example 3.2 Solve \\(4x^2 + 8x + 3 = 0\\) by factorising. We need the \\(x\\) terms to multiply together to make \\(4x^2\\), so we could have either \\[(4x + \\star)(x + \\star)\\] or \\[(2x + \\star)(2x + \\star)\\] and we need the constant terms to multiply together to make \\(3\\), so we could have either \\[(\\star + 3)(\\star + 1)\\] or \\[(\\star - 3)(\\star - 1).\\] The sum of the products of the outer terms and inner terms needs to be \\(8x\\) and the only way this is possible is with \\[(2x+3)(2x+1).\\] The solutions then come from solving for each factor being \\(0\\), giving \\[x=-\\frac{3}{2}\\quad\\text{ or }\\quad x= -\\frac{1}{2}\\] Alternatively, we can start by looking for two numbers that add to give the \\(b\\) coefficient, and multiply to give \\(ac\\). In this case, we are looking for numbers that add to give \\(8\\) and multiply to give \\(4\\times3=12\\). The only option is \\(2\\) and \\(6\\). Now we write \\(8x=2x+6x\\) to give \\[4x^2 + 2x + 6x + 3 = 0\\] and next, we factorise the first two terms and last two terms to give \\[2x(2x+1)+3(2x+1)\\] and noticing the common factor of \\((2x+1)\\), we can factorise this to give \\[(2x+3)(2x+1)\\] as before. Not all quadratics will factorise “nicely”, that is to say, where the coefficients in the linear factors will be integers. In this case, it can be very difficult to determine the coefficients by inspection and the following two methods can be applied instead. 3.1.2 Completing the square In this method, we first rewrite a quadratic equation \\[ax^2+bx+c=0\\] into the form \\[a(x-h)^2+k=0\\] that is, a squared term plus a constant, hence the name “completing the square”. We then solve by rearranging and taking square roots \\[\\begin{align*} (x-h)^2+k&amp;=0\\\\ (x-h)^2&amp;=-k\\\\ x-h&amp;=\\pm\\sqrt{-k}\\\\ x&amp;=h\\pm\\sqrt{-k} \\end{align*}\\] where \\(\\pm\\) means there is one solution coming from taking the \\(+\\) option and the other from taking the \\(-\\) option. We just need to find \\(h\\) and \\(k\\). They are given by \\[h=-\\frac{b}{2a},\\quad k=c-\\frac{b^2}{4a}.\\] It is not necessary to remember these formulae, we can instead figure out the coefficients as we go along. Example 3.3 (Completing the Square) Consider the quadratic equation \\[2x^2+12x-26=0.\\] We first take out the factor \\(a=2\\) \\[2x^2+12x-26=2(x^2+6x-13)\\] Next we can make a square term that agrees with the first two terms by taking half the \\(x\\) coefficient (i.e. \\(6\\div2=3\\)): \\[(x+3)^2=x^2+6x+9.\\] This differs from the required result in the constant term by \\[-13-9=-22\\] and so we need to “complete the square” by adding \\(-22\\), to obtain \\[2x^2+6x+13=2[(x+3)^2-22]=2(x+3)^2-44.\\] The solutions are then \\[\\begin{align*} 2(x+3)^2-44&amp;=0\\\\ 2(x+3)^2&amp;=44\\\\ (x+3)^2&amp;=22\\\\ x&amp;=-3\\pm\\sqrt{22}. \\end{align*}\\] Another use of completing the square is in determining the location of the minimum or maximum point of a quadratic function. We know that the graph of such a function is a parabola which either opens upwards in a “\\(\\cup\\)” shape or opens downwards in a “\\(\\cap\\)” shape, so it has a minimum or a maximum, respectively: the sign of the \\(x^2\\) coefficient determines this, with \\(+\\) corresponding to upward opening and \\(-\\) corresponding to downward opening. In the previous example, after completing the square we obtained \\(y=2(x+3)^2-44\\), and since the coefficient in \\(2x^2\\) is positive the quadratic function must have a minimum somewhere. Since the term \\((x+3)^2\\) must be positive, the smallest it can be is when \\(x=-3\\) and the term is \\((-3+3)^2=0\\). This means we must have a minimum at \\(x=-3\\) where \\(y=2(-3+3)^2-44=-44\\). This idea can be generalised: find the value of \\(x\\) that makes the squared term \\(0\\), and then the minimum/maximum \\(y\\) value is equal to the constant term. 3.1.3 The quadratic formula Sometimes it is difficult to find the solutions using the above methods and so thankfully we have a general forumula for finding them (or to determine if there are no real number solutions). Theorem 3.1 (Quadratic Formula) The solutions to the quadratic equation \\[ax^2+bx+c=0\\] are given by \\[x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}.\\] If the quantity \\(\\Delta = b^2-4ac\\), known as the discriminant, is such that \\(\\Delta&gt;0\\) then there will be two different solutions, if \\(\\Delta = 0\\) then there will be one solution; if \\(\\Delta\\) is negative, then there are no real number solutions (since we cannot take the square root of a negative number). Exercise 3.1 Derive the quadratic formula. Hint: use the method of “completing the square” on the general form of a quadratic equation \\(ax^2+bx+c=0\\). 3.2 Higher order polynomials We are often interested in finding the values of \\(x\\) for which \\(f(x)=0\\), known as the roots of a polynomial. We already know how to find roots of a quadratic using the quadratic formula (section 3.1). We will now look at the more general factor theorem that can help in finding roots of higher degree polynomials. If we factorise the quadratic equation \\[x^2-3x-10=0\\] we obtain \\[(x+2)(x-5)=0.\\] If the product of two numbers is zero, then either one or both of the numbers must be zero. So the possible roots are \\[(x+2)=0 \\quad \\implies\\quad x=-2\\] or \\[(x-5)=0\\quad \\implies\\quad x=5.\\] More generally, a factor \\((x-a)\\) corresponds to a root \\(x=a\\). Knowing the factors tells us the roots, and vice versa. It turns out this holds more generally for any degree polynomial. Theorem 3.2 (Factor Theorem) The value \\(x=a\\) is a root of the polynomial equation \\(f(x)=0\\) if and only if \\((x-a)\\) is a factor of the polynomial \\(f(x)\\). We already have a fool-proof way to solve quadratic equations – use the quadratic formula. There are also formulae for cubic and quartic polynomials, but these are a bit more complicated. Furthermore, it turns out it is impossible to derive a formula for quintic and higher degree polynomials! The factor theorem can be helpful in finding roots of polynomials greater than degree 2. Here is an example. Example 3.4 (Factor theorem applied to a cubic polynomial) Find the roots of the cubic polynomial \\[f(x)=x^3-7x-6.\\] After a little trial and error with small integer values of \\(x\\) we find \\[f(3)=3^3-7(3)-6=0\\] which by the factor theorem implies that \\((x-3)\\) is a factor. Now applying polynomial division by the factor \\((x-3)\\) we find \\[\\frac{x^3-7x-6}{x-3}=x^2+3x+2\\] so that \\[x^3-7x-6=(x-3)(x^2+3x+2).\\] Now that we have taken out one linear factor we are left with a quadratic factor, which we know how to deal with. Factorising the quadratic factor yields \\[x^3-7x-6=(x-3)(x+1)(x+2).\\] Hence the roots are \\[x=3, x=-1,\\,\\text{ and } x=-2.\\] 3.3 Simultaneous equations Sometimes a problem will be formulated in terms of multiple equations with multiple, shared variables. The set of equations usually represent constraints between the variables and we need to determine which values of the variables are valid solutions, i.e. which values satisfy all of the equations simultaneously – hence such sets of equations are known as simultaneous equations. Sometimes we can solve simultaneous equations by rearranging one equation to set one of the variables as the subject and then substitute this into another equation in order to eliminate one of the variables. 3.3.1 Simultaneous linear equations We begin with the simplest type of simultaneous equations: the case when all of the equations are linear, that is, geometrically they correspond to straight lines in the plane. We will just consider the case of two equations in two unknowns (the variables \\(x\\) and \\(y\\)). There are three possible types of solution, which we illustrate with the following three examples. Example 3.5 Solve the following two simultaneous equations in the variables \\(x\\) and \\(y\\): \\[\\begin{align*} 3x+2y&amp;=5,\\\\ x-4y&amp;=1. \\end{align*}\\] We could start by rearranging equation two to make \\(x\\) the subject \\[x=1+4y\\] (it does not matter which equation we choose first or which variable we choose first, this choice was just easier to re-arrange) and then substitute this back in for \\(x\\) in equation one \\[3(1+4y)+2y=5\\] and then solve for \\(y\\) \\[\\begin{align*} 3(1+4y)+2y&amp;=5\\\\ 3+12y+2y&amp;=5\\\\ 14y&amp;=2\\\\ y&amp;=\\frac{1}{7}. \\end{align*}\\] Now that we have the value for \\(y\\) we can substitute this back into either equation to find \\(x\\). Since we already rearranged equation two to make \\(x\\) the subject, we might as well use that: \\[x=1+4y=1+\\frac{4}{7}=\\frac{11}{7}.\\] Hence the solution is \\[x=\\frac{11}{7},\\quad y=\\frac{1}{7}.\\] Geometrically, the two linear equations describe lines in the plane. If we have \\(x\\) and \\(y\\) values that satisfy both equations simultaneously, we have a point \\((x,y)\\) that lies on both lines: that is, \\((x,y)\\) is a point of intersection of the two lines. Figure 3.2: The lines \\(3x+2y=5\\) (red line) and \\(x-4y=1\\) (blue line) intersect at a single point. [Open graph in browser.] Example 3.6 Solve the following two simultaneous equations in the variables \\(x\\) and \\(y\\): \\[\\begin{align*} -x+3y&amp;=2,\\\\ 2x-6y&amp;=11. \\end{align*}\\] We could start by rearranging equation one to make \\(x\\) the subject \\[x=3y-2\\] and then substitute this back in for \\(x\\) in equation two \\[2(3y-2)-6y=11\\] and then solve for \\(y\\) \\[\\begin{align*} 2(3y-2)-6y&amp;=11\\\\ 6y-6-6y&amp;=11\\\\ 0&amp;=17. \\end{align*}\\] which is impossible. This tells us there are no solutions to the simultaneous equations; that is, there are no values of \\(x\\) and \\(y\\) that satisfy both equations at the same time. Geometrically, the two equations correspond to parallel lines, and of course, two parallel lines never intersect. Figure 3.3: The lines \\(-x+3y=2\\) (red line) and \\(2x-6y=11\\) (blue line) are parallel and do not intersect. [Open graph in browser.] Example 3.7 Solve the following two simultaneous equations in the variables \\(x\\) and \\(y\\): \\[\\begin{align*} 2x-y&amp;=2\\\\ 4x-2y&amp;=4 \\end{align*}\\] we can rearrange equation one to make \\(y\\) the subject \\[y=2x-2\\] and then substitute this back in for \\(y\\) in equation two \\[4x-2(2x-2)=4\\] and then solve for \\(x\\) \\[\\begin{align*} 4x-2(2x-2)&amp;=4\\\\ 4x-4x+4&amp;=4\\\\ 0x&amp;=0\\\\ 0&amp;=0. \\end{align*}\\] This equality holds for any value of \\(x\\), so \\(x\\) can be any number. Therefore so long as \\(y\\) satisfies one of the equations, for example \\[y=2x-2\\] then the pair of values \\((x,y)\\) is a solution: in this case any point on the line \\(y=2x-2\\) is a solution, so we have infinitely many solutions. Note that equation two is just \\(2\\times\\) equation one, so they are effectively the same equation and describe the same line in the plane, hence all of their points intersect. The solutions are just the points that lie on the line described by equation one, or equivalently, equation two. Figure 3.4: The lines \\(2x-y=2\\) (red line) and \\(4x-2y=4\\) (blue line) are in fact the same line, so intersect at all points on the line: there is a solution for any value of \\(x\\) or any value of \\(y\\). [Open graph in browser.] The three examples above demonstrate the three general possibilities for two equations with two unknowns: one pair of solutions \\((x,y)\\); no solutions; infinitely many solutions along a line. This is simply the three ways that two lines could intersect in the plane: at one point; at no points (parallel, unequal lines); at all points (the equations describe the same line). We shall look at a systematic way to deal with linear simultaneous equations in arbitrary dimensions (any number of equations and any number of variables) in section 7. 3.3.2 Non-linear simultaneous equations Example 3.8 Given the following two simultaneous equations, solve for the variables \\(x\\) and \\(y\\) \\[\\begin{align*} 2x+y&amp;=7,\\\\ x^2-xy&amp;=6. \\end{align*}\\] We note that the first equation is linear, but the second is non-linear. It will be easiest to rearrange the first (linear) equation for \\(y\\), to get \\[y=7-2x\\] and then substituting this into the second (non-linear) equation \\[\\begin{align*} x^2-x(7-2x)&amp;=6\\\\ 3x^2-7x-6&amp;=0\\\\ (3x+2)(x-3)&amp;=0\\\\ \\end{align*}\\] so the factorisation tells us \\[x=-\\frac{2}{3},\\text{ or } x = 3.\\] Now substiting these two possibilities back into the first equation gives \\[\\begin{align*} 2(-\\frac{2}{3})+y&amp;=7\\\\ y&amp;=\\frac{25}{3} \\end{align*}\\] and \\[\\begin{align*} 2(3)+y&amp;=7\\\\ y&amp;=1. \\end{align*}\\] To summarise, the solutions are: \\[x = -\\frac{2}{3},\\quad y = \\frac{25}{3}\\] and \\[x=3,\\quad y=1.\\] We can think about this problem graphically as we did for simultaneous linear equations: each equation describes a line or curve in the plane, and a solution corresponds to a point of intersection. Figure 3.5: The lines \\(2x+y=7\\) (red line) and the curve \\(x^2-xy=6\\) (blue curve) intersect at two points. [Open graph in browser.] The example presented above is relatively simple. In some real-world scenarios equations might be very complicated (with many variables or many simultaneous equations), and it is known that some equations are impossible to solve by hand. In these cases we need to turn to computational techniques. We’ll look at some computational techniques in section 18. 3.4 Exponentials and Logarithms We shall now look at solving some equations involving exponentials and logarithms: recall that these functions are inverses of one another. First, we look at some of the rules for manipulating logs (which can be derived from the rules of exponents). Rules of Logs: 1. \\(\\log_a(xy)=\\log_a(x)+\\log_a(y)\\) 2. \\(\\log_a(x^p)=p\\log_a(x)\\) 3. \\(\\log_a(\\frac{x}{y})=\\log_a(x)-\\log_a(y)\\) 4. \\(\\log_a(1)=0\\) 5. \\(\\log_a(a)=1\\) 3.4.1 Standard Bases In science and engineering applications it is common to use base \\(e\\), base \\(2\\) and base \\(10\\). For base \\(10\\), the following notation is sometimes used \\[\\log(x)=\\log_{10}(x)\\] but we should always check what the author intends as sometimes \\(\\log(x)\\) is used to mean \\(\\ln(x)\\). We can also change between bases in logarithms with the following rule: \\[\\begin{equation*} \\log_a(y)=\\dfrac{\\log_b (y)}{\\log_b (a)}. \\end{equation*}\\] This allows us to calculate \\(\\log_a\\) of a number in terms of \\(\\log_b\\). 3.4.2 Change of Base for Exponentials An exponential function with base \\(a\\) can be re-written in any other base \\(b\\) with a constant factor in the argument as follows: \\[\\begin{aligned}a^x&amp;=b^{\\log_b (a^x)} \\quad \\text{(note that } b^{\\log_b y}=y\\text{)} \\\\&amp;=b^{x\\log_b (a)}\\\\&amp;=b^{kx},\\quad \\text{where }k=\\log_b(a).\\end{aligned}\\] The “natural” choice of base for mathematical use is \\(b=e\\) and hence we usually only consider exponential functions in the form \\[e^{kx} \\text{ where } k=\\ln(a).\\] 3.5 Inequalities Assume we are comparing two expressions \\(P\\) and \\(Q\\) that depend on the variable \\(x\\) and need to find, for example, the values of \\(x\\) for which \\(P&gt;Q\\). Let us take a look at a range of examples to see how to solve these types of problems. Example 3.9 We wish to find all values of \\(x\\) satisfying the following inequalities. \\(2x+6&lt;18.\\) Here we can easily re-arrange the inequality (subtract \\(6\\) from each side and divide by the positive number \\(2\\) – which preserves the direction of the inequality) to obtain \\[x&lt;6.\\] \\(x^2-7x+12&gt;0\\) Factorise the l.h.s. to give \\((x-3)(x-4)&gt;0\\), so to be positive the factors on the left need to be either both positive or both negative, i.e.: \\((x-3)&gt;0\\) and \\((x-4)&gt;0\\), so we must have both \\(x&gt;4\\) and \\(x&gt;3\\), which means that we must take \\(x&gt;4\\). \\((x-3)&lt;0\\) and \\((x-4)&lt;0\\), so we require both \\(x&lt;3\\) and \\(x&lt;4\\), which means we must take \\(x&lt;3\\). Since either situation a or b satisfies the inequality the solution is \\(x&lt;3\\) or \\(x&gt;4\\). \\(\\left|10-3x\\right|\\leq 8\\), where \\(|\\cdot|\\) denotes the absolute value. We must have both: \\[\\begin{align*} 10-3x&amp;\\leq 8\\\\ -3x&amp;\\leq-2\\\\ x&amp;\\geq \\frac{2}{3} \\end{align*}\\] i.e. the interval \\(x\\geq\\dfrac{2}{3}.\\) And, \\(-(10-3x)\\leq 8\\), leading to \\(x\\leq 6\\). Hence \\(\\dfrac{2}{3}\\leq x \\leq 6\\). \\(\\dfrac{1}{x-3}&gt;\\dfrac{1}{x-2}\\) Let’s first do this the wrong way to illustrate a point. Let’s multiply both sides by \\((x-2)\\) to obtain \\[\\begin{gather*} \\frac{x-2}{x-3}&gt;1\\\\ \\frac{x-2}{x-3}-1&gt;0\\\\ \\frac{(x-2)-(x-3)}{x-3}=\\frac{1}{x-3}&gt;0 \\end{gather*}\\] giving the solution \\(x&gt;3\\). We can check the solution graphically by plotting the l.h.s. and r.h.s. and seeing where the l.h.s. is greater than the r.h.s. Figure 3.6: A plot of the inequality \\(\\frac{1}{x-3}&gt;\\frac{1}{x-2}\\): the solid red line is the l.h.s and the dashed blue line is the r.h.s.. We are interested in finding the values of \\(x\\) where the red line is above the blue line (the red-shaded region). [Open graph in browser.] It would appear that something has gone wrong! There is a second interval \\(x&lt;2\\) where the inequality holds true. The problem is that we multiplied by the factor \\((x-2)\\) forgetting the fact that \\(x\\) is a variable, so this factor could be positive or negative depending on the value of \\(x\\) and hence can flip the inequality. We could still perform this multiplication so long as we keep track of the two possible cases when \\((x-2)\\) is positive or negative. However, a safer strategy is to first subtract the r.h.s. from the l.h.s., then factorise as much as possible: \\[\\frac{1}{x-3}-\\frac{1}{x-2}=\\frac{(x-2)-(x-3)}{(x-3)(x-2)}=\\frac{1}{(x-3)(x-2)}&gt;0.\\] Hence for the denominator to be positive we must have either \\(x&gt;3\\) and \\(x&gt;2\\), or \\(x&lt;3\\) and \\(x&lt;2\\). Together these yield the solution \\(x&lt;2\\) or \\(x&gt;3\\). The general strategy for finding \\(P&gt;Q\\) (or similar) is therefore: (1) Consider \\(P-Q\\) and factorise as much as possible; (2) Determine the sign of each factor of \\(P-Q\\) for varying \\(x\\); (3) Determine when \\(P-Q&gt;0\\) (and hence when \\(P&gt;Q\\)). In fact, any quadratic can be factorised as a product of two linear factors, but we may need complex numbers to do this; more on this in section 5.↩︎ That is, no solutions for which \\(\\alpha\\) and \\(\\beta\\) are real numbers, but there will instead be complex number solutions.↩︎ "],["trigonometry.html", "Chapter 4 Trigonometry 4.1 Pythagoras 4.2 Degrees and radians 4.3 Trigonometric ratios 4.4 Sine and cosine rules 4.5 Angles in Cartesian Coordinates 4.6 Trigonometric waveforms 4.7 Trigonometric identities", " Chapter 4 Trigonometry 4.1 Pythagoras The most fundamental result in trigonometry is the Pythagorean Theorem: Theorem 4.1 (Pythagorean Theorem) In a right-angle triangle, the hypotenuse is the side opposite the right angle. In any right-angle triangle, the square of the hypotenuse is equal to the sum of the squares of the other two sides. With reference to figure 4.1, we have \\[c^2=a^2+b^2\\] Figure 4.1: A right-angled triangle with sides \\(a, b\\) and \\(c\\), with \\(c\\) being the hypotenuse. One particular application is finding the distance between two points in a Cartesian coordinate system. 4.2 Degrees and radians We can measure an angle in two different units: degrees or radians. In degrees, we split a full circle into 360 segments and then call the angle bewteen each segment 1 degree, or \\(1^\\circ\\). Of course a full circle is \\(360^\\circ\\). An alternative measure of angle is radians. In this case, we start from the fact that the circumference of a circle is given by \\[ C=2\\pi r \\] where \\(r\\) is the radius of the circle. If we had a circle with radius \\(r=1\\), then the circumference is \\(C=2\\pi\\). Now we consider this circle to be split into \\(2\\pi\\) segments7, with each segment being 1 radian, or \\(1 \\text{ rad}\\). A full circle is then \\(2\\pi \\text{ rad} = 6.283 \\text{ rad}\\) (to 3 sig. fig.). Sometimes it is more convenient to work in degrees, and other times it is more convenient to work in radians. We can easily convert between degrees and radians as follows. If we have an angle \\(D^\\circ\\) in degrees, then the corresponding angle in radians \\(R \\text{ rad}\\) is: \\[ R \\text{ rad}=\\frac{2\\pi}{360}\\times D^\\circ \\] and in the other direction \\[ D^\\circ=\\frac{360}{2\\pi}\\times R \\text{ rad}. \\] Where possible, we would state radians as multiples of \\(\\pi\\), so in particular: Degrees Radians \\(360^\\circ\\) \\(2\\pi\\text{ rad}\\) \\(270^\\circ\\) \\(\\frac{3}{2}\\pi\\text{ rad}\\) \\(180^\\circ\\) \\(\\pi\\text{ rad}\\) \\(120^\\circ\\) \\(\\frac{2}{3}\\pi\\text{ rad}\\) \\(90^\\circ\\) \\(\\frac{\\pi}{2}\\text{ rad}\\) \\(60^\\circ\\) \\(\\frac{\\pi}{3}\\text{ rad}\\) \\(45^\\circ\\) \\(\\frac{\\pi}{4}\\text{ rad}\\) \\(30^\\circ\\) \\(\\frac{\\pi}{6}\\text{ rad}\\) Note that a scientific calculator will have a button to switch between using degrees and radians: make sure your calculator is in the correct mode! 4.3 Trigonometric ratios Calculating angles and side lengths of right-angled triangles is of fundamental importance in science and engineering applications. Figure 4.2: A right-angled triangle. Recall that we can calculate relationships between angles and side lengths of a right-angled triangle (as described in figure 4.2) using sine, cosine and tangent: \\[\\begin{align*} \\sin(\\theta)&amp;=\\frac{Opp.}{Hyp.}\\\\ \\cos(\\theta)&amp;=\\frac{Adj.}{Hyp.}\\\\ \\tan(\\theta)&amp;=\\frac{Opp.}{Adj.} \\end{align*}\\] A useful way to remember these relationships is the mnemonic “SOH CAH TOA”: SOH - Sine equals Opposite over Hypotenuse CAH - Cosine equals Adjacent over Hypotenuse TOA - Tan equals Opposite over Adjacent These are most commonly used to determine angles by using the inverse functions: \\[\\begin{align*} \\theta&amp;=\\sin^{-1}(\\frac{Opp.}{Hyp.})\\\\ \\theta&amp;=\\cos^{-1}(\\frac{Adj.}{Hyp.})\\\\ \\theta&amp;=\\tan^{-1}(\\frac{Opp.}{Adj.}) \\end{align*}\\] WARNING: the notation suggests we are taking \\(\\sin\\) to the power \\(-1\\), so that \\(\\sin^{-1}=\\frac{1}{\\sin}\\), but this is NOT how the inverse is defined. Remember that the inverse “undoes” the action of the function. Scientific calculators will have buttons to apply these functions. The inverses are also sometimes called \\[\\begin{align*} \\arcsin&amp;=\\sin^{-1},\\\\ \\arccos&amp;=\\cos^{-1},\\\\ \\arctan&amp;=\\tan^{-1}. \\end{align*}\\] Example 4.1 (Applying inverse trig. functions) Calculate the angle \\(\\theta\\) in the following triangle. Figure 4.3: A right angled triangle with hypotenuse legth 14 units and adjacent length 8 units. Since we have the lengths of the hypotenuse and adjacent, we can use \\(\\cos^{-1}\\) to find \\(\\theta\\). Using a calculator we find \\[\\theta=\\cos^{-1}\\left(\\frac{8}{14}\\right)=55.15^\\circ \\text{(to 2 d.p.)}\\] We also have special names for the reciprocal trigonometric functions: \\[\\begin{align*} \\operatorname{cosec}(\\theta)&amp;=\\frac{1}{\\sin(\\theta)},\\\\ \\sec(\\theta)&amp;=\\frac{1}{\\cos(\\theta)},\\\\ \\cot(\\theta)&amp;=\\frac{1}{\\tan(\\theta)}. \\end{align*}\\] 4.4 Sine and cosine rules The Pythagorean Theorem and Trigonometric ratios above only apply to right-angle triangles. For general triangles, the sine and cosine rules give us useful relationsips between angles and side lengths. Figure 4.4: A general triangle with angles \\(A, B,\\) and \\(C\\) and the corresponding opposite sides as \\(a, b\\) and \\(c\\). Theorem 4.2 (Sine Rule) Label a triangle with angles \\(A, B,\\) and \\(C\\) and the corresponding opposite sides as \\(a, b\\) and \\(c\\) (as in figure 4.4). Then, \\[\\frac{a}{\\sin(A)}=\\frac{b}{\\sin(B)}=\\frac{c}{\\sin(C)}.\\] This is useful when we have: one side and any two angles, or two sides and an angle (but not the included angle). Theorem 4.3 (Cosine Rule) Label a triangle with angles \\(A, B,\\) and \\(C\\) and the corresponding opposite sides as \\(a, b\\) and \\(c\\) (as in figure 4.4). Then, \\[\\begin{align*} a^2&amp;= b^2 +c^2 -2bc\\cos(A)\\quad\\text{ or,}\\\\ b^2&amp;=a^2+c^2-2ac\\cos(B)\\quad\\text{ or,}\\\\ c^2&amp;=a^2+b^2-2ab\\cos(C). \\end{align*}\\] This is useful when we have: two sides and the included angle, or three sides. 4.5 Angles in Cartesian Coordinates When calculating angles in the Cartesian plane we need to be a bit careful with the inverse trigonometric functions, because they are only directly valid in certain ranges (see section @ref(inverse_trig_funcs)). The easiest way around this is to always find a suitable right-anged triangle, and then interpret the angles and lengths correctly in the plane (as we will show below). We usually measure angles in the Cartesian plane from the positive \\(x\\)-axis in an anti-clockwise direction. Negative angles correspond to measuring in the clockwise direction, so that, for example: \\(180^\\circ\\) is equivalent to \\(-180^\\circ\\), \\(90^\\circ\\) is equivalent to \\(-270^\\circ\\), etc. Also, angles greater than \\(360^\\circ\\), or \\(2\\pi\\text{ rad}\\), correspond to “wrapping” around the circle more than once, for example: \\(360^\\circ\\) is equivalent to \\(0^\\circ\\), \\(405^\\circ\\) is equivalent to \\(45^\\circ\\), \\(-540^\\circ\\) is equivalent to \\(180^\\circ\\). Let’s consider a circle centered at the origin, which has equation \\(x^2+y^2=r^2\\), where \\(r\\) is the radius (note that by Pythagoras this equation is all points that are a distance \\(r\\) from the origin). What is the angle between the \\(x\\)-axis and a radial line joining the origin \\((0,0)\\) to a point \\((x,y)\\) on the circle? Let’s first assume \\(x\\) and \\(y\\) are positive. We can consider a triangle formed from the points \\((0,0)\\), \\((x,y)\\) and \\((x,0)\\). Then we know the hypotenuse has length \\(r\\), the opposite has length \\(y\\) and the adjacent has length \\(x\\), and since we have a right-angled triangle we can use all of the usual trigonometric ratios to calculate angles and lengths in this triangle. Now consider a point \\((x,y)\\) with \\(x\\) negative and \\(y\\) positive, that is, in the second quadrant. We can draw a right-angled triangle between the points \\((0,0)\\), \\((x,0)\\) and \\((x,y)\\). Since we want to consider lengths in this triangle, we take the positive value \\(|x|\\). Then the angle \\(\\phi\\) between the negative \\(x\\)-axis and the radial line can be found from \\(\\phi = \\arctan\\left(\\frac{y}{|x|}\\right)\\). However, the actual angle we want is \\(\\theta\\), and so we can get this from \\(\\theta = 180^\\circ - \\phi\\), or in radians \\(\\theta=\\pi-\\phi\\). We can do a similar proceedure in the remaining two quadrants. 4.6 Trigonometric waveforms The trigonometric functions often arise in applications in the context of waves. Whilst there are different forms of waves, trigonometric waves are arguably the most ubiquitous. In general, a function of the form \\[ f(x)=A\\sin(\\omega x + \\phi) \\] with parameters \\(A,\\omega\\) and \\(\\phi\\) is known as a sinusoidal function. Figure 4.5: A sinusoidal wave form plotted in radians. \\(A\\) is called the amplitude – this determines the range of values, from \\(-A\\) to \\(A\\); \\(\\omega\\) is the angular frequency – the rate of change of the sine function argument in units of radians per second or degrees per second; \\(\\phi\\) is the phase – this determines the offset of the sine function at \\(x=0\\) in units of radians or degrees. \\(T=\\frac{2\\pi}{\\omega}\\) is the length of one cycle e.g. measured from peak to peak, or trough to trough. If \\(x\\) represents time, then \\(T\\) is called the period. If \\(x\\) represents distance, then \\(T\\) is usually denoted by \\(\\lambda\\) and called the wavelength. Figure 4.6: The function \\(f(x)=A\\sin(\\omega x + \\phi)\\) (blue curve). [Open graph in browser.] A useful formula for combining \\(\\sin\\) and \\(\\cos\\) waves is: \\[a\\cos(\\theta)+b\\sin(\\theta)=R\\cos(\\theta-\\phi)\\] where: \\(R=\\sqrt{a^2+b^2}\\) \\(\\phi=\\tan^{-1}(b/a)\\) Such waves are associated with circular motion. If we imagine a particle moving around a circle at a constant angular speed and take the projection onto one of the coordinate axes, for example the \\(y\\)-axis, then the displacement from the origin plotted against time will draw out a sinusoid. This is becuase the position on the \\(y\\)-axis is \\(y=r\\sin(\\theta)\\). (#fig:circular_motion)Click the play button in block 1 (next to variable \\(t\\), the angle). Demonstration of a sinusoidal wave from circular motion: as the angle \\(t\\) increases and the point moves around the circle (red) the projection onto the \\(y\\) axis (blue) describes a sinusoid (green). [Open graph in browser.] 4.7 Trigonometric identities Recall that there are a number of useful relationships between the trigonometric functions. Here are some key ones. 4.7.1 Pythagorean identities These follow from the Pythagorean theorem. \\[\\begin{gather*} \\sin^2(\\theta)+\\cos^2(\\theta)=1\\\\ 1+\\tan^2(\\theta)=\\sec^2(\\theta)\\\\ \\cot^2(\\theta)+1=\\operatorname{cosec}^2(\\theta) \\end{gather*}\\] 4.7.2 Compound angle formulae The following formulae allow us to manipulate sines, cosines and tangents of the sum or difference of two angles. \\[\\begin{align*} \\sin(\\theta+\\phi)&amp;=\\sin(\\theta)\\cos(\\phi)+\\cos(\\theta)\\sin(\\phi)\\\\ \\sin(\\theta-\\phi)&amp;=\\sin(\\theta)\\cos(\\phi)-\\cos(\\theta)\\sin(\\phi)\\\\ \\cos(\\theta+\\phi)&amp;=\\cos(\\theta)\\cos(\\phi)-\\sin(\\theta)\\sin(\\phi)\\\\ \\cos(\\theta-\\phi)&amp;=\\cos(\\theta)\\cos(\\phi)+\\sin(\\theta)\\sin(\\phi)\\\\ \\tan(\\theta+\\phi)&amp;=\\frac{\\tan(\\theta)+\\tan(\\phi)}{1-\\tan(\\theta)\\tan(\\phi)}\\\\ \\tan(\\theta-\\phi)&amp;=\\frac{\\tan(\\theta)-\\tan(\\phi)}{1+\\tan(\\theta)\\tan(\\phi)} \\end{align*}\\] 4.7.3 Double angle formulae Setting \\(\\phi=\\theta\\) in the compound angle formulae gives the following double angle formulae: \\[\\begin{align*} \\sin(2\\theta)&amp;=2\\sin(\\theta)\\cos(\\theta)\\\\ \\cos(2\\theta)&amp;=\\cos^2(\\theta)-\\sin^2(\\theta)\\\\ \\tan(2\\theta)&amp;=\\frac{2\\tan(\\theta)}{1-\\tan^2(\\theta)} \\end{align*}\\] 4.7.4 Product to sum formulae From the compound angle formulae we can derive the following. \\[\\begin{align*} \\sin(\\theta)\\cos(\\phi)&amp;=\\frac{1}{2}[\\sin(\\theta+\\phi)+\\sin(\\theta-\\phi)]\\\\ \\cos(\\theta)\\sin(\\phi)&amp;=\\frac{1}{2}[\\sin(\\theta+\\phi)-\\sin(\\theta-\\phi)]\\\\ \\cos(\\theta)\\cos(\\phi)&amp;=\\frac{1}{2}[\\cos(\\theta+\\phi)+\\cos(\\theta-\\phi)]\\\\ \\sin(\\theta)\\sin(\\phi)&amp;=-\\frac{1}{2}[\\cos(\\theta+\\phi)-\\cos(\\theta-\\phi)]\\\\ \\end{align*}\\] 4.7.5 Sum to product formulae In the other direction (also derived from the compound angle formulae) we have the following. \\[\\begin{align*} \\sin(\\theta)+\\sin(\\phi)=2\\sin\\left(\\frac{\\theta+\\phi}{2}\\right)\\cos\\left(\\frac{\\theta-\\phi}{2}\\right)\\\\ \\sin(\\theta)-\\sin(\\phi)=2\\cos\\left(\\frac{\\theta+\\phi}{2}\\right)\\sin\\left(\\frac{\\theta-\\phi}{2}\\right)\\\\ \\cos(\\theta)+\\cos(\\phi)=2\\cos\\left(\\frac{\\theta+\\phi}{2}\\right)\\cos\\left(\\frac{\\theta-\\phi}{2}\\right)\\\\ \\cos(\\theta)-\\cos(\\phi)=-2\\sin\\left(\\frac{\\theta+\\phi}{2}\\right)\\sin\\left(\\frac{\\theta-\\phi}{2}\\right) \\end{align*}\\] Note this is not an integer number of segments! It is approximately 6.283 segments.↩︎ "],["complex.html", "Chapter 5 Complex Numbers 5.1 \\(i\\) and complex numbers 5.2 Complex arithmetic 5.3 The argument, polar and exponential form for complex numbers 5.4 Roots of complex numbers 5.5 \\(e^{i\\theta}\\) and trigonometric identities", " Chapter 5 Complex Numbers We are familiar with integers (\\(\\dots, -5, -4, -3, -2, -1, 0, 1 \\dots\\)), denoted by \\(\\mathbb{Z}\\), and rational numbers (\\(1/2, 4/5\\), etc.), denoted by \\(\\mathbb{Q}\\). We also know about irrational numbers such as \\(e\\), \\(\\pi\\) (the area of a circle with radius equal to \\(1\\)) or \\(\\sqrt{2}\\) — one solution of the quadratic equation \\[ x^2 - 2 = 0. \\] The collection of natural numbers, integers, rational and irrational numbers make up what we call the real numbers, denoted by \\(\\mathbb{R}\\). But do we have “enough” numbers? The answer is no! We do not have to look hard for why we do not have enough numbers. The simple equation \\[ x^2 + 1 = 0 \\] does not have real solutions. The answer would be \\(\\pm \\sqrt{-1}\\), if that would make sense. More generally, the quadratic equation \\[ a x^2 + b x + c = 0, \\quad \\text{with}\\quad b^2 - 4 ac &lt; 0 \\] does not have real number solutions! 5.1 \\(i\\) and complex numbers Our fix is to define the imaginary number \\(i\\) by8 \\[ i = \\sqrt{-1},\\quad \\text{ so that }\\quad i^2 = -1. \\] With this definition in mind, consider the quadratic equation \\[ x^2 + 4 x + 13 = 0. \\] Completing the square gives \\[ (x+2)^2 + 9 = 0 \\quad \\implies \\quad x+2 = \\pm \\sqrt{-9} = \\pm 3 \\sqrt{-1} = \\pm 3 i \\quad \\implies \\quad x = -2 \\pm 3 i. \\] This leads us to Complex Numbers, denoted by \\(\\mathbb{C}\\), defined as the set of all numbers \\[ z = x + i y, \\quad \\text{where $x$ and $y$ are real numbers}. \\] This form is also called the Cartesian representation of a complex number. It has a real part \\(\\mathbf{Re}(z) = x\\) and an imaginary part \\(\\mathbf{Im}(z) = y\\). We can then represent a complex number graphically by plotting the real and imaginary parts as coordinates in a Cartesian coordinate system, as in figure 5.1, known as the complex plane. The \\(x\\)-axis is called the real axis and the \\(y\\)-axis is called the imaginary axis. Figure 5.1: The complex number \\(z = x + iy\\) in Cartesian coordinates. Note that any real number \\(x\\) can also be considered as a complex number, since it is a complex number that happens to have \\(0\\) imaginary part: \\(x = x +0i\\); it is a complex number that lies on the real axis. We know from experience that a quadratic equation can have at most 2 roots. Once we have accepted complex numbers as part of our everyday lives, we see that they complete the picture of roots of polynomials. Theorem 5.1 (Fundamental Theorem of Algebra) Every non-zero, complex, single variable, degree \\(n\\) polynomial, has exactly \\(n\\) roots. To clarify the above theorem, we are talking about a polynomial of the form \\[f(x)=a_0 + a_1 x + a_2 x^2 + \\dotsb + a_n x^n\\] where the variable \\(x\\) can be a complex number (so can also be a real number) and the coefficients \\(a_i\\) are complex numbers (so can also be real numbers) and at least one of these coefficients is not \\(0\\). Since we allow the single variable \\(x\\) to be a complex number, the roots may be complex numbers. Note that some of the \\(n\\) roots might be repeated roots, for example, according to the theorem the quadratic \\[x^2-4x+4=(x-2)(x-2)\\] must have two roots and in this case they happen to be repeated roots; we say the root is \\(x=2\\) with multiplicity 2. 5.2 Complex arithmetic We can add, subtract and multiply complex numbers \\(z = x+iy\\) and \\(w = u+iv\\), using usual algebraic rules for expanding brackets — just remembering that \\(i^2 = -1\\): \\[\\begin{align*} z + w &amp;= (x + iy) + (u + iv) = (x+u) + i (y+v),\\\\ z - w &amp;= (x + iy) - (u + iv) = (x-u) + i (y-v),\\\\ z \\times w &amp;= (x + iy) \\times (u + iv) = x u + i x v + i yu + i^2 y v = (xu - yv) + i (xv + yu). \\end{align*}\\] Example 5.1 (Complex Arithmetic) Let \\(z = 3 - 5i\\) (that is, \\(z = 3 + (-5)i\\)) and \\(w = 2 + i\\) then \\[ z + w = 5 - 4i, \\qquad z - w = 1 - 6i, \\] and \\[ z\\times w = (3 - 5i)\\times (2+i) = 6 + 3i - 10i - 5i^2 = 11 - 7i. \\] Thus \\(\\mathbf{Re}(z\\times w) = 11\\) and \\(\\mathbf{Im}(z\\times w) = -7\\). The complex conjugate of \\(z = x + iy\\) is the complex number \\[ \\overline{z} = x - iy. \\] This is the “mirror image” of \\(z\\) in the real axis. The modulus of \\(z = x + iy\\) is \\[ |z| = \\sqrt{x^2 + y^2} \\qquad \\text{(the non-negative square root).} \\] Geometrically, this is the distance of \\(z\\) (i.e. the point \\(P\\)) from the origin – See figure 5.1. Note that if \\(b = 0\\) (so that \\(z\\) is actually a real number), then this definition of \\(|z|\\) agrees with the usual modulus (absolute value) for real numbers. Example 5.2 (Complex conjugate) For \\(z = 2 - i\\), we have \\(\\overline{z} = 2 + i\\) and \\(|z| = \\sqrt{2^2 + (-1)^2} = \\sqrt{5}\\). Some properties of modulus and conjugate: For any complex numbers \\(z, w\\), \\(\\overline{\\overline{z}} = z\\); \\(\\overline{z \\pm w} = \\overline{z} + \\overline{w}\\); \\(\\overline{z\\times w} = \\overline{z}\\times \\overline{w}\\); \\(|z|\\) is a positive real number unless \\(z = 0\\) with \\(|0| = 0\\); \\(z\\times \\overline{z} = |z|^2\\); \\(|z\\times w| = |z|\\,|w|\\). What about division of complex numbers? This is made easy using the complex conjugate as follows: \\[\\frac{z}{w}=\\frac{z}{w}\\frac{\\overline{w}}{\\overline{w}}=\\frac{z\\times \\overline{w}}{|w|^2}.\\] Example 5.3 (Complex division) Let \\(z = 2 + 3i\\) and \\(w = 4 - 2i\\). \\[\\begin{align*} \\frac{z}{w}&amp;=\\frac{2 + 3i}{4 - 2i}\\frac{4+2i}{4+2i}\\\\ &amp;=\\frac{8+4i+12i+6i^2}{16+4}\\\\ &amp;=\\frac{2+16i}{20}\\\\ &amp;=\\frac{1}{10}+\\frac{4}{5}i \\end{align*}\\] A useful fact: if a polynomial has real coefficients and has a complex root \\(z\\), then its complex conjugate \\(\\overline{z}\\) is also a root; we say that complex roots appear in complex conjugate pairs in real polynomials. 5.3 The argument, polar and exponential form for complex numbers If we think of the complex number \\(z = x + iy\\) as a point \\(P = z\\) in the \\((x,y)\\)-plane, then it is natural to think also of representing \\(P\\) in polar coordinates \\((r,\\theta)\\) – see figure 5.2. Figure 5.2: The complex number \\(z = x + iy\\) in polar coordinates. Here, \\(r = |z| = \\sqrt{x^2 + y^2}\\) is the distance from the origin \\(O\\) and \\(\\theta\\) is the angle between the positive real axis and the line \\(OP\\). We call \\(\\theta\\) the argument of \\(z\\), denoted \\(\\theta = \\arg(z)\\). We have that \\[ P = (x,y) \\quad \\text{(in Cartesian coordinates)}\\quad \\text{or} \\quad P = (r,\\theta) \\quad \\text{(in Polar coordinates)} \\] with \\[\\begin{array}{rrclcrcl} &amp; r &amp;=&amp; \\sqrt{x^2 + y^2} &amp; \\quad\\text{and}\\quad &amp; \\tan(\\theta) &amp;=&amp; \\frac{y}{x},\\\\ \\text{or} \\qquad &amp; x &amp;=&amp; r \\cos(\\theta) &amp; \\quad\\text{and}\\quad &amp; y &amp;=&amp; r \\sin(\\theta). \\end{array}\\] Therefore, we can recover the Cartesian coordinates of \\(P\\) from the polar form \\((r, \\theta)\\) of a complex number \\(z\\) as \\[ z = r \\cos(\\theta) + i (r \\sin(\\theta)) = r (\\cos(\\theta) + i \\sin(\\theta)), \\] Theorem 5.2 (Euler's formula) For any real number \\(\\theta\\), \\[ e^{i\\theta}=\\cos (\\theta) + i \\sin(\\theta). \\] This can be derived from the power series of \\(e^\\theta, \\sin(\\theta)\\) and \\(\\cos(\\theta)\\). Eulers formula allows us to write any complex number \\(z\\) in yet another form, the exponential form of \\(z\\): \\[ z = r (\\cos (\\theta) + i \\sin (\\theta)) = re^{i\\theta}. \\] Note that since \\(\\sin\\) and \\(\\cos\\) are periodic with period \\(2\\pi\\), there are actually an infinite number of ways of expressing a complex number in polar or exponential form; for any integer value of \\(m\\) \\[re^{i(\\theta+2m\\pi)}=r(\\cos(\\theta+2m\\pi)+i\\sin(\\theta+2m\\pi))=r(\\cos(\\theta)+i\\sin(\\theta))=re^{i\\theta}=w\\] so we can add any multiple of \\(2m\\pi\\) to \\(\\theta\\) and get the same complex number. Graphically, this corresponds to going around a full circle \\(m\\) times in the complex plane and back to the same point. Figure 5.3: A complex number \\(w=re^{i\\theta}\\) plotted in the complex plane. Drag the sliders to vary \\(\\theta\\) and \\(r\\). [Open graph in browser.] The usual rules of exponents hold for complex exponentials, now using the rules of complex arithmetic. The exponential form is particularly nice when taking the product of two complex numbers. For \\(z = re^{i\\theta}\\) and \\(w = se^{i\\phi}\\), we have \\[\\begin{align*} u &amp;= (re^{i\\theta}) \\times (se^{i\\phi})\\\\ &amp;= rs e^{i(\\theta + \\phi)} \\\\ &amp;= R e^{i\\alpha}, \\end{align*}\\] where \\(R = rs\\) is the distance of \\(u\\) from the origin and \\(\\alpha = \\theta + \\phi\\) is the argument of \\(u\\). Caution: For \\(z = x + iy\\) (with \\(x \\neq 0\\)), if \\(\\theta = \\arg(z)\\) then we always have \\(\\tan (\\theta) = y/x\\). However, this does not mean that \\(\\theta = \\tan^{-1}(y/x)\\). The \\(\\tan^{-1}\\) (or \\(\\arctan\\)) function can only give values in the first and fourth quadrants (between \\(-\\pi/2\\) and \\(\\pi/2\\)), but the argument of a complex number could be in any of the four quadrants (between \\(-\\pi\\) and \\(\\pi\\)). Therefore, to find the argument of a complex number always draw a diagram. (A quick sketch is all that is needed.) 5.4 Roots of complex numbers We know that square roots of positive real numbers have two solutions, for example \\(\\sqrt{4}=\\pm 2\\). This agrees with Theorem (thm:FTA) as we could formulate this as a solution to the equation \\[x^2=4\\] which is the quadratic \\[x^2-4=0\\] and so must have two roots. More generally, the \\(n^\\text{th}\\) root of any number \\(w\\) can be formulated as the solutions to the polynomial equation \\[z^n-w=0.\\] Theorem (thm:FTA) implies that there are \\(n\\) solutions, allowing for these to be complex numbers. Furthermore, it turns out that these roots will be distinct (no repeated roots). The easiest way to find these roots is using the exponential form. We can write \\(w\\) as \\[w=re^{i\\theta}\\] then the first \\(n^\\text{th}\\) root is \\[w^{\\frac{1}{n}}=(re^{i\\theta})^\\frac{1}{n}=r^\\frac{1}{n}e^{i\\frac{\\theta}{n}}\\] but where are the remaining \\(n-1\\) roots? Well, since we can also write \\(w=re^{i(\\theta+2m\\pi)}\\), so \\[w^{\\frac{1}{n}}=r^{\\frac{1}{n}}e^{i(\\frac{\\theta}{n}+\\frac{2m}{n}\\pi)}\\] and we have a distinct solution for all values of \\(m=0,\\dotsc,n-1\\). Once we reach \\(m=n\\) we have gone full circle and are back to the original solution. To double check these are solutions, we can take them to the power \\(n\\) \\[\\begin{align*} (r^{\\frac{1}{n}}e^{i(\\frac{\\theta}{n}+\\frac{2m}{n}\\pi)})^n&amp;=re^{in(\\frac{\\theta}{n}+\\frac{2m}{n}\\pi)}\\\\ &amp;=re^{i(\\frac{n\\theta}{n}+\\frac{2mn}{n}\\pi)}\\\\ &amp;=re^{i(\\theta+2m\\pi)}\\\\ &amp;=re^{i\\theta}\\\\ &amp;=w. \\end{align*}\\] Geometrically, these \\(n\\) solutions are evenly spaced around a circle of radius \\(r^{\\frac{1}{n}}\\) in the complex plane, with an angle of \\(\\frac{2}{n}\\pi\\) between them. Example 5.4 (Complex roots) Find the cube roots of \\(z=2\\) and sketch them in the complex plane. We first write \\(z=2+0i\\) in exponential form \\[z=2e^{i0}\\] then the solutions are \\[\\begin{align*} w_1&amp;=\\sqrt[3]{2}e^{i0}=\\sqrt[3]{2}\\\\ w_2&amp;=\\sqrt[3]{2}e^{i(0+\\frac{2\\pi}{3})}=\\sqrt[3]{2}e^{i\\frac{2\\pi}{3}}\\\\ w_3&amp;=\\sqrt[3]{2}e^{i(0+\\frac{2(2)\\pi}{3})}=\\sqrt[3]{2}e^{i\\frac{4\\pi}{3}} \\end{align*}\\] Figure 5.4: The cube roots of \\(2\\) in the complex plane. Note they are evenly spaced around a circle of radius \\(\\sqrt[3]{2}\\). 5.5 \\(e^{i\\theta}\\) and trigonometric identities There are many double angle, and similar, formulas relating the various trig. functions. Remembering them can be quite a struggle. In fact we can recover them easily using complex numbers in polar form: \\[ e^{i \\theta} = \\cos (\\theta) + i \\sin (\\theta). \\] So for arbitrary \\(\\theta\\) and \\(\\phi\\) \\[ e^{i \\theta} e^{i \\phi} = \\begin{cases} (\\cos (\\theta) + i \\sin (\\theta)) \\times (\\cos (\\phi) + i \\sin (\\phi)) &amp; \\text{or} \\\\ e^{i (\\theta + \\phi)} = \\cos (\\theta + \\phi) + i \\sin (\\theta + \\phi). \\end{cases} \\] It follows that \\[\\begin{align*} (\\cos (\\theta) + i \\sin (\\theta)) \\times (\\cos (\\phi) + i \\sin (\\phi)) &amp;= \\cos (\\theta) \\cos (\\phi) - \\sin (\\theta) \\sin (\\phi) + i (\\cos (\\theta) \\sin (\\phi) + \\sin (\\theta) \\cos (\\phi))\\\\ &amp;= \\cos (\\theta + \\phi) + i \\sin (\\theta + \\phi) \\end{align*}\\] and equating real and imaginary parts on the left and right hand sides gives: \\[ \\cos (\\theta) \\cos (\\phi) - \\sin (\\theta) \\sin (\\phi) = \\cos (\\theta + \\phi) \\qquad \\text{and}\\qquad \\cos (\\theta) \\sin (\\phi) + \\sin (\\theta) \\cos (\\phi) = \\sin (\\theta + \\phi) \\] Engineers often use the notation \\(j\\) instead of \\(i\\).↩︎ "],["vectors.html", "Chapter 6 Vectors 6.1 Vector addition 6.2 Scalar multiplication 6.3 Vectors in Cartesian coordinates 6.4 Vector products", " Chapter 6 Vectors In physics, we distiguish between scalar quantities and vector quantities: Scalars are defined by a single numeric value. Examples include distance, speed, time, temperature, pressure, mass and energy. Vectors have associated both a numeric value and a direction. Examples include displacement, velocity, acceleration, force, and momentum. We depict vectors by arrows whose length is proportional to the magnitude of the quantity in question and whose direction is that of the action of the quantity. In symbols, we will use bold typeface to indicate a vector, such as \\(\\mathbf{v}\\), and we will denote a vector from point \\(A\\) to \\(B\\) by \\(\\overrightarrow{AB}\\). See figure 6.1. Figure 6.1: The vector \\(\\mathbf{v} = \\overrightarrow{AB}\\) is the vector from \\(A\\) to \\(B\\). Next we develop the mathematics of vectors. They are invaluable tools in science and engineering and in particular they can make light work of some otherwise difficult geometric calculations. 6.1 Vector addition Geometrically, to add two vectors together we can place the tail of one vector at the head of the other and take the vector that goes from the starting point to the finish point. Figure 6.2: Addition of two vectors \\(\\textbf{v}\\) and \\(\\textbf{w}\\) by aligning them tail to head. Example 6.1 (Vector addition) A swallow is flying at 40 km/h due north with an easterly wind blowing at a speed of 20 km/h. The swallow’s groundspeed can be found by adding the velocity vectors: \\[\\begin{align*} \\mathbf{v} &amp;= 40 \\text{ km/h North}\\\\ \\mathbf{w} &amp;= 20 \\text{ km/h West}\\\\ \\mathbf{v}+\\mathbf{w}&amp;=20\\sqrt{5} \\text{ km/h North by North West}. \\end{align*}\\] Alternatively, we can use the parallelogram rule (which amounts to the same thing): we draw a parallelogram with two of the non-parallel sides given by the vectors and take the diagonal as the resultant vector, as in figure 6.3. Figure 6.3: Parallelogram for addition of two vectors \\(\\textbf{v}\\) and \\(\\textbf{w}\\). 6.2 Scalar multiplication If we multiply a vector by a positive scalar, we change only the magnitude of the vector and keep its direction. For example, if the swallow in example 6.1 starts flying twice as fast, we have the velocity vector \\[2\\mathbf{v} = 80 \\text{ km/h North}.\\] If we multiply by a negative value, the vector now points in the opposite direction: \\[-2\\mathbf{v} = 80 \\text{ km/h South}.\\] Figure 6.4: Scalar multiplication of a vector \\(\\mathbf{v}\\). Finally, if we multiply by \\(0\\), we get the zero-vector \\(\\mathbf{0}\\), which has magnitude \\(0\\) and no direction: \\[0\\mathbf{v}=\\mathbf{0}\\]. 6.3 Vectors in Cartesian coordinates We mostly deal with vectors in a Cartesian coordinate system. We then define vectors of length 1 that point out from the origin along the coordinate axes. In three dimensions we label these as \\(\\mathbf{i}\\) along the \\(x\\)-axis, \\(\\mathbf{j}\\) along the \\(y\\)-axis and \\(\\mathbf{k}\\) along the \\(z\\)-axis. In two dimensions we simply drop the \\(\\mathbf{k}\\) vector. We can then write any vector \\(\\overrightarrow{OA}\\) from the origin \\(O\\) to a point \\(A\\) as some combination of the these vectors. For example, the vector in the plane from the origin to the point \\(A=(2,3)\\) is given by: \\[\\overrightarrow{OA}=2\\mathbf{i} + 3\\mathbf{j}.\\] We can reconcile this with our geometric understanding of addition of two vectors: we place the vector \\(2\\mathbf{i}\\) from the origin to the point \\((2,0)\\) and then place the tail of the vector \\(3\\mathbf{j}\\) at the head of \\(2\\mathbf{i}\\) to get to the point \\((2,3)\\); or, in terms of the parallelogram rule we have a rectangle with sides \\(2\\mathbf{i}\\) and \\(3\\mathbf{j}\\). See figure 6.5. Figure 6.5: The vector \\(2\\mathbf{i}+3\\mathbf{j}\\). Yet another way to write this vector is as a column vector \\[\\overrightarrow{OA}= \\begin{pmatrix} 2\\\\ 3 \\end{pmatrix}. \\] Such a representation is called a coordinate vector. More generally, the vector \\[\\mathbf{v}=x\\mathbf{i}+y\\mathbf{j}+z\\mathbf{k}\\] can be written as the column \\[\\begin{pmatrix} x\\\\ y\\\\ z \\end{pmatrix}. \\] Now addition and scalar multiplication can be carried out component-wise as follows. If we have \\[\\mathbf{v}=x\\mathbf{i}+y\\mathbf{j}+z\\mathbf{k}\\] and \\[\\mathbf{w}=x&#39;\\mathbf{i}+y&#39;\\mathbf{j}+z&#39;\\mathbf{k}\\] then \\[\\mathbf{v}+\\mathbf{w}=(x+x&#39;)\\mathbf{i}+(y+y&#39;)\\mathbf{j}+(z+z&#39;)\\mathbf{k}\\] and with \\(a\\) a scalar, \\[a\\mathbf{v}=ax\\mathbf{i}+ay\\mathbf{j}+az\\mathbf{k}.\\] Or, as column vectors with \\[ \\mathbf{v} = \\begin{pmatrix} x\\\\ y\\\\ z \\end{pmatrix}, \\qquad \\mathbf{w} = \\begin{pmatrix} x&#39;\\\\ y&#39;\\\\ z&#39; \\end{pmatrix} \\] we have \\[\\mathbf{v}+\\mathbf{w}= \\begin{pmatrix} x+x&#39;\\\\ y+y&#39;\\\\ z+z&#39; \\end{pmatrix}. \\] and \\[ a\\mathbf{v} = \\begin{pmatrix} ax\\\\ ay\\\\ az \\end{pmatrix}. \\] If points \\(A\\) and \\(B\\) have coordinates \\((a_1,a_2,a_3)\\) and \\((b_1,b_2,b_3)\\), respectively, then the vector from \\(A\\) to \\(B\\) is \\[\\overrightarrow{AB} = \\begin{pmatrix} b_1 - a_1 \\\\ b_2 - a_2\\\\ b_3 - a_3\\end{pmatrix}. \\] In 3-dimensional Cartesian coordinates, the length of the vector \\[\\mathbf{v} = \\begin{pmatrix} x\\\\ y\\\\ z\\end{pmatrix}\\] is written as \\(|\\mathbf{v}|\\) and defined as \\[|\\mathbf{v}| = \\sqrt{x^2 + y^2 + z^2}\\]. This is essentially a three-dimensional version of the Pythagorean theorem. A vector \\(\\mathbf{u}\\) is said to be a unit vector if it has unit length. That is, if \\(|\\mathbf{u}| = 1\\). For any non-zero vector \\(\\mathbf{v}\\), the vector \\[ \\mathbf{u}=\\frac{1}{|\\mathbf{v}|} \\mathbf{v} \\] is a unit vector in the same direction as \\(\\mathbf{v}\\). Example 6.2 Let \\[\\mathbf{v} = \\begin{pmatrix} 2\\\\ -3\\\\ 6\\end{pmatrix}\\] Then the length of \\(\\mathbf{v}\\) is \\(|\\mathbf{v}| = \\sqrt{2^2 + 3^2 + 6^2} = 7\\). So the unit vector \\(\\mathbf{u}\\) parallel to \\(\\mathbf{v}\\) is \\[ \\mathbf{u}=\\frac{1}{7}\\begin{pmatrix} 2\\\\ -3\\\\ 6\\end{pmatrix}. \\] 6.4 Vector products We have seen how to add vectors and how to multiply vectors with a scalar. In the following, we see how to multiply two vectors with each other. 6.4.1 Dot product The dot product (also called the scalar product or inner product) of two vectors \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\), denoted \\(\\mathbf{u}\\cdot\\mathbf{v}\\), is defined to be the quantity \\[\\begin{equation} \\mathbf{u}\\cdot\\mathbf{v} = |\\mathbf{u}||\\mathbf{v}|\\cos(\\theta) \\tag{6.1} \\end{equation}\\] where \\(\\theta\\) is the angle between the vectors \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\). Note that the symmetry of the \\(\\cos\\) function means it does not matter which direction we measure the angle, i.e. clockwise or anticlockwise. Figure 6.6: The projection of \\(\\mathbf{v}\\) onto \\(\\mathbf{u}\\). An immediate application of the scalar product is the projection of one vector onto another. Consider Figure 6.6, which shows the projection of the vector \\(\\mathbf{v}\\) onto the vector \\(\\mathbf{u}\\). We drop a line from the tip of \\(\\mathbf{v}\\) running at right angles to the direction of the vector \\(\\mathbf{u}\\). This is akin to thinking of the shadow that \\(\\mathbf{v}\\) would cast on the vector \\(\\mathbf{u}\\) if the Sun is shining at right angles to \\(\\mathbf{u}\\). The length of the shadow is the projection of \\(\\mathbf{v}\\) onto \\(\\mathbf{u}\\), or \\[|\\mathbf{v}|\\cos(\\theta).\\] We have: \\[\\mathbf{u} \\cdot \\mathbf{v} = |\\mathbf{u}| \\times \\text{projection of $\\mathbf{v}$ onto $\\mathbf{u}$}\\] Since there was nothing special about choosing the projection onto \\(\\mathbf{v}\\) – we could have chosen the projection onto \\(\\mathbf{u}\\) – it is also true that: \\[\\mathbf{u} \\cdot \\mathbf{v}= |\\mathbf{v}| \\times \\text{projection of $\\mathbf{u}$ onto $\\mathbf{v}$}.\\] Example 6.3 (Work) An application of the dot product in physics is to the concept of work. We want to consider how much work is required to push a block over a certain distance \\(x\\). By calculation or measurement, we can determine the force \\(F\\) required to push the block. Then, by definition, the work done by the force is \\[W = Fx.\\] This is sufficient if the force acts in the same direction as the motion of the block. If, however, this is not the case (maybe the block is constrained to move on a rail), then it is the component of the force in the direction of motion that is important. Suppose \\(\\mathbf{F}\\) is the force vector and \\(\\mathbf{x}\\) is the displacement vector of the block. Let \\(\\theta\\) be the angle between the two vectors. Then the component of \\(\\mathbf{F}\\) in the \\(\\mathbf{x}\\) direction is precisely the projection of \\(\\mathbf{F}\\) onto \\(\\mathbf{x}\\) (as described in Figure 6.6). This is equal to \\[ |\\mathbf{F}|\\cos(\\theta). \\] So the total work done will be the product of this quantity with the magnitude of the displacement vector, that is \\[\\begin{align*} W &amp;= |\\mathbf{F}|\\cos(\\theta) \\times |\\mathbf{x}| \\\\ &amp;= |\\mathbf{F}||\\mathbf{x}|\\cos(\\theta) \\\\ &amp;= \\mathbf{F}\\cdot\\mathbf{x}, \\end{align*}\\] i.e. the dot product of \\(\\mathbf{F}\\) and \\(\\mathbf{x}\\). Note that if the dot product is \\(\\mathbf{u}\\cdot\\mathbf{v}=0\\) then either \\(\\cos(\\frac{\\pi}{2})=0\\) so that the two vectors are perpendicular, or one or both of \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) are the zero vector \\(\\mathbf{0}\\). When the dot product is zero, we say that the two vectors are orthogonal. Some other properties of the dot product that follow from the definition are: \\(\\mathbf{u} \\cdot \\mathbf{v} = \\mathbf{v} \\cdot \\mathbf{u}\\); \\((a\\mathbf{u}) \\cdot \\mathbf{v} = \\mathbf{u} \\cdot (a\\mathbf{v})= a(\\mathbf{u} \\cdot \\mathbf{v})\\); \\(\\mathbf{u} \\cdot (\\mathbf{v} + \\mathbf{w}) = \\mathbf{u} \\cdot \\mathbf{v} + \\mathbf{u} \\cdot \\mathbf{w}\\); \\(\\mathbf{u}\\cdot\\mathbf{u} = |\\mathbf{u}|^2\\). Theorem 6.1 (Calculating the dot product) In Cartesian coordinates, the dot product of two vectors \\[\\mathbf{u} = x\\mathbf{i} + y\\mathbf{j} + z\\mathbf{k} \\qquad\\text{and}\\qquad \\mathbf{v} = a\\mathbf{i} + b\\mathbf{j} + c\\mathbf{k}\\] can be calulated as \\[\\begin{equation*} \\mathbf{u}\\cdot\\mathbf{v} = (x\\mathbf{i} + y\\mathbf{j} + z\\mathbf{k})\\cdot(a\\mathbf{i} + b\\mathbf{j} + c\\mathbf{k}) = xa + yb + zc. \\end{equation*}\\] To see this, consider the full product: \\[\\begin{align*} \\mathbf{u} \\cdot \\mathbf{v} &amp;= xa \\mathbf{i} \\cdot \\mathbf{i} + xb \\mathbf{i} \\cdot \\mathbf{j} + xc \\mathbf{i} \\cdot \\mathbf{k} \\\\ &amp;\\phantom{={}} + ya \\mathbf{j} \\cdot \\mathbf{i} + yb \\mathbf{j} \\cdot \\mathbf{j} + yc \\mathbf{j} \\cdot \\mathbf{k} \\\\ &amp;\\phantom{={}} + za \\mathbf{k} \\cdot \\mathbf{i} + zb \\mathbf{k} \\cdot \\mathbf{j} + zc \\mathbf{k} \\cdot \\mathbf{k} \\\\ &amp;= xa + yb + zc, \\end{align*}\\] then noting that the unit vectors \\(\\mathbf{i}\\), \\(\\mathbf{j}\\) and \\(\\mathbf{k}\\) have unit length and are perpendicular to one another, we first have by the property \\(\\mathbf{u}\\cdot\\mathbf{u}=|\\mathbf{u}|^2\\) that \\[ \\mathbf{i}\\cdot\\mathbf{i} = \\mathbf{j}\\cdot\\mathbf{j} =\\mathbf{k}\\cdot\\mathbf{k}=1, \\] and secondly, by orthogonality each of the following products are zero \\[\\begin{align*} \\mathbf{i} \\cdot \\mathbf{j}&amp;,\\; \\mathbf{i} \\cdot \\mathbf{k}\\\\ \\mathbf{j} \\cdot \\mathbf{i}&amp;,\\; \\mathbf{j} \\cdot \\mathbf{k}\\\\ \\mathbf{k} \\cdot \\mathbf{i}&amp;,\\; \\mathbf{k} \\cdot \\mathbf{j}. \\end{align*}\\] Example 6.4 (Geometry) Consider a triangle in three-dimensional space whose vertices are given by the points \\[ A = (2,4,-1),\\quad B = (0,3,1), \\quad C = (-3,1,5). \\] We compute the side lengths and angles for the triangle \\(ABC\\) above. First note that \\[ \\overrightarrow{AB} = \\begin{pmatrix} 0\\\\ 3\\\\ 1\\end{pmatrix} - \\begin{pmatrix} 2\\\\ 4\\\\ -1\\end{pmatrix} = \\begin{pmatrix} -2\\\\ -1\\\\ 2\\end{pmatrix} \\] and similarly \\[ \\overrightarrow{BC} = \\begin{pmatrix} -3\\\\ -2\\\\ 4\\end{pmatrix} \\quad\\text{and}\\quad \\overrightarrow{CA} = \\begin{pmatrix} 5\\\\ 3\\\\ -6\\end{pmatrix}. \\] From this, we can immediately calculate the length of the sides, namely \\[\\begin{align*} AB &amp;= |\\overrightarrow{AB}| = \\sqrt{(-2)^2 + (-1)^2 + 2^2} = 3, \\\\ BC &amp;= |\\overrightarrow{BC}| = \\sqrt{(-3)^2 + (-2)^2 + 4^2} = \\sqrt{29}, \\\\ CA &amp;= |\\overrightarrow{CA}| = \\sqrt{5^2 + 3^2 + (-6)^2} = \\sqrt{70}. \\end{align*}\\] The angles can then be computed using the dot product. For instance, the angle \\(\\theta_A\\) at the vertex \\(A\\) can be computed via \\[ \\cos(\\theta_A) = \\frac{\\overrightarrow{AB}\\cdot\\overrightarrow{AC}}{AB\\times AC} = -\\frac{\\overrightarrow{AB}\\cdot\\overrightarrow{CA}}{AB\\times CA}, \\] thus \\[ \\cos(\\theta_A) = -\\frac{-2\\times 5 - 1\\times 3 + 2\\times(-6)}{3\\sqrt{70}} = \\frac{25}{3\\sqrt{70}} = \\frac{25\\sqrt{70}}{3\\times 70} = \\frac{5\\sqrt{70}}{42}. \\] Similarly, we calculate \\[ \\cos(\\theta_B) = \\frac{\\overrightarrow{BA}\\cdot\\overrightarrow{BC}}{BA\\times BC} = -\\frac{16}{87}\\sqrt{29}. \\] and \\[ \\cos(\\theta_C) = \\frac{\\overrightarrow{CA}\\cdot\\overrightarrow{CB}}{CA\\times CB} = \\frac{9}{406}\\sqrt{29}\\sqrt{70}. \\] 6.4.2 Cross product Let \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) be vectors in a three-dimensional space and let \\(\\theta\\) be the angle between the vectors. Note there are potentially two choices for the angle between two vectors: both \\(\\theta\\) and \\(2\\pi - \\theta\\). Unlike the case of the dot product, we need to be clear about our choice of angle \\(\\theta\\). We choose the angle \\(\\theta\\) such that \\(0 \\le \\theta &lt; \\pi\\). The cross product (or vector product) \\(\\mathbf{u}\\times\\mathbf{v}\\) of two vectors \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) in three-dimensional space is defined to be the (unique) vector of length \\[ |\\mathbf{u}||\\mathbf{v}|\\sin(\\theta) \\] that is orthogonal to both the vectors \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\), such that \\(\\mathbf{u}, \\mathbf{v}\\) and \\(\\mathbf{u}\\times\\mathbf{v}\\) form a right-handed system. The last part of the definition needs some explanation. There are always two possible directions that are perpendicular to \\(\\mathbf{u}\\) and to \\(\\mathbf{v}\\), one being the opposite of the other. When we say that a set of three vectors \\(\\{\\mathbf{u}, \\mathbf{v}, \\mathbf{w}\\}\\) forms a right-handed system, we mean that if take our right hand and point our thumb in the direction of \\(\\mathbf{u}\\) and our index finger in the direction of \\(\\mathbf{v}\\), then our middle finger points (roughly) in the direction of \\(\\mathbf{w}\\). From Figure 6.7 we see that \\(\\{\\mathbf{u}, \\mathbf{v}, \\mathbf{u}\\times\\mathbf{v}\\}\\) form a right-handed system. Figure 6.7: The cross product of \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\). The cross product has the following properties: \\(\\mathbf{u}\\times\\mathbf{v} = -(\\mathbf{v} \\times \\mathbf{u})\\); \\(\\mathbf{u}\\times\\mathbf{v} = \\mathbf{0}\\) if and only if \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) are parallel, or \\(\\mathbf{u} = \\mathbf{0}\\) or \\(\\mathbf{v} = \\mathbf{0}\\); \\(|\\mathbf{u}\\times\\mathbf{v}| = |\\mathbf{u}||\\mathbf{v}|\\) if and only if \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) are orthogonal; \\((a\\mathbf{u})\\times\\mathbf{v} = \\mathbf{u}\\times(a\\mathbf{v}) = a(\\mathbf{u}\\times\\mathbf{v})\\); \\(\\mathbf{u}\\times(\\mathbf{v}+\\mathbf{w}) = \\mathbf{u}\\times\\mathbf{v} + \\mathbf{u}\\times\\mathbf{w}\\). It follows that: \\[ \\begin{array}{rclrclrcl} \\mathbf{i}\\times\\mathbf{j} &amp;=&amp; \\mathbf{k}, \\qquad &amp; \\mathbf{j}\\times\\mathbf{k} &amp;=&amp; \\mathbf{i}, \\qquad &amp; \\mathbf{k}\\times\\mathbf{i} &amp;=&amp; \\mathbf{j},\\\\ \\mathbf{j}\\times\\mathbf{i} &amp;=&amp; -\\mathbf{k}, \\qquad &amp; \\mathbf{k}\\times\\mathbf{j} &amp;=&amp; -\\mathbf{i}, \\qquad &amp; \\mathbf{i}\\times\\mathbf{k} &amp;=&amp; -\\mathbf{j},\\\\ \\mathbf{i}\\times\\mathbf{i} &amp;=&amp; \\mathbf{0}, \\qquad &amp; \\mathbf{j}\\times\\mathbf{j} &amp;=&amp; \\mathbf{0}, \\qquad &amp; \\mathbf{k}\\times\\mathbf{k} &amp;=&amp; \\mathbf{0}. \\end{array} \\] Then we can compute the cross product of \\[ \\mathbf{u} = u_1\\mathbf{i} + u_2\\mathbf{j} + u_3\\mathbf{k} \\qquad\\text{and}\\qquad \\mathbf{v} = v_1\\mathbf{i} + v_2\\mathbf{j} + v_3\\mathbf{k}, \\] as \\[ \\mathbf{u} \\times \\mathbf{v} = (u_2v_3 - u_3v_2)\\mathbf{i} + (u_3v_1 - u_1v_3)\\mathbf{j} + (u_1v_2 - u_2v_1)\\mathbf{k}. \\] An easy way to remember this is to compute the determinant: \\[ \\mathbf{u}\\times\\mathbf{v} = \\begin{vmatrix} \\mathbf{i} &amp; \\mathbf{j} &amp; \\mathbf{k}\\\\ u_1 &amp; u_2 &amp; u_3\\\\ v_1 &amp; v_2 &amp; v_3\\end{vmatrix}. \\] Example 6.5 (Magnetic fields) The vector product occurs in many equations in physics. For instance, consider a charged particle moving through a magnetic field. Let the charge on the particle be \\(q\\) Coulombs, let its velocity vector be \\(\\mathbf{v}\\) metres per second and let the magnetic field be \\(\\mathbf{B}\\) Teslas. Then the force \\(\\mathbf{F}\\) Newtons experienced by the particle is \\[ \\textbf{F} = q\\mathbf{v}\\times\\textbf{B}. \\] This formula expresses mathematically the fact that the force experienced by the particle is perpendicular to its direction of motion and to the magnetic field. Example 6.6 (Triangle area) What is the area of the triangle with vertices \\[ A = (2,4,-1), \\qquad B = (0,3,1), \\qquad C = (-3,1,5)? \\] Note that this is the same triangle that we considered in Example @ref{exm:dottriangle}, where we considered the lengths of the sides and the angles at the vertices. Figure 6.8: Computing the area of a triangle via the vector product. The area of a triangle is half its base times its height. In view of the diagram in Figure 6.8, the base is \\(|\\overrightarrow{AB}|\\) and the height is \\(|\\overrightarrow{AC}| \\sin(\\theta_A)\\), so the area of the triangle is \\[ \\frac{1}{2} |\\overrightarrow{AB}||\\overrightarrow{AC}| \\sin(\\theta_A). \\] This quantity can be computed in terms of the vector product as \\[ \\frac{1}{2} |\\overrightarrow{AB}\\times\\overrightarrow{AC}|. \\] Using the determinant method for computing the vector product, we obtain \\[\\begin{align*} \\overrightarrow{AB}\\times\\overrightarrow{AC} = \\begin{vmatrix} \\mathbf{i} &amp; \\mathbf{j} &amp; \\mathbf{k}\\\\ -2 &amp; -1 &amp; 2\\\\ -5 &amp; -3 &amp; 6\\end{vmatrix} = (-6 + 6)\\mathbf{i} - (-12 + 10)\\mathbf{j} + (6 - 5)\\mathbf{k} = 2\\mathbf{j} + \\mathbf{k}. \\end{align*}\\] Thus, \\[ |\\overrightarrow{AB}\\times\\overrightarrow{AC}| = \\sqrt{2^2 + 1^2} = \\sqrt{5}, \\] and we deduce that the area of the triangle \\(ABC\\) is equal to \\(\\frac{\\sqrt{5}}{2}\\). "],["gauss.html", "Chapter 7 Systems of Linear Equations 7.1 Lines and planes 7.2 Solving linear systems - Gaussian elimination 7.3 Echelon Form", " Chapter 7 Systems of Linear Equations So-called linear equations arise often in mathematical problems in science and engineering. In this chapter we will see a very useful method for solving simultaneous linear equations, known as Gaussian elimination. We’ll start by understanding the geometric nature of linear equations. 7.1 Lines and planes A linear equation is one of the form \\[a_1x_1+a_2x_2+\\dotsb+a_nx_n=b\\] where the \\(x_i\\)’s are variables, the \\(a_i\\)’s are coefficients, \\(b\\) is a constant and \\(n\\) is the number of variables in the equation. For \\(n=2\\), we have an equation of the form \\[a_1x_1+a_2x_2=b\\] which we know to be the equation of a line in the Cartesian plane (see section 2.1, where we used the notation \\(ax+by=c\\)). Suppose we have a pair of such equations. Then we could conveniently write them as \\[\\begin{align*} a_{11}x_1+a_{12}x_2&amp;=b_1\\\\ a_{21}x_1+a_{22}x_2&amp;=b_2 \\end{align*}\\] where now the first subscipt \\(i\\) on the \\(a_{ij}\\)’s and \\(b_i\\)’s denotes the equation it belongs to and the second subscipt \\(j\\) denotes the variable it belongs to. If we need to solve these equations to find the values of \\(x_1\\) and \\(x_2\\) that satisfy both equations simultaneously, then we call this a system of linear equations. Figure 7.1: The two intersecting lines from example (exm:gaus1). Geometrically, a solution to the equations corresponds to those coordinates \\((x_1,x_2)\\) where the lines meet – these are values of \\(x_1\\) and \\(x_2\\) that satisfy both equations simultaneously – see figure (fig:sim-lines). We therefore have three different scenarios for the solutions of such equations. Most of the time, two lines in the plane will cross at exactly one point, hence we have just one solution (one pair of coordinates \\((x_1,x_2)\\)). It is possible that both lines are parallel to one another, with different axis intercepts. In this case, the lines never meet – there are no solutions. Finally, it is possible that the two equations actually describe the same line. In this case, any pair of coordinates \\((x_1,x_2)\\) that lies on the (common) line is a solution – there are infinitely many solutions. This idea extends to having more equations. For example, if we have a system of three equations in two variables: \\[\\begin{align*} a_{11}x_1+a_{12}x_2&amp;=b_1\\\\ a_{21}x_1+a_{22}x_2&amp;=b_2\\\\ a_{31}x_1+a_{32}x_2&amp;=b_3 \\end{align*}\\] Then it is possible that: All three lines will cross at exactly one point, hence we have just one solution. The three lines don’t cross at a common point – there are no solutions. This is the most probable scenario in this set-up: whilst any two of the lines might cross at a point, we need all three to cross at the same point in order for there to be a solution to the simultaneous equations. Finally, it is possible that the three equations actually describe the same line and again there are infinitely many solutions. When there are more equations than variables, the system is sometimes called overdetermined, since then we usually have scenario 2 above where trying to satsify the contraints impossed by the three equations is not possible. On the other hand, a system with less equations is sometimes called underdetermined, since in these cases we usually have an infinite number of solutions. For example, if we had a system with just one equation in two variables \\[\\begin{align*} a_{11}x_1+a_{12}x_2&amp;=b_1\\\\ \\end{align*}\\] then all points \\((x_1,x_2)\\) lying on this line are solutions. We can extend these ideas to higher dimensional systems, i.e. a higher number of variables. For example, if we have three equations in three variables \\[\\begin{align*} a_{11}x_1+a_{12}x_2+a_{13}x_3&amp;=b_1\\\\ a_{21}x_1+a_{22}x_2+a_{23}x_3&amp;=b_2\\\\ a_{31}x_1+a_{32}x_2+a_{33}x_3&amp;=b_3 \\end{align*}\\] then each equation describes a plane in 3-dimensional Cartesian coordinates. Now we have: A unique solution \\((x_1,x_2,x_3)\\) if all three planes cross at a single point – the most likely scenario. No solutions if none of the planes cross at a common point – think about all the ways this could happen, there are more ways than in two dimensions! Infinetely many solutions if all three planes intersect along a line or all are the same plane – again, think about the ways this could happen! You should also think about the meaning of overdetermined and underdetermined systems in 3-dimensions and how they look geometrically. We can of course extend these ideas to as many variables and equations as we wish: a linear equation in \\(n\\) variables represents a hyperplane in \\(n\\)-dimensional space, which is a subspace with dimension \\(n-1\\), but is impossible for us to directly visualise things in dimensions greater than 3! 7.2 Solving linear systems - Gaussian elimination There are a number of different approaches to solving linear equations. They all ultimately amount to the same thing, but some methods are more straighforward or computationally efficient depending on the situation. In example ?? we use rearrangement and substitution to solve \\[\\begin{align*} 3x_1+2x_2&amp;=5\\\\ x_1-4x_2&amp;=1. \\end{align*}\\] Now we will instead add and subtract multiples of each equation to reduce them to the solution. Example 7.1 Solve \\[\\begin{align*} 3x_1+2x_2&amp;=5\\\\ x_1-4x_2&amp;=1. \\end{align*}\\] First, lets swap the order of the equations so that the coefficient of \\(x_1\\) in the first equation is \\(1\\) \\[\\begin{align*} x_1-4x_2&amp;=1\\\\ 3x_1+2x_2&amp;=5. \\end{align*}\\] Next, we subtract 3 times the first equation from the second to eliminate \\(x_1\\) from the second equation. The second equation becomes \\[\\begin{align*} 3x_1+2x_2-3(x_1-4x_2)&amp;=5-3\\times 1\\\\ 14x_2&amp;=2 \\end{align*}\\] so we have the equivalent system \\[\\begin{align*} x_1-4x_2&amp;=1\\\\ 14x_2&amp;=2. \\end{align*}\\] Now divide the second equation by 14 \\[\\begin{align*} x_1-4x_2&amp;=1\\\\ x_2&amp;=\\frac{1}{7}. \\end{align*}\\] Add 4 times the second equation to the first to eliminate \\(x_2\\) from the first equation \\[\\begin{align*} x_1-4x_2+4x_2&amp;=1+\\frac{4}{7}\\\\ x_2&amp;=\\frac{1}{7}. \\end{align*}\\] and hence we have the solution \\[\\begin{align*} x_1&amp;=\\frac{11}{7}\\\\ x_2&amp;=\\frac{1}{7}. \\end{align*}\\] Note that in the above example, it is the coefficients \\(a_{ij}\\) and \\(b_i\\) that we are manipulating – the \\(x_j\\)’s just came along for the ride. So, let’s simplify things by just writing down the coefficients in the system of equations in a table as follows: \\[\\left(\\begin{array}{rr|r} 3&amp;2\\\\ 1&amp;-4 \\end{array} \\right). \\] This is called the matrix of coefficients. We also need to keep track of the right-hand side of the equation, so we add this as another column separated by a vertical line: \\[\\left(\\begin{array}{rr|r} 3&amp;2&amp;5\\\\ 1&amp;-4&amp;1 \\end{array} \\right). \\] We call this the augmented matrix. Now in solving the system of equations, we simply add/subtract multiples of rows of this augmented matrix. Labelling each row as \\(R_1\\) and \\(R_2\\) we perform the following operations: swap rows 1 and 2: \\(R_1\\leftrightarrow R_2\\) \\[\\left(\\begin{array}{rr|r} 1&amp;-4&amp;1\\\\ 3&amp;2&amp;5 \\end{array} \\right). \\] subtract 3 times row 1 from row 2: \\(R_2 \\to R_2-3R_1\\) \\[\\left(\\begin{array}{rr|r} 1&amp;-4&amp;1\\\\ 0&amp;14&amp;2 \\end{array} \\right). \\] divide row 2 by 14: \\(R_2\\to \\frac{1}{14}R_2\\) \\[\\left(\\begin{array}{rr|r} 1&amp;-4&amp;1\\\\ 0&amp;1&amp;\\frac{1}{7} \\end{array} \\right). \\] add 4 times the second row to the first: \\(R_1 \\to R_1+4 R_2\\) \\[\\left(\\begin{array}{rr|r} 1&amp;0&amp;\\frac{11}{7}\\\\ 0&amp;1&amp;\\frac{1}{7} \\end{array} \\right) \\] This represents \\[\\begin{align*} 1\\times x_1 + 0 \\times x_2 &amp;=x_1= \\frac{11}{7}\\\\ 0\\times x_1 + 1 \\times x_2 &amp;=x_2= \\frac{1}{7}\\\\ \\end{align*}\\] that is, we can just read off the solutions in the right-most column. This method is known as Gaussian9 elimination and provides a systematic way to solve simultaneous linear equations. Note that each step in the above process is reversible. For instance, the operation \\[R_1 \\to R_1 + 4R_2\\] can be reversed by performing \\[R_1 \\to R_1 - 4R_2.\\] This means that the final set of equations produced by Gaussian elimination is equivalent to the original set of equations and therefore has the same set of solutions. No matter the number of variables or equations, the aim is to reduce the coefficient matrix to a diagonal of \\(1\\)’s (or as close as possible, we’ll clarify this shortly) and \\(0\\)’s everywhere else, like so \\[\\left(\\begin{array}{rrrr|r} 1&amp;0&amp;\\dotsb&amp;0&amp;\\omega_1\\\\ 0&amp;1&amp;\\dotsb&amp;0&amp;\\omega_2\\\\ \\vdots&amp;&amp;\\ddots&amp;\\vdots&amp;\\vdots\\\\ 0&amp;0&amp;\\dotsb&amp;1&amp;\\omega_n \\end{array} \\right), \\] then read off the solutions as \\(x_1=\\omega_1, x_2=\\omega_2,\\dotsc, x_n=\\omega_n\\) from the right hand column. The following elementary row operations (EROs) comprise all operations required for Gaussian elimination: \\(R_i \\to R_i + \\alpha R_k\\), where \\(k \\neq i\\) and \\(\\alpha \\neq 0\\) is some scalar; \\(R_i \\to \\alpha R_i\\), where \\(\\alpha \\neq 0\\) is some scalar; \\(R_i \\leftrightarrow R_k\\), where \\(k\\neq i\\), denotes the swapping of the \\(i\\)-th and \\(k\\)-th rows. We now present a sketch of the full Gaussian elimination procedure using these EROs. First, note that we call the first non-zero entry (reading from left to right) in any row of a matrix the leading entry. A leading entry will always be used as a pivot, where a pivot is an element used to zero-out the other entries in the same column as the pivot. select the leading entry in the top row as a pivot; perform EROs to eliminate the entries below the pivot; move down to the next row and continue the process; having reached the bottom row, work back up again, that is: select the bottom right entry in the matrix of coefficients as the pivot; perform EROs to eliminate the entries above the pivot; move to the row above and continue the process; having reached the top row, stop and read off the solutions. Let’s have a look at another example applying these steps, this time in 3-dimensions. Example 7.2 Solve the system of equations \\[\\begin{align*} x+y+z&amp;=3,\\\\ 2x+3y+z&amp;=10, \\\\ 3x-y+2z&amp;=-2. \\end{align*}\\] We start by writing down the augmented matrix: \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; 1 &amp; 3 \\\\ 2 &amp; 3 &amp; 1 &amp; 10 \\\\ 3 &amp; -1 &amp; 2 &amp; -2 \\end{array}\\right). \\] We select the top-left hand entry of the augmented matrix as a pivot. We eliminate the entries in the same column that lie below the pivot, that is \\[\\require{enclose} \\begin{array}{l} \\phantom{\\enclose{circle}{1}}\\quad \\\\ R_2 \\to R_2 - 2R_1\\colon \\quad\\\\ R_3 \\to R_3 - 3R_1\\colon \\quad \\end{array} \\left(\\begin{array}{crr|r} \\enclose{circle}{1} &amp; 1 &amp; 1 &amp; 3 \\\\ 0 &amp; 1 &amp; -1 &amp; 4 \\\\ 0 &amp; -4 &amp; -1 &amp; -11 \\end{array}\\right). \\] Then we select the first non-zero entry in the second row as our pivot and eliminate the entry below it, to obtain \\[ \\begin{array}{l} \\quad \\\\ \\phantom{\\enclose{circle}{1}} \\quad\\\\ R_3 \\to R_3 + 4R_2\\colon \\quad \\end{array} \\left(\\begin{array}{rcr|r} 1 &amp; 1 &amp; 1 &amp; 3 \\\\ 0 &amp; \\enclose{circle}{1} &amp; -1 &amp; 4 \\\\ 0 &amp; 0 &amp; -5 &amp; 5 \\end{array}\\right). \\] Next perform \\[ \\begin{array}{l} \\quad \\\\ \\quad\\\\ R_3 \\to -\\frac{1}{5}R_3\\colon \\quad \\end{array} \\left( \\begin{array}{rrr|r} 1 &amp; 1 &amp; 1 &amp; 3, \\\\ 0 &amp; 1 &amp; -1&amp; 4, \\\\ 0 &amp; 0 &amp; 1&amp; -1. \\end{array}\\right). \\] We continue, similarly to the steps above, by eliminating the entries above the pivot in the bottom row. \\[ \\begin{array}{l} R_1 \\to R_1 - R_3\\colon \\quad \\\\ R_2 \\to R_2 + R_3\\colon \\quad \\\\ \\phantom{\\enclose{circle}{1}}\\quad \\end{array} \\left(\\begin{array}{rrc|r} 1 &amp; 1 &amp; 0 &amp; 4 \\\\ 0 &amp; 1 &amp; 0 &amp; 3 \\\\ 0 &amp; 0 &amp; \\enclose{circle}{1} &amp;-1 \\end{array}\\right). \\] Finally, we eliminate the second column using the \\(1\\) in the second row as a pivot, that is \\[ \\begin{array}{l} R_1 \\to R_1 - R_2\\colon \\quad \\\\ \\phantom{\\enclose{circle}{1}}\\quad \\\\ \\quad \\end{array} \\left(\\begin{array}{rcr|r} 1 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; \\enclose{circle}{1} &amp; 0 &amp; 3 \\\\ 0 &amp; 0 &amp; 1 &amp; -1 \\end{array}\\right). \\] We read off the solution \\((x,y,z) = (1,3,-1)\\). 7.3 Echelon Form Recall that in general there may be one, none or infinitely many solutions to a system of linear equations. We now see what happens in Guassian elimination in these scenarios. When following the proceedure of Gaussian elimination we reduce the coefficient matrix to make the leading entry in each row equal to 1 and then clear all the values (make them zero) above and below this entry. This results in a coefficient matrix in what is known as reduced echelon form. This allows us to easily read off the solutions. Here is a formal definition of the reduced echelon form. Definition 7.1 (Reduced Echelon Form) A matrix is said to be in reduced echelon form (REF) if 1. all the rows consisting entirely of zeros lie below all non-zero rows (note, there need not be any zero or non-zero rows); 1. each leading entry in a row lies at least one place to the right of all leading entries in any previous rows; 1. every leading entry is \\(1\\); 1. each leading entry is the only non-zero entry in its column. The following are some examples of possible reduced echelon forms for \\(3\\times 3\\) coefficient matrices. \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 0 &amp; 0 &amp; \\omega_1 \\\\ 0 &amp; 1 &amp; 0 &amp; \\omega_2 \\\\ 0 &amp; 0 &amp; 1 &amp; \\omega_3 \\end{array}\\right),\\qquad \\left(\\begin{array}{rrr|r} 1 &amp; 0 &amp; 2 &amp; \\omega_1 \\\\ 0 &amp; 1 &amp; 0 &amp; \\omega_2 \\\\ 0 &amp; 0 &amp; 0 &amp; \\omega_3 \\end{array}\\right),\\qquad \\left(\\begin{array}{rrr|r} 1 &amp; 0 &amp; 0 &amp; \\omega_1 \\\\ 0 &amp; 0 &amp; 1 &amp; \\omega_2 \\\\ 0 &amp; 0 &amp; 0 &amp; \\omega_3 \\end{array}\\right). \\] The previous examples were all square coefficient matrices (the same number of equations as variables). It is also possible that we have rectangular coefficient matrices. Here are some possible echelon forms. \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 0 &amp; 0 &amp; \\omega_1 \\\\ 0 &amp; 1 &amp; 0 &amp; \\omega_2 \\\\ 0 &amp; 0 &amp; 1 &amp; \\omega_3 \\\\ 0 &amp; 0 &amp; 0 &amp; \\omega_4 \\end{array}\\right),\\qquad \\left(\\begin{array}{rrrr|r} 1 &amp; 0 &amp; 2 &amp; -4&amp;\\omega_1 \\\\ 0 &amp; 1 &amp; 0 &amp; 1 &amp; \\omega_2 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\omega_3 \\end{array}\\right),\\qquad \\left(\\begin{array}{rrrr|r} 1 &amp; 3 &amp; 0 &amp; 0 &amp; \\omega_1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; \\omega_2 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; \\omega_3 \\end{array}\\right). \\] Note that the reduced echelon form resuts in a “staircase” of \\(1\\)’s appearing either on or above the diagonal, with all entries below the staircase being zero. We can only take one step down any column, but might take multiple steps right along a row. So far, we have only seen examples like the first matrix above, where we have a diagonal of \\(1\\)’s. Since in this case we simply read off the solutions, it is easy to see that such forms result in a unique solution. We now give some examples and interpretations for other echelon forms. In the following \\(\\alpha_i\\) and \\(\\omega_i\\) can be any value. Example 7.3 (Zero coefficient row) \\[ \\left(\\begin{array}{rcr|r} 1 &amp; 0 &amp; \\alpha &amp; \\omega_1 \\\\ 0 &amp; 1 &amp; 0 &amp; \\omega_2 \\\\ 0 &amp; 0 &amp; 0 &amp; \\omega_3 \\end{array}\\right),\\qquad \\] If \\(\\omega_3=0\\) the equations read \\[\\begin{align*} x_1+\\alpha x_3&amp;=\\omega_1\\\\ x_2&amp;=\\omega_2\\\\ 0&amp;=0 \\end{align*}\\] In effect, we only have two equations. There is no constraint on \\(x_3\\) and we call this a free variable. We can parameterise the solution by setting \\(x_3=\\beta\\) where \\(\\beta\\) can take any values – there are infinitely many solutions. So the solution is all points \\[(\\omega_1-\\alpha\\beta,\\omega_2,\\beta).\\] Geometrically, this is a line in 3-dimensional Cartesian coordinates which is drawn by varying \\(\\beta\\). On the other hand, if \\(\\omega_3\\neq 0\\), then in the bottom row we have the equation \\[0=\\omega_3\\] which is not possible. In this case, there are no solutions to the system of equations. We sometimes say that the set of equations is inconsistent. Example 7.4 (A rectangular reduced echelon form) \\[ \\left(\\begin{array}{rrrrr|r} 1 &amp; 0 &amp; \\alpha_1 &amp; 0 &amp; \\alpha_2 &amp; \\omega_1 \\\\ 0 &amp; 1 &amp; \\alpha_3 &amp; 0 &amp; \\alpha_4 &amp; \\omega_2 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; \\alpha_5 &amp; \\omega_3 \\end{array}\\right). \\] In this case, we have the solutions \\[\\begin{align*} x_1 &amp; = \\omega_1 - \\alpha_1x_3 - \\alpha_2x_5\\\\ x_2 &amp; = \\omega_2 - \\alpha_3x_3 -\\alpha_4 x_5\\\\ x_4 &amp; = \\omega_3 - \\alpha_5x_5 \\end{align*}\\] where \\(x_3\\) and \\(x_5\\) are free variables, and hence we can set them as parameterise \\(x_3=\\beta\\), \\(x_4=\\gamma\\). More generally, any column that does not have a leading entry will correspond to a free variable. Since we have 2 parameters, this describes a plane in 5-dimensional space. The solution is all points \\[(\\omega_1 - \\alpha_1\\beta - \\alpha_2\\gamma, \\omega_2 - \\alpha_3\\beta -\\alpha_4\\gamma, \\beta, \\omega_3 - \\alpha_5\\gamma, \\gamma).\\] The method is named after Carl Friedrich Gauss (1777–1855) born in Braunschweig in the Holy Roman Empire, in what is now Germany. Gauss worked at the University of Gottingen.↩︎ "],["matrices.html", "Chapter 8 Matrices 8.1 Solving linear systems revisited 8.2 Determinants", " Chapter 8 Matrices A matrix \\(A\\) is a two-dimensional array of numbers. We say that \\(A\\) is an \\(m \\times n\\) matrix if it has \\(m\\) rows and \\(n\\) columns, for some natural numbers \\(m\\) and \\(n\\). We use the notation \\[ A = (a_{ij})_{m \\times n}, \\qquad \\text{or more simply} \\qquad A = (a_{ij}), \\] to indicate that the entry in row \\(i\\) and column \\(j\\) of \\(A\\) is \\(a_{ij}\\). We refer to \\(a_{ij}\\) as the \\(i\\)–\\(j\\) entry of the matrix \\(A\\). 8.1 Solving linear systems revisited In the previous chapter, given a set of \\(m\\) linear equations with \\(n\\) variables \\[\\begin{align*} a_{11}x_1+a_{12}x_2+\\dotsb+a_{1n}x_n&amp;=b_1\\\\ a_{21}x_1+a_{22}x_2+\\dotsb+a_{2n}x_n&amp;=b_2\\\\ \\vdots\\qquad&amp;=\\,\\vdots\\\\ a_{m1}x_1+a_{m2}x_2+\\dotsb+a_{mn}x_n&amp;=b_m \\end{align*}\\] we introduced the coefficient matrix \\[ A= \\begin{pmatrix} a_{11}&amp;a_{12}&amp;\\dotsb&amp;a_{1n}\\\\ a_{21}&amp;a_{22}&amp;\\dotsb&amp;a_{2n}\\\\ \\vdots&amp;\\vdots&amp;\\dotsb&amp;\\vdots\\\\ a_{m1}&amp;a_{n2}&amp;\\dotsb&amp;a_{mn} \\end{pmatrix}. \\] We will now write the variables and r.h.s. as vectors of length \\(n\\) and \\(m\\) respectively \\[ \\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{pmatrix} \\qquad\\text{and}\\qquad \\mathbf{b} = \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{pmatrix}. \\] Next, we define the operation of multiplying a vector \\(\\mathbf{x}\\) of length \\(n\\) by an \\(m\\times n\\) matrix \\(A\\). The result is a vector of length \\(m\\) whose first entry is the sum of the element-wise products of the first row of \\(A\\) with the vector \\(\\mathbf{x}\\), the second entry is the sum of the element-wise products of the second row of \\(A\\) with the vector \\(\\mathbf{x}\\) and so on: \\[ A\\mathbf{x}=\\begin{pmatrix} a_{11}&amp;a_{12}&amp;\\dotsb&amp;a_{1n}\\\\ a_{21}&amp;a_{22}&amp;\\dotsb&amp;a_{2n}\\\\ \\vdots&amp;\\vdots&amp;\\dotsb&amp;\\vdots\\\\ a_{n1}&amp;a_{n2}&amp;\\dotsb&amp;a_{nn} \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{pmatrix} = \\begin{pmatrix} a_{11}x_1+a_{12}x_2+\\dotsb+a_{1n}x_n\\\\ a_{21}x_1+a_{22}x_2+\\dotsb+a_{2n}x_n\\\\ \\vdots\\\\ a_{m1}x_1+a_{m2}x_2+\\dotsb+a_{mn}x_n \\end{pmatrix} \\] Hence we can express the system of equations more compactly as \\[A\\mathbf{x}=\\mathbf{b}\\] where each row of the expanded equation corresponds to one of the linear equations. In the previous chapter we saw that solving such a system corresponds to finding the intersection points of the hyperplanes defined by these rows. We will call this the row picture of linear equations. However, there is another way to interpret \\(A\\mathbf{x}=\\mathbf{b}\\) in terms of column vectors. We must first introduce some new definitions. Definition 8.1 (Linear combinations) Consider a list of vectors \\[\\mathbf{v}_1, \\mathbf{v}_2,\\dotsc,\\mathbf{v}_n.\\] A linear combination of a list of vectors is a sum of the form \\[ \\alpha_1\\mathbf{v}_1+\\alpha_2\\mathbf{v}_2 + \\dotsb + \\alpha_n\\mathbf{v}_n \\] for some scalar coefficients \\(\\alpha_i\\). A list of vectors is called linearly independent if we cannot write one of the vectors as a linear combination of the others, such as \\[ \\mathbf{v}_i=\\alpha_1\\mathbf{v}_1+\\alpha_2\\mathbf{v}_2+\\dotsb+\\alpha_{i-1}\\mathbf{v}_{i-1}+\\alpha_{i+1}\\mathbf{v}_{i+1}+\\dotsb+\\alpha_n\\mathbf{v}_n \\] (none of the vectors depends on the others). The span of a list of vectors is all of the possible linear combinations. If we can reach any vector in the space by taking some linear combination then we say the vectors span the space. An intuitive way to think about linearly independent vectors is that they all point in “independent” directions. An intuitive way to think about the span is as all the points we can reach in the space by only walking in the directions of the list of vectors. Figure 8.1 demonstrates the concepts of linear combinations and span in 2-dimensions. Figure 8.1: Any vector \\(\\mathbf{u}\\) in the plane can be written as a linear combination of the vectors \\(\\mathbf{v}_1\\) and \\(\\mathbf{v}_2\\), that is \\(\\mathbf{u}=\\alpha_1\\mathbf{v}_1+\\alpha_2\\mathbf{v}_2\\). Drag the vector \\(\\mathbf{u}\\) to any point in the plane to see this decomposition. This means that \\(\\mathbf{v}_1\\) and \\(\\mathbf{v}_2\\) span the entire plane. You can also drag the vectors \\(\\mathbf{v}_1\\) and \\(\\mathbf{v}_2\\) and so long as these point in “independent directions” they still span the plane; if they lie along the same direction, then they only span a line.[Open plot in browser.] If we consider each column of the matrix \\(A\\) as a vector \\(\\mathbf{a}_i\\) of length \\(m\\), then the multiplication \\(A\\mathbf{x}\\) can also be written as \\[\\begin{align*} A\\mathbf{x}&amp;=x_1\\mathbf{a}_1 + x_2\\mathbf{a}_2 + \\dotsb + x_n\\mathbf{a}_n\\\\ &amp;=x_1 \\begin{pmatrix} a_{11} \\\\ a_{21} \\\\ \\vdots \\\\ a_{m1} \\end{pmatrix} + x_2 \\begin{pmatrix} a_{12} \\\\ a_{22} \\\\ \\vdots \\\\ a_{m2} \\end{pmatrix} + \\dotsb + x_n \\begin{pmatrix} a_{1n} \\\\ a_{2n} \\\\ \\vdots \\\\ a_{mn} \\end{pmatrix}\\\\ &amp;= \\begin{pmatrix} a_{11}x_1+a_{12}x_2+\\dotsb+a_{1n}x_n\\\\ a_{21}x_1+a_{22}x_2+\\dotsb+a_{2n}x_n\\\\ \\vdots\\\\ a_{m1}x_1+a_{m2}x_2+\\dotsb+a_{mn}x_n \\end{pmatrix}. \\end{align*}\\] That is, \\(A\\mathbf{x}\\) is the linear combination of the columns \\(\\mathbf{a}_i\\) with coefficients \\(x_i\\). We will call this the column picture of matrix equations. As we shall come to see, this different point of view is very powerful in understanding the nature of linear equations. Finding a solution to \\(A\\mathbf{x}=\\mathbf{b}\\) can now be interpreted as answering the question: can we find a linear combination of the column vectors of \\(A\\) that sum to give the vector \\(\\mathbf{b}\\)? Or in other words: is the vector \\(\\mathbf{b}\\) in the span of the columns of \\(A\\)? The question of unique solutions or infinitely many solutions becomes: is there one way or infinitely many ways to take a linear combination of the columns of \\(A\\) to reach the vector \\(\\mathbf{b}\\)? Or in other words: are the columns of \\(A\\) linearly independent? These questions can once again be answered from inspecting the REF of the augmented matrix. In the statements below we shall refer to the coefficient matrix part of the REF as the l.h.s. and the final augmented column as the r.h.s. If there is a row of zeros in the l.h.s. but a non-zero value in the corresponding row of the r.h.s., then there are no solutions (\\(\\mathbf{b}\\) is not in the span of the columns of \\(A\\)). If all zero rows in the l.h.s. have a zero in the corresponding row of the r.h.s, together with every column in the l.h.s. containing a leading entry, then there is a unique solution (\\(\\mathbf{b}\\) is in the span of the columns of \\(A\\) together with the columns being linearly independent). If all zero rows in the l.h.s. have a zero in the corresponding row of the r.h.s, but not every column in the l.h.s. contains a leading entry, then there are infinitely many solutions (\\(\\mathbf{b}\\) is in the span of the columns of \\(A\\) but the columns are linearly dependent). A list of vectors that both span the space and are linearly independent are called a basis. A basis can be used as a coordinate system. We generally use the standard basis consisting of the unit vectors \\(\\mathbf{i}, \\mathbf{j}\\) and \\(\\mathbf{k}\\). The coordinates of a vector \\(\\mathbf{v}\\) in this basis are the values \\(\\alpha_i\\) in the linear combination \\(\\mathbf{v}=\\alpha_1\\mathbf{i} + \\alpha_2\\mathbf{j} + \\alpha_3\\mathbf{k}\\). If we had a different basis \\(\\mathbf{p}, \\mathbf{q}, \\mathbf{r}\\) then we could also express \\(\\mathbf{v}\\) as \\(\\mathbf{v}=\\beta_1\\mathbf{p}+\\beta_2\\mathbf{q}+\\beta_3\\mathbf{r}\\) and specify points using \\(\\beta_1,\\beta_2\\) and \\(\\beta_3\\) as coordinates. 8.2 Determinants When we have a square coefficient matrix \\(A\\), we can find out if there exists a unique solution to \\(A\\mathbf{x}=\\mathbf{b}\\) for any possible vector \\(\\mathbf{b}\\) by computing a scalar quantity associated to \\(A\\) known as the determinant. For a \\(2\\times 2\\) matrix \\[ A = \\begin{pmatrix} a &amp; b\\\\ c &amp; d\\end{pmatrix} \\] we define the determinant of \\(A\\), written as \\(\\det(A)\\) or \\(|A|\\), as \\[ \\det(A) = \\begin{vmatrix} a &amp; b\\\\ c &amp; d\\end{vmatrix} = ad - bc. \\] Example 8.1 (2x2 determinants) For instance, we have \\[\\begin{align*} \\begin{vmatrix} 1 &amp; 5\\\\ 6 &amp; 2\\end{vmatrix} &amp;= 1\\times 2 - 5\\times 6 = -28,\\\\ \\begin{vmatrix} 2 &amp; -5\\\\ 7 &amp; 3\\end{vmatrix} &amp;= 2\\times 3 - (-5\\times 7) = 41,\\\\ \\begin{vmatrix} a &amp; \\frac{b}{2}\\\\ \\frac{b}{2} &amp; c\\end{vmatrix} &amp; = ac - \\frac{b^2}{4} = -\\frac{1}{4}(b^2 - 4ac). \\end{align*}\\] Higher-order determinants are defined recursively in terms of lower-order determinants. For instance, for a \\(3\\times 3\\) matrix, we define \\[ \\begin{vmatrix} a &amp; b &amp; c\\\\ d &amp; e &amp; f\\\\ g &amp; h &amp; i\\end{vmatrix} = a\\begin{vmatrix} e &amp; f\\\\ h &amp; i\\end{vmatrix} - b\\begin{vmatrix} d &amp; f\\\\ g &amp; i\\end{vmatrix} + c\\begin{vmatrix} d &amp; e\\\\ g &amp; h\\end{vmatrix}. \\] Note that the expression above contains three terms, each of which is the product of two factors: an entry of the matrix multiplied by a \\(2\\times 2\\) determinant. Each \\(2\\times 2\\) determinant is formed by crossing out the row and column containing the other factor. Also note the \\(-\\) sign in the second term. Example 8.2 (A 3x3 determinant) Compute the determinant of the matrix \\(A = \\left(\\begin{smallmatrix} 1 &amp; 2 &amp; 3\\\\ 4 &amp; 5 &amp; 6\\\\ 7 &amp; 8 &amp; 9\\end{smallmatrix}\\right)\\). \\[\\begin{align*} \\det(A) = \\begin{vmatrix} 1 &amp; 2 &amp; 3\\\\ 4 &amp; 5 &amp; 6\\\\ 7 &amp; 8 &amp; 9\\end{vmatrix} &amp;= 1\\begin{vmatrix} 5 &amp; 6\\\\ 8 &amp; 9\\end{vmatrix} - 2\\begin{vmatrix} 4 &amp; 6\\\\ 7 &amp; 9\\end{vmatrix} + 3\\begin{vmatrix} 4 &amp; 5\\\\ 7 &amp; 8\\end{vmatrix} \\\\ &amp;= 1\\left(5\\times 9-6\\times 8\\right) - 2\\left(4\\times 9 - 6\\times 7\\right) + 3(4\\times 8 - 5\\times 7)\\\\ &amp;= -3 - 2(-6)+3(-3)\\\\ &amp;=0 \\end{align*}\\] Theorem 8.1 (Unique solutions) Let \\(A\\) be a square matrix. There is a unique solution to \\(A\\mathbf{x}=\\mathbf{b}\\) for any vector \\(\\mathbf{b}\\) if and only if \\(\\det(A)\\neq 0\\). This gives us a useful test if we want to know if there are unique solutions for any vector \\(\\mathbf{b}\\). Note however that even if \\(\\det(A)=0\\) there could be solutions for a particular vector \\(\\mathbf{b}\\) – we would have to perform Guassian elimination to check. "],["linear-transformations.html", "Chapter 9 Linear Transformations 9.1 Matrix Algebra 9.2 Matrix inverse", " Chapter 9 Linear Transformations We have seen that we can formulate a system of linear equations as a matrix-vector equation \\[A\\mathbf{x}=\\mathbf{b}\\] and viewed this in two ways: as a compact way of expressing the system of linear equations: multiplying the vector \\(\\mathbf{x}\\) by the matrix \\(A\\), each row in the resulting vector equation is one of the linear equations as a vector equation with the l.h.s. being a linear combination of the columns of \\(A\\) We now introduce a third point of view: Multiplication by the matrix \\(A\\) acts as a function, taking the (vector) input \\(\\mathbf{x}\\) and returning the (vector) output \\(\\mathbf{b}\\). As a function, the matrix \\(A\\) represents a Linear Transformation. This is a type of function \\(f\\) whose inputs and outputs are vectors, with the following properties: \\(f(\\mathbf{x}_1+\\mathbf{x}_2)=f(\\mathbf{x}_1)+f(\\mathbf{x}_2)\\) for any two vectors \\(\\mathbf{x}_1\\) and \\(\\mathbf{x}_2\\) \\(f(\\lambda\\mathbf{x})=\\lambda f(\\mathbf{x})\\) for any scalar \\(\\lambda\\) and vector \\(\\mathbf{x}\\) Translating this to matrices: \\(A(\\mathbf{x}_1+\\mathbf{x}_2)=A\\mathbf{x}_1+A\\mathbf{x}_2\\) for any two vectors \\(\\mathbf{x}_1\\) and \\(\\mathbf{x}_2\\) \\(A(\\lambda\\mathbf{x})=\\lambda A\\mathbf{x}\\) for any scalar \\(\\lambda\\) and vector \\(\\mathbf{x}\\) Exercise: convice yourself that these properties hold by evaluating the left and right hand sides for a general \\(3\\times 3\\) matrix and confirming they are equal. Example 9.1 (Rotation about the origin) The following matrix rotates a vector by an angle \\(\\theta\\) anticlockwise about the origin. \\[R_\\theta=\\begin{pmatrix} \\cos(\\theta)&amp; -\\sin(\\theta)\\\\ \\sin(\\theta)&amp; \\cos(\\theta) \\end{pmatrix} \\] Figure 9.1: The action of \\(R_\\theta\\) on a vector \\(\\mathbf{v}\\) We can understand that this is a linear transformation geometrically, since: adding two vectors and then rotating is the same as rotating two vectors and then adding; taking a scalar multiple of a vector and then rotating is the same as rotating and then scaling. It turns out that all linear transformations can (in a certain sense) be decomposed as a rotation or reflection, followed by a coordinate scaling, followed by another rotation or reflection, as explained by the Singular Value Decomposition theorem. Of course not all functions have these special properties. Exercise: convince yourself that \\(f(x)=x^2\\) is not a linear transformation by finding values \\(x\\) and \\(y\\) (real numbers are 1-dimensional vectors) and a scalar \\(\\lambda\\) for which the above properties I. and II. do not hold. Now, if we were trying to solve an equation involving a function, say \\(f(x)=b\\), we would apply the inverse \\(f^{-1}\\) to both sides to get \\[\\begin{align*} f(x)&amp;=b\\\\ f^{-1}(f(x))&amp;=f^{-1}(b)\\\\ x&amp;=f^{-1}(b). \\end{align*}\\] Note this only works if \\(f^{-1}\\) exists – we know that not all functions have inverses10. We will soon show a condition for the existence of the inverse of a matrix \\(A\\), which we denote by \\(A^{-1}\\) and that is itself another matrix. We will then have another way to solve linear equations by applying the inverse matrix: \\[\\begin{align*} A\\mathbf{x}&amp;=\\mathbf{b}\\\\ A^{-1}(A\\mathbf{x})&amp;=A^{-1}\\mathbf{b}\\\\ \\mathbf{x}&amp;=A^{-1}\\mathbf{b}. \\end{align*}\\] First, we look at the algebra of matrices. 9.1 Matrix Algebra 9.1.1 Addition and Subtraction We can add and subtract two matrices, so long as the have the same dimensions \\(m\\times n\\). Then the sum and difference of two matrices \\(A\\) and \\(B\\) are \\[A+B=(a_{ij}+b_{ij}),\\qquad A-B=(a_{ij}-b_{ij}),\\] that is, we simply add or subtract the corresponding entries. Example 9.2 (Matrix Addition) Define the matrices \\(A\\) and \\(B\\) as \\[ A = \\begin{pmatrix} 2 &amp; 9 &amp; 6 \\\\ -1 &amp; 3 &amp; 5 \\end{pmatrix} \\qquad\\text{and}\\qquad B = \\begin{pmatrix} 0 &amp; 3 &amp; -1 \\\\ 2 &amp; 7 &amp; 8 \\end{pmatrix}. \\] Because the both matrices have dimensions \\(2 \\times 3\\), we may calculate \\[ A + B = \\begin{pmatrix} 2 &amp; 12 &amp; 5 \\\\ 1 &amp; 10 &amp; 13 \\end{pmatrix} \\qquad\\text{and}\\qquad A - B = \\begin{pmatrix} 2 &amp; 6 &amp; 7 \\\\ -3 &amp; -4 &amp; -3 \\end{pmatrix}. \\] Note, that matrix addition is commutative11, that is \\[ A + B = B + A. \\] 9.1.2 Multiplication by a scalar Let \\(A = (a_{ij})_{m\\times n}\\) be an \\(m\\times n\\) matrix and let \\(\\lambda\\) be a scalar. We define the matrix \\(\\lambda A\\) by \\[ (\\lambda A)_{ij} = \\lambda a_{ij}, \\] that is, we multiply every entry of \\(A\\) by \\(\\lambda\\). Example 9.3 (Scalar Multiplication) With \\(A\\) as in Example @ref(exm:mat_add), \\(\\lambda = 2\\) and \\(\\mu = -1\\), we have \\[ \\lambda A = 2A = \\begin{pmatrix} 4 &amp; 18 &amp; 12 \\\\ -2 &amp; 6 &amp; 10 \\end{pmatrix} \\qquad\\text{and}\\qquad \\mu A = -A = \\begin{pmatrix} -2 &amp;-9 &amp;-6 \\\\ 1 &amp; -3 &amp; -5\\end{pmatrix} \\] 9.1.3 Matrix multiplication We saw in section 8.1 how to multiply a vector by a matrix. This idea extends naturally to multiplying two matrices together as follows. Let \\(A = (a_{ij})_{m\\times l}\\) and \\(B = (b_{ij})_{l \\times n}\\). Then the matrix product \\(C = AB\\) is defined to be the matrix \\(AB = (c_{ij})_{m\\times n}\\) such that \\(c_{ij}\\) is the dot product of row \\(i\\) of \\(A\\) with column \\(j\\) of \\(B\\). That is, for all \\(i =1,\\dotsc, m\\) and all \\(j =1, \\dotsc, n\\), \\[ c_{ij} = a_{i1} b_{1j} + a_{i2} b_{2j} + \\dots + a_{il} b_{lj} \\] Note that the product \\(AB\\) is defined only if the number of columns of \\(A\\) is the equal to the number of rows of \\(B\\). The product matrix has the same number of rows as \\(A\\) and the same number of columns as \\(B\\). Example 9.4 (Matrix Multiplication) Let \\[ A = \\begin{pmatrix} 3 &amp; 2 &amp; -1\\\\ 0 &amp; 5 &amp; 4 \\end{pmatrix} \\qquad\\text{and}\\qquad B = \\begin{pmatrix} 1 &amp; 2 &amp; 4 &amp; 6\\\\ 5 &amp; 3 &amp; 0 &amp; 7\\\\ -1 &amp; -2 &amp; 1 &amp; 5 \\end{pmatrix}. \\] Then \\[ AB = \\begin{pmatrix} 3 &amp; 2 &amp; -1\\\\ 0 &amp; 5 &amp; 4 \\end{pmatrix} \\begin{pmatrix} 1 &amp; 2 &amp; 4 &amp; 6\\\\ 5 &amp; 3 &amp; 0 &amp; 7\\\\ -1 &amp; -2 &amp; 1 &amp; 5 \\end{pmatrix} = \\begin{pmatrix} 14 &amp; 14 &amp; 11 &amp; 27\\\\ 21 &amp; 7 &amp; 4 &amp; 55 \\end{pmatrix}. \\] Note that \\(A\\) is \\(2\\times3\\), that \\(B\\) is \\(3\\times 4\\) and that the product \\(AB\\) is a \\(2\\times 4\\) matrix. We have skipped the intermediate steps of multiplying all rows of \\(A\\) with all columns of \\(B\\), but to give an example, the \\(1\\)–\\(3\\) entry of \\(AB\\) is 11, which must be the dot product of the \\(1^\\text{st}\\) row of \\(A\\) and the \\(3^\\text{rd}\\) column of \\(B\\): \\[ \\begin{pmatrix} 3 &amp; 2 &amp; -1\\end{pmatrix} \\cdot \\begin{pmatrix} 4\\\\ 0\\\\ 1\\end{pmatrix} = 3 \\times 4 + 2 \\times 0 - 1\\times 1 = 11. \\] Unlike with ordinary (scalar) numbers, we do not normally have \\(AB = BA\\), that is Matrix multiplication is not commutative. Indeed, in the above example, \\(BA\\) is not even defined. The reason is that \\(B\\) has \\(4\\) columns, but \\(A\\) has \\(2\\) rows. 9.1.4 Functional interpretations Here we understand what the algebraic operations above mean when we are considering a matrix as a function. We let \\(A\\) and \\(B\\) be compatible matrices, \\(\\mathbf{x}\\) a vector and for comparison to other (non-linear) functions we take the examples \\(f(x)=x^2\\) and \\(g(x)=x^3\\). Addition/Subtraction \\[(A+B)\\mathbf{x}=A\\mathbf{x}+B\\mathbf{x}\\] This agrees with the usual definition of the sum of two functions, for example we have \\((f+g)(x)=f(x)+g(x)=x^2+x^3\\). Scalar multiplication \\[(\\lambda A)\\mathbf{x}=\\lambda (A \\mathbf{x})\\] Again this agrees with the usual definition for functions, for example \\((\\lambda f)(x)=\\lambda f(x)=\\lambda x^2\\). Matrix Multiplication \\[(AB)\\mathbf{x}=A(B\\mathbf{x})\\] Matrix multiplication corresponds to function composition, that is, first apply matrix \\(B\\) then apply matrix \\(A\\). In our example for non-linear functions, \\((f\\circ g)(x)=f(g(x))=f(x^3)=(x^3)^2=x^6\\) (where \\(\\circ\\) denotes function composition). When we have repeated multiplication of a matrix with itself \\(n\\) times we use the power notation: \\[A\\dotsb A=A^n\\] for example, \\(AA=A^2\\). 9.1.5 Two special matrices The \\(m\\times n\\) zero matrix \\(0_{m\\times n}\\) is defined as the \\(m\\times n\\) matrix which has only zero entries. Example 9.5 (Zero Matrix) For \\(m = 2\\) and \\(n = 3\\), we have \\[ 0_{m\\times n} = 0_{2\\times 3} = \\begin{pmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}, \\] and (in contrast) \\[ 0_{n\\times m} = 0_{3\\times 2} = \\begin{pmatrix} 0 &amp; 0\\\\ 0 &amp; 0 \\\\ 0 &amp; 0 \\end{pmatrix}. \\] Note that for any vector \\(\\mathbf{x}\\) of length \\(n\\), we have \\(0_{m\\times n} \\mathbf{x}=\\mathbf{0}_m\\). The \\(n\\times n\\) identity matrix \\(I_n\\), is defined by \\(I_n = (\\delta_{ij})_{n\\times n}\\), where \\(\\delta_{ij}\\) is given as \\[\\delta_{ij} = \\begin{cases} 1 &amp; \\text{if $i = j$,} \\\\ 0 &amp; \\text{if $i \\neq j$.} \\end{cases} \\] The function (or sometimes referred to as a “symbol”) \\(\\delta\\) of the two variables \\(i\\) and \\(j\\) is called the Kronecker delta and pops up often in pure and applied mathematics. Example 9.6 (Identity Matrix) For \\(n = 3\\), we have \\[ I_3 = \\begin{pmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix}. \\] Note that for any vector \\(\\mathbf{x}\\) of length \\(n\\), we have \\[I_n\\mathbf{x}=\\mathbf{x}.\\] 9.1.6 Some further properties Assuming the matrices \\(A, B, C\\) all have compatible dimensions and with \\(\\lambda, \\mu\\) being scalars, we have: \\(\\lambda(A+B)=\\lambda A + \\lambda B\\) \\((\\lambda + \\mu)A=\\lambda A +\\mu A\\) \\(I_m A = A\\) and \\(A I_n=A\\) \\(0_{l\\times m}A=0_{l\\times n}\\) and \\(A0_{n\\times p}=0_{m\\times p}\\) \\((AB)C=A(BC)\\) \\(A(B+C)=AB+AC\\) \\((A+B)C=AC+BC\\) Exercise: pick some matrices and check that these hold. 9.2 Matrix inverse We are now ready to discuss the matrix inverse. By definition, the inverse \\(f^{-1}\\) of a function \\(f\\) is the function that satisfies \\[f^{-1}(f(x))=x\\quad\\text{and}\\quad f(f^{-1}(y))=y\\] for all input values \\(x\\) and output values \\(y\\) (the function and its inverse “reverse” the action of one another.) For a matrix, function composition is given by matrix mutiplication, so the definition of the inverse matrix \\(A^{-1}\\) of a matrix \\(A\\) requires \\[A^{-1}A\\mathbf{x}=\\mathbf{x}\\quad\\text{and}\\quad AA^{-1}\\mathbf{y}=\\mathbf{y}\\] for all input vectors \\(\\mathbf{x}\\) and output vectors \\(\\mathbf{y}\\). It turns out12 this will only work for square matrices, that is, a matrix \\(A\\) with same number of rows and columns: an \\(n\\times n\\) matrix. This immediately implies that \\(A^{-1}\\) is also an \\(n\\times n\\) matrix. Now another way to express the matrix inverse is via the statement: \\[A^{-1}A=I_n=AA^{-1}\\] since applying \\(A\\) and its inverse \\(A^{-1}\\) has the same effect as applying the identity matrix. Exercise: Show that the matrix \\[ B = \\begin{pmatrix} 1 &amp; 0 &amp; 1 \\\\ 0 &amp; 2 &amp; 5 \\\\ 0 &amp; 1 &amp; 3 \\end{pmatrix} \\] is the inverse of the matrix \\[ A = \\begin{pmatrix} 1 &amp; 1 &amp; -2 \\\\ 0 &amp; 3 &amp; -5 \\\\ 0 &amp; -1 &amp; 2 \\end{pmatrix}. \\] by computing \\(AB\\) and \\(BA\\) and observing that \\(AB = BA = I_3\\). So \\(A\\) is invertible and \\(B=A^{-1}\\) is the inverse. It is important to note that not all (square) matrices are invertible. Example 9.7 (No inverse) Consider the matrix \\[ A = \\begin{pmatrix} 1 &amp; -1 \\\\ -1 &amp; 1 \\end{pmatrix}. \\] Assume that there exist \\(a,b,c,d\\), such that \\[ B = \\begin{pmatrix} a &amp; b \\\\ c &amp; d \\end{pmatrix} \\] is an inverse of \\(A\\). For this, we require that \\[ \\begin{pmatrix} 1 &amp; -1 \\\\ -1 &amp; 1 \\end{pmatrix} \\begin{pmatrix} a &amp; b \\\\ c &amp; d \\end{pmatrix} = \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix}. \\] That is, we require that \\[ \\begin{pmatrix} a - c &amp; b - d \\\\ -a + c &amp; -b + d \\end{pmatrix} = \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix}. \\] Comparing the entries in the left-most column of the matrices on the left- and right-hand sides of the above matrix equation, we deduce that, both \\[ a - c = 1 \\qquad\\text{and}\\qquad -a + c = 0, \\] which, adding both equations, gives \\(0 = 1\\), which is not true. Thus, assuming that \\(A\\) has an inverse leads to a contradiction, so there cannot be an inverse of \\(A\\) 9.2.1 Finding the inverse of a \\(2\\times 2\\) matrix We start by presenting the formula for the inverse of a \\(2\\times 2\\) matrix, which is relatively straightforward. Then we will discuss how to find the inverse of a general \\(n\\times n\\) matrix, which is more involved, in the next section. Theorem 9.1 (Inverse of a 2 x 2 matrix) Let \\(A\\) be the \\(2\\times 2\\) matrix \\[A=\\begin{pmatrix} a&amp;b\\\\ c&amp;d \\end{pmatrix}\\] with \\(\\det(A)=ad-bc\\neq 0\\). Then \\(A\\) is invertible, with inverse \\[A^{-1}=\\frac{1}{\\det(A)}\\begin{pmatrix} d&amp;-b\\\\ -c&amp;a \\end{pmatrix}.\\] Note that the formula only makes sense if \\(\\det(A)\\neq 0\\). It turns out that the condition \\(\\det(A)\\neq 0\\) is precisely the condition that must be satisfied for invertibility (for any size matrix). Theorem 9.2 (Existence of matrix inverse) An \\(n\\times n\\) matrix \\(A\\) is invertible if and only if \\(\\det(A)\\neq 0\\). If \\(A\\) is not invertible, then we say that \\(A\\) is singular. This is analagous to not being able to divide by zero in the one-dimensional case: we cannot solve \\(ax=b\\) if \\(a=0\\). Example 9.8 (2 x 2 inverse examples) Let \\[A = \\begin{pmatrix} 1 &amp; 5 \\\\ 2 &amp; 10 \\end{pmatrix}.\\] The determinant of \\(A\\) is \\(\\det(A) = 1\\times 10 - 5\\times 2 = 0\\). Thus \\(A\\) is singular. Let \\[M = \\begin{pmatrix} 7 &amp; 3 \\\\ 2 &amp; 3 \\end{pmatrix}.\\] We have \\(\\det(M) = 15\\), hence, \\(M\\) is invertible and its inverse is \\[M^{-1} = \\frac{1}{15} \\begin{pmatrix} 3 &amp; -3 \\\\ -2 &amp; 7 \\end{pmatrix}.\\] 9.2.2 Finding the inverse of an \\(n\\times n\\) matrix There does exist a formula that is a generalisation of that for \\(2\\times 2\\) matrices, based on Cramer’s Rule. This is important in the theory of matrices, but not very useful in practice for large matrices. Hence we present a different way of computing the inverse, via Guassian elimination. For the moment, denote \\(X=A^{-1}\\). We are looking for \\(X\\) such that \\(AX=I_n\\) and \\(XA=I_n\\). It turns out that if \\(X\\) satisfies either one of these equations then it is the unique inverse, so we shall just consider \\(AX=I_n\\). By the rules of matrix multiplication, the first column of \\(I_n\\) is the result of taking the dot product of the rows of \\(A\\) with the first column of \\(X\\). Denoting the \\(i^\\text{th}\\) row of \\(A\\) by \\(\\mathbf{a}_i\\) and the \\(j^\\text{th}\\) column of \\(X\\) by \\(\\mathbf{x}_j\\), we have \\[ A\\mathbf{x}_1= \\begin{pmatrix} \\mathbf{a}_1\\cdot \\mathbf{x}_1\\\\ \\mathbf{a}_2\\cdot \\mathbf{x}_1\\\\ \\vdots\\\\ \\mathbf{a}_n\\cdot \\mathbf{x}_1\\ \\end{pmatrix} = \\begin{pmatrix} 1\\\\ 0\\\\ \\vdots\\\\ 0 \\end{pmatrix}. \\] More generally, \\[ A\\mathbf{x}_j= \\begin{pmatrix} \\mathbf{a}_1\\cdot \\mathbf{x}_j\\\\ \\mathbf{a}_2\\cdot \\mathbf{x}_j\\\\ \\vdots\\\\ \\mathbf{a}_n\\cdot \\mathbf{x}_j\\ \\end{pmatrix} = \\begin{pmatrix} \\delta_{1j}\\\\ \\delta_{2j}\\\\ \\vdots\\\\ \\delta_{nj} \\end{pmatrix}. \\] These are just standard matrix–vector equations of the form “\\(A\\mathbf{x}=\\mathbf{b}\\)”, which we can solve using Guassian elimination to find the columns \\(\\mathbf{x}_j\\). Moreover, instead of doing this one column at a time, we can solve for all columns at once, as in the following example. Example 9.9 (Inverse via Gaussian elimination) Consider the matrix \\[ A = \\begin{pmatrix} 1 &amp; 0 &amp; 1 \\\\ 0 &amp; 2 &amp; 5 \\\\ 0 &amp; 1 &amp; 3 \\end{pmatrix}. \\] We wish to find the inverse of \\(A\\). That is, we wish to find a \\(3\\times 3\\) matrix \\(X\\) such that \\(AX = I_3\\). Writing \\(\\mathbf{x}_1, \\mathbf{x}_2\\) and \\(\\mathbf{x}_3\\) for the columns of \\(X\\), this is equivalent to solving the \\(3\\) matrix–vector equations \\[ A\\mathbf{x}_1 = \\mathbf{e}_1, \\qquad A\\mathbf{x}_2 = \\mathbf{e}_2 \\qquad\\text{and}\\qquad A\\mathbf{x}_3 = \\mathbf{e}_3 \\] where \\[\\mathbf{e}_j= \\begin{pmatrix} \\delta_{1j}\\\\ \\delta_{2j}\\\\ \\delta_{3j}\\\\ \\end{pmatrix}. \\] Note \\(\\mathbf{e}_1=\\mathbf{i}, \\mathbf{e}_2=\\mathbf{j}, \\mathbf{e}_3=\\mathbf{k}\\), the newly introduced indexed notation \\(\\mathbf{e}_i\\) is just more convenient for extending to arbitrary dimensions. We could set this up for Gaussian elimination via the \\(3\\) augmented matrices \\[ \\left(A\\ |\\ \\mathbf{e}_1\\right), \\qquad \\left(A\\ |\\ \\mathbf{e}_2\\right) \\qquad\\text{and}\\qquad \\left(A\\ |\\ \\mathbf{e}_3\\right) \\] and then perform EROs to transform the above augmented matrices to the form \\[ \\left(I_3\\ | \\mathbf{x}_1\\right), \\qquad \\left(I_3\\ |\\ \\mathbf{x}_2\\right) \\qquad\\text{and}\\qquad \\left(I_3\\ |\\ \\mathbf{x}_3\\right), \\] allowing us to read off the solutions \\(\\mathbf{x}_1\\), \\(\\mathbf{x}_2\\) and \\(\\mathbf{x}_3\\). However, these will all require the same EROs, and so we can compute all three vectors \\(\\mathbf{x}_1\\), \\(\\mathbf{x}_2\\) and \\(\\mathbf{x}_3\\) at the same time by starting with the following augmented matrix \\[ \\left(A\\ |\\ \\mathbf{e}_1 \\ \\mathbf{e}_2 \\ \\mathbf{e}_3\\right), \\] and then perform EROs to bring it into the reduced echelon form \\[ \\left(I_3\\ |\\ \\mathbf{x}_1\\ \\mathbf{x}_2\\ \\mathbf{x}_3\\right). \\] For the above matrix \\(A\\), the augmented matrix \\((A\\ |\\ I_3)\\) is given by \\[ \\left(\\begin{array}{rrr|rrr} 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 2 &amp; 5 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 3 &amp; 0 &amp; 0 &amp; 1 \\end{array}\\right). \\] First, we swap rows \\(2\\) and \\(3\\), which gives \\[ \\begin{array}{l} \\quad\\\\ \\quad\\\\ R_2 \\leftrightarrow R_3\\colon \\quad \\end{array} \\left(\\begin{array}{rrr|rrr} 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 3 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 2 &amp; 5 &amp; 0 &amp; 1 &amp; 0 \\end{array}\\right). \\] As there are only zeros below the leading entry in row \\(1\\), we proceed to eliminate the entry under the leading entry in row \\(2\\), that is \\[ \\begin{array}{l} \\quad\\\\ \\quad\\\\ R_3 \\to R_3 - 2R_2\\colon\\quad \\end{array} \\left(\\begin{array}{rrr|rrr} 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 3 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; -1 &amp; 0 &amp; 1 &amp; -2 \\end{array}\\right). \\] Next, we eliminate the entries above the leading entry in row \\(3\\), which yields \\[ \\begin{array}{l} R_1 \\to R_1 + R_3\\colon\\quad \\\\ R_2 \\to R_2 + 3R_2\\colon\\quad \\\\ \\quad \\end{array} \\left(\\begin{array}{rrr|rrr} 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; -2 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 3 &amp; -5 \\\\ 0 &amp; 0 &amp; -1 &amp; 0 &amp; 1 &amp; -2 \\end{array}\\right). \\] Finally, we multiply row \\(3\\) by \\(-1\\) to arrive at \\[ \\begin{array}{l} \\quad \\\\ \\quad \\\\ R_3 \\to -R_3\\colon\\quad \\end{array} \\left(\\begin{array}{rrr|rrr} 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; -2 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 3 &amp; -5 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 &amp; 2 \\end{array}\\right). \\] We read off the solutions \\[ \\mathbf{x}_1 = \\begin{pmatrix} 1\\\\ 0\\\\ 0\\end{pmatrix}, \\qquad \\mathbf{x}_2 = \\begin{pmatrix} 1\\\\ 3\\\\ -1\\end{pmatrix} \\qquad\\text{and}\\qquad \\mathbf{x}_3 = \\begin{pmatrix} -2\\\\ -5\\\\ 2\\end{pmatrix}. \\] This corresponds to \\[ X = \\begin{pmatrix} 1 &amp; 1 &amp; -2 \\\\ 0 &amp; 3 &amp; -5 \\\\ 0 &amp; -1 &amp; 2\\end{pmatrix}. \\] It can easily be checked that \\(AX = I_3 = XA\\), so \\(X\\) is the inverse of \\(A\\). Note that in the case of a singular matrix, this would be revealed in the above Gaussian elimination by yeilding an inconsistent set of equations. The advantage of having the matrix inverse is that we can now compute the solutions to \\(A\\mathbf{x}=\\mathbf{y}\\) for any vector \\(\\mathbf{y}\\) and we only had to perform the Guassian elimintation process once. Sometimes we make do with so called partial inverses as we have for the inverse trigonometric functions and the square root function.↩︎ The technical term for the fact that we can swap the order.↩︎ Due to the rank-nullity theorem.↩︎ "],["eigenvalues-and-eigenvectors.html", "Chapter 10 Eigenvalues and Eigenvectors 10.1 Matrix Diagonalisation 10.2 Finding Eigenvalues 10.3 Finding Eigenvectors 10.4 Powers of diagonalisable matrices", " Chapter 10 Eigenvalues and Eigenvectors Some linear transformations have “natural directions” associated with them. Example 10.1 Let \\[ A = \\begin{pmatrix} 1 &amp; 1 \\\\ 2 &amp; 0 \\end{pmatrix}, \\] We can see that \\[ A \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 &amp; 1 \\\\ 2 &amp; 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}. \\] Thus, it follows that \\[ A\\mathbf{u}_1 = 2 \\mathbf{u}_1, \\qquad \\text{where }\\quad\\mathbf{u}_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}. \\] Moreover, we have \\[ A \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} 1 &amp; 1 \\\\ 2 &amp; 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\2\\end{pmatrix}, \\] and so \\[ A\\mathbf{u}_2 = -\\mathbf{u}_2, \\qquad \\text{where }\\quad \\mathbf{u}_2 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}. \\] The above example shows that there are vectors associated to a matrix, which, when multiplied with the matrix from the left, are only scaled by a factor. This motivates the following definition. Definition 10.1 (Eigenvalues and Eigenvectors) Let \\(A\\) be an \\(n\\times n\\) matrix. Then a non-zero vector \\(\\mathbf{u}\\) is said to be an eigenvector of \\(A\\) if there exists a scalar \\(\\lambda\\) such that \\[ A\\mathbf{u} = \\lambda \\mathbf{u} \\] The scalar \\(\\lambda\\) is called the eigenvalue associated to \\(\\mathbf{u}\\). Example 10.2 In Example 10.1, we have that \\(\\mathbf{u}_1 = \\left(\\begin{smallmatrix}1\\\\1\\end{smallmatrix}\\right)\\) is an eigenvector associated with an eigenvalue \\(\\lambda_1 = 2\\), and that \\(\\mathbf{u}_2 = \\left(\\begin{smallmatrix}1\\\\-2\\end{smallmatrix}\\right)\\) is an eigenvector associated with an eigenvalue \\(\\lambda_2 = -1\\). We claim that any vector may be written as a linear combination of \\(\\mathbf{u}_1\\) and \\(\\mathbf{u}_2\\). That is, for all \\(\\mathbf{v}\\), there exist scalars \\(x_1, x_2\\) such that \\[ x_1 \\mathbf{u}_1 + x_2 \\mathbf{u}_2 = \\mathbf{v}. \\] Write \\(\\mathbf{x} = \\left(\\begin{smallmatrix}x_1\\\\ x_2\\end{smallmatrix}\\right)\\), then we may write the above equation as \\(B \\mathbf{x} = \\mathbf{v}\\), where \\(B = (\\mathbf{u}_1 \\ \\mathbf{u}_2)\\), i.e. the columns of the matrix \\(B\\) are \\(\\mathbf{u}_1\\) and \\(\\mathbf{u}_2\\). Note that \\[ \\det(B) = \\begin{vmatrix} 1 &amp; 1 \\\\ 1 &amp; -2 \\end{vmatrix} = -2 -1 = -3, \\] which is non-zero, hence the matrix is invertible, and so the equation \\(B \\mathbf{x} = \\mathbf{v}\\) has the (unique) solution \\(\\mathbf{x} = B^{-1} \\mathbf{v}\\). The matrix \\(B\\) being invertible is equivalent to saying that \\(\\mathbf{u}_1\\) and \\(\\mathbf{u}_2\\) are linearly independent. Having shown that any vector \\(\\mathbf{v}\\) may be written as a (unique) linear combination of \\(\\mathbf{u}_1\\) and \\(\\mathbf{u}_2\\), we apply \\(A\\) to both sides of and deduce \\[\\begin{align*} A\\mathbf{v} &amp;= A(x_1 \\mathbf{u}_1 + x_2 \\mathbf{u}_2)\\\\ &amp;= x_1 A\\mathbf{u}_1 + x_2 A\\mathbf{u}_2\\\\ &amp;= \\lambda _1 x_1 \\mathbf{u}_1 + \\lambda_2 x_2 \\mathbf{u}_2, \\end{align*}\\] where we use the facts \\(A\\mathbf{u}_1 = \\lambda_1 \\mathbf{u}_1\\) and \\(A\\mathbf{u}_2 = \\lambda_2 \\mathbf{u}_2\\) for the last equality. Hence if we write a vector \\(\\mathbf{v}\\) in terms of the eigenvectors \\(\\mathbf{u}_1\\) and \\(\\mathbf{u}_2\\), it is simple to calculate the result of multiplying by the matrix \\(A\\): we simply multiply these components by their eigenvalues. That is, we just strech/compress by a factor \\(\\lambda_i\\) in the \\(\\mathbf{u}_i\\) direction (and reverse direction if \\(\\lambda_i\\) is negative). 10.1 Matrix Diagonalisation Definition 10.2 (Diagonal Matrix) A square matrix is said to be a diagonal matrix if its non-diagonal entries are zero. That is, a matrix of the form \\[ D = \\begin{pmatrix} \\lambda_1 &amp; 0 &amp; 0 &amp; \\dotsb &amp; 0\\\\ 0 &amp; \\lambda_2 &amp; 0 &amp;\\dotsb &amp; 0\\\\ \\vdots &amp; &amp;\\ddots &amp; &amp; \\vdots\\\\ 0&amp; &amp; \\dotsb &amp; &amp; \\lambda_n\\\\ \\end{pmatrix} \\] for any scalars \\(\\lambda_1,\\dotsc,\\lambda_n\\). Consider the diagonal matrix \\[ D = \\begin{pmatrix} \\lambda_1 &amp; 0 \\\\ 0 &amp; \\lambda_2 \\end{pmatrix} = \\begin{pmatrix} 2 &amp; 0 \\\\ 0 &amp; -1 \\end{pmatrix}, \\] Note that this acts very simply on a vector \\(\\mathbf{x}=\\left(\\begin{smallmatrix}x_1\\\\x_2\\end{smallmatrix}\\right)\\): \\[ D\\mathbf{x}= \\begin{pmatrix} \\lambda_1 &amp; 0 \\\\ 0 &amp; \\lambda_2 \\end{pmatrix} \\begin{pmatrix}x_1\\\\x_2\\end{pmatrix} =\\begin{pmatrix} \\lambda_1 x_1\\\\ \\lambda_2 x_2 \\end{pmatrix} = \\begin{pmatrix} 2 x_1\\\\ -x_2 \\end{pmatrix} \\] it simply multiplies each element of the vector by a value on the diagonal. This is reminiscent of the action of \\(A\\) on We’ll now look at an example to understand the meaning of the term “diagonalising a matrix”. Example 10.3 Suppose that we write a vector \\(\\mathbf{v} = x_1 \\mathbf{u}_1 + x_2 \\mathbf{u}_2\\) in terms of the eigenvectors \\(\\mathbf{u}_1\\) and \\(\\mathbf{u}_2\\) from example (exm:eigen2). We say that \\(\\mathbf{v}\\) has the coordinate vector \\[\\mathbf{x}_{\\mathcal{P}}=\\begin{pmatrix}x_1\\\\x_2\\end{pmatrix}\\] with respect to the vectors13 \\(\\mathcal{P}=[\\mathbf{u}_1,\\mathbf{u}_2]\\) – these vectors take the place of the usual vectors \\(\\mathcal{E}=[\\mathbf{e}_1,\\mathbf{e}_2]\\) (although note that the vectors in \\(\\mathcal{P}\\) are not unit vectors here). We may write \\(\\mathbf{v}\\) as \\[ \\mathbf{v} = P \\mathbf{x}_\\mathcal{P}, \\] where \\(P = (\\mathbf{u}_1\\; \\mathbf{u}_2)\\) is the matrix whose columns are the vectors \\(\\mathbf{u}_1\\) and \\(\\mathbf{u}_2\\). Consider an exemplar vector \\[ \\mathbf{v} = 5 \\mathbf{u}_1 - 3 \\mathbf{u}_2= 2 \\mathbf{e}_1 + 11 \\mathbf{e}_2 \\] Then \\(\\mathbf{v}\\) has co-ordinate vector \\(\\mathbf{x}_\\mathcal{P}=(5,-3)\\) and \\[ \\mathbf{v} = P \\begin{pmatrix} 5 \\\\ -3 \\end{pmatrix} = \\begin{pmatrix} 1 &amp; 1 \\\\ 1 &amp; -2 \\end{pmatrix} \\begin{pmatrix} 5 \\\\ -3 \\end{pmatrix} = \\begin{pmatrix} 2\\\\ 11\\end{pmatrix} \\] We have seen that \\(A\\) acts very simply in these coordinates: \\[ A\\mathbf{v}=\\lambda _1 x_1 \\mathbf{u}_1 + \\lambda_2 x_2 \\mathbf{u}_2 \\] and writing this result as a coordinate vector with respect to \\(\\mathcal{P}\\) we would have \\[ (A\\mathbf{v})_\\mathcal{P}= \\begin{pmatrix} \\lambda_1 x_1\\\\ \\lambda_2 x_2 \\end{pmatrix} \\] We can see that \\(A\\) acts like a diagonal matrix in the coordinates \\(\\mathcal{P}\\). If we defined \\[D=\\begin{pmatrix} \\lambda_1 &amp; 0 \\\\ 0 &amp; \\lambda_2 \\end{pmatrix}\\] then note that \\(D\\) acts on the coordinate vector as \\[D\\mathbf{x}_\\mathcal{P}= \\begin{pmatrix} \\lambda_1 &amp; 0 \\\\ 0 &amp; \\lambda_2 \\end{pmatrix} \\begin{pmatrix} x_1\\\\ x_2 \\end{pmatrix} =\\begin{pmatrix} \\lambda_1 x_1\\\\ \\lambda_2 x_2 \\end{pmatrix} \\] Since the matrix \\(P\\) converts between coordinates \\(\\mathcal{P}\\) and standard coordinates \\(\\mathcal{E}\\), that is \\(\\mathbf{v}=P\\mathbf{x}_\\mathcal{P}\\), we can see that \\(P^{-1}\\) converts in the other direction \\(\\mathbf{x}_\\mathcal{P}=P^{-1}\\mathbf{v}\\). We can use this to write \\(A\\) as \\[A=PDP^{-1}.\\] This decomposes \\(A\\mathbf{v}\\) into three operations \\(PDP^{-1}\\mathbf{v}\\): Apply \\(P^{-1}\\) to convert \\(\\mathbf{v}\\) to \\(P^{-1}\\mathbf{v}=\\mathbf{x}_\\mathcal{P}\\); Now apply the diagonal matrix \\(D\\) to \\(\\mathbf{x}_\\mathcal{P}\\), which simply multiplies each component by the eigenvalue \\(\\lambda_i\\); Finally, convert back to standard coordinates by applying \\(P\\) to give the result \\(A\\mathbf{v}\\). We call the matrix \\(D\\) the diagonalisation of the matrix \\(A\\). Note that \\(D\\) can be obtained by applying \\(P^{-1}\\) to the left and \\(P\\) to the right of the above equation to obtain: \\[P^{-1}AP=P^{-1}PDP^{-1}P=D.\\] (using \\(P^{-1}P=I\\)). Theorem 10.1 (Diagonalisation) Let \\(A\\) be an \\(n\\times n\\) matrix with \\(n\\) eigenvectors \\(\\mathbf{u}_1, \\dots, \\mathbf{u}_n\\) with corresponding eigenvalues \\(\\lambda_1, \\dotsc, \\lambda_n\\). If the matrix \\(P=(\\mathbf{u}_1 \\dotsb \\mathbf{u}_n)\\) is invertible (in other words, the eigenvectors are linearly independent) then \\[ D = P^{-1}A P, \\] where \\(D\\) is the diagonal matrix whose \\(i\\)-th diagonal entry is \\(\\lambda_i\\). We say that \\(A\\) is diagonalisable. It is worth noting here that it is not always possible to diagonalise a matrix. We shall see an example later. 10.2 Finding Eigenvalues Suppose \\(\\mathbf{u}\\) is an eigenvector of a matrix \\(A\\) with associated eigenvalue \\(\\lambda\\). This means that \\(\\mathbf{u}\\) is a non-zero vector such that \\(A\\mathbf{u} = \\lambda \\mathbf{u}\\). Equally, \\[\\begin{array}{rrcl} &amp; \\lambda \\mathbf{u} - A \\mathbf{u} &amp;=&amp; \\mathbf{0} \\\\ \\Longleftrightarrow\\qquad &amp; \\lambda I_n \\mathbf{u} - A\\mathbf{u} &amp;=&amp; \\mathbf{0} \\\\ \\Longleftrightarrow\\qquad &amp; (\\lambda I_n-A) \\mathbf{u} &amp;=&amp; \\mathbf{0}. \\end{array}\\] Setting \\(B_{\\lambda} = \\lambda I_n - A\\), we have that \\(\\lambda\\) is an eigenvalue of \\(A\\) if, and only if, \\(B_{\\lambda}\\mathbf{u} = \\mathbf{0}\\) has a non-zero solution \\(\\mathbf{u}\\). Recall that for a general square matrix \\(M\\), the matrix–vector system \\(M \\mathbf{v} = \\mathbf{b}\\) has a unique solution for \\(\\mathbf{v}\\) if, and only if, \\(\\det(M) \\neq 0\\). Note the system \\(B_{\\lambda} \\mathbf{v} = \\mathbf{0}\\) always has at least one solution, namely \\(\\mathbf{v} = \\mathbf{0}\\), so the system has a non-zero solution if, and only if, it has more than one solution, which is equivalent to \\(\\det(B_{\\lambda}) = 0\\). We use this fact to find eigenvalues, as shown in the following example. Example 10.4 (Finding Eigenvalues) Let \\[ A = \\begin{pmatrix} 1 &amp; 1 \\\\ 2 &amp; 0 \\end{pmatrix}. \\] Then the matrix \\(B_{\\lambda} = \\lambda I_{2} - A\\) is given as \\[ B_{\\lambda} = \\begin{pmatrix} \\lambda - 1 &amp; -1 \\\\ -2 &amp; \\lambda \\end{pmatrix}. \\] Then we have \\[\\begin{align*} \\det(B_{\\lambda}) &amp;= \\lambda(\\lambda-1) - 2 \\\\ &amp;= \\lambda^2 - \\lambda - 2 \\\\ &amp;= (\\lambda - 2)(\\lambda + 1). \\end{align*}\\] Thus, \\(\\lambda\\) is an eigenvalue of \\(A\\) if and only if \\[ 0 = (\\lambda - 2)(\\lambda + 1), \\] and equivalently if and only if \\(\\lambda = 2\\) or \\(\\lambda = -1\\). Hence, the eigenvalues of \\(A\\) are \\[ \\lambda_1 = 2 \\qquad\\text{and}\\qquad \\lambda_2 = -1. \\] Note, that in the above example \\(\\det(B_\\lambda)\\) is a polynomial of degree 2 in the variable \\(\\lambda\\). We can generalise this observation. Definition 10.3 (Characteristic Polynomial) Let \\(A\\) be an \\(n\\times n\\) matrix. Then the function \\[ p_A(\\lambda)=\\det(\\lambda I_n - A) \\] is a polynomial of degree \\(n\\) in the variable \\(\\lambda\\). We call this polynomial \\(p_A\\) the characteristic polynomial of \\(A\\). So in general, we can find the eigenvalues of a square matrix \\(A\\) by finding the roots of the characteristic polynomial \\(p_A\\), which is obtained from computing the determinant \\(\\det(\\lambda I_n - A)\\). 10.3 Finding Eigenvectors Example 10.5 (Finding Eigenvectors) Let again \\[ A = \\begin{pmatrix} 1 &amp; 1 \\\\ 2 &amp; 0 \\end{pmatrix}. \\] We know from above that \\(\\lambda_1 = 2\\) and \\(\\lambda_2 = -1\\) are the eigenvalues of \\(A\\). We first find an eigenvector corresponding to \\(\\lambda_1\\). Any non-zero solution \\(\\mathbf{v} = \\left(\\begin{smallmatrix}v_1\\\\v_2\\end{smallmatrix}\\right)\\) of the equation \\(B_2 \\mathbf{v} = \\mathbf{0}\\) is such an eigenvector. For \\(\\lambda = \\lambda_1 = 2\\), we have \\[ B_2 = \\begin{pmatrix} 1 &amp; -1 \\\\ -2 &amp; 2 \\end{pmatrix}. \\] We solve \\(B_2 \\mathbf{v} = \\mathbf{0}\\) via Gaussian elimination. The augmented matrix for \\(B_2 \\mathbf{v} = \\mathbf{0}\\) is given by \\[ \\left(\\begin{array}{rr|r} 1 &amp; -1 &amp; 0 \\\\ -2 &amp; 2 &amp; 0 \\end{array}\\right). \\] We perform the ERO \\(R_2 \\to R_2 + 2R_1\\) to obtain \\[ \\left(\\begin{array}{rr|r} 1 &amp; -1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] From this, we see that \\(v_2\\) is arbitrary, say \\(v_2 = \\alpha\\), and \\(v_1 = v_2 = \\alpha\\). So, the eigenvectors corresponding to the eigenvalue \\(\\lambda_1 = 2\\) are given by the set \\[ \\alpha \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\] for any non-zero value of \\(\\alpha\\). By a similar process, we find an eigenvector corresponding to \\(\\lambda_2 = -1\\). Any non-zero solution \\(\\mathbf{v} = \\left(\\begin{smallmatrix}v_1\\\\v_2\\end{smallmatrix}\\right)\\) of the equation \\(B_{-1} \\mathbf{v} = \\mathbf{0}\\) is such an eigenvector. We have \\[ B_{-1} = \\begin{pmatrix} -2 &amp; -1 \\\\ -2 &amp; -1\\end{pmatrix}, \\] and again solve \\(B_{-1} \\mathbf{v} = \\mathbf{0}\\) via Gaussian elimination to give the eigenvectors corresponding to \\(\\lambda_2 = -1\\) as \\[ \\beta \\begin{pmatrix} 1 \\\\ -2\\end{pmatrix} \\] for any non-zero value of \\(\\beta\\). Note that there are infinitely many eigenvectors corresponding to an eigenvalue, because if a non-zero vector \\(\\mathbf{v}\\) satisfies \\(B_{\\lambda} \\mathbf{v} = \\mathbf{0}\\), then any multiple of \\(\\mathbf{v}\\), i.e. \\(\\mu\\mathbf{v}\\) for any \\(\\mu \\neq 0\\) satisfies the equation, too, as we have \\(B_{\\lambda} (\\mu\\mathbf{v}) = \\mu (B_{\\lambda}{\\mathbf{v}}) = \\mu\\mathbf{0} = \\mathbf{0}\\). In order to obtain specific eigenvectors, we simply need to set \\(\\alpha\\) and \\(\\beta\\) to some non-zero value, for which we usually simply take \\(\\alpha=1\\) and \\(\\beta=1\\). Hence two suitable eigenvectors of \\(A\\) are \\[ \\mathbf{u}_1=\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\quad\\text{ and }\\quad \\mathbf{u}_2=\\begin{pmatrix} 1 \\\\ -2\\end{pmatrix} \\] With the following example, we demonstrate how to find the eigenvalues and eigenvectors for a \\(3\\times 3\\) matrix. Example 10.6 Let \\(A\\) be given by \\[ A = \\begin{pmatrix} 1 &amp; 0 &amp; -1 \\\\ 1 &amp; 2 &amp; 1 \\\\ 2 &amp; 2 &amp; 3 \\end{pmatrix}. \\] Then \\(A\\) has characteristic polynomial \\[\\begin{align*} p_A(\\lambda) &amp;= \\det(\\lambda I_3 - A) \\\\ &amp;= \\begin{vmatrix} \\lambda - 1 &amp; 0 &amp; 1 \\\\ -1 &amp; \\lambda - 2 &amp; -1 \\\\ -2 &amp; -2 &amp; \\lambda - 3 \\end{vmatrix}. \\end{align*}\\] We have: \\[\\begin{align*} p_A(\\lambda) &amp;= (\\lambda - 1) \\begin{vmatrix} \\lambda -2 &amp; -1 \\\\ -2 &amp; \\lambda -3 \\end{vmatrix} + \\begin{vmatrix} -1 &amp; \\lambda -2 \\\\ -2 &amp; -2 \\end{vmatrix}\\\\ &amp;= (\\lambda - 1)\\big( (\\lambda - 2)(\\lambda - 3) - 2 \\big) + (2 + 2(\\lambda - 2)) \\\\ &amp;= (\\lambda - 1)(\\lambda^2 - 5 \\lambda + 4) + 2(\\lambda - 1) \\\\ &amp;= (\\lambda - 1)(\\lambda^2 - 5 \\lambda + 6) \\\\ &amp;= (\\lambda - 1)(\\lambda - 2)(\\lambda - 3). \\end{align*}\\] Therefore, we find that \\(A\\) has eigenvalues \\(\\lambda_1 = 1\\), \\(\\lambda_2 = 2\\) and \\(\\lambda_3 = 3\\). It remains to find the eigenvectors of \\(A\\). Recall that, for each eigenvalue \\(\\lambda\\), this is equivalent to finding all non-zero solutions \\(\\mathbf{v} = (v_1,v_2,v_3)\\) to the equation \\(B_{\\lambda} \\mathbf{v} = \\mathbf{0}\\), where \\(B_{\\lambda} = \\lambda I_3 - A\\). Here, we have \\[ B_{\\lambda} = \\begin{pmatrix} \\lambda - 1 &amp; 0 &amp; 1 \\\\ -1 &amp; \\lambda - 2 &amp; -1 \\\\ -2 &amp; -2 &amp; \\lambda - 3 \\end{pmatrix}. \\] We find the eigenvectors for the eigenvalue \\(\\lambda_1 = 1\\). For \\(\\lambda = \\lambda_1 = 1\\), we have \\[ B_{1} = \\begin{pmatrix} 0 &amp; 0 &amp; 1 \\\\ -1 &amp; -1 &amp; -1 \\\\ -2 &amp; -2 &amp; -2 \\end{pmatrix}, \\] which is (automatically) the augmented matrix representing \\(B_{1} \\mathbf{v} = \\mathbf{0}\\) where we omit the solution vector. We perform a Gaussian elimination. First, we apply EROs \\(R_3 \\to R_3 - 2 R_2\\) and \\(R_2 \\to -R_2\\) to obtain \\[ \\begin{pmatrix} 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}, \\] and then we apply \\(R_1 \\leftrightarrow R_2\\) to have \\[ \\begin{pmatrix} 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}, \\] and finally \\(R_1 \\to R_1 - R_2\\) to arrive at \\[ \\begin{pmatrix} 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}. \\] From this we see that \\(v_2\\) can be chosen arbitrary, say \\(v_2 = \\alpha\\). Then, in view of \\(v_1 = -v_2\\) and \\(v_3 = 0\\), we have the set of eigenvectors corresponding to the eigenvalue \\(\\lambda_1 = 1\\) given as \\[ \\alpha \\begin{pmatrix} -1 \\\\ 1 \\\\ 0 \\end{pmatrix} \\] For instance, taking \\(\\alpha = 1\\), gives a specific eigenvector \\[ \\mathbf{u}_1 = \\begin{pmatrix} -1 \\\\ 1 \\\\ 0 \\end{pmatrix}. \\] We find the eigenvectors for the eigenvalue \\(\\lambda_2 = 2\\). For \\(\\lambda = \\lambda_2 = 2\\), we have \\[ B_{2} = \\begin{pmatrix} 1 &amp; 0 &amp; 1 \\\\ -1 &amp; 0 &amp; -1 \\\\ -2 &amp; -2 &amp; -1 \\end{pmatrix}. \\] As above, we use Gaussian elimination to find non-zero solutions \\(\\mathbf{v}\\) to the equation \\(B_{2} \\mathbf{v} = \\mathbf{0}\\). This gives the set of eigenvectors \\[ \\beta \\begin{pmatrix} -2 \\\\ 1 \\\\ 2 \\end{pmatrix} \\] For instance, taking \\(\\beta = 1\\), we find the specific eigenvector \\[ \\mathbf{u}_2 = \\begin{pmatrix} -2 \\\\ 1 \\\\ 2 \\end{pmatrix}. \\] We find the eigenvectors for the eigenvalue \\(\\lambda_3 = 3\\). For \\(\\lambda = \\lambda_3 = 4\\), we have \\[ B_{3} = \\begin{pmatrix} 2 &amp; 0 &amp; 1 \\\\ -1 &amp; 1 &amp; -1 \\\\ -2 &amp; -2 &amp; 0 \\end{pmatrix}. \\] As above, we use Gaussian elimination to find non-zero solutions \\(\\mathbf{v}\\) to the equation \\(B_{3} \\mathbf{v} = \\mathbf{0}\\). This gives the set of eigenvectors \\[ \\gamma \\begin{pmatrix} -1 \\\\ 1 \\\\ 2 \\end{pmatrix}. \\] For instance, taking \\(\\gamma = -1\\), we find the specific eigenvector \\[ \\mathbf{u}_3 = (1,-1,-2). \\] It also makes sense to consider vectors and matrices with complex number entries. These arise in applications such as analysis of electronic circuits and in quantum mechanics. We won’t consider such situations here, but we will now see that even if we start with vectors and matrices with real entries, complex number eigenvalues and eigenvectors with complex entries can still arise. We can immediately see that this could be possible, since the eigenvalues are calculated as roots of the characteristic polynomial and we know that real polynomials can have complex roots. Example 10.7 (Complex Eigenvalues and Eigenvectors) Consider the matrix \\[ A= \\begin{pmatrix} 0&amp;-1\\\\ 1&amp;0 \\end{pmatrix} \\] The matrix \\(A\\) has the effect of rotating vectors in the plane anticlockwise by \\(\\pi/2\\) (it is matrix \\(R_{\\pi/2}\\) from example (exm:rotmat)), so we can see geometrically that it can’t have any real eigenvectors, since these would correspond to fixed directions in the plane that are scaled by an eigenvalue. The characteristic polynomial is \\[p_A(\\lambda)=\\lambda^2+1\\] which has solutions \\(\\lambda_1=i\\) and \\(\\lambda_2=-i\\). We can also find the eigenvectors in the usual way by solving \\((A-\\lambda I)\\mathbf{v}=0\\). For \\(\\lambda_1\\) \\[ (A-iI)= \\begin{pmatrix} -i&amp;-1\\\\ 1&amp;-i \\end{pmatrix} \\] and performing \\(R_1\\to iR_1\\) \\[ \\begin{pmatrix} 1&amp;-i\\\\ 1&amp;-i \\end{pmatrix} \\] we find that the corresponding eigenvectors are \\(\\alpha\\left(\\begin{smallmatrix}1\\\\-i\\end{smallmatrix}\\right)\\) and taking \\(\\alpha=1\\), \\[ \\mathbf{u}_1= \\begin{pmatrix} 1\\\\ -i \\end{pmatrix} \\] Similarly, we find an eigenvector for \\(\\lambda_2\\): \\[ \\mathbf{u}_2= \\begin{pmatrix} 1\\\\ i \\end{pmatrix} \\] Let \\[ P=\\begin{pmatrix} 1&amp;1\\\\ -i&amp;i \\end{pmatrix} \\] then \\[ P^{-1}= \\frac{1}{2i} \\begin{pmatrix} i&amp;-1\\\\ i&amp;1 \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} 1&amp;i\\\\ 1&amp;-i \\end{pmatrix} \\] and letting \\[ D= \\begin{pmatrix} i&amp;0\\\\ 0&amp;-i \\end{pmatrix} \\] we may write \\[ A=PDP^{-1}. \\] Although \\(P^{-1}\\), \\(D\\) and \\(P\\) all contain complex numbers, their product leaves only real numbers and we get back to the real matrix \\(A\\) (check that \\(PDP^{-1}\\) does indeed equal \\(A\\)). Complex roots of real polynomials always come in complex conjugate pairs and so we will have complex conjugate eigenvalue pairs and corresponding complex conjugate eigenvector pairs. To see this, if \\(p_B(\\lambda)=\\lambda^n+a_{n-1}\\lambda^{n-1}+\\dotsb+a_1\\lambda+a_0\\) is a (real) characteristic polynomial of a real \\(n\\times n\\) matrix \\(B\\) and \\(\\lambda\\) is a complex root, then taking the complex conjugate \\[\\begin{align*} 0=p_B(\\lambda)=\\overline{p_B(\\lambda)}&amp;=\\overline{\\lambda^n}+\\overline{a_{n-1}\\lambda^{n-1}}+\\dotsb+\\overline{a_1\\lambda}+\\overline{a_0}\\\\ &amp;=\\overline{\\lambda}^n+a_{n-1}\\overline{\\lambda}^{n-1}+\\dotsb+a_1\\overline{\\lambda}+{a_0} \\end{align*}\\] (using that the coefficients \\(a_j\\) are real) shows that \\(\\overline{\\lambda}\\) is also a root. Let \\(\\mathbf{u}\\) be an eigenvector corresponding to \\(\\lambda\\). Then, \\[ B\\overline{\\mathbf{u}}=\\overline{B}\\overline{\\mathbf{u}}=\\overline{B\\mathbf{u}}=\\overline{\\lambda \\mathbf{u}}=\\overline{\\lambda}\\overline{\\mathbf{u}} \\] (using that \\(B\\) is real in the first step) i.e. the vector \\(\\overline{\\mathbf{u}}\\) is an eigenvector with eigenvalue \\(\\overline{\\lambda}\\). As we mentioned earlier, not all matrices are diagonalisable. Here is an example. Example 10.8 (A non-diagonalisable matrix) Consider the matrix \\[ A=\\begin{pmatrix} 3&amp;1\\\\ 0&amp;3 \\end{pmatrix}. \\] The characteristic polynomial of \\(A\\) is \\[ p_A(x)=\\det(\\lambda I-A)= \\begin{vmatrix} \\lambda-3&amp;-1\\\\ 0&amp;\\lambda-3 \\end{vmatrix} =(\\lambda-3)^2 \\] so the only eigenvalue of \\(A\\) is \\(3\\). Now \\[ A-3I= \\begin{pmatrix} 0&amp;1\\\\ 0&amp;0 \\end{pmatrix} \\] so the eigenvectors are \\[ \\alpha \\begin{pmatrix} 1\\\\ 0 \\end{pmatrix} \\] So we do not have 2 linearly independent eigenvectors since all eigenvectors are multiples of \\(\\mathbf{u}=\\left(\\begin{smallmatrix}1\\\\0\\end{smallmatrix}\\right)\\). Therefore, we cannot diagonalise this matrix. We briefly mention that there are other useful matrix decompositions to diagonalisation that always work. The generalisation of diagonalisation is the Jordan Normal Form, which is an important theoretical tool. Another key technique is the Singular Value Decomposition which is important in numerical applications of matrices and in data science (see Principal Component Analysis). 10.4 Powers of diagonalisable matrices One of the most important applications of diagaonalisation is in computing powers of matrices. If a matrix \\(A\\) is diagonalisable, we can write it as \\[A=PDP^{-1}\\] Now if we want to cmopute \\(A^2\\), we have \\[A^2=PDP^{-1}PDP^{-1}=PD^2P^{-1}\\] where we used \\(P^{-1}P=I\\). Now, more generally \\[ A^n=PDP^{-1}PDP^{-1}\\dotsb PDP^{-1}=PD^nP^{-1} \\] for any natural number \\(n\\). By the rules of matrix multiplication, the \\(n\\)-th power of the diagonal matrix \\[ D= \\begin{pmatrix} \\lambda_1&amp;&amp;0\\\\ &amp;\\ddots&amp;\\\\ 0&amp;&amp;\\lambda_m \\end{pmatrix} \\] is simply \\[ D^n = \\begin{pmatrix} \\lambda_1^n&amp;&amp;0\\\\ &amp;\\ddots&amp;\\\\ 0&amp;&amp;\\lambda_m^n \\end{pmatrix}. \\] This gives us an efficient way to compute \\(A^n\\). Example 10.9 (Powers of a diagonalisable matrix) Consider the matrix \\[ A= \\begin{pmatrix} 8&amp;-6\\\\ 3&amp;-1 \\end{pmatrix}. \\] We find \\[A=PDP^{-1}= \\begin{pmatrix} 1&amp;2\\\\ 1&amp;1 \\end{pmatrix} \\begin{pmatrix} 2&amp;0\\\\ 0&amp;5 \\end{pmatrix} \\begin{pmatrix} -1&amp; 2\\\\ 1&amp; -1 \\end{pmatrix}.\\] Now using \\[ A^n=PD^nP^{-1} \\] we have \\[ A^n= \\begin{pmatrix} 1&amp;2\\\\ 1&amp;1 \\end{pmatrix} \\begin{pmatrix} 2^n&amp;0\\\\ 0&amp;5^n \\end{pmatrix} \\begin{pmatrix} -1&amp; 2\\\\ 1&amp; -1 \\end{pmatrix} = \\begin{pmatrix} -2^n+2\\times 5^n&amp; 2^{n+1}-2\\times 5^n\\\\ -2^{n}+5^n&amp; 2^{n+1}-5^n \\end{pmatrix}. \\] We now have a nice expression that works for any \\(n\\) and this is much easier than trying to calculate \\(A^n\\) directly. Technically, \\(\\mathcal{P}\\) is what is known as a basis – a list of vectors that are linearly independent and span the space and hence can act as a coordinate system.↩︎ "],["differentiation.html", "Chapter 11 Differentiation 11.1 Concept 11.2 Standard derivatives 11.3 Rules 11.4 Higher order derivatives 11.5 Further Techniques", " Chapter 11 Differentiation 11.1 Concept Differentiation is the mathematical tool to answer questions about rates of change. The derivative of a real function \\(f\\) at a point \\((x,f(x))\\) is the slope of the tangent line at that point. Figure 11.1: The tangent line to a graph. To find this gradient, we start by approximating the tangent line by taking a secant line through the point \\((x,f(x))\\) and a point \\((x+h,f(x+h))\\) with \\(h\\) a small number. Figure 11.2: A secant line through \\((x,f(x))\\) and a point \\((x+h,f(x+h))\\). Now if we take \\(h\\to 0\\), that is \\(h\\) becomes vanishingly small, the second point approaches \\((x,f(x))\\). Then the gradient of the secant line converges to the gradient of the tangent line. The gradient of the secant line is: \\[ \\frac{\\Delta y}{\\Delta x}=\\frac{f(x+h)-f(x)}{h}. \\] The mathematical term for taking \\(h\\to 0\\) is taking the limit as \\(h\\) tends to \\(0\\), written \\[ \\lim\\limits_{h\\to 0}\\frac{f(x+h)-f(x)}{h}. \\] The idea here is to consider what happens to this mathematical expression as \\(h\\) becomes infinitesimally small. We call this gradient of the tangent line the derivative of \\(f\\) at \\(x\\). We use the following notations for the derivative: \\[f&#39;(x)\\quad\\text{ or }\\quad \\frac{df}{dx} \\] Here we present some examples of finding derivatives from first principles, i.e. by using the limit definition of the derivative. Example 11.1 (Derivatives from first principles) The first two examples are applied to straight lines, whose tangents are the same as the lines themselves, hence we should get the same gradient from the derivative. Consider a constant function \\(f(x)=c\\) (the graph of which is a straight horizontal line). We know that the gradient of this line is zero. Let’s try applying the definition. \\[\\begin{align*} f&#39;(x)&amp;=\\lim\\limits_{h\\to 0}\\frac{f(x+h)-f(x)}{h}\\\\ &amp;=\\lim\\limits_{h\\to 0}\\frac{c-c}{h}\\quad\\text{applying the definition of $f$}\\\\ &amp;=\\lim\\limits_{h\\to 0}\\frac{0}{h}\\\\ &amp;=\\lim\\limits_{h\\to 0}0\\quad\\text{note this expression is now independent of the value of $h$, hence...}\\\\ &amp;=0 \\end{align*}\\] in agreement with our geometical understanding. Consider a straight line of the form \\(f(x)=mx+c\\). Using the definition of the derivative \\[\\begin{align*} f&#39;(x)&amp;=\\lim\\limits_{h\\to 0}\\frac{f(x+h)-f(x)}{h}\\\\ &amp;=\\lim\\limits_{h\\to 0}\\frac{[m(x+h)+c]-[mx+c]}{h}\\quad\\text{applying the definition of $f$}\\\\ &amp;=\\lim\\limits_{h\\to 0}\\frac{mh}{h}\\\\ &amp;=\\lim\\limits_{h\\to 0}m\\quad\\text{note this expression is now independent of the value of $h$, hence...}\\\\ &amp;=m. \\end{align*}\\] again in agreement with our geometical understanding. Consider \\(f(x)=x^2\\). \\[\\begin{align*} f&#39;(x)&amp;=\\lim\\limits_{h\\to 0}\\frac{f(x+h)-f(x)}{h}\\\\ &amp;=\\lim\\limits_{h\\to 0}\\frac{(x+h)^2-x^2}{h}\\quad\\text{applying the definition of $f$}\\\\ &amp;=\\lim\\limits_{h\\to 0}\\frac{x^2+2xh+h^2-x^2}{h}\\quad\\text{expanding brackets}\\\\ &amp;=\\lim\\limits_{h\\to 0}2x+h\\quad\\text{by simplifying}\\\\ &amp;=2x\\quad\\text{since $h$ becomes vanishingly small.} \\end{align*}\\] It would be hard work if we always had to apply the definition to find the derivatives of functions. Thankfully, others have already done the hard work and we have some rules for derivatives of standard functions, together with some rules for derivatives of combinations of functions (including sums, products and compositions). This allows us to compute the derivatives of a wide variety of expressions we might encounter. 11.2 Standard derivatives \\[\\begin{align*} &amp;\\frac{d}{dx}x^a=ax^{a-1}\\qquad \\text{for any $a\\in\\mathbb{R}$}\\\\ &amp;\\\\ &amp;\\frac{d}{dx}\\ln(x)=\\frac{1}{x}\\\\ &amp;\\frac{d}{dx}e^{x}=e^{x}\\\\ &amp;\\\\ &amp;\\frac{d}{dx}\\sin(x)=\\cos(x)\\\\ &amp;\\frac{d}{dx}\\cos(x)=-\\sin(x)\\\\ &amp;\\frac{d}{dx}\\tan(x)=\\sec^2(x)\\\\ &amp;\\\\ &amp;\\frac{d}{dx}\\sinh(x)=\\cosh(x)\\\\ &amp;\\frac{d}{dx}\\cosh(x)=\\sinh(x) \\end{align*}\\] 11.3 Rules Sum Rule \\[ (f+g)&#39;(x)=f&#39;(x)+g&#39;(x) \\] Example 11.2 Find the derivative of \\[h(x)=x^3+\\sin(x).\\] Let \\(f(x)=x^3\\), \\(g(x)=\\sin(x)\\). Then \\[h(x)=(f+g)(x)=x^3+\\sin(x)\\] and \\[h&#39;(x)=(f+g)&#39;(x)=f&#39;(x)+g&#39;(x)=3x^2+\\cos(x).\\] Product Rule \\[ (f\\cdot g)&#39;(x)=f&#39;(x)\\cdot g(x)+f(x)\\cdot g&#39;(x) \\] Example 11.3 Find the derivative of \\[h(x)=x^3\\sin(x)\\] Let \\(f(x)=x^3\\), \\(g(x)=\\sin(x)\\). Then \\[h(x)=(f\\cdot g)(x)=x^3\\sin(x)\\] and \\[h&#39;(x)=(f\\cdot g)&#39;(x)=f&#39;(x)g(x)+f(x)g&#39;(x)=3x^2\\sin(x)+x^3\\cos(x).\\] In particular (exercise), for any constant \\(a\\) we have: \\((af(x))&#39;=af&#39;(x)\\). Quotient Rule \\[ \\left(\\dfrac{f}{g}\\right)&#39;(x)=\\frac{g(x)\\cdot f&#39;(x)-f(x)\\cdot g&#39;(x)}{[g(x)]^2} \\] Example 11.4 Find the derivative of \\[h(x)=\\frac{x^3}{\\sin(x)}.\\] Let \\(f(x)=x^3\\), \\(g(x)=\\sin(x)\\). Then \\[h(x)=(\\frac{f}{g})(x)=\\frac{x^3}{\\sin(x)}\\] and \\[h&#39;(x)=(\\frac{f}{g})&#39;(x)=\\frac{g(x)\\cdot f&#39;(x)-f(x)\\cdot g&#39;(x)}{[g(x)]^2}=\\frac{3x^2\\sin(x)-x^3\\cos(x)}{\\sin^2(x)}.\\] Chain Rule \\[ \\left(f\\circ g\\right)&#39;(x)=f&#39;(g(x))\\cdot g&#39;(x) \\] (where \\(\\left(f\\circ g\\right)(x)=f(g(x))\\) denotes function composition). Example 11.5 Find the derivative of \\[h(x)=\\sin(x^3)\\] Let \\(f(x)=\\sin(x)\\), \\(g(x)=x^3\\). Then \\[h(x)=(f\\circ g)(x)=\\sin(x^3)\\] and \\[h&#39;(x)=(f\\circ g)&#39;(x)=f&#39;(g(x))\\cdot g&#39;(x)=\\cos(x^3)(3x^2)=3x^2\\cos(x^3).\\] The key to using these rules is in splitting your function \\(h(x)\\) into the right combination of two or more simpler functions (\\(f(x)\\) and \\(g(x)\\) in the above examples) to make it easy to apply the rules. 11.4 Higher order derivatives The derivative of a function \\(f\\) is also a function, which we denote \\(f&#39;\\). We can also take the derivative of the function \\(f&#39;\\), yielding the function \\((f&#39;)&#39;\\), which is usually written as \\(f&#39;&#39;\\), and is called the second derivative of \\(f\\). For example, with \\(f(x)=x^3\\) we have \\(f&#39;(x)=3x^2\\) and \\(f&#39;&#39;(x)=6x\\). There is no reason to stop at the second derivative, and we can define \\(f&#39;&#39;&#39;=(f&#39;&#39;)&#39;\\), \\(f&#39;&#39;&#39;&#39;=(f&#39;&#39;&#39;)&#39;\\) etc. After a few derivatives of \\(f\\) it is more convenient to use the notation: \\[\\begin{align*} f^{(0)}&amp;=f\\\\ f^{(1)}&amp;=f&#39;\\\\ f^{(2)}&amp;=(f&#39;)&#39;=f&#39;&#39;\\\\ f^{(3)}&amp;=(f&#39;&#39;)&#39;=f&#39;&#39;&#39;\\\\ &amp;\\phantom{..}\\vdots\\\\ f^{(n+1)}&amp;=(f^{(n)})&#39; \\end{align*}\\] The functions \\(f^{(n)}\\) for \\(n\\geq 2\\) are called higher-order derivatives. Derivatives may also be denoted using Leibniz notation: \\[ \\frac{df(x)}{dx} \\] This notation ties in with Leibniz’s intuitive notion of the derivative as the quotient of the “infinitely small difference \\(df(x)=f(x+dx)-f(x)\\)”, by the “infinitely small number \\(dx\\)”; but it is important to note that the derivative is defined as the limit, and the symbols \\(df(x)\\) and \\(dx\\) have no meaning of their own, and cannot be manipulated separately. Higher order derivatives are denoted \\[ \\frac{d^2f(x)}{dx^2},\\frac{d^3f(x)}{dx^3},\\dotsc,\\frac{d^nf(x)}{dx^n},\\dotsc \\] Leibniz’s Formula allows us to easily compute higher order derivatives of products. The \\(n^\\text{th}\\) derivative of the product \\((f\\cdot g)(x)\\) is \\[ (f\\cdot g)^{(n)}(x)=\\sum_{k=0}^{n}\\binom{n}{k}f^{(k)}(x)\\cdot g^{(n-k)}(x). \\] Recall that the binomial coefficient is given by: \\[ \\binom{n}{k}=\\frac{n!}{k!(n-k)!}. \\] 11.5 Further Techniques 11.5.1 Implicit Differentiation Curves in the plane are often described by the set of all coordinates \\((x,y)\\) satisfying an equation of the form \\({F(x,y)=0}\\) for some function \\(F\\) of two variables. For example, the unit circle is described by the equation \\(F(x,y)=x^2+y^2-1=0\\). As with the circle, we often cannot describe such a curve in the form of a graph of a function \\(y=f(x)\\) (since it is multivalued for each \\(x\\)). How do we differentiate such a curve? Example 11.6 The unit circle \\(x^2+y^2=1\\) has a well defined slope at every point except \\((-1,0)\\) and \\((1,0)\\) where there are vertical tangents. For the circle we can quite easily find functions that describe the differentiable parts of the curve: \\[\\begin{align*} f_1(x)&amp;=\\sqrt{1-x^2} &amp;-1&lt; x &lt; 1\\\\ f_2(x)&amp;=-\\sqrt{1-x^2} &amp;-1&lt; x &lt; 1 \\end{align*}\\] which describe the upper and lower halves of the circle, respectively. Figure 11.3: Functions describing the upper an lower parts of the circle Then to obtain the derivative at any point on the circle (except \\((-1,0),(1,0)\\)), we can calculate the derivative of the relevant function \\(f_1\\) or \\(f_2\\): \\[ f_1&#39;(x)=\\dfrac{-x}{(1-x^2)^\\frac{1}{2}},\\qquad f_2&#39;(x)=\\dfrac{x}{(1-x^2)^\\frac{1}{2}}. \\] For the circle we are able to write down differentiable functions with explicit formulae. In general, however, it will not be possible, or at least not easy, to find such functions. A function \\(f\\) defined by the fact that it satisfies an equation \\(F(x,f(x))=0\\) is called an implicit function; it is defined implicitly, rather than by an explicit formula. In general, the coordinates where \\(F(x,y)=0\\) may not be describable by the graph of a differentiable function. Even where it is, there may be more than one function defined by the relation, as was the case with the circle. Furthermore, it may not be possible to write down \\(f\\) as a nice formula as we did for the circle. If we assume that a function \\(f\\) is a differentiable solution to the equation, then we can derive a formula for \\(f&#39;\\) by the process of implicit differentiation. (We will only deal with simple cases here anyway and so need not be concerned with the technichal details, but in general we would need to turn to the Implicit Function Theorem to guarantee that all technichal assumptions are valid.) The process has two main steps: Differentiate both sides of the equation with respect to \\(x\\), treating \\(y\\) as a differentiable function of \\(y(x)\\) and using the Chain Rule. Solve for \\(y&#39;(x)\\), giving a formula involving \\(x\\) and \\(y\\) that yields the derivative at any point \\((x,y)\\) on the curve \\(F(x,y)=0\\). Example 11.7 (Implicit differentiation) Consider the unit circle \\(x^2+y^2=1\\). We treat \\(y=y(x)\\) as a differentiable function. \\[\\begin{align*} \\frac{d}{dx}(x^2+y^2)&amp;=\\frac{d}{dx}(1)\\\\ \\frac{d}{dx}(x^2)+\\frac{d}{dx}(y^2)&amp;=0\\\\ 2x+2y\\frac{dy}{dx}&amp;=0\\\\ \\frac{dy}{dx}&amp;=-\\frac{x}{y} \\end{align*}\\] Where in the third line we have used the chain rule, by setting \\(y=y(x)\\) so that \\[ \\frac{d}{dx}(y(x)^2)=2y(x)\\dfrac{d}{dx}(y(x)). \\] Note that we have “infinite gradients” if \\(y=0\\), as we had already stated. Note that this agrees with our previous analysis: if \\((a,b)\\) lies on the upper half of the circle then the slope at this point is given by \\[ f_1&#39;(a)=\\dfrac{-a}{(1-a^2)^\\frac{1}{2}} \\] or using the above implicit derivative and the formula for \\(f_1\\) \\[ \\frac{dy}{dx}=-\\frac{a}{b}=-\\frac{a}{f_1(a)}=-\\frac{a}{\\sqrt{1-a^2}}. \\] and similarly for a point on the lower half of the circle. 11.5.2 Logarithmic Differentiation By the chain rule, the derivative of \\(\\ln\\circ f\\) is \\(\\dfrac{f&#39;}{f}\\), and this will often be easier to compute than \\(f&#39;\\) because logarithms turn products into sums, and powers into products. The derivative for \\(f\\) can then be recovered by multiplying through by \\(f\\). This process is known as logarithmic differentiation. Example 11.8 (Logarithmic differentiation) Find the derivative of \\[ y=x^x. \\] First take the natural logarithm: \\[ \\ln(y)=x\\ln(x), \\] then differentiate implicitly: \\[\\begin{align*} \\frac{d}{dx}(\\ln(y))&amp;=\\frac{d}{dx}(x\\ln(x))\\\\ \\frac{1}{y}\\frac{dy}{dx}&amp;=\\frac{dx}{dx}\\ln(x)+x\\frac{d}{dx}\\ln(x)\\\\ \\frac{1}{y}\\frac{dy}{dx}&amp;=\\ln(x)+x\\frac{1}{x}\\\\ \\frac{dy}{dx}&amp;=y(\\ln(x)+1)=x^x(\\ln(x)+1). \\end{align*}\\] Warning! The derivative of \\(x^x\\) is \\(x\\cdot x^{x-1}\\). We can’t treat variable exponents like constant exponents! 11.5.3 Parametric Differentiation Curves in the plane may also be described parametrically. Given two functions \\(u(t)\\) and \\(v(t)\\), the curve \\[ \\{(x,y): x=u(t), y=v(t)\\} \\] is said to be represented parametrically by \\(u\\) and \\(v\\), and the pair of functions \\(u\\) and \\(v\\) are called a parametric representation of the curve. We can think of such a curve as being the path traced out by a particle moving in the plane; at time \\(t\\) the particle is at the position with coordinates \\((u(t),v(t))\\). A parametric curve is a function from the real numbers into the plane, given by \\(F(t)=(u(t),y(t))\\). Such curves will generally not be the graph of a function (due to being multivalued for a given \\(x\\)-coordinate). Figure 11.4: The parametric curve given by \\(x(\\theta)=4\\sin(\\theta)+2\\sin(3\\theta)\\) and \\(y(\\theta)=4\\cos(\\theta)+2\\cos(3\\theta)\\). How do we differentiate such a curve? Suppose that \\({x=u(t)}\\), \\({y=v(t)}\\) is a parametric representation of a curve, and that \\(u&#39;\\neq 0\\) on some interval. Then on this interval the curve lies on the graph of a function \\(f\\), and at the point \\(x=u(t)\\) \\[ f&#39;(x)=\\frac{v&#39;(t)}{u&#39;(t)} \\] To see this, we have \\({v(t)=f(x(t))}\\), so differentiating with respect to \\(t\\) and using the chain rule on the right hand side, \\[ v&#39;(t)=f&#39;(x)u&#39;(t) \\] and since \\(u&#39;(t)\\neq 0\\) \\[ f&#39;(x)=\\frac{v&#39;(t)}{u&#39;(t)}. \\] In Leibniz notation this is often written as: \\[ \\frac{dy}{dx}=\\frac{\\dfrac{dy}{dt}}{\\dfrac{dx}{dt}} \\] and one can imagine “cancelling the \\(dt\\)’s”. Example 11.9 (Parametric differentiation) An ellipse \\(\\dfrac{x^2}{a^2}+\\dfrac{y^2}{b^2}=1\\) can be represented parametrically by \\({x=a\\cos(\\theta), y=b\\sin(\\theta)}\\). The derivative at a point on the ellipse corresponding to parameter value \\(\\theta\\) is: \\[\\begin{align*} \\frac{dy}{dx}&amp;=\\frac{dy/d\\theta}{dx/d\\theta}\\\\ &amp;=-\\frac{b\\cos(\\theta)}{a\\sin(\\theta)}\\\\ &amp;=-\\frac{b}{a}\\cot(\\theta). \\end{align*}\\] Second order parametric derivatives. Suppose that \\(x=u(t)\\), \\(y=v(t)\\), then \\[ \\frac{d^2y}{dx^2}=\\frac{d}{dx}\\left(\\frac{dy}{dx}\\right)=\\frac{d}{dx}\\left(\\frac{\\dfrac{dy}{dt}}{\\dfrac{dx}{dt}}\\right) \\] and we can compute this using the chain rule: \\[ \\frac{d^2y}{dx^2}=\\frac{d}{dt}\\left(\\frac{dy}{dx}\\right)\\frac{dt}{dx}. \\] Alternatively, we could use the quotient rule, but this is more complicated: \\[ \\frac{d^2y}{dx^2}=\\frac{\\frac{dx}{dt}\\frac{d^2y}{dt^2}-\\frac{dy}{dt}\\frac{d^2x}{dt^2}}{\\left( \\frac{dx}{dt}\\right)^3}. \\] "],["applications-of-differentiation.html", "Chapter 12 Applications of Differentiation 12.1 Maxima and Minima 12.2 Points of Inflection 12.3 Higher Order Derivative Test 12.4 Graph Sketching 12.5 Optimisation", " Chapter 12 Applications of Differentiation 12.1 Maxima and Minima “…nothing at all takes place in the universe in which some rule of maximum or minimum does not appear…” Leonhard Euler We quite often need to find maximum and minimum points of a function in relation to optimisation or due to some physical principle, such as the minimisation of potential energy in physics. We distinguish between local maxima/minima and global maxima/minima. A global maximum is a “peak” in the graph of a function that is higher than or equal to any other value of the function, whilst a local maximum is a “peak” that is higher than or equal to any other value in the immediate region around the peak; we have similar definitions for a global and local minimum. If we are looking at maxima/minima where there are no points (globally/locally) that are equal in value, we add the word strict maximum/minimum. Differentiation can help us to find local maxima/minima. We first mention some basic relationships between functions and their derivatives. These are all intuitively obvious (their mathematical proofs follow from the Mean Value Theorem). Fermat’s Theorem. If \\(x=a\\) is a local maximum or local minimum point for \\(f(x)\\), then \\(f&#39;(a)=0\\). The converse to this theorem is not true, e.g. for \\(f(x)=x^3\\), we have \\(f&#39;(0)=0\\), but \\(a=0\\) is clearly not a local maximum or minimum for \\(f\\). We use the term critical point or stationary point for a point \\(a\\) at which the derivative \\(f&#39;(a)=0\\). Constant Function. If \\(f&#39;(x)=0\\) for all \\(x\\) then \\(f\\) is constant (that is, \\(f(x)=c\\) for some constant \\(c\\)). Constant Difference. If \\(f\\) and \\(g\\) are such that \\(f&#39;(x)=g&#39;(x)\\) for all \\(x\\), then there is some constant \\(c\\) such that \\(f=g+c\\) (geometrically this says that \\(f\\) is a vertical translation of \\(g\\)). Functions with Positive or Negative Derivatives. If \\(f&#39;(x)&gt;0\\) for all \\(x\\), then \\(f\\) is strictly increasing. If \\(f&#39;(x)&lt;0\\) for all \\(x\\), then \\(f\\) is strictly decreasing. The converse is not true: consider again \\(f(x)=x^3\\) which is strictly increasing but has \\(f&#39;(0)=0\\). Note that in order to have a local maximum or minimum at a point \\(x=a\\) it is a requirement that \\(f&#39;(a)=0\\), but this is not a sufficient condition to gaurantee we have a maximum or minimum at \\(a\\). We can determine if a critical point is a local maximum or minimum using the so-called second derivative test. Theorem 12.1 (Second Derivative Test for Maxima and Minima) Suppose \\(f&#39;(a)=0\\) (i.e. \\(a\\) is a critical point of \\(f\\)). If \\(f&#39;&#39;(a)&gt;0\\), then \\(f\\) has a strict local minimum at \\(a\\), If \\(f&#39;&#39;(a)&lt;0\\), then \\(f\\) has a strict local maximum at \\(a\\). To understand this theorem, note that if \\(f&#39;&#39;(a)&gt;0\\) then this says that \\(f&#39;(x)\\) is strictly increasing near \\(a\\) and we also know that \\(f&#39;(x)\\) passes through \\(0\\) at \\(x=a\\). This means \\(f&#39;(a-\\delta)&lt;0\\) and \\(f&#39;(a+\\delta)&gt;0\\) for an arbitrary small number \\(\\delta&gt;0\\); that is, we have a negative gradient to the left of \\(a\\) and a positive gradient to the right of \\(a\\), hence \\(a\\) must be a local minimum of the function. A similar argument holds for \\(f&#39;&#39;(a)&lt;0\\) and \\(a\\) being a local maximum. Warning! The function \\(g(x)=x^4\\) has a strict global (and hence also local) minimum at \\(0\\), where \\(g&#39;(0)=0\\) but we have \\(g&#39;&#39;(0)=0\\), hence the converse to the Second Derivative Test is not true. 12.2 Points of Inflection An inflection point \\(x=a\\) is a point where the tangent line to a graph of a function \\(f\\) at \\((a,f(a))\\) crosses the graph at \\((a,f(a))\\). This corresponds to a point where the graph changes from being convex to concave (or vice versa). Figure 12.1: Inflection points It is necessary that the second derivative has different signs to the left and right of \\(a\\) for it to be an inflection point, and hence \\(f&#39;&#39;(a)=0\\). But note that \\(f&#39;&#39;(a)=0\\) alone is not sufficient for \\(a\\) to be an inflection point (for example, \\(f(x)=x^4\\) at \\(x=0\\) has derivative \\(f&#39;&#39;(0)=0\\), but this is a minimum). Note that we do not need \\(f&#39;(a)=0\\), so a point of inflection is not necessarily a critical point. Having a nonzero third order derivative at a point \\(a\\) where \\(f&#39;&#39;(a)=0\\) ensures that the second derivative has different signs to the left and right of \\(a\\). Theorem 12.2 (Third Derivative Test for Inflection Points) If \\(f&#39;&#39;(a)=0\\) and \\(f&#39;&#39;&#39;(a)\\neq 0\\) then \\(a\\) is a point of inflection Warning! The function \\(g(x)=x^5\\) has a point of inflection at \\(0\\), but with \\(g&#39;&#39;(0)=0\\) and \\(g&#39;&#39;&#39;(0)=0\\). This demonstrates that the above criteria on the third derivative is sufficient but not necessary. 12.3 Higher Order Derivative Test We can generalise the above derivative tests to determine whether critical points are maxima, minima or inflection points based on higher order derivatives. Theorem 12.3 (Higher Order Derivative Test) Let \\(f\\) be a sufficiently differentiable function on an interval containing the point \\(a\\). If with \\(n&gt;1\\) we have \\(f^{(i)}(a)=0\\) for \\(i=1,\\dotsc,{n-1}\\) but \\(f^{(n)}\\neq 0\\), then If \\(n\\) is even and \\(f^{(n)}&lt;0\\), then \\(a\\) is a strict local maximum point If \\(n\\) is even and \\(f^{(n)}&gt;0\\), then \\(a\\) is a strict local minimum point If \\(n\\) is odd and \\(f^{(n)}&lt;0\\), then \\(a\\) is a strictly decreasing point and an inflection point If \\(n\\) is odd and \\(f^{(n)}&gt;0\\), then \\(a\\) is a strictly decreasing point and an inflection point Note that the test can fail if the higher order derivatives at \\(a\\) cease to exist before they become non-zero, or if the derivatives of \\(f\\) at \\(a\\) of all orders are zero i.e. \\(f^{(i)}(a)=0\\) for all \\(i\\). 12.4 Graph Sketching We now have a lot of tools to help us understand the nature of a function and to sketch graphs. We can analyse a function \\(f\\) by looking at: the values \\(x\\) where \\(f(x)=0\\), i.e. where the graph crosses the \\(x\\)-axis the value of \\(f(0)\\), i.e. where the graph crosses the \\(y\\)-axis the critical points of \\(f\\) (possibly local maxima/minima, inflection points) and the value of \\(f\\) at these critical points the sign of \\(f&#39;\\) the location and nature of any vertical asymptotes if the function is periodic 12.5 Optimisation Optimisation is the process of finding the “best” inputs, that maximise or minimise some objective function. For suitable objective functions we can use our derivative tests to find these inputs. Here we shall look at an example and give a general method for solving such problems. Example 12.1 (A fencing problem) A rectangular storage compound needs to be built on a building site. An existing wall is to be used as one side of the compound and the other 3 walls will be built with fencing. There is 100m of fencing available. What is the maximum storage area that can be built and what are the lengths of the sides? Let the side opposite the wall have length \\(y\\) and the other two sides length \\(x\\). The length of the fencing will be the perimeter of these three sides, hence \\[2x+y=100 m\\] We want to maximise the area, hence our objective function is \\[A=x\\times y.\\] We use the first equation to find \\(y\\) in terms of \\(x\\): \\[y=100-2x\\] then \\[A=x(100-2x)=100x-2x^2.\\] To maximise, we need to find the solution for \\(\\frac{dA}{dx}=0\\): \\[\\frac{dA}{dx}=100-4x=0\\quad\\implies\\quad x=25 m\\] We check this is a maximum at \\(x=25\\). We have \\[\\frac{d^2A}{dx^2}=-4\\] which is indeed negative, hence we have a maximum at \\(x=25\\). Substituting back into our equations for \\(y\\) and \\(A\\) we have: \\[\\begin{align*} x&amp;=25m\\\\ y&amp;=50m\\\\ A&amp;=1250 m^2. \\end{align*}\\] Methodology Obtain an expression for the quantity that must be maximised or minimised; Ensure that the expression is in terms of just one unknown variable; Get the resulting expression into a form that can be differentiated; Differentiate the function and set equal to zero; Solve for the unknown variable, i.e. find the critical points; Find the second derivative of the function and check which critical points are maxima/minima; Substite the points back into the objective function (in terms of the one variable) to find the values at these points – select the largest/smallest. "],["sequences.html", "Chapter 13 Sequences 13.1 Limits of Sequences", " Chapter 13 Sequences A sequence is an ordered list of objects (usually numbers, but also vectors, matrices or any other mathematical object). It may be finite or infinite. Some sequences of numbers: A finite sequence: \\(2, 4, 6, 8\\) Square numbers: \\(1, 4, 9, 16,\\dotsc\\) Fibonacci: \\(0, 1, 1, 2, 3, 5, 8, 13, 21, 34,\\dotsc\\) What comes next?: \\(1, 11, 21, 1211, 111221, 312211,\\dotsc\\) (the “look-and-say’’ sequence) We write \\[\\begin{align*} (a_n)&amp;_{n=1}^{\\infty}\\quad\\text{or simply}\\quad(a_n)\\quad\\text{for the infinite sequence of numbers }a_1,a_2,a_3,\\dotsc\\\\ &amp;\\big\\uparrow_\\text{read as &#39;&#39;from $n$ equals $1$ to infinity&#39;&#39;} \\end{align*}\\] We say that the number \\(a_1\\) is the first term of the sequence, \\(a_2\\) the second term etc. and \\(a_n\\) is a general term of the sequence – the \\(n^\\text{th}\\) term. Note that a sequence of real numbers can also be viewed as a function from the natural numbers to the real numbers with \\(f(n)=a_n\\). Two ways of specifying the terms of a sequence are: 1. By a formula for each term depending on \\(n\\), e.g. \\[ a_n=n^2-1\\quad\\text{corresponding to the sequence}\\quad 0,3,8,15,24,\\dotsc \\] By a recursive forumla, i.e. a formula that depends on previous terms in the sequence, e.g. the Fibonacci sequence can be defined by \\(F_1=0,F_2=1\\) together with \\[ F_n=F_{n-1}+F_{n-2}\\qquad\\text{for }n&gt;2 \\] Two commonly encountered forms of sequences are arithmetic sequences and geometric sequences. An arithmetic sequence is given by a formula of the form \\[a_n=a+(n-1)d\\] where \\(a\\) is the first term and \\(d\\) is the common difference. For example, \\[4,7,10,13,\\dotsc\\] is given by the formula \\[a_n=4+(n-1)3.\\] A geometric sequence is given by a formula of the form \\[a_n=ar^{n-1}\\] where \\(a\\) is the first term and \\(r\\) is the common ratio. For example, \\[2, 1, \\frac{1}{4}, \\frac{1}{8},\\dotsc\\] is given by the formula \\[a_n=2\\times \\left(\\frac{1}{2}\\right)^{n-1}.\\] 13.1 Limits of Sequences Consider the sequence defined by the following formula: \\[ a_n=\\frac{n}{n+1}. \\] The first three terms are \\[ a_1=\\frac{1}{2},\\quad a_2=\\frac{2}{3},\\quad a_3=\\frac{3}{4}. \\] The terms corresponding to \\(n=100,101,102\\) are \\[ a_{100}=\\frac{100}{101},\\quad a_{101}=\\frac{101}{102},\\quad a_{102}=\\frac{102}{103} \\] which are close to \\(1\\), for example \\(\\frac{100}{101}\\) is different to \\(1\\) by just \\(\\frac{1}{101}\\). We can see that as \\(n\\) grows, \\(a_n\\) becomes closer and closer to the value \\(1\\); we say that the sequence \\(\\{a_n\\}_{n=1}^\\infty\\) has limit \\(1\\). Intuitively a sequence has a limit \\(L\\) if its terms get closer and closer to \\(L\\). More mathematically we say that a sequence \\((a_n)\\) converges to a limit \\(L\\) if \\(a_n\\) is “close to” \\(L\\) “for all large positive integers \\(n\\)”. We give a formal mathematical definition below. The following examples introduce some more terminology. The harmonic sequence \\[ 1, \\frac{1}{2}, \\frac{1}{3},\\dotsc \\] defined by the formula \\[ a_n=\\dfrac{1}{n} \\] is continually decreasing and converges to zero. The Fibonacci sequence does not converge to a limit and keeps growing without bound \\[ 0, 1, 1, 2, 3, 5, 8, 13, 21, 34,\\dotsc \\] If a sequence does not converge we say that it diverges. Because this sequence continues to grow we say it diverges to infinity. The sequence \\[ a_n=(-1)^{n+1} \\] has terms \\(1,-1,1,-1,1,\\dotsc\\) and does not converge to a single value; because it does not converge it diverges, but because it does not simply grow to \\(+\\infty\\) or \\(-\\infty\\) we say that it . The formal definition of a limit for a sequence is: Definition 13.1 (definition name) Let \\((a_n)_{n=1}^{\\infty}\\) be a sequence of real numbers. We say that the sequence has limit \\(L\\) if for every \\(\\varepsilon&gt;0\\) there exists a positive integer \\(N\\) such that if \\(n\\geq N\\) then \\[ \\left|a_n-L\\right|&lt;\\varepsilon. \\] This definition works as follows: by choosing a small value for \\(\\varepsilon\\) we set how close the terms of the sequence need to be to \\(L\\) and the definition then says we must be able to find an integer \\(N\\) such that all terms of the sequence \\(a_n\\) for \\(n\\geq N\\) (i.e. the values \\(a_N,a_{N+1},a_{N+2},\\dotsc\\)) are within \\(\\varepsilon\\) of \\(L\\); we then need to be able to do this for any value of \\(\\varepsilon\\) – this is how we formally state that the terms must be getting closer to \\(L\\). (The Greek lower-case letter epsilon \\(\\varepsilon\\) is commonly used to denote a “small” number in mathematics.) If the sequence \\((a_n)_{n=1}^{\\infty}\\) has limit \\(L\\), we write \\[ \\lim\\limits_{n\\to\\infty}a_n=L \\] read as “the limit of \\(a_n\\) as \\(n\\) approaches infinity is \\(L\\)”, or alternatively \\[ a_n\\to L\\text{ as }n\\to\\infty \\] read as “\\(a_n\\) tends to the limit \\(L\\) as \\(n\\) tends to infinity”. Note that for any arithmetic sequence \\(a_n=a+(n-1)d\\) we have: \\(d&gt;0\\): divergence to \\(\\infty\\); \\(d=0\\): convergence to \\(a\\) (all terms are \\(a\\)); \\(d&lt;0\\): divergence to \\(-\\infty\\). For geometric sequences \\(a_n=ar^n\\) with \\(a\\neq 0\\) we have: \\(r&gt;1\\): divergence to \\(\\infty\\) if \\(a&gt;0\\), or \\(-\\infty\\) if \\(a&lt;0\\); \\(r=1\\): convergence to \\(a\\) (the constant sequence with all terms \\(a\\)); \\(-1 &lt; r &lt; 1\\): convergence to \\(0\\) (the constant sequence with all terms \\(0\\) in the case \\(r=0\\)); \\(r\\leq-1\\): an oscillating sequence. "],["series.html", "Chapter 14 Series 14.1 Sigma Notation 14.2 Infinite Series 14.3 Power Series 14.4 Taylor Series", " Chapter 14 Series A series is the sum of the terms of a sequence. 14.1 Sigma Notation Given a sequence \\(a_1,a_2,a_3,\\dotsc\\) the sum of the first \\(n\\) terms is written \\[ \\sum_{k=1}^{n}a_k=a_1+a_2+\\dotsb+a_n \\] (read as “the sum of \\(a_k\\) from \\(k=1\\) to \\(n\\)”). Such a sum is called a series. Note that the summation index \\(k\\) is a dummy index — we can happily replace it with another label. We can also shift the starting value of the index, that is, we can reindex the series; this may be useful to give a simpler expression for the series. For example, we can equivalently write the above series as \\[\\begin{align*} \\sum_{j=1}^{n}a_j,&amp;&amp;\\sum_{k=0}^{n-1}a_{k+1},&amp;&amp;\\sum_{p=100}^{n+99}a_{p-99}, \\end{align*}\\] since these all sum the same values from the sequence. We are quite often interested in summing the terms of a given sequence. The sum of the first \\(n\\) terms of an arithmetic sequence is: \\[ \\sum_{k=1}^{n}a_k=\\frac{n}{2}\\left(2a+(n-1)d\\right) \\] and the sum of the first \\(n\\) terms is: \\[ \\sum_{k=1}^{n}a_k=\\frac{a(1-r^n)}{1-r} \\] for \\(r\\neq1\\), and \\[ \\sum_{k=1}^{n}a_k=na \\] for \\(r=1\\). 14.2 Infinite Series Consider the sequence defined by \\(a_n=\\dfrac{1}{2^n}\\). What is the sum of all the terms of this sequence? That is, the sum \\[ \\frac{1}{2}+\\frac{1}{2^2}+\\frac{1}{2^3}+\\frac{1}{2^4}+\\dotsb=\\frac{1}{2}+\\frac{1}{4}+\\frac{1}{8}+\\frac{1}{16}+\\dotsb \\] We can view the terms of the sequence geometrically as fractions of a square with total area one. Figure 14.1: The series \\(\\sum_{n=1}^\\infty\\dfrac{1}{2^n}\\) can be viewed as summing up parts of a square with total area one. We are effectively summing up parts of the square, whereby we keep adding half of what is left. Since after an “infinite number” of terms we will have included all parts of the square, it looks like \\[ \\frac{1}{2}+\\frac{1}{2^2}+\\frac{1}{2^3}+\\frac{1}{2^4}+\\dotsb=1. \\] This example is a geometric series, which is a sum of a geometric sequence. Here we have first term \\(a=\\frac{1}{2}\\) and common ratio \\(r=\\frac{1}{2}\\). The sum of the first \\(n\\) terms of a geometric series is (for \\(r\\neq1\\)): \\[ S_n=\\sum_{k=1}^{n}ar^{k-1}=\\frac{a(1-r^n)}{1-r} \\] so we have \\[ S_n=\\frac{\\dfrac{1}{2}\\left(1-\\dfrac{1}{2^n}\\right)}{1-\\dfrac{1}{2}}=\\left(1-\\dfrac{1}{2^n}\\right). \\] The sum of the first \\(n\\) terms of a series is called the \\(n^\\text{th}\\) partial sum of the series. We define the sum of an infinite series to be the limit of the partial sums. In this example we have \\[ \\lim\\limits_{n\\to\\infty}S_n=\\lim\\limits_{n\\to\\infty}\\left(1-\\dfrac{1}{2^n}\\right)=1. \\] Infinite series can be convergent (sum to a finite value) or divergent (to \\(+\\infty\\) or \\(-\\infty\\), or oscillate). Example 14.1 (Some infinite series) Consider the sum of the first \\(n\\) natural numbers: \\[ T_n=\\sum_{k=1}^{n}k=1+2+3+\\dotsb +n \\] This is an , i.e. the sum of an arithmetic sequence. The partial sum can be written as the general formula \\[ T_n=\\frac{n(n+1)}{2}. \\] We have \\(\\displaystyle\\sum_{k=1}^\\infty k=\\lim\\limits_{n\\to\\infty} T_n=\\infty\\), and hence this infinite series diverges to infinity. Note that all arithmetic series diverge to \\(\\pm\\infty\\) (why?). Let \\(a_n=(-1)^n\\) and consider the infinite series \\(\\sum_{n=1}^{\\infty}a_n\\). This is a geometric series with \\(a=-1\\) and \\(r=-1\\). We have the partial sums \\[\\begin{align*} S_1&amp;=-1\\\\ S_2&amp;=-1+1=0\\\\ S_3&amp;=-1+1-1=-1 \\end{align*}\\] with general formula \\[ S_n= \\begin{cases} -1&amp;\\text{if $n$ is odd,}\\\\ 0&amp;\\text{if $n$ is even.} \\end{cases} \\] Hence \\(\\lim\\limits_{n\\to\\infty}S_n\\) does not exist (it oscillates) and the infinite series diverges. We have seen an example of a convergent geometric series \\(\\sum_{n=1}^\\infty\\frac{1}{2^n}=1\\), a divergent geometric series \\(\\sum_{n=1}^{\\infty}(-1)^n\\) which oscilates$. We can also have divergent series that diverge to \\(\\pm\\infty\\). We’ll now look at the general behaviour of a geometric series \\(\\sum_{k=1}^{\\infty}ar^{k-1}\\). Recall that the partial sums are given by \\[ S_n=\\sum_{k=1}^{n}ar^{k-1}=\\frac{a(1-r^n)}{1-r} \\] and note that the only term that depends on \\(n\\) is \\(r^n\\). If \\(-1&lt; r &lt;1\\), then \\(r^n\\to 0\\) as \\(n\\to infty\\) and the sum will be convergent with \\[ S=\\lim\\limits_{n\\to\\infty}S_n=\\frac{a}{1-r} \\] If \\(r=1\\) then the partial sums become \\(S_n=\\sum_{k=1}^{n}a=na\\), which clearly diverges to infinity. If \\(r&gt;1\\), then \\(r^n\\)$ and hence \\(S_n\\to\\infty\\). If \\(r=-1\\), then we have a similar situation to the previous example with \\(S_n\\) alternating between \\(+a\\) and \\(-a\\). The series oscillates (a type of divergence). If \\(r&lt;-1\\) then we alternately add and subtract numbers which are getting bigger and bigger in absolute value, so the series oscillates between increasingly larger positive and negative values. The \\[ \\sum_{n=1}^{\\infty}\\frac{1}{n} \\] diverges to infinity, that is, \\(\\lim\\limits_{n\\to\\infty}\\sum_{k=1}^{n}\\frac{1}{k}=\\infty\\). To see this we collect together some terms \\[ \\sum_{n=1}^{\\infty}\\frac{1}{n}=1+\\frac{1}{2}+\\left( \\frac{1}{3}+\\frac{1}{4}\\right) +\\left( \\frac{1}{5}+\\frac{1}{6}+\\frac{1}{7}+\\frac{1}{8}\\right) +\\dotsb \\] and by comparing the terms in brackets with those in the following series, we can see that the harmonic series must be greater than this series \\[\\begin{align*} &amp;1+\\frac{1}{2}+\\left( \\frac{1}{4}+\\frac{1}{4}\\right) +\\left( \\frac{1}{8}+\\frac{1}{8}+\\frac{1}{8}+\\frac{1}{8}\\right) +\\dotsb\\\\ &amp;=1+\\frac{1}{2}+\\left( \\frac{1}{2}\\right) +\\left(\\frac{1}{2}\\right) +\\dotsb \\end{align*}\\] Since the second series clearly diverges to infinity, so must the harmonic series. It actually diverges incredibly slowly — here are some of the partial sums: \\[ S_{10}\\approx 2.93,\\qquad S_{20}\\approx 3.40,\\qquad S_{1000}\\approx 7.49,\\qquad S_{100000}\\approx 12.09 \\] This example shows in particular that even if the terms are shrinking towards zero the series need not converge — the speed at which they shrink is also important. On the other hand, if the terms in a series don’t shrink to zero then the series will obviously diverge! Interestingly a series of the form \\[ \\sum_{n=1}^{\\infty}\\frac{1}{n^p} \\] where \\(p\\) is a real constant diverges if \\(p\\leq 1\\) and converges if \\(p&gt;1\\), so the terms \\(\\frac{1}{n}\\) in the harmonic series are decreasing only just too slowly to give a convergent series. In particular it can be shown that \\[ \\sum_{n=1}^{\\infty}\\frac{1}{n^2}=\\frac{\\pi}{6} \\] This curious result was found by Leonhard Euler in 1734: see The Basel Problem. It is not easy to solve with the techniques considered in these notes and is best tackled with more powerful mathematical tools, like Fourier Series. 14.3 Power Series Let \\(t\\) be a fixed real number. A power series is a series of the form \\[ \\sum_{n=0}^{\\infty}a_n(x-t)^n \\] where \\((a_n)_{n=0}^{\\infty}\\) is a sequence and \\(x\\) is a real number. Power series can be thought of as “polynomials with infinite degree”, but technically they are not polynomials, which must have finite degree. Consider the power series \\[ \\sum_{n=0}^{\\infty}\\frac{x^n}{n+1}=1+\\frac{x}{2}+\\frac{x^2}{3}+\\frac{x^3}{4}+\\dotsb \\] For \\(x=-1\\) this gives the alternating harmonic series, which converges. For \\(x=1\\) this gives the harmonic series, which diverges. So convergence of a power series can depend on the value of \\(x\\). The binomial series is another example of a power series \\[ (1+x)^\\alpha=1+\\alpha x+\\frac{\\alpha(\\alpha-1)}{2!}x^2+\\frac{\\alpha(\\alpha-1)(\\alpha-2)}{3!}x^3+\\dotsb \\] which converges for any real value of \\(\\alpha\\) as long as \\(|x|&lt;1\\). 14.4 Taylor Series 14.4.1 Linearisation It is often useful to approximate a complicated function by something that is easier to work with. The simplest way to do this at a differentiable point \\(a\\) of a function \\(f\\) is to approximate the values of the function \\(f\\) near \\(a\\) by the tangent line \\[ y=f(a)+f&#39;(a)(x-a). \\] In this context, we call the tangent line the of \\(f\\) at \\(a\\), and write it as the function \\[ L_a(x)=f(a)+f&#39;(a)(x-a). \\] At values of \\(x\\) sufficiently close to \\(a\\), \\(L_a(x)\\) gives a good approximation to \\(f(x)\\). We can see this should be true since the derivative is obtained as a limit of the slope of secant lines passing through nearby points and since this limit converges, if we zoom in on the graph of \\(f\\) at \\((a,f(a))\\) it should look more and more like a straight line, i.e. it is approximately linear. Figure 14.2: Zooming in on the tangent line at \\((a,f(a))\\). More mathematically we have \\[ \\lim\\limits_{x\\to a}\\frac{f(x)-L_a(x)}{(x-a)}=\\lim\\limits_{x\\to a}\\frac{f(x)-f(a)}{x-a}-f&#39;(a)=0 \\] where the second equality uses the definition of the derivative. This says that as \\(x\\) approaches \\(a\\) not only does the difference \\(f(x)-L_a(x)\\) become small, but it becomes small faster than \\(x-a\\). Whether or not the linearisation is a good enough approximation depends on the application, and in particular how wide a range of \\(x\\) values we are interested in near the point. Next we look at a better (but necessarily more complicated) way of obtaining a local approximation to a differentiable function by using polynomials. 14.4.2 Taylor Polynomials Consider a general polynomial function \\[ p(x)=a_0+a_1 x+\\dotsb +a_n x^n. \\] The coefficients \\(a_k\\) can be expressed in terms of the value of \\(p\\) and its derivatives at \\(0\\) as follows \\[\\begin{align*} p(x)&amp;=a_0+a_1 x+\\dotsb +a_n x^n &amp; p(0)&amp;=a_0\\\\ p&#39;(x)&amp;=a_1+2a_2x+\\dotsb +n a_n x^{n-1}&amp; p&#39;(0)&amp;=a_1\\\\ p&#39;&#39;(x)&amp;=2a_2+6a_3 x+\\dotsb +n(n-1)a_n x^{n-2}&amp;p&#39;&#39;(0)&amp;=2a_2 \\end{align*}\\] and in general \\[ p^{(k)}(0)=k!a_k\\qquad\\text{or}\\qquad a_k=\\frac{p^{(k)}(0)}{k!} \\] for \\(0\\leq k \\leq n\\), with the definitions \\(p^{(0)}=p\\) and \\(0!=1\\). We could perform a similar analysis (exercise) for a polynomial in \\((x-a)\\) \\[ p(x)=a_0+a_1(x-a)+\\dotsb +a_n (x-a)^n \\] and arrive at \\[ a_k=\\frac{p^{(k)}(a)}{k!}. \\] Suppose that \\(f\\) is any function such that the derivatives \\(f^{(1)}(a),\\dotsc, f^{(n)}(a)\\) all exist. Then letting \\[ a_k=\\frac{f^{(k)}(a)}{k!} \\] we define the Taylor Polynomial of degree \\(n\\) for \\(f\\) at \\(a\\) as \\[ P_{n,a}(x)=a_0+a_1(x-a)+\\dotsb +a_n (x-a)^n. \\] The Taylor Polynomial \\(P_{n,a}\\) has been defined so that it has the same \\(k^\\text{th}\\) derivative as \\(f\\) at \\(a\\): \\[ P_{n,a}^{(k)}(a)=f^{(k)}(a)\\qquad\\text{for all }0\\leq k\\leq n \\] (Exercise: check this) and in fact is clearly the unique polynomial with degree \\(\\leq n\\) with this property. Also note that the first degree Taylor Polynomial \\(P_{1,a}\\) is the same as the linearisation \\(L_a\\). We now want to show that a Taylor Polynomial can provide a good approximation to a function and in particular that the higher the degree of the polynomial the better the approximation. Example 14.2 (Taylor Polynomial) We find the \\(n^\\text{th}\\) degree Taylor Polynomial of \\(\\sin\\) at \\(0\\). The first few derivatives at \\(0\\) are: \\[\\begin{align*} \\sin(0)&amp;=0\\\\ \\sin^{(1)}(0)&amp;=\\cos(0)=1\\\\ \\sin^{(2)}(0)&amp;=-\\sin(0)=0\\\\ \\sin^{(3)}(0)&amp;=-\\cos(0)=-1\\\\ \\sin^{(4)}(0)&amp;=\\sin(0)=0 \\end{align*}\\] and we can see that higher order derivatives will cycle through \\(0,1,0,-1\\). The coefficients \\(a_k=\\dfrac{\\sin^{(k)}(a)}{k!}\\) are therefore: \\(0,1,0,-\\frac{1}{3!},0,\\frac{1}{5!},\\dotsc\\), so there are no even powers of \\(x\\). We can list just odd numbers by considering \\(2n+1\\) for any natural number \\(n\\). Then the Taylor Polynomial \\(P_{2n+1,0}\\) of degree \\({2n+1}\\) for \\(\\sin\\) at \\(0\\) is: \\[ P_{2n+1,0}(x)=x-\\frac{x^3}{3!}+\\frac{x^5}{5!}-\\frac{x^7}{7!}+\\dotsc+(-1)^n\\frac{x^{2n+1}}{(2n+1)!} \\] By plotting the first few Taylor polynomials of \\(\\sin\\) at \\(0\\), it appears that adding more terms provides a better approximation of \\(\\sin\\) Figure 14.3: First few Taylor polynomials of \\(\\sin(x)\\) at \\(0\\) As another example, consider the \\(n^\\text{th}\\) degree Taylor Polynomial of \\(e^x\\) at \\(0\\): \\[ P_{n,0}=1+x+\\frac{x^2}{2!}+\\frac{x^3}{3!}+\\dotsb+\\frac{x^n}{n!} \\] If we plot \\(P_{n,0}\\) for the first few \\(n\\) it does indeed appear that \\(P_{n,0}(x)\\) is closer to \\(e^x\\) at zero for higher values of \\(n\\). We will now make this idea more precise. Theorem 14.1 (theorem name) Let \\(P_{n,a}\\) be the Taylor polynomial of degree \\(n\\) of a function \\(f\\) at a point \\(a\\). Then \\[ \\lim\\limits_{x\\to a}\\frac{f(x)-P_{n,a}(x)}{(x-a)^n}=0, \\] that is, \\(P_{n,a}\\) is equal to \\(f\\) up to order \\(n\\) at \\(a\\). Moreover, \\(P_{n,a}\\) the unique polynomial of degree \\(n\\) with this property. This says that \\(P_{n,a}\\) is the unique degree \\(n\\) polynomial that best approximates \\(f\\) at \\(a\\), in the sense that as \\(x\\to a\\) the difference between \\(f\\) and \\(P_{n,a}\\) tends to zero relatively quickly (faster than \\((x-a)^n\\), which goes to zero faster for increasing values of \\(n\\)). So, the higher the degree of the Taylor Polynomial the faster the values converge to the original function at the point \\(a\\). 14.4.3 Taylor Series So far we have considered approximating functions by Taylor polynomials, that is, for a function \\(f\\) we defined the \\(n^\\text{th}\\) degree Taylor polynomial \\[ P_{n,a}(x)=\\sum_{k=0}^{n}\\frac{f^{(k)}(a)}{k!}(x-a)^k. \\] We saw that taking higher degree Taylor polynomials can give better approximations of a function. Now, what if we let \\(n\\to\\infty\\)? That is, if we consider the power series \\[ \\sum_{k=0}^{\\infty}\\frac{f^{(k)}(a)}{k!}(x-a)^k=\\lim\\limits_{n\\to\\infty}P_{n,a}(x). \\] We might expect that in the limit we in fact get \\[ \\displaystyle\\sum_{k=0}^{\\infty}\\frac{f^{(k)}(a)}{k!}(x-a)^k=f(x). \\] Is this the case? The short answer is: not always, but it does for “everyday” functions at least on some interval around \\(a\\) (such as trigonometric functions, hyperbolic functions, roots, exponentials and logarithms). We call a power series of the form \\[ \\sum_{k=0}^{\\infty}\\frac{f^{(k)}(a)}{k!}(x-a)^k \\] the Taylor series for \\(f\\) at \\(a\\). When a Taylor series is formulated at the point \\(a=0\\), it is often referred to as a Maclaurin series. A Taylor series is a type of power series. In the previous section we saw that a power series might only converge for certain values of \\(x\\). Generally, the Taylor series of a functino will either converge to the function for all values of \\(x\\) or within some interval. Here we list some commonly used Taylor series derived at \\(a=0\\), which you should familiarise yourself with. The Validity column states the interval around \\(0\\) for which the Taylor series is equal to the original function. Series Validity \\(\\frac{1}{1-x}=1+x+x^2+x^3+\\dotsb=\\sum_{n=0}^{\\infty}x^n\\) \\(-1&lt; x &lt; 1\\) \\(e^x=1+x+\\frac{x^2}{2!}+\\frac{x^3}{3!}+\\dotsb = \\sum_{n=0}^{\\infty}\\frac{x^n}{n!}\\) \\(-\\infty\\leq x \\leq \\infty\\) \\(\\cos(x)=1-\\frac{x^2}{2!}+\\frac{x^4}{4!}-\\dotsb= \\sum_{n=0}^{\\infty}(-1)^n\\frac{x^{2n}}{(2n)!}\\) \\(-\\infty\\leq x \\leq \\infty\\) \\(\\sin(x)=x-\\frac{x^3}{3!}+\\frac{x^5}{5!}-\\dotsb=\\sum_{n=0}^{\\infty}(-1)^n\\frac{x^{2n+1}}{(2n+1)!}\\) \\(-\\infty\\leq x \\leq \\infty\\) \\(\\ln(x+1)=x-\\frac{x^2}{2!}+\\frac{x^3}{3!}-\\dotsb= \\sum_{n=1}^{\\infty}(-1)^{n+1}\\frac{x^{n}}{n!}\\) \\(-1&lt; x \\leq 1\\) \\(\\tan^{-1}(x)=x-\\frac{x^3}{3}+\\frac{x^5}{5}-\\dotsb= \\sum_{n=0}^{\\infty}(-1)^n\\frac{x^{2n+1}}{2n+1}\\) \\(-1\\leq x \\leq 1\\) "],["integration.html", "Chapter 15 Integration 15.1 Indefinite Integrals 15.2 Definite Integrals", " Chapter 15 Integration Integration is (almost) the reverse process of differentiation. Geometrically, differentiation corresponds to finding the gradient of a tangent line, whilst integration corresponds to finding the area under a curve. The precise relationship between differentation and integration will be given later by the Fundamental Theorem of Calculus. 15.1 Indefinite Integrals Consider the following function \\[F(x)=x^2.\\] Its derivative is \\[\\frac{dF(x)}{dx}=2x.\\] If integration is the reverse process of differentation, then we might expect the integral of \\(f(x)=2x\\) to be \\(F(x)=x^2\\). However, note that the derivative of \\[G(x)=x^2+3\\] is also \\[\\frac{dG(x)}{dx}=2x=f(x).\\] Hence, it would be impossible to know if \\(F\\) or \\(G\\) was the original function. In fact, any function of the form \\(2x+C\\) where \\(C\\) is a constant would yield the same derivative. Therefore, the best we can do is to say the integral of \\(f(x)=2x\\) has the form \\(x^2+C\\). More generally, the graphs of all functions of the form \\(F(x)+C\\) for some particular function \\(F\\) and various constants \\(C\\) are just vertical translations of one another, so we can see they would indeed have the same gradient at any point \\(x\\). If \\(\\frac{dF(x)}{dx}=f(x)\\) we say that “\\(F(x)+C\\)” with \\(C\\) an arbitrary constant is the indefinite integral of \\(f(x)\\). The operation of taking the indefinite integral of a function \\(f(x)\\) is written \\[\\int f(x) dx\\] which is read as “the integral of \\(f(x)\\) with respect to \\(x\\)”, where \\(\\int\\) denotes taking the integral and \\(dx\\) specifies that we are integrating with respect to the variable \\(x\\) (we need to specify this as some functions might have more than one variable). In this context the function \\(f(x)\\) being integrated is called the integrand. If we know a function \\(F(x)\\) whose derivative is \\(f(x)\\) then we can immediately find the indefinite integral as \\(F(x)+C\\). A function \\(F\\) such that \\(\\frac{dF(x)}{dx}=f(x)\\) is called an anti-derivative of \\(f\\). 15.1.1 Standard Integrals Some basic integrals obtained from differentiating well known functions \\[\\begin{eqnarray} &amp;&amp; \\frac{d }{d x} \\sin(x) = \\cos(x) \\; \\to \\; \\int \\cos(x) d x = \\sin(x) +C \\nonumber \\\\ &amp;&amp; \\frac{d }{d x} \\cos(x) = -\\sin(x) \\; \\to \\; \\int \\sin(x) d x = -\\cos(x) +C \\nonumber \\\\ &amp;&amp; \\frac{d }{d x} \\tan(x) = \\frac{1}{\\cos^2(x)} \\; \\to \\; \\int \\frac{1}{\\cos^2(x)} d x = \\tan(x) +C \\nonumber \\\\ &amp;&amp; \\frac{d }{d x} \\cot(x) = - \\frac{1}{\\sin^2(x)} \\; \\to \\; \\int \\frac{1}{\\sin^2(x)} d x = - \\cot(x) +C \\nonumber \\\\ &amp;&amp; \\frac{d }{d x} \\frac{x^{n+1}}{n+1} = x^n \\; \\to \\; \\int x^n \\; dx = \\frac{x^{n+1}}{n+1} +C \\; \\; \\nonumber \\\\ &amp;&amp; \\frac{d }{d x} \\sin^{-1}(x) = \\frac{1}{\\sqrt{1-x^2} } \\; \\to \\; \\int \\frac{1}{\\sqrt{1-x^2} } d x = \\sin^{-1}(x) +C \\nonumber \\\\ &amp;&amp; \\frac{d }{d x} \\tan^{-1}(x) = \\frac{1}{1+x^2} \\; \\to \\; \\int \\frac{1}{1+x^2 } d x = \\tan^{-1}(x) +C \\nonumber \\\\ &amp;&amp; \\frac{d }{d x} e^x = e^x \\; \\to \\; \\int e^x dx = e^x +C\\nonumber \\\\ &amp;&amp; \\frac{d }{d x} \\ln |x| = \\frac{1 }{x} \\; \\to \\; \\int \\frac{1}{x} d x = \\ln |x| +C \\nonumber \\\\ &amp;&amp; \\frac{d }{d x} a^x = a^x \\ln a \\; \\to \\; \\int a^x d x = \\frac{a^x}{\\ln a} +C \\nonumber \\\\ &amp;&amp; \\frac{d }{d x} \\sinh(x) = \\cosh(x) \\; \\to \\; \\int \\cosh(x) d x = \\sinh(x) +C, \\nonumber \\\\ &amp;&amp; \\frac{d }{d x} \\cosh(x) = \\sinh(x) \\; \\to \\; \\int \\sinh(x) d x = \\cosh(x) +C, \\nonumber \\\\ \\end{eqnarray}\\] 15.2 Definite Integrals Integration is defined by finding the area under the curve of a function. This is achieved by taking successively more accurate approximations, in a similar way to finding the gradient of a tangent line in differentation. To find the area under a curve \\(f\\) between points \\(x=a\\) and \\(x=b\\), we can draw rectangles of some “small” width and whose height is the value of the function at some point between the edges of the rectangle. Some of these rectangles will over-estimate the area under their part of the curve and others will under-estimate the area. This error is reduced by taking thinner and thinner rectangles (and hence using a greater number of rectangles). In the limit that the width tends to \\(0\\), we obtain the area under the curve \\(f\\) between \\(a\\) and \\(b\\). When the upper limit \\(a\\) and lower limit \\(b\\) are specified like this, we have the definite integral of \\(f\\). Note that if a curve crosses the \\(x\\)-axis, then the “area under the curve” obtained from the definite integral is the area above the \\(x\\)-axis minus the area below the \\(x\\)-axis. The following is a formal definition of the integral, which is included for completeness, but can be ignored for now. Definition 15.1 (Reimann Integral) Consider a partition \\(P_n\\) of the interval \\(a\\leq x\\leq b\\) into \\(n\\) equal width subintervals \\[x_i\\leq x\\leq x_j\\] for \\(i=0,\\dotsc,n\\) with \\(x_0=a\\), \\(x_i=a+i\\Delta x\\), \\(x_n=b\\) and width \\(\\Delta x=(b-a)/n\\). For each subinterval choose a point \\(c_i\\) such that \\(x_i &lt; c_i &lt; x_j\\). Then the integral is approximated by \\[\\sum_{i=1}^{n-1}f(c_i)\\Delta x.\\] If the following limit exists independently of the choice of the points \\(c_i\\) \\[\\lim_\\limits{n\\to\\infty}\\sum_{i=1}^{n-1}f(c_i)\\Delta x\\] then we call this the integral of \\(f\\) between \\(a\\) and \\(b\\), and denote it by \\[\\int_{a}^{b}f(x)dx.\\] Theorem 15.1 (Some Properties of Definite Integrals) \\[\\begin{eqnarray} &amp;&amp;\\int_a^b [f(x)+g(x)] dx = \\int_a^b f(x) dx + \\int_a^b g(x) dx \\nonumber \\\\ &amp;&amp;\\int_a^b \\alpha f(x) dx = \\alpha \\int_a^b f(x) dx dx \\nonumber \\\\ &amp;&amp; \\int_a^b f(x) dx = -\\int_b^a f(x) dx \\nonumber \\\\ &amp;&amp;\\int_a^a f(x) dx = 0 \\nonumber \\\\ &amp;&amp; \\int_a^b f(x) dx = \\int_a^c f(x) dx + \\int_c^b f(x) dx, \\; \\text{ for any $c$ such that $a&lt;c&lt;b$} \\nonumber \\\\ &amp;&amp; \\int_a^b f(x) dx \\ge 0,\\; \\mbox{ if } \\; f(x) &gt;0, \\; a \\leq x \\leq b \\nonumber \\\\ &amp;&amp; \\int_{-a}^a f(x) dx =2 \\int_{0}^a f(x) dx ,\\; \\text{ if $f(x)= f(-x)$ (e.g. $\\cos(x)$, $x^2$)} \\nonumber \\\\ &amp;&amp; \\int_{-a}^a f(x) dx = 0 ,\\; \\text{ if $f(x)= -f(x)$ (e.g. $\\sin(x)$, $x^3$)} \\nonumber \\end{eqnarray}\\] The key theorem of calculus that links differentiation and integration is known as the Fundamental Theorem of Calculus. Theorem 15.2 (Fundamental Theorem of Calculus (FTC)) Let the function \\(f\\) be continuous on the interval from \\(a\\) to \\(b\\). Then: The function \\(g\\) defined by \\[g(x)=\\int_a^xf(x)dx\\] is continuous on the interval \\(a\\le x \\le b\\) and differentiable on the interval \\(a&lt; x &lt; b\\) with \\[\\frac{dg(x)}{dx}=f(x).\\] The definite integral of \\(f\\) from \\(a\\) to \\(b\\) is given by \\[\\int_a^bf(x)dx=F(b)-F(a)\\] where \\(F\\) is any anti-derivative of \\(f\\). To find the definite integral we can make use of part 2 of the FTC 15.2 together with the properties in 15.1. Example 15.1 (Definite Integrals) Evaluate the definite integral \\[ \\int_0^3 f(x) dx = \\int_0^3 (x^3- 6x) dx, \\] First observe that: \\[ \\frac{d}{d x} \\left( \\frac{1}{4}x^4-3 x^2 \\right)=x^3- 6x=f(x). \\] So an anti-derivative of \\(f(x)\\) is \\(F(x)=\\frac{1}{4}x^4-3 x^2\\). The fundamental Theorem of Calculus then gives \\[ \\begin{array}{ll} \\int_0^3 f(x) dx =F(3) -F(0) \\\\ \\\\ &amp; = \\frac{1}{4} 3^4-3\\,3^2 =\\frac{3}{4} 27- 27= -\\frac{27}{4} \\end{array} \\] Alternatively, using the properties of the integral and our list of standard integrals \\[\\begin{align*} \\int_0^3 (x^3- 6x) dx&amp;=\\int_0^3 x^3 dx -6\\int_0^3 x dx\\\\ &amp;=[\\frac{x^4}{4}]_0^3-6[\\frac{x^2}{2}]_0^3\\\\ &amp;=[\\frac{x^4}{4}-3x^2]_0^3\\\\ &amp;=(\\frac{81}{4}-27)-(0-0)\\\\ &amp;=\\frac{-27}{4} \\end{align*}\\] Evaluate \\[ \\int_0^\\frac{\\pi}{2} \\cos(x) dx. \\] We have: \\[\\begin{align*} \\int_0^\\frac{\\pi}{2} \\cos(x) dx&amp;=[\\sin(x)]_0^\\frac{\\pi}{2}\\\\ &amp;=\\sin\\left(\\frac{\\pi}{2}\\right)-\\sin(0)\\\\ &amp;=1 \\end{align*}\\] "],["further-integration-techniques.html", "Chapter 16 Further Integration Techniques 16.1 Integration by Substitution 16.2 Integrals of trigonometric and hyperbolic functions 16.3 Integrals of rational functions using partial fractions 16.4 Integration by Parts", " Chapter 16 Further Integration Techniques 16.1 Integration by Substitution Theorem 16.1 (Integration by Substitution) If $ u=u(x)$ is a differentiable function and \\(f\\) is continuous, then \\[ \\int f( u(x) ) \\frac{du(x)}{dx} dx = \\int f( u ) du \\quad \\text{indefinite integral} \\] \\[ \\int_a^b f( u(x) ) \\frac{du(x)}{dx} dx = \\int_{u(a)}^{u(b)} f(u) du \\quad \\text{definite integral}. \\] Here \\(d u\\) acts as if it is a differential: \\[ du= \\frac{du(x)}{dx} dx, \\;\\; d (c+x)=dx; \\;\\; d (x^2)=2x dx, \\;\\; d (\\sin x)= \\cos x d x, ..., \\] Example 16.1 (Integration by Substitution) Evaluate the indefinite integral \\[ \\int (3x+2)^4 dx \\] Introduce \\(u=3x+2\\), then \\(du= \\frac{du}{dx}\\; dx = 3\\; dx\\), so \\(dx=\\frac{1}{3} du\\). Now we can write \\[\\begin{align*} \\int (3x+2)^4 dx&amp;= \\int u^4 \\frac{du}{3}\\\\ &amp;=\\frac{1}{3}\\frac{u^5}{5}+C\\\\ &amp;=\\frac{1}{15}(3x+2)^5+C. \\end{align*}\\] Evaluate the indefinite integral \\[\\int \\cos(5x) dx\\] Introduce \\(u=5x\\), then \\(du = \\frac{du}{dx}\\; dx = 5\\; dx\\), so \\(dx = \\frac{1}{5} du\\). Now we can write \\[\\begin{align*} \\int \\cos(5x) dx&amp;=\\int \\cos(u)\\frac{du}{5}\\\\ &amp;=\\frac{1}{5}\\sin(u)+C\\\\ &amp;=\\frac{1}{5}\\sin(5x)+C \\end{align*}\\] Evaluate the indefinite integral \\[ \\int 2 x \\sqrt{1+x^2} dx. \\] Introduce \\(u=1+x^2\\), then \\(d u = \\frac{du}{dx}\\; d x=2x \\; dx\\) and we can write \\[\\begin{align*} \\int \\sqrt{(1+x^2)} (2x dx)&amp;=\\int {u}^{1/2} du &amp;=\\frac{2}{3} u^{3/2}+C\\\\ &amp;= \\frac{2}{3} (1+x^2)^{3/2}+C. \\end{align*}\\] Evaluate the indefinite integral \\[ \\int x^3 \\cos (2+x^4) dx. \\] Introduce \\(u=2+x^4\\), then \\(d u =\\frac{du}{dx} \\; d x=4x^3 \\; dx\\) and we can write \\begin{align*} (2+x^4) (4x^3 dx) &amp;= (u) du &amp;= (u) +C \\ &amp;= (2+x^4) +C. $$ Evaluate the definite integral \\[\\int_1^2 \\frac{-3}{2x} \\; dx.\\] Introduce \\(u=2x\\), then \\(du=\\frac{du}{dx}\\; dx = 2\\; dx\\) and we have (remembering to change the limits \\(a=1\\) and \\(b=2\\) to \\(u(a)=2\\) and \\(u(b)=4\\)) \\[\\begin{align*} \\int_1^2 \\frac{-3}{2x} \\; dx&amp;=\\frac{-3}{2}\\int_2^4\\frac{1}{u}\\; du\\\\ &amp;= [-\\frac{3}{2}\\ln(u)]_2^4\\\\ &amp;=\\frac{-3}{2}(\\ln(4)-\\ln(2))\\\\ &amp;=\\frac{-3}{2}\\ln(4/2)\\\\ &amp;=\\frac{-3}{2}\\ln(2)\\\\ &amp;=-1.04 \\text{to 2 d.p.} \\end{align*}\\] Or alternatively, rather than changing the limits we can substitute back in for \\(u\\) and use the original limits: \\[ [-\\frac{3}{2}\\ln(2x)]_1^2=-\\frac{3}{2}(\\ln(4)-\\ln(2))=\\frac{-3}{2}\\ln(2)=-1.04 \\text{to 2 d.p.} \\] 16.2 Integrals of trigonometric and hyperbolic functions Here we make extensive use of trigonometric and hyperbolic identities to transform the integrand into a more manageable form. Example 16.2 (Integrals using identities) Evaluate the definite integral \\[\\begin{align*} \\int_0^{\\pi} \\sin^2(x) dx &amp;=\\int_0^{\\pi} \\frac{1}{2} \\left( 1 - \\cos(2x) \\right) dx\\\\ &amp;= \\frac{1}{2} \\left[ x - \\frac{1}{2}\\sin(2x) \\right]_0^{\\pi}\\\\ &amp;= \\frac{\\pi}{2}\\\\ \\end{align*}\\] where we have used \\(\\cos(2\\theta) = 1 - 2 \\sin^2(\\theta)\\). Evaluate the indefinite integral \\[\\begin{align*} \\int \\sinh(3x)\\cosh(3x) dx &amp;= \\int \\frac{1}{2}\\sinh(6x) dx\\\\ &amp;=\\frac{1}{12}\\cosh(6x) + C \\end{align*}\\] where we have used \\(\\sinh(2x)=2\\sinh(x)\\cosh(x)\\). Evaluate the indefinite integral \\[\\begin{align*} \\int (\\sin^2 (x))^2 dx &amp; = \\int_0^{\\pi} \\frac{1}{4} \\left( 1 - \\cos(2x) \\right)^2 dx \\\\ &amp; =\\int_0^{\\pi} \\frac{1}{4} \\left( 1 - 2\\cos(2x) +\\cos^2(2x) \\right) dx \\\\ &amp; =\\int_0^{\\pi} \\frac{1}{4} \\left[ 1 - 2\\cos(2x) + \\frac{1}{2} \\left( 1 - \\cos(4x) \\right) \\right] dx\\\\ &amp; = \\frac{1}{4} \\left[ \\frac{3}{2} x -\\sin(2x) + \\frac{1}{8} \\sin(4x) \\right] +C \\end{align*}\\] where we have used \\(\\cos(2\\theta)=2\\cos^2(\\theta)-1\\). Evaluate the indefinite integral \\[\\begin{align*} \\int (\\sin4x \\cos 5x ) dx &amp; = \\int \\frac{1}{2} \\left[ \\sin (-x) +\\sin 9x \\right] dx \\\\ &amp; =\\frac{1}{2} \\left( \\cos(x) - \\frac{1}{9} \\cos 9x \\right) +C \\end{align*}\\] where we have used \\(\\sin(\\theta)\\cos(\\phi)=\\frac{1}{2}(\\sin(\\theta-\\phi)+\\sin(\\theta+\\phi))\\). Evaluate the indefinite integral \\[\\begin{equation*} \\int \\frac{\\sqrt{9-x^2}}{x^2} dx\\\\ \\end{equation*}\\] Making the substitution \\(x=3\\sin(\\theta), \\;\\; -\\frac{\\pi}{2} \\leq \\theta \\leq \\frac{\\pi}{2}\\), \\[\\begin{align*} \\int \\frac{\\sqrt{9-x^2}}{x^2} dx &amp; =\\int \\frac{\\sqrt{9-(3\\sin(\\theta))^2} }{(3\\sin(\\theta))^2} d(3\\sin(\\theta)) \\\\ &amp; = \\int \\frac{3\\cos(\\theta) }{9\\sin^2(\\theta) }(3\\cos(\\theta)) d\\theta\\\\ &amp;= \\int \\frac{\\cos^2(\\theta) }{\\sin^2(\\theta) } d \\theta \\\\ &amp; = \\int \\frac{1- \\sin^2(\\theta) }{\\sin^2(\\theta) } d \\theta\\\\ &amp; = \\int \\left( \\frac{1 }{\\sin^2(\\theta) } -1 \\right) d \\theta\\\\ &amp; = -\\cot(\\theta)-\\theta+C. \\end{align*}\\] 16.3 Integrals of rational functions using partial fractions Recall that a function of the form \\[f(x)=\\frac{p(x)}{q(x)}\\] where \\(p\\) and \\(q\\) are polynomials is known as a rational function. If \\(q(x)\\) is a polynomial of degree \\(m\\) and \\(p(x)\\) is a polynomial of degree \\(n &lt; m\\) then we can often write a rational function as \\[ \\frac{p(x)}{q(x)}=\\frac{c_1}{x-\\alpha_1}+\\dotsb + \\frac{c_n}{x-\\alpha_n} \\] where \\(\\alpha_i\\) are the distinct roots of \\(q\\). We can find the coefficients \\(c_1\\) by multiplying through by \\(q(x)\\) and equating coefficients of powers of \\(x\\) to obtain a system of linear equations for the \\(c_i\\). We know that \\[ \\frac{d}{dx} \\ln (x-\\alpha) = \\frac{1}{x-\\alpha} \\] and by using this fact repeatedly, we can then integrate any rational function of this form — but the answer depends on the details (because \\(\\ln(z)\\) is only defined for positive \\(z\\)). Other cases: If \\(p\\) has degree greater than \\(q\\), then we can first apply polynomial long division to obtain \\[\\frac{p(x)}{q(x)}=s(x)+\\frac{r(x)}{q(x)}\\] where the degree of \\(r\\) will be strictly less that the degree of \\(q\\), and we can then perform partial fractions on the remainder term \\(\\frac{r}{q}\\). If \\(q(x)\\) contains an irreducible quadratic factor — factors of the form \\(x^2+bx+c\\) that cannot be factorised into a product of linear factors \\((x-\\alpha)(x-\\beta)\\) with integer coefficients — then the numerator in the partial fractions will be a linear polynomial. For example, \\[\\frac{x^2+1}{(x+2)(x-1)(x^2+x+1)}=\\frac{c_1}{(x+2)}+\\frac{c_2}{x-1}+\\frac{bx+c}{x^2+x+1}.\\] If \\(q(x)\\) contains repeated roots — factors of the form \\((x-\\alpha)^t\\) — then the first \\(t\\) powers of \\((x-\\alpha)\\) will appear as denominators (although possibly with a zero numerator). For example, \\[\\frac{p(x)}{(x-\\alpha)^t}=\\frac{c_1}{x-\\alpha}+\\frac{c_2}{(x-\\alpha)^2}\\dotsb + \\frac{c_t}{(x-\\alpha)^t}.\\] Example 16.3 (Integration by partial fractions) Evaluate the indefinite integral \\[ I=\\int \\frac{2x^2 -x + 4} { x(x^2+4) } dx \\] we have \\[ \\left[ \\frac{2x^2 -x + 4} { x(x^2+4)}=\\frac{A} { x}+\\frac{Bx+C} {(x^2+4)}, A=1, B=1, C=-1 \\right] \\\\ \\] then \\[\\begin{align*} I= \\int \\left[ \\frac{1} {x} + \\frac{x-1} {x^2 +4 } \\right] \\\\ &amp; =\\int \\frac{dx} {x} + \\int \\frac{x} {x^2 +4 } dx -\\int \\frac{1} {x^2 +4 } dx \\\\ &amp; = \\ln |x| +\\frac{1}{2} \\ln (x^2 +4) - \\frac{1}{2} \\tan^{-1}(x/2)+C \\end{align*}\\] Evaluate the indefinite integral (the degree of the numerator is not less than the degree of the denominator) \\[ I=\\int \\frac{4x^2 -3x + 2} { 4x^2 -4x +3 } dx \\] We have \\[\\frac{4x^2 -3x + 2} { 4x^2 -4x +3 }=1+\\frac{x-1} { 4x^2 -4x +3 }; 4x^2 -4x +3=( 2x -1)^2 +2\\] Hence \\[\\begin{align*} I &amp; =\\int \\left[ 1+ \\frac{x-1} {(2x-1)^2+2 } \\right]dx \\\\ &amp;= x+ \\int \\left[ \\frac{ (1/2)(2x-1)-(1/2) } {(2x-1)^2+2 } \\right] (1/2) d(2x-1) \\\\ &amp;= x+\\int \\left(\\frac{1}{4} \\frac{(2x-1)} {(2x-1)^2+2 } - \\frac{1}{4} \\frac{1} {(2x-1)^2+2 } \\right) d(2x-1)\\\\ &amp;=x+ \\frac{1}{8} \\ln[(2x-1)^2+2] - \\frac{1}{4 \\sqrt{2}}\\tan^{-1} \\frac{2x-1}{ \\sqrt{2}} +C \\end{align*}\\] 16.4 Integration by Parts According to the product rule from differentiation: If \\(u(x)\\) and \\(v(x)\\) are differentiable functions, then \\[ \\frac{d (u(x)v(x))}{dx}=u(x) \\frac{d v(x)}{dx}+v(x) \\frac{d u(x)}{dx}. \\] From the Fundamental Theorem of Calculus 15.2 it follows that \\[ \\int \\frac{d}{dx} \\left( u(x)v(x) \\right) dx = u(x)v(x)= \\int \\left[u(x) \\frac{d v(x)}{dx}+v(x) \\frac{d u(x)}{dx}\\right] dx, \\] or \\[ u(x)v(x)= \\int u(x) \\frac{d v(x)}{dx} dx + \\int v(x) \\frac{d u(x)}{dx} dx. \\] Rearranging gives: \\[ \\int u(x) \\frac{d v(x)}{dx} dx= u(x)v(x) - \\int v(x) \\frac{d u(x)}{dx} dx. \\] This is the formula for integration by parts: \\[ \\int u \\; dv = uv - \\int v \\; d u. \\] Example 16.4 (Integration by parts) Evaluate the indefinite integral \\[ \\int \\ln x \\; dx, \\] where we take \\[ u=\\ln x, \\;\\; v=x \\] \\[\\begin{align*} uv - \\int v \\; d u &amp;= x \\ln x - \\int x d \\ln x \\\\ &amp; = x \\ln x - \\int x \\left( \\frac{1}{x} \\; d x \\right) \\\\ &amp; = x \\ln x - \\int \\; d x \\\\ &amp; = x \\ln x - x +C \\end{align*}\\] Evaluate the indefinite integral \\[ \\int x^2 e^x \\; dx, \\] where we take \\[ u=x^2, \\;\\; v=e^x, \\;\\; dv=d e^x= e^x \\; dx \\] \\[\\begin{align*} uv - \\int v \\; d u&amp;= x^2 e^x - \\int e^x d x^2\\\\ &amp;= x^2 e^x - \\int e^x (2x d x) \\end{align*}\\] We need to use integration by parts again by taking \\[ u=x, \\;\\; v=e^x, \\;\\; dv=d e^x= e^x \\; dx \\] \\[\\begin{align*} x^2 e^x - \\left( 2 \\int x d e^x \\right)&amp; = x^2 e^x - \\left( 2 x e^x - 2 \\int e^x d x \\right) \\\\ &amp; = x^2 e^x - \\left( 2 x e^x - 2 e^x +C \\right) \\end{align*}\\] Evaluate the indefinite integral \\[ I=\\int e^x \\sin(x) \\; dx, \\] where we take \\(u=e^x, v=-\\cos(x), dv= d (-\\cos(x))=\\sin(x) dx\\) \\[\\begin{align*} I=uv - \\int v \\; d u &amp;= - e^x \\cos(x) + \\int \\cos(x) e^x d x \\; \\; \\\\ &amp; = - e^x \\cos(x) + \\left( \\int e^x d \\sin(x) \\right) \\\\ &amp; = - e^x \\cos(x) + \\left( \\sin(x) e^x - \\int \\sin x d e^x\\right) \\\\ &amp; = - e^x \\cos(x) + \\sin(x) e^x - I \\end{align*}\\] Solving for \\(I\\): \\[\\begin{align*} I=\\frac{1}{2}(- e^x \\cos(x) + \\sin(x) e^x) + C \\end{align*}\\] "],["differential-equations.html", "Chapter 17 Differential Equations 17.1 Linear or Nonlinear ODEs 17.2 Separable First Order ODEs 17.3 Linear first order ODEs 17.4 Linear Second Order ODEs", " Chapter 17 Differential Equations A differential equation (DE) is an equation containing an unknown function and one or more of its derivatives. Here we stick to Ordinary Differential Equations (ODEs) which are DEs of only one independent variable14. Here are some classic examples: Falling under constant gravity \\[ m \\frac{d^2h}{dt^2} (t) = -mg \\] Newton’s Law of Cooling \\[ \\frac{dT_{in}}{dt} = c (T_{out} - T_{in}) \\] Cash in the bank (with interest rate \\(r\\)) \\[ \\frac{dc}{dt} = r c \\] Mass on the end of a spring (Newton’s law + Hooke’s law) \\[ m \\frac{d^2 x}{dt^2} = -k x \\] Many physical laws are formulated in terms of differential equations: we know how the rate of change of some quantity is related to the value of that quantity, then to find the function that describes the system, we need to solve the differential equation. We classify differential equations according to their structure and corresponding solution methods. It is useful to first identify the class so we can decide which solution method to apply. Here are some basic classes: The order of a differential equation is the highest order derivative that occurs in the equation. A linear ordinary differential equation of order \\(n\\) may be written as: \\[ p_0(x) \\frac{d^n y}{d x^n} +p_1(x) \\frac{d^{n-1} y}{d x^{n-1}} +p_2(x) \\frac{d^{n-2} y}{d x^{n-2}}+\\ldots + p_n(x) y(x)=r(x); \\] \\(y\\) is the dependent variable, \\(x\\) is the independent variable. A nonlinear differential equation: An equation that cannot be put in the above form. A homogeneous differential equation: \\(r(x)=0\\). An inhomogeneous differential equation: \\(r(x) \\ne 0.\\) What is the solution of an ODE? General solution: the general solution of an \\(n^\\text{th}\\) order ODE contains \\(n\\) arbitrary constants (a solution effectively needs us to integrate \\(n\\) times). Particular solution: A particular solution is obtained from a general solution by assigning particular values of the arbitrary constants. If \\(n\\) boundary conditions are specified, the \\(n\\) arbitrary constants can be determined. 17.1 Linear or Nonlinear ODEs Let’s take a look at a couple of examples. The differential equation \\[ \\frac{ d^2 y}{d x^2} +4 x \\frac{ d y}{d x}+ 2y= \\cos(x) \\] is (i) linear, (ii) second order and (iii) inhomogeneous. Linearity is determined solely by the way that the dependent variable \\(y\\) and its derivative occur in the equation. The differential equation \\[ \\frac{ d^2 y}{d x^2} + \\sin(y) = 0 \\] is second order and nonlinear because of the term \\(\\sin(y)\\). 17.2 Separable First Order ODEs This is a key approach to solving differential equations. A separable differential equation takes the form: \\[ \\frac{dy}{dx} = \\frac{f(x)}{g(y)}, \\;\\; \\mbox{or} \\;\\; g(y)\\; dy = f(x) \\, dx. \\] The general solution of such separable ODEs are obtained by integration: \\[ \\int {g(y)}\\, dy = \\int f(x) \\, dx. \\] The constant of integration gives the one arbitrary constant required for the general solution. If a condition is specified, use it to determine the value of the constant to get the particular solution. Example 17.1 (Separable First Order ODEs) Solve the differential equation \\[ \\frac{dy}{dx} = \\frac{1-y^2}{y(1-x)} \\] Separating the terms \\(x\\), \\(dx\\) and \\(y\\), \\(dy\\) gives \\[ \\frac{y}{1-y^2} dy = \\frac{1}{1-x} dx \\] so that \\[ \\int \\frac{ y \\; dy}{(1-y^2)}= \\int \\frac{dx}{(1-x)} \\mbox{ or } \\int - \\frac{1}{2}\\frac{d(1-y^2)}{1-y^2}= -\\int \\frac{d(1-x)}{(1-x)} \\] Integrating the above equation, we obtain an equation defining \\(y\\) as an implicit function of \\(x\\): \\[ \\ln |1-y^2|= 2 \\ln |1-x| -C, \\] i.e. \\[ \\ln \\frac{|1-x|^2}{|1-y^2|}= C, \\;\\; \\frac{|1-x|^2}{|1-y^2|}=e^C=k^2, \\;\\; k^2 \\ne 0 \\] Clearing the fractions and eliminating the absolute values gives: \\[ (1-x)^2 = \\lambda (1-y^2), \\;\\; \\lambda= \\pm k^2 \\ne 0; \\;\\; \\frac{(x-1)^2}{\\lambda}+y^2=1 \\] where \\(\\lambda\\) takes on any real value, except for \\(0\\). If \\(\\lambda &gt; 0\\), the solution curves are all ellipses; If \\(\\lambda &lt; 0\\), the solution curves are all hyperbolas. For example, the particular solution passing through the point \\((x=0, y=0)\\), we then have \\(\\lambda=1\\) giving \\[ (x-1)^2+y^2=1. \\] 17.3 Linear first order ODEs Linear first order inhomogeneous ODEs can be written in the form \\[ \\frac{dy}{dx} + p(x) y = r(x). \\] To solve these equations we use the integrating factor method. We multiply the ODE by the integrating factor \\[ u (x) = \\exp \\left(\\int p \\, dx\\right). \\] Then \\[\\begin{align*} \\frac{d}{dx}( u(x) y(x) ) &amp; = \\frac{du}{dx} y(x) + u(x) \\frac{dy}{dx}\\\\ &amp; = p(x) u(x) y(x) + u(x) \\left(r(x) - p(x) y(x) \\right)\\\\ &amp;= u(x) r(x). \\end{align*}\\] It follows that \\[ u(x)y(x) = \\int u(x) r(x) \\, dx +C\\,. \\] This means that \\[ y(x) = \\left[\\int \\left( e^{\\int p(x) \\, dx} \\right) r(x) \\, dx +C \\; \\right] e^{-\\int p(x) \\, dx}. \\] is the general solution of the linear first order inhomogeneous ODE \\[ \\frac{dy}{dx} + p(x) y = r(x). \\] Example 17.2 (Integrating Factor) Find the solution of the differential equation \\[ \\frac{dy}{dx} - \\frac{ 2x}{1 +x^2 }y=1 \\] and the initial condition \\(y(0) = 1\\). The integrating factor \\(u(x)\\) is \\[ \\exp \\left( - \\int \\frac{ 2x}{1 +x^2 } \\, dx \\right)=\\exp \\left( - \\ln (1 +x^2)\\right)=\\frac{1}{\\exp(\\ln(1+x^2))} = \\frac{1}{1 +x^2 }. \\] Multiplying the equation by this factor \\[ \\frac{ 1}{1 +x^2 } \\frac{dy}{dx} - \\frac{ 2x}{(1 +x^2)^2 }y=\\frac{d}{d x } \\left( \\frac{ y}{1 +x^2 } \\right) =\\frac{ 1}{1 +x^2 }. \\] Integrating \\[ \\left( \\frac{ y}{1 +x^2 } \\right) = \\int \\frac{ 1}{1 +x^2 } \\; dx= \\tan^{-1} x+C. \\] When \\(x=0, y=1\\) so that \\[ C = 1, \\;\\; \\mbox{and } y(x)= (1 +x^2 )(\\tan^{-1} x+1). \\] 17.4 Linear Second Order ODEs A general second order linear differential equation has the form \\[ \\frac{d^2 y}{dx^2} + p(x) \\frac{dy}{dx} + q(x) y = r(x). \\] where \\(p(x)\\) and \\(q(x)\\) are coefficient functions. When \\(p(x)\\) and \\(q(x)\\) are constants \\(p\\) and \\(q\\) then the equation is said to have constant coefficients \\[ \\frac{d^2 y}{dx^2} + p\\frac{dy}{dx} + q y = r(x). \\] When \\(r(x)=0\\), the equation is said to be homogeneous \\[ \\frac{d^2 y}{dx^2} + p(x) \\frac{dy}{dx} + q(x) y = 0. \\] We will only study equations with constant coefficients here, and begin with the homogeneous case since this is used in the solution of the inhomogeneous case. 17.4.1 Homogeneous equation with constant coefficients The standard form is \\[ \\frac{d^2 y}{dx^2} + p \\frac{dy}{dx} + q y = 0, \\] where \\(p\\) and \\(q\\) are constants. Consider \\(y=e^{mx}\\) as a possible solution. Substitution yields \\[ \\left(m^2+ pm + q \\right)e^{mx}=0, \\;\\; \\implies \\;\\; \\left(m^2+ pm + q \\right)=0 \\text{ (since $e^{mx}$ is never zero)}, \\] which is called the auxiliary equation or characteristic equation. The two roots \\(m_1, m_2\\) are are given by the quadratic formula \\[ m_1, m_2= \\frac{ -p \\pm \\sqrt{p^2- 4q} }{2}. \\] There are three possible cases. Distinct real roots when \\((p^2- 4q)&gt;0\\). In this case, we get the two linearly independent solutions \\[ y_1= e^{m_1 x}, \\;\\; y_2= e^{m_2 x} \\] and the general solution is \\[ y(x)= C_1 e^{m_1 x} +C_2 e^{m_2 x}. \\] Distinct complex roots when \\((p^2- 4q)&lt;0\\). In this case, \\[ m_1=a+ib=\\frac{ -p + i\\sqrt{|p^2- 4q}| }{2}; \\;\\; m_2=a-ib=\\frac{ -p - i\\sqrt{|p^2- 4q}| }{2} \\] we get the two linearly independent solutions \\[ y_1= e^{(a+ib) x}=e^{a x}( \\cos(bx) +i \\sin(bx)) , \\;\\; y_2= e^{(a-ib) x}=e^{a x}( \\cos(bx) -i \\sin(bx)) , \\;\\; \\] and the general solution is \\[ y(x)=e^{a x}\\left[ C_1( \\cos(bx) +i \\sin(bx))+ C_2( \\cos(bx) -i \\sin(bx)) \\right]=e^{ax}\\left( c_1 \\cos(bx) +c_2 \\sin(bx) \\right) \\] where \\(c_1=C_1+C_2; \\;\\; c_2=i(C_1-C_2)\\). Equal real roots when \\((p^2- 4q)=0\\). In this case (\\(m_1=m_2=m=-p/2\\)), we get the two linearly independent solutions \\[ y_1= e^{m x}, \\;\\; y_2= x e^{m x} \\] and the general solution is \\[ y(x)= C_1 e^{m x} +C_2 x e^{m x} \\] Given sufficient information, we can fix the constants in the general solution to obtain a particular solution. There are two situations: having the values of \\(y\\) and \\(y&#39;\\) at a particular value of \\(x\\), or having the value of \\(y\\) at different values of \\(x\\). Initial-value problems. This consists of finding a solution of \\(y\\) that satisfies initial conditions of the form \\[ y(a)=A, \\;\\; y&#39;(a)=B, \\] where \\(A\\) and \\(B\\) are given constants. Boundary-value problems. This consists of finding a solution of \\(y\\) that satisfies boundary conditions of the form \\[ y(a)=A, \\;\\; y(b)=B, \\] where \\(A\\) and \\(B\\) are given constants. Example 17.3 (Initial Conditions) Solve the initial-value problem: \\[ y&#39;&#39;+ y=0 \\;;\\; y(0)=2 \\;;\\; y&#39;(0)=3 \\] The auxiliary equation is , \\[ m^2+1=0 \\] whose roots are \\(m_1=i, m_2=-i\\). The general solution is \\[ y(x)=c_1 \\cos(x) + c_2 \\sin(x) \\] \\[ y&#39;(x)= -c_1 \\sin(x) + c_2 \\cos(x) \\] This yields \\[ y(0)=c_1=2, \\;\\; y&#39;(0)=c_2=3. \\] Therefore, the solution of the initial value problem is \\[ y(x)=2 \\cos(x) +3 \\sin(x). \\] 17.4.2 Inhomogeneous equation with constant coefficients The standard form is \\[ \\frac{d^2 y}{dx^2} + p \\frac{dy}{dx} + q y = r(x), \\] where \\(r(x) \\ne 0\\) and \\(p\\) and \\(q\\) are constants. The First step is to solve the equivalent homogeneous problem, the so-called Complementary Equation, \\[ \\frac{d^2 y}{dx^2} + p \\frac{dy}{dx} + q y = 0, \\] obtained by setting \\(r(x)=0\\). Since this equation is linear and homogeneous, if we find two independent solutions, \\(y_1(x)\\) and \\(y_2(x)\\), the Complementary Function is \\[ y_c = C_1 y_1+ C_2 y_2. \\] The Second step is to find a Particular Integral, \\(y_p\\). This is basically a matter of trial and error, but the following guidelines are helpful. If \\(r(x)\\) is a polynomial of degree \\(m\\), try \\[ y = a_n x^m + a_{n-1} x^{m-1} + \\cdots +a_0 \\] and substitute in to the ODE. Equate the powers of \\(x\\) in the result with \\(r(x)\\) to determine the coefficients. (This is sometimes called the method of undetermined coefficients.) If \\(r(x)\\) contains \\(h e^{\\lambda x}\\), try for the P.I. \\[ y= a e^{\\lambda x}. \\] Again substitute into the ODE and equate both sides to determine \\(a\\). If \\(r(x) = C \\cos(\\lambda x) + D \\sin(\\lambda x)\\), try \\(y = a\\cos(\\lambda x) + b\\sin (\\lambda x)\\), substitute in and equate coefficients of \\(\\cos \\lambda x\\) and \\(\\sin(\\lambda x)\\) to determine \\(a\\) and \\(b\\). If \\(r(x)\\) is any combination of the above, find P.I.’s for each piece separately, and add to find the full P.I. If \\(r(x) = h e^{\\lambda x}\\) and \\(e^{\\lambda x}\\) happens to be a part of the C.F., try \\(a x e^{\\lambda x}\\) instead of \\(a e^{\\lambda x}\\). If \\(r(x) = he^{\\lambda x}\\) is a double root of the homogeneous problem, try \\(a x^2 e^{\\lambda x}\\). Similarly, if \\(r(x)= \\exp(px) [C \\cos(qx) + D \\sin(qx)]\\) happens to be part of the C.F., try \\(y = x e^{px} (a \\cos(qx) + b \\sin(qx))\\) for the P.I. The third step. The general solution of the inhomogeneous equation is written as \\[ y(x)=y_p +y_c \\] Since the complementary function has two arbitrary constants if the equation is of second order, this general solution has the correct number of arbitrary constants. Example 17.4 (Inhomogeneous equations) Solve \\[ y&#39;&#39;+ 4 y= e^{3x}. \\] The auxiliary equation is \\[ m^2+4=0, \\] whose roots are \\(m_1=2i, m_2=-2i\\). The solution of the complementary equation is \\[ y_c=c_1 \\cos(2x) + c_2 \\sin(2x). \\] For a particular integral (solution), we try \\(y_p= a e^{3x}\\) (the method of undetermined coefficients) \\[ 9 a e^{3x} + 4 a e^{3x} = e^{3 x}, \\;\\; \\to \\;\\; a =1/13, \\] leading to the general solution \\[ y=y_p+ y_c= \\frac{1}{13} e^{3 x} + c_1 \\cos(2x) + c_2 \\sin(2x). \\] Solve \\[ y&#39;&#39;+ y= \\sin(x). \\] The auxiliary equation is \\[ m^2+1=0, \\] whose roots are \\(m_1=i, m_2=-i\\). The solution of the complementary equation is \\[ y_c=c_1 \\cos(x) + c_2 \\sin(x). \\] For a particular integral (solution), we try \\[ y_p=x( a \\cos(x) + b \\sin(x)). \\] Then \\[\\ y_p&#39;= a \\cos(x) + b \\sin(x) + x( -a \\sin(x) + b \\cos(x)) \\] \\[ y_p&#39;&#39;= -2a \\sin(x) + 2b \\cos(x) -a x \\cos(x) - b x \\sin(x) \\] Substitution in the equation gives \\[ \\left( -2a \\sin(x) + 2b \\cos(x) -a x \\cos(x) - b x \\sin(x) \\right) + \\left( a x \\cos(x) + b x \\sin(x) \\right)= \\sin(x), \\] \\[ -2a \\sin(x) + 2b \\cos(x) = \\sin(x); \\;\\; \\to \\;\\; a= -1/2; b=0; \\;\\; y_p= -\\frac{x}{2} \\cos(x). \\] The general solution is \\[ y=y_p+ y_c= c_1 \\cos(x) + c_2 \\sin(x) -\\frac{x}{2} \\cos(x). \\] In contrast to partial differential equations (PDEs) which involve derivatives of multiple independent variables.↩︎ "],["numerics.html", "Chapter 18 Numerical Methods 18.1 Numerical Root Finding 18.2 Numerical differentiation 18.3 Numerical Integration 18.4 Numerical Solutions to ODEs", " Chapter 18 Numerical Methods In general, many mathematical problems do not have algebraic solution methods. Instead, we need to resort to numerical methods. This usually results in an approximate solution: we get an answer that is close to the true solution \\(x\\), but might have an error \\(\\varepsilon\\), so that we obtain some value in the interval \\(x-\\varepsilon\\) to \\(x+\\varepsilon\\). For many practical applications an approximate solution is “good enough”. 18.1 Numerical Root Finding We have seen how to solve linear and quadratic equations algebraically. We mentioned in section 2.2 that there also exist formulae for finding roots of cubic and quartic polynomial equations, but not quintic or higher. We often need to find the roots (values of \\(x\\) for which \\(f(x)=0\\)) of some function 18.2 Numerical differentiation 18.3 Numerical Integration 18.4 Numerical Solutions to ODEs "],["probability-fundamentals.html", "Chapter 19 Probability Fundamentals 19.1 Sample space and events 19.2 Counting 19.3 Permutations and Combinations 19.4 Probabilities 19.5 Conditional Probability 19.6 Independence 19.7 Law of Total Probability 19.8 Bayes’ Theorem", " Chapter 19 Probability Fundamentals Uncertainty is an integral component of our everyday lives, and we are always making decisions in the face of it e.g. Will it rain today? Should I take out life insurance? Should I buy a lottery ticket? Should I buy ten lottery tickets? Probability is the branch of mathematics that seeks to study uncertainty in a systematic way. We measure the likelihood of something happening on a scale from 0 to 1. Probability theory is fundamental in its own right, but also as a pre-requisite for the study of statistics, where we aim to explain real data and make predictions by fitting probability models. 19.1 Sample space and events Fundamental to the study of probability is the idea of a stochastic experiment. Definition 19.1 (Stochastic Experiment) A stochastic experiment is a phenomenon or process with multiple possible outcomes, which are uncertain until the experiment has been run. In contrast, a deterministic experiment is one that produces the same outcome each time it is run. The collection of all possible outcomes is known as the sample space. Mathematically, it is a set \\(S\\) – this can be thought of as a box containing a collection of objects, but where we do not consider duplicate objects. We denote this set and the objects it contains, known as the elements of the set, as a pair of braces containing the elements \\(\\{\\dotsb\\}\\). For example: Tossing a coin: \\(S=\\{H,T\\}\\) The number of days it rains in a week: \\(S=\\{0,1,2,3,4,5,6,7\\}\\) Number of cars that pass a given point on a motorway in one minute: \\(S=\\{0,1,2,3,\\dotsc\\}\\) The sum of the values on two dice, that is all of the values in the following table. \\(+\\) 1 2 3 4 5 6 1 2 3 4 5 6 7 2 3 4 5 6 7 8 3 4 5 6 7 8 9 4 5 6 7 8 9 10 5 6 7 8 9 10 11 6 7 8 9 10 11 12 Note that many of the 36 outcomes in this table are repetitions – we only record the 11 unique possibilities in the sample space: \\(S=\\{2,3,4,5,6,7,8,9,10,11,12\\}\\) An event \\(A\\) is a particular collection of outcomes from a stochastic experiment. Mathematically, it is a subset of \\(S\\). That is, a set consisting of some (possibly all or none) of the elements of \\(S\\). We write this as \\(A\\subset S\\). For example: The event of obtaining a heads in a coin toss: \\(A=\\{H\\}\\) It rains an odd number of days in the week: \\(A=\\{1,3,5,7\\}\\) More than 5 cars pass by on the motorway: \\(A=\\{6,7,8,\\dotsc\\}\\) The sum of the value on two dice is greater than 1: \\(A=S\\) It is sometimes the case that an event does not correspond to any elements of the sample space. For example, the event that it rains 8 days in a week. In this case the event set is empty. Although this was a silly example, it is in general useful to have a particular notation for this: the set with no elements \\(\\{\\;\\}\\) is called the empty set and is denoted by \\(\\emptyset\\). We sometimes need to consider combinations of events occuring at the same time. For example, More than 5 cars and less than 10 cars pass by on the motorway: The events \\(A=\\{6,7,8,\\dotsc\\}\\) and \\(B=\\{0,1,2,3,4,5,6,7,8,9\\}\\), resulting in the event \\(C=\\{6,7,8,9\\}\\) The sum of two dice rolls is an odd number or it is less than or equal to 4: The events \\(A=\\{3,5,7,9,11\\}\\) and \\(B=\\{2,3,4\\}\\), resulting in the event \\(C=\\{2,3,4,5,7,9,11\\}\\) Taking the outcomes that only occur in both \\(A\\) and \\(B\\) is known as taking the intersection of the two sets, denoted \\[C=A\\cap B.\\] Combining all of the outcomes in \\(A\\) or15 \\(B\\) is known as taking the union of the two sets, denoted \\[C=A\\cup B\\]. The complement of an event \\(A\\) is the event that \\(A\\) does not occur, denoted \\(A^c\\). For example, if we have the event that it rains on an odd number of days in the week \\(A=\\{1,3,5,7\\}\\), then the complement of \\(A\\) is \\(A^c=\\{0,2,4,6\\}\\). If \\(A\\cap B=\\emptyset\\) (they have no outcomes in common) then we say that events \\(A\\) and \\(B\\) are mutually exclusive: they cannot occur at the same time. In set language, we say the sets are disjoint. 19.2 Counting Many basic results in probability come from a consideration of counting the number of possible outcomes, that is, the number of elements \\(N\\) in the set \\(S\\). For example, if we have a fair 6-sided die, then with six possible equally likely outcomes the probability of getting a six, the event \\(A=\\{6\\}\\), is simply \\(\\dfrac{1}{6}\\). We write the probability of this event as \\[P(A)=\\frac{1}{6}.\\] When we have \\(N\\) equally likely outcomes, the probability of any particular outcome \\(A=\\{a\\}\\) where \\(a\\) is an element of the sample space \\(S\\) is simply \\[P(A)=\\frac{1}{N}.\\] More generally, if the event \\(A=\\{a_1,\\dotsc,a_k\\}\\) consists of \\(k\\) equally likely outcomes, we have \\[P(A)=\\frac{k}{N}.\\] For example, what is the probability of rolling greater than or equal to a \\(3\\)? We have \\(A=\\{3,4,5,6\\}\\), so \\(P(A)=\\frac{4}{6}=\\frac{2}{3}\\). Note these definitions only make sense if our sample space \\(S\\) is finite. We’ll look at more general definitions of probability later. For now, we look at some further methods for counting a finite number of outcomes. In particular, we look at the situation of a finite sequence of stochastic experiments. 19.3 Permutations and Combinations In compound experiments we have a number of stages in sequence, for example throwing a die three times. The multiplication principle says that in a compound experiment with \\(r\\) stages, with \\(n_1\\) possible outcomes in stage 1, \\(n_2\\) possible outcomes in stage 2 for each particular outcome in stage 1, \\(n_3\\) possible outcomes in stage 3 for each particular outcome in stage 2, and so on, then the total number of outcomes is \\[n_1 \\times n_2\\times \\dotsb \\times n_r.\\] For example in throwing a die 3 times we have 6 possible outcomes in each throw, so the total number of outcomes is \\(6\\times 6\\times 6=6^3=216\\). Hence the probability of any given sequence of length three consisting of the numbers 1 to 6, the event $A={(a_1,a_2,a_3)} for some particular values of the \\(a_i\\) from \\(1,\\dotsc,6\\), is \\(P(A)=\\dfrac{1}{216}\\). The multiplication principle holds in problems of sampling with replacement. For example, if we draw a card from a standard deck of 52 (well shuffled) playing cards three times in a row, putting the card back into the deck after each draw and re-shuffling, then the chance of getting the ace of spades three times \\(A=\\{(\\text{A}\\spadesuit,\\text{A}\\spadesuit,\\text{A}\\spadesuit)\\}\\) is \\(P(A)=\\dfrac{1}{52^3}\\). In problems where we have sampling without replacement, the number of possible outcomes changes at each stage. For example, the number of ways 3 runners can be placed at the finish are: any one of the 3 could come first, leaving 2 possibilities for second and 1 possibility for third, that is \\[3\\times 2\\times 1=6\\] We call this the factorial of 3, denoted \\(3!\\). It is more generally defined for a number \\(n\\) as \\[n!=n\\times(n-1)\\times(n-2)\\times\\dotsb\\times 2\\times 1.\\] 19.3.1 Permutations In a race of 8 runners, the number of possibilities for first, second and third are: \\[8\\times 7\\times 6 = 336.\\] We can calculate this in a neat way as \\[\\frac{8\\times 7\\times 6\\times 5\\times 4\\times 3\\times 2\\times 1}{5\\times 4\\times 3\\times 2\\times 1}=\\frac{8!}{5!}=336.\\] If all the runners are equally likely to win, then the probability of a particular outcome for first, second and third is simply \\(\\frac{1}{336}\\). A permutation of \\(r\\) objects from \\(n\\) is an ordered arrangement of \\(r\\) of the \\(n\\) objects. The number of permutations is: \\[{}_n P_r = \\frac{n!}{(n-r)!}.\\] 19.3.2 Combinations In a lottery, 6 distinct numbers are drawn from the numbers 1-59. How many different outcomes are there? In this case we do not care about the order of each number. If we did care about the order then we are looking at the permutations and the answer would be \\[\\frac{59!}{(59-6)!}=\\frac{59!}{(53)!}.\\] However, since we do not care about the order we consider the \\(6!\\) different orderings of each outcome to be the same, hence we need to divide through by this number of arrangements to obtain \\[\\frac{59!}{6!(59-6)!}=\\frac{59!}{6!53!}=45\\,057\\,474.\\] Since each outcome is equally likely, the probability of a winning ticket is \\(\\dfrac{1}{45\\,057\\,474}\\). A combination of \\(r\\) objects from \\(n\\) is an unordered arrangement of \\(r\\) of the \\(n\\) objects. The number of combinations is \\[{}_n C_r ={{n}\\choose{r}}=\\frac{n!}{r!(n-r)!}\\] usually read as “\\(n\\) choose \\(r\\)”. 19.4 Probabilities We have already looked at how to find probabilities when we have equally likely outcomes. We now look at the rules of probability in more generality. The probability \\(P\\) is a function that associates every possible event \\(A\\) to a value \\(P(A)\\) in the range \\(0\\leq P(A) \\leq 1\\), such that \\(P(A)\\geq 0\\) for all events \\(A\\) \\(P(S)=1\\) \\(P(A\\cup B)=P(A)+P(B)\\) when \\(A\\) and \\(B\\) are mutually exclusive. The term “mutually exclusive” means that \\(A\\) and \\(B\\) cannot take place at the same time. In terms of sets we have \\[A\\cap B=\\emptyset.\\] Since \\(A\\cap A^c=\\emptyset\\) together with \\(A\\cup A^c=S\\) we have \\[1=P(S)=P(A\\cup A^c)=P(A)+P(A^c)\\] and hence \\[P(A)=1-P(A^c).\\] (Note in particular that this implies \\(P(\\emptyset)=0\\), why?) This is useful because sometimes it is easier to calculate \\(P(A^c)\\) instead calculating \\(P(A)\\) directly. To simplify notation, we sometimes just write the outcomes of an event directly in the argument of \\(P\\). For example, we could write the probability of getting a head from a coin toss as \\(P(H)\\) or of getting the sequence \\(HTT\\) in 3 tosses as \\(P(HTT)\\). 19.5 Conditional Probability Given that the outcome of a dice roll is greater than 3, what is the probability it is even number? Let \\(A\\) be the event the roll is even, so \\(A=\\{2,4,6\\}\\) and let \\(B\\) be the event that the roll is greater than 3, so \\(B=\\{4,5,6\\}\\). Given that \\(B\\) has happened, for \\(A\\) to also happen we need an element from \\(A\\cap B=\\{4,6\\}\\). So, out of the 3 possibilities following event \\(B\\) there are 2 which give event \\(A\\). Hence the probability is \\(\\frac{2}{3}\\). This is an example of a conditional probability: given that (“conditional on”) some event \\(B\\) happens, what is the probability of event \\(A\\)? This is written as \\(P(A|B)\\). It is defined by: \\[P(A|B)=\\frac{P(A\\cap B)}{P(B)}.\\] In our example above, we had \\[P(A|B)=\\frac{P(A\\cap B)}{P(B)}=\\frac{2/6}{3/6}=\\frac{2}{3}.\\] Conditional probabilities can also be useful to find \\(P(A \\cap B)\\). Example 19.1 There are 20 balls in a bag: 6 reds, 10 greens and 4 blues. What is the probability that the first ball drawn will be red? Call this event \\(B\\). Each ball is equally likely, so \\(P(B)=\\frac{6}{20}=\\frac{3}{10}\\). If the first ball is red, what is the probability the second ball drawn will be blue? Let the event that the second ball is blue be called \\(A\\). Now we have to account for the fact that the first ball was red. We have 19 balls remaining, including all 4 blues, hence \\(P(A|B)=\\frac{4}{19}\\). What is the probability that the first ball is red and the second ball is blue? This is hard to calculate directly, but we can instead use the answers to 1. and 2. to get \\[P(A\\cap B)=P(A|B)P(A)=\\frac{4}{19}\\times \\frac{6}{20}=\\frac{6}{95}.\\] 19.6 Independence Two events \\(A\\) and \\(B\\) are independent if \\[P(A\\cap B)=P(A)P(B)\\] or equivalently (from the deifinition of conditional probability) if \\[P(A|B)=P(A).\\] We have already seen many examples of independent events. For example, in tossing a coin twice, the sample space is \\(S=\\{TT,TH,HT,HH\\}\\). The event that the first toss is a heads \\(A=\\{HH,HT\\}\\) has \\(P(A)=\\frac{2}{4}=\\frac{1}{2}\\) and the event the second toss is a heads \\(B=\\{TH, HH\\}\\) also has \\(P(B)=\\frac{1}{2}\\). These events are independent – intuitively, the outcome of the first toss has no influence on the outcome of the second toss. Mathematically we have: \\[P(A\\cap B)=P(HH)=\\frac{1}{4}\\] since there are 4 equally likely outcomes from tossing a coin twice, and \\[P(A)P(B)=\\frac{1}{2}\\times\\frac{1}{2}=\\frac{1}{4}.\\] 19.7 Law of Total Probability A sequence of sets \\(B_1,B_2,\\dotsc,B_n\\) is said to form a partition of \\(S\\) if for all \\(i\\neq j\\) we have \\[B_i\\cap B_j = \\emptyset\\] (no two sets have any elements in common) and \\[B_1\\cup B_2\\cup \\dotsb\\cup B_n=S\\] (taking all the sets together, they include all of the outcomes in \\(S\\)). Theorem 19.1 (Law of Total Probability) Let \\(B_1,B_2,\\dotsc,B_n\\) be a partition of \\(S\\) and let \\(A\\) be an event. Then \\[P(A)=P(A|B_1)P(B_1)+P(A|B_2)P(B_2)+\\dotsb + P(A|B_n)P(B_n).\\] Example 19.2 (Disease Prevalence: part 1) A certain disease occurs in 0.02% of the population. A test to discover the disease gives a positive reaction for 92% of the people suffering from the disease, but also for 3% of people not having it. What is the probability that a randomly selected person has a positive test? Denote a positive test as \\(+\\), having the disease as \\(D\\) and not having the disease as \\(ND\\). We want to find \\(P(+)\\). We can find this from the law of total probability, since \\(D\\) and \\(ND\\) form a partition of the sample space: \\[\\begin{align*} P(+)&amp;=P(+|D)P(D)+P(+|ND)P(ND)\\\\ &amp;=0.92\\times 0.0002 + 0.03\\times(1-0.0002)\\\\ &amp;=0.031834. \\end{align*}\\] 19.8 Bayes’ Theorem Theorem 19.2 (Bayes' Theorem) For any two events \\(A\\) and \\(B\\), we have \\[P(B|A)=\\frac{P(A|B)P(B)}{P(A)}.\\] Example 19.3 (Disease Prevalence: part 2) A certain disease occurs in 0.02% of the population. A test to discover the disease gives a positive reaction for 92% of the people suffering from the disease, but also for 3% of people not having it. If a randomly selected person has a positive test, what is the probability that they have the disease? Denoting a positive test as \\(+\\), having the disease as \\(D\\) and not having the disease as \\(ND\\), from the question we have: \\[\\begin{align*} P(D)&amp;=0.0002\\\\ P(+|D)&amp;=0.92\\\\ P(+|ND)&amp;=0.03. \\end{align*}\\] We want to calculate \\(P(D|+)\\). From Bayes’ theorem this is \\[P(D|+)=\\frac{P(+|D)P(D)}{P(+)}.\\] We have all the ingredients, where we found \\(P(+)\\) in the earlier example on the law of total probability. Hence \\[P(D|+)=\\frac{0.92\\times 0.0002}{0.031834}=0.0058\\text{ to 2 s.f.}\\] So when getting a positive test, there is less than a 1% chance of actually having the disease. This is largely due to the rarity of the disease. in mathematics the word or used in the inclusive sense, rather than the exclusive sense, which is sometimes abreviated as xor.↩︎ "],["discrete-random-variables.html", "Chapter 20 Discrete Random Variables 20.1 Bernoulli trials 20.2 Binomial Distribution 20.3 Cumulative Distribution Functions 20.4 Poisson distribution 20.5 Expectation and Variance 20.6 Summary of Discrete Distributions", " Chapter 20 Discrete Random Variables A random variable is a numerical valued function defined on the sample space. Example 20.1 (Random Variables) A coin with probability \\(p\\) of getting a head is tossed three times. There are 8 possible outcomes from the experiment. Let \\(X\\) be a random variable counting the number of heads. Sample Probability \\(X\\) TTT \\((1-p)^3\\) 0 TTH \\(p(1-p)^2\\) 1 THT \\(p(1-p)^2\\) 1 HTT \\(p(1-p)^2\\) 1 THH \\(p^2(1-p)\\) 2 HTH \\(p^2(1-p)\\) 2 HHT \\(p^2(1-p)\\) 2 HHH \\(p^3\\) 3 The convention is to denote a random variable using upper case letters and lower-case letters to denote a value that the random variable takes e.g. here we have \\(X=x\\) with \\(x = 0, 1, 2, 3\\). A random variable is said to be discrete if its range of values is finite or countably infinite (i.e. it must be possible to list all the values in a, possibly infinite, sequence). In the coin toss example, we could write a function to map the probabilities of observing \\(x\\) heads from three tosses as: \\[ P(X = x) = {3 \\choose x} p^x (1 - p)^{3 - x}\\quad\\mbox{for}~x = 0, 1, 2, 3. \\] The function \\(P(X = x)\\) is known as a probability distribution. In the discrete case, it is also called a probability mass function. Some authors use the notation \\(p_X(x)\\) or \\(f_X(x)\\). We will tend to use the former for discrete random variables and the latter for continuous random variables (more on that later). By the laws of probability, we always have \\[ P(X = x) \\geq 0 \\] and \\[ \\sum_{x} P(X = x) = 1. \\] Where the notation \\(\\displaystyle \\sum_x\\) means to sum over all possible values of \\(x\\). 20.1 Bernoulli trials Possibly the simplest example of a random variable is when an outcome can only take one of two values e.g. success / failure, survival / death, defective / non-defective. Note that these outcomes are not numerical, but typically we can assign numerical values to them, for example we could let \\[ X = \\begin{cases} 1 &amp; \\text{if success,}\\\\ 0 &amp; \\text{if failure.} \\end{cases} \\] If we assume that the probability of success is given by a value \\(0\\le p\\le 1\\), then the probability mass function is: \\[ p_X(x) = P(X = x) = p^x (1 - p)^{1 - x} \\qquad \\mbox{for}~x = 0, 1. \\] The experiment is known as a Bernoulli trial, after Jacob Bernoulli (1654–1705). We write \\(X \\sim \\mbox{Bern}(p)\\) to say that the random variable \\(X\\) has a Bernoulli probability distribution with parameter \\(p\\). 20.2 Binomial Distribution Often we may have an experiment which consists of a fixed number \\(n\\) of independent Bernoulli trials. Let \\(X\\) denote the number of successes. In this case there are \\(2^n\\) possible outcomes and \\(X\\) is defined in the range \\(0, \\dots, n\\). There will be \\({n \\choose x}\\) of the \\(2^n\\) possible outcomes corresponding to a value \\(X = x\\), which will occur with probability \\(p^x(1-p)^{n - x}\\), A binomial random variable, \\(X \\sim \\mbox{Bin}(n, p)\\), is the number of successes from a fixed number (\\(n\\)) of Bernoulli trials. A binomial random variable \\(X\\) therefore has probability mass function: \\[ p_X(x) = P(X = x) = {n \\choose x} p^x (1 - p)^{n - x} \\quad \\mbox{for}~x = 0, \\dots, n~\\mbox{ and }~0 \\leq p \\leq 1. \\] The coin tossing example we saw earlier is a case of a binomial random variable, with p.m.f. \\[\\begin{eqnarray*} p_X(x) = {3 \\choose x} p^x (1 - p)^{3 - x} \\\\ \\mbox{for}~x = 0, 1, 2, 3. \\end{eqnarray*}\\] So for a fair coin (\\(p = 0.5\\)): \\[\\begin{eqnarray*} p_X(0) &amp;=&amp; 0.125\\\\ p_X(1) &amp;=&amp; 0.375\\\\ p_X(2) &amp;=&amp; 0.375\\\\ p_X(3) &amp;=&amp; 0.125 \\end{eqnarray*}\\] and note that as expected \\(\\sum_{x = 0}^3 p_X(x) = 1\\). 20.3 Cumulative Distribution Functions Another useful quantity is called the cumulative distribution function and for discrete random variables is defined as: \\[ P(X \\leq x) = \\sum_{k \\leq x} P(X = k). \\] So for a fair coin (\\(p = 0.5\\)): Probability mass function: \\[\\begin{eqnarray*} p_X(0) &amp;=&amp; 0.125\\\\ p_X(1) &amp;=&amp; 0.375\\\\ p_X(2) &amp;=&amp; 0.375\\\\ p_X(3) &amp;=&amp; 0.125. \\end{eqnarray*}\\] Cumulative distribution function: \\[\\begin{eqnarray*} P(X \\leq 0) &amp;=&amp; 0.125\\\\ P(X \\leq 1) &amp;=&amp; 0.5\\\\ P(X \\leq 2) &amp;=&amp; 0.875\\\\ P(X \\leq 3) &amp;=&amp; 1. \\end{eqnarray*}\\] Example 20.2 (Cumulative distributions) If 1% of a product is defective, then in a random sample of 200 items, what is the probability that less than 2 are defective? We can consider that the sampling scheme is approximately equivalent to a sequence of independent Bernoulli trials. Here “success” is defined as “having a defect” and has probability \\(p = 0.01\\). Let \\(X\\) be the number of defective items. Hence, \\[\\begin{eqnarray*} P(X &lt; 2) &amp;=&amp; P(X = 0) + P(X = 1)\\\\ &amp;=&amp; {200 \\choose 0} \\cdot 0.01^0 \\cdot 0.99^{200} + {200 \\choose 1} \\cdot 0.01^1 \\cdot 0.99^{199}\\\\ &amp;=&amp; 0.40 \\text{ to 2 s.f.} \\end{eqnarray*}\\] 20.4 Poisson distribution The Poisson distribution is named after Simeon Denis Poisson (1781–1840). The Poisson distribution has been used to model (according to Wikipedia): the number of goals in a football match, the number of children in a family, the number of patients arriving in an hour in A &amp; E, the number of soldiers killed in a year by horse-kicks in a corps of the Prussian cavalry. Roughly speaking, a Poisson distribution is appropriate when recording the number of events occuring in a given unit time if these events are independent and occur at a constant rate. A discrete random variable \\(X\\) follows a Poisson distribution with rate \\(\\lambda\\) if it has probability mass function: \\[\\begin{eqnarray*} P(X = x) &amp;=&amp; \\frac{\\lambda^x e^{-\\lambda}}{x!}\\\\ &amp;&amp; \\mbox{for}~x = 0, 1, 2, \\dots\\\\ &amp;&amp; \\mbox{and}~\\lambda &gt; 0. \\end{eqnarray*}\\] We write \\(X\\sim Po(\\lambda)\\) to denote \\(X\\) being a random variable with a Poisson distribution with parameter \\(\\lambda\\). Example 20.3 (Poisson distribution) Births occur in a hospital at an average rate of 1.8 births per hour. What is the probability that 5 births will occur in any given hour? What is the probability that no births will occur in any given hour? What is the probability that at least two births will occur in any given hour? Let \\(X\\) be the number of births in any given hour. Here \\(X \\sim Po(1.8)\\) and \\(P(X = 5) = \\frac{1.8^5 e^{-1.8}}{5!} = 0.0260\\text{ to 3 s.f.}.\\) \\(P(X = 0) = e^{-1.8} = 0.165\\text{ to 3 s.f.}.\\) \\(P(X \\geq 2) = 1 - P(X &lt; 2) = 1 - e^{-1.8} - 1.8 e^{-1.8} = 0.537\\text{ to 3 s.f.}.\\) In some instances, we can use the Poisson distribution to approximate the binomial distribution. Example 20.4 (Poisson approximation of binomial) A manufacturer sells screws in boxes of 100. On average, 0.5% of screws produced at the factory are defective. Find the probability that no more than one screw in a randomly selected box is defective. In this case, we can model the number of defective screws in a box, \\(X\\), as a binomial random variable with parameters \\(n = 100\\) and \\(p = 0.005\\). So the answer is: \\[\\begin{eqnarray*} P(X \\leq 1) = p_X(0) + p_X(1) &amp;=&amp; {100 \\choose 0} 0.995^{100} + {100 \\choose 1}0.005(0.995)^{99}\\\\ &amp;=&amp; 0.91 \\text{ to 2 s.f.} \\end{eqnarray*}\\] However, a binomial distribution can be well-approximated by a Poisson distribution with rate \\(\\lambda = np\\) if \\(n\\) is “large” and “\\(np\\)” is fairly small. Here \\(n = 100\\) and \\(np = 0.5\\), and so we could approximate the above result as: \\[\\begin{eqnarray*} P(X \\leq 1) &amp;\\approx&amp; e^{-0.5} + 0.5e^{-0.5}\\\\ &amp;=&amp; 0.91 \\text{ to 2 s.f.} \\end{eqnarray*}\\] Rule-of-thumb: \\(np &lt; 10\\), \\(n \\geq 20\\), \\(p \\leq 0.05\\) 20.5 Expectation and Variance 20.5.1 Expectation Given a discrete random variable \\(X\\), we define its expected value (or expectation) as: \\[ \\operatorname{E}(X) = \\sum_x xp_X(x). \\] The expectation of \\(X\\) corresponds to the approximate average value of \\(X\\) obtained from a repeated series of independent experiments. For example, if \\(X\\) is the amount of money you win in a gambling game, then if \\(\\operatorname{E}(X) = 0\\), in the long-term you would expect to break even. (In reality, a casino would ensure \\(\\operatorname{E}(X) &lt; 0\\).) We sometimes refer to \\(\\operatorname{E}(X)\\) as the mean of \\(X\\). Example 20.5 (Expectation) Find the expected score from a single roll of a fair die. \\[\\begin{eqnarray*} \\operatorname{E}(X) &amp;=&amp; \\sum_{x = 1}^6 x p_X(x)\\\\ &amp;=&amp; \\left(1 \\times \\frac{1}{6}\\right) + \\left(2 \\times \\frac{1}{6}\\right) + \\dots + \\left(6 \\times \\frac{1}{6}\\right)\\\\ &amp;=&amp; 3.5 \\end{eqnarray*}\\] We can apply functions to a random variable, which then define a new random variable. We can then also find the expectation of these new random variables as in the following example. Example 20.6 (Expectation of functions) Let \\(X\\) be the score from a single roll of a fair die. Find the expected value of the random variable \\(Y = X^2\\). We note that \\(Y\\) can take values \\(\\{1, 4, 9, 16, 25, 36\\}\\), each with probability \\(\\frac{1}{6}\\). Therefore \\[\\begin{eqnarray*} \\operatorname{E}(Y) &amp;=&amp; \\left(1 \\times \\frac{1}{6}\\right) + \\left(4 \\times \\frac{1}{6}\\right) + \\dots + \\left(36 \\times \\frac{1}{6}\\right)\\\\ &amp;=&amp; \\sum_{x = 1}^6 x^2 p_X(x)\\\\ &amp;=&amp; 15.2\\text{ to 3 s.f.} \\end{eqnarray*}\\] In general, if \\(g(\\cdot)\\) is a function defined on the range of a discrete random variable \\(X\\), then \\(g(X)\\) is also a random variable, and it follows that \\[ \\operatorname{E}[g(X)] = \\sum_{x} g(x) p_X(x) \\] Some useful properties of the expectation: Let \\(a\\) and \\(b\\) be constants, and let \\(g(X)\\) and \\(h(X)\\) be functions defined on the range of a random variable \\(X\\). Then, \\[ \\operatorname{E}\\left[ag(X) + bh(X)\\right] = a\\operatorname{E}[g(X)] + b\\operatorname{E}[h(X)] \\] The expected value of a constant, \\(a\\), is itself i.e. \\[ \\operatorname{E}(a) = a. \\] 20.5.2 Variance and Standard Deviation The variance is the expected squared deviation of a random variable from its mean. \\[ \\operatorname{var}(X) = \\operatorname{E}\\left[(X - \\mu)^2\\right] \\] where \\(\\mu = \\operatorname{E}(X)\\) is the mean of \\(X\\). Informally it measures how spread out a set of random numbers are expected to be from their mean, such that random variables with higher variances are harder to predict than those with smaller variances. A useful alternative form for the variance is given as \\[ \\operatorname{var}(X) = \\operatorname{E}\\left(X^2\\right) - \\operatorname{E}^2(X). \\] This can be derived by considering that \\[\\begin{align*} \\operatorname{var}(X) &amp;= \\operatorname{E}\\left[(X - \\mu)^2\\right]\\\\ &amp;= \\operatorname{E}\\left(X^2 - 2X\\mu + \\mu^2\\right)\\\\ &amp;= \\operatorname{E}\\left(X^2\\right) - 2\\mu \\operatorname{E}(X) + \\operatorname{E}(\\mu^2)\\\\ &amp;= \\operatorname{E}\\left(X^2\\right) - 2\\mu^2 + \\mu^2\\\\ &amp;= \\operatorname{E}\\left(X^2\\right) - \\mu^2. \\end{align*}\\] Another important quantity is the standard deviation \\[ \\sigma = \\operatorname{sd}(X) = \\sqrt{\\operatorname{var}(X)}. \\] This effectively re-scales the variance to be on the same scale as the data (having the same units rather than the units squared). Example 20.7 (Variance) Find the variance of the score, \\(X\\), from a single roll of a fair die. If we use the alternative form for the variance, then from earlier results we have: \\[ \\operatorname{var}(X) = \\operatorname{E}(X^2) -\\operatorname{E}^2(X) = 15.17 - 3.5^2 = 2.917\\text{ to 4 s.f.}. \\] The standard deviation is \\[ \\operatorname{sd}(X) = \\sqrt{2.917} = 1.708\\text{ to 4 s.f.}. \\] A useful property of the variance: For \\(a\\) and \\(b\\) constants: \\[ \\operatorname{var}(aX + b) = a^2\\operatorname{var}(X) \\] 20.6 Summary of Discrete Distributions Here we list (without proof) the expectation and variance of the discrete probability distributions we have considered above. Distribution Probability Density Function Expectation Variance Bernoulli \\(X\\sim\\operatorname{Bern}(p)\\) \\(p_X(x)=p^x(1-p)^{1-x}\\); \\(x=0,1\\); \\(0 \\le p \\le 1\\). \\(\\operatorname{E}(X)=p\\) \\(\\operatorname{var}(X)=p(1-p)\\) Binomial \\(X\\sim\\operatorname{Bin}(n,p)\\) \\(p_X(x)={n \\choose x} p^x (1-p)^{n-x}\\); \\(n=1,2,\\dotsc\\); \\(0 \\le p \\le 1\\); \\(x=0,1,2\\dotsc,n\\) \\(\\operatorname{E}(X)=np\\) \\(\\operatorname{var}(X)=np(1-p)\\) Poisson \\(X\\sim\\operatorname{Po}(\\lambda)\\) \\(p_X(x)=\\dfrac{\\lambda^xe^{-\\lambda}}{x!}\\); \\(x=0,1,2,\\dotsc\\); \\(\\lambda&gt;0\\) \\(\\operatorname{E}(X)=\\lambda\\) \\(\\operatorname{var}(X)=\\lambda\\) "],["continuous-random-variables.html", "Chapter 21 Continuous Random Variables 21.1 Uniform distribution 21.2 Cumulative Distribution Function 21.3 Expectation and Variance 21.4 Normal Distribution 21.5 Standard Normal Distribution Tables 21.6 The Law of Large Numbers 21.7 Central Limit Theorem", " Chapter 21 Continuous Random Variables Recall that a random variable is a numerical valued function defined on the sample space. In plain language, it is a rule for assigning a number to each point in the sample space. So far all our discussion has been about discrete random variables i.e. those whose range of values is finite or countably infinite. However, it is conceptually possible for a random variable to take a continuum of values, such as an interval of real values (or a number of such intervals). A continuous random variable has an uncountably infinite number of possible values. Most properties of continuous random variables are analogous to the ideas we have already seen for discrete random variables, but the probability mass function is replaced by the probability density function, and summation is replaced by integration. Consider the random variable \\(X\\) which represents the life, in hours, of a 100 watt electric light bulb. The range of values of \\(X\\) is the interval \\(0 \\leq x &lt; \\infty\\), which is not a countably infinite set. So \\(X\\) is a continuous random variable. Suppose that \\(a\\) and \\(b\\) are two non-negative real values with \\(a &lt; b\\), then \\({a \\leq X \\leq b}\\) is an event in the sample space of \\(X\\), so we should be able to define the probability, \\(P(a \\leq X \\leq b)\\), that this event occurs. In general for a continuous random variable we assume there is some function \\(f_X(x)\\), such that for all \\(a &lt; b\\): \\[ P(a \\leq X \\leq b) = \\int_a^b f_X(x) dx. \\] We call the function \\(f_X(x)\\) the probability density function of the continuous random variable \\(X\\). Hence \\(P(a \\leq X \\leq b)\\) is equal to the area under the graph of \\(f_X(x)\\) between \\(x = a\\) and \\(x = b\\). Figure 21.1: \\(P(a&lt;X&lt;b)\\) is the area under \\(f_X(x)\\) from \\(a\\) to \\(b\\) When the range of values of a random variable is a continuum, we concentrate on probabilities of events such as \\(a \\leq X \\leq b\\), rather than events such as \\(X = a\\). We can see that: \\[P(X = a) = \\int_a^a f_X(x) dx =0.\\] Hence if \\(X\\) is a continuous random variable then for any single real number \\(a\\), \\(P(X = a) = 0\\). (Note \\(P(X=a)\\neq f_X(a)\\), since \\(f_X\\) is a probability density not a probability.) This also means we do not in general have to distinguish between \\(P(a &lt; X)\\) and \\(P(a \\leq X)\\) or between \\(P(X &lt; b)\\) and \\(P(X \\leq b)\\) for continuous random variables. As with discrete random variables, the probability of the whole sample space for a continuous random variable must be one, so \\(f_X(x)\\) must integrate to one over the range of \\(X\\) i.e.: \\[ \\int_{-\\infty}^{\\infty} f_X(x) = 1. \\] Note we can take this integral to be over the whole real line \\((-\\infty, \\infty)\\), since even if the range of possible values of \\(X\\) is more restricted than that, then \\(f_X(x)\\) will be zero outside of its range. 21.1 Uniform distribution A random variable \\(X\\) is equally likely to take any value in the range \\([a, b]\\), where \\(a &lt; b\\). What is the probability density function of \\(X\\)? If \\(X\\) is equally likely to take any value in the range \\([a, b]\\), then the probability density function of \\(X\\) must be a constant across the range. Hence, \\(f_X(x) = c\\) for some \\(c &gt; 0\\) when \\(x \\in [a, b]\\). Since \\(\\int_a^b c~dx = 1\\), then this implies that \\(c = 1 / (b - a)\\). Hence, \\[ f_X(x) = \\begin{cases} \\frac{1}{b - a} &amp; \\mbox{for $x \\in [a, b]$,}\\\\ 0 &amp; \\mbox{otherwise.} \\end{cases}. \\] Here \\(X \\sim U(a, b)\\) has a uniform distribution. As an example, we plot the probability density function for \\(X \\sim U(-0.5, 1.5)\\). \\[ f_X(x) = \\begin{cases} \\frac{1}{2} &amp; \\mbox{for $-0.5 &lt; x &lt; 1.5$,}\\\\ 0 &amp; \\mbox{otherwise.} \\end{cases}. \\] Figure 21.2: Graph of the density function \\(f_X(x)\\) for \\(X\\sim U(-0.5,1.5)\\). 21.2 Cumulative Distribution Function For a continuous random variable \\(X\\), we define the cumulative distribution function of \\(X\\) in a similar way to that for a discrete random variable i.e: \\[ F_X(x) = P(X &lt; x) = \\int_{-\\infty}^{x} f_X(u) du. \\] Note that, as for discrete random variables, if \\(X\\) is continuous then \\(0 \\leq F_X(x) \\leq 1\\) (because \\(F_X(x)\\) is a probability). Furthermore, \\(F_X(x)\\) is a non-decreasing function of \\(x\\), with \\[ \\lim_{x \\to -\\infty} F_X(x) = 0 \\quad \\mbox{and} \\quad \\lim_{x \\to \\infty} F_X(x) = 1. \\] In the continuous case \\(F_X(x)\\) is in general a smooth (usually S shaped) curve rather than a step function as it is in the discrete case. \\(F_X(x)\\) is defined for all values of \\(x\\) (not just the range of values for which \\(f_X(x)\\) is non-zero). For example, if \\(X \\sim U(a, b)\\), then \\[ F_X(x) = \\begin{cases} 0 &amp; \\mbox{for $x &lt; a$,}\\\\ \\frac{x - a}{b - a} &amp; \\mbox{for $a &lt; x &lt; b$,}\\\\ 1 &amp; \\mbox{for $x &gt; b$.} \\end{cases}. \\] As an example, we plot the cumulative distribution function for \\(X \\sim U(-0.5, 1.5)\\). \\[ F_X(x) = \\begin{cases} 0 &amp; \\mbox{for $x &lt; -0.5$,}\\\\ \\frac{x + 0.5}{2} &amp; \\mbox{for $-0.5 &lt; x &lt; 1.5$,}\\\\ 1 &amp; \\mbox{for $x &gt; 1.5$.} \\end{cases}. \\] Figure 21.3: Graph of the cumulative distribution function \\(F_X(x)\\) for \\(X\\sim U(-0.5,1.5)\\). The distribution function is useful for calculating probabilities such as \\(P(a \\leq X \\leq b)\\), since \\[ P(a \\leq X \\leq b) = P(X \\leq b) - P(X \\leq a) = F_X(b) - F_X(a). \\] 21.3 Expectation and Variance The expected value of a continuous random variable \\(X\\) is: \\[ \\operatorname{E}(X) = \\int_{-\\infty}^{\\infty} xf_X(x) dx. \\] Remember that if the range of values of \\(X\\) is more restricted than the whole real line, then \\(f_X(x)\\) will be zero outside of this range, so this definition still holds. In essence we say that we “integrate over the range of values” of \\(X\\). This is analogous to the discrete case, except we take an integral instead of a sum. Example 21.1 (Expectation of a Uniform RV) If \\(X \\sim U(a, b)\\), what is \\(\\operatorname{E}(X)\\)? \\[\\begin{eqnarray*} \\operatorname{E}(X) = \\int_{a}^{b} \\frac{x}{b - a} dx &amp;=&amp; \\left[\\frac{x^2}{2(b - a)} \\right]_{a}^{b} \\\\ &amp;=&amp; \\frac{b^2 - a^2}{2(b - a)} \\\\ &amp;=&amp; \\frac{(b - a)(b + a)}{2(b - a)}\\\\ &amp;=&amp; \\frac{b+a}{2}. \\end{eqnarray*}\\] The variance of a continuous random variable \\(X\\) is defined in the same way as for the discrete case: \\[ \\operatorname{var}(X) = \\operatorname{E}\\left([X - \\operatorname{E}(X)]^2\\right) = \\int_{-\\infty}^{\\infty} (x - \\mu)^2f_X(x) dx, \\] where \\(\\mu = \\operatorname{E}(X)\\). Other analogous properties to the discrete case also hold: Let \\(a\\) and \\(b\\) be constants, and let \\(g(X)\\) and \\(h(X)\\) be functions defined on the range of a random variable \\(X\\). Then, \\[ \\operatorname{E}\\left[ag(X) + bh(X)\\right] = a\\operatorname{E}[g(X)] + b\\operatorname{E}[h(X)] \\] and in particular \\(\\operatorname{E}(aX + b) = a\\operatorname{E}(X) + b\\). If \\(g(\\cdot)\\) is a function of a continuous random variable \\(X\\), then: \\[ E\\left[g(X)\\right] = \\int_{-\\infty}^{\\infty} g(x)f_X(x) dx. \\] It can be shown that \\[ \\operatorname{var}(X) = E\\left(X^2\\right) - E^2(X), \\] and \\(\\operatorname{var}(aX + b) = a^2\\operatorname{var}(X)\\). Example 21.2 (Variance of a Uniform RV) If \\(X \\sim U(a, b)\\), what is \\(\\operatorname{var}(X)\\)? We can calculate \\[\\begin{eqnarray*} \\operatorname{E}\\left(X^2\\right) = \\int_{a}^{b} \\frac{x^2}{b - a} dx &amp;=&amp; \\left[\\frac{x^3}{3(b - a)} \\right]_{a}^{b} \\\\ &amp;=&amp; \\frac{b^3 - a^3}{3(b - a)}. \\end{eqnarray*}\\] Hence, \\[\\begin{eqnarray*} \\operatorname{var}(X) = E\\left(X^2\\right) - E^2(X) &amp;=&amp; \\frac{b^3 - a^3}{3(b - a)} - \\frac{(a + b)^2}{4}\\\\ &amp;=&amp; \\frac{(b - a)^2}{12}. \\end{eqnarray*}\\] 21.4 Normal Distribution The normal (or ) distribution is the king of probability distributions. We say that \\(X\\) has the standard normal distribution if its density function is \\[ \\phi(x)=\\frac{e^{-x^2/2}}{\\sqrt{2\\pi}} \\] for \\(-\\infty &lt; x &lt; \\infty\\). The graph of \\(\\phi\\) is the famous “bell-shaped curve”. Figure 21.4: Graph of the normal distribution density function \\(\\phi\\). If \\(\\phi\\) is a density, we should have \\[ \\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^\\infty e^{-x^2/2}\\,dx = 1. \\] However, evaluating this definite integral requires methods beyond the scope of these notes. The mean and variance are \\(\\operatorname{E}(X)=0\\) and \\(\\operatorname{var}(X)=1\\). If \\(X\\) is a standard normal random variable and \\(Y=\\sigma X+\\mu\\) where \\(\\sigma&gt;0\\) and \\(-\\infty &lt; \\mu &lt; \\infty\\), then \\(Y\\) has a normal (Gaussian) distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). The probability density function of \\(Y\\) is \\[ f_Y(y)=\\frac1{\\sigma\\sqrt{2\\pi}}\\exp\\left[-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right]. \\] We write \\(Y\\sim N(\\mu,\\sigma^2)\\) to denote the distribution of this random variable being a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). The plot is shifted to the right by \\(\\mu\\) and “stretched” by \\(\\sigma\\). Figure 21.5: Density for \\(Y\\sim N(3,4)\\). The cumulative distribution function of a standard normal random variable, usually denoted by \\(\\Phi\\), is \\[ \\Phi(x)=P(X &lt; x)=\\frac1{\\sqrt{2\\pi}}\\int_{-\\infty}^x e^{-u^2/2}\\,du \\] but this integral can’t be expressed in terms of standard functions, like exponentials, logarithms and trigonometric functions. For this reason, values of this function (\\(\\Phi(x)\\)) are tabulated in statistical tables (but usually not available on pocket calculators). Figure 21.6: Cumulative distribution function \\(\\Phi(x)\\). We remark on one useful identity. Since the standard normal distribution is symmetric about zero \\[\\begin{eqnarray*} \\Phi(-x)&amp;=&amp;P(X &lt; -x)=P(X &gt; x)\\\\ &amp;=&amp;1-P(X &lt; x)=1-\\Phi(x) \\end{eqnarray*}\\] and it’s only necessary to tabulate \\(\\Phi(x)\\) for \\(x&gt;0\\). 21.5 Standard Normal Distribution Tables There are two forms commonly used, tabulating either . \\[P(X&lt;x)=\\int_{-\\infty}^x \\phi(u)\\,du$=\\Phi(x)\\] or \\[P(0&lt;X&lt;x)=\\int_{0}^x \\phi(u)\\,du=\\Phi(x)-\\Phi(0)=\\Phi(x)-0.5\\] where \\(X\\sim N(0,1)\\) and noting \\(\\Phi(0)=0.5\\) by symmetry. To save space, values of \\(P(X&lt; x)\\) or \\(P(0&lt; X &lt; x)\\) are listed down the rows in increments of \\(x\\) by \\(0.1\\) and along the columns in increments of \\(x\\) by \\(0.01\\). Figure 21.7: \\(P(X&lt;x)\\) is the area under \\(\\phi(x)\\) from \\(-\\infty\\) to \\(x\\) Table 21.1: Standard Normal Cumulative Distribution Table: type 1. 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0 0.5000 0.5040 0.5080 0.5120 0.5160 0.5199 0.5239 0.5279 0.5319 0.5359 0.1 0.5398 0.5438 0.5478 0.5517 0.5557 0.5596 0.5636 0.5675 0.5714 0.5753 0.2 0.5793 0.5832 0.5871 0.5910 0.5948 0.5987 0.6026 0.6064 0.6103 0.6141 0.3 0.6179 0.6217 0.6255 0.6293 0.6331 0.6368 0.6406 0.6443 0.6480 0.6517 0.4 0.6554 0.6591 0.6628 0.6664 0.6700 0.6736 0.6772 0.6808 0.6844 0.6879 0.5 0.6915 0.6950 0.6985 0.7019 0.7054 0.7088 0.7123 0.7157 0.7190 0.7224 0.6 0.7257 0.7291 0.7324 0.7357 0.7389 0.7422 0.7454 0.7486 0.7517 0.7549 0.7 0.7580 0.7611 0.7642 0.7673 0.7704 0.7734 0.7764 0.7794 0.7823 0.7852 0.8 0.7881 0.7910 0.7939 0.7967 0.7995 0.8023 0.8051 0.8078 0.8106 0.8133 0.9 0.8159 0.8186 0.8212 0.8238 0.8264 0.8289 0.8315 0.8340 0.8365 0.8389 1 0.8413 0.8438 0.8461 0.8485 0.8508 0.8531 0.8554 0.8577 0.8599 0.8621 1.1 0.8643 0.8665 0.8686 0.8708 0.8729 0.8749 0.8770 0.8790 0.8810 0.8830 1.2 0.8849 0.8869 0.8888 0.8907 0.8925 0.8944 0.8962 0.8980 0.8997 0.9015 1.3 0.9032 0.9049 0.9066 0.9082 0.9099 0.9115 0.9131 0.9147 0.9162 0.9177 1.4 0.9192 0.9207 0.9222 0.9236 0.9251 0.9265 0.9279 0.9292 0.9306 0.9319 1.5 0.9332 0.9345 0.9357 0.9370 0.9382 0.9394 0.9406 0.9418 0.9429 0.9441 1.6 0.9452 0.9463 0.9474 0.9484 0.9495 0.9505 0.9515 0.9525 0.9535 0.9545 1.7 0.9554 0.9564 0.9573 0.9582 0.9591 0.9599 0.9608 0.9616 0.9625 0.9633 1.8 0.9641 0.9649 0.9656 0.9664 0.9671 0.9678 0.9686 0.9693 0.9699 0.9706 1.9 0.9713 0.9719 0.9726 0.9732 0.9738 0.9744 0.9750 0.9756 0.9761 0.9767 2 0.9772 0.9778 0.9783 0.9788 0.9793 0.9798 0.9803 0.9808 0.9812 0.9817 2.1 0.9821 0.9826 0.9830 0.9834 0.9838 0.9842 0.9846 0.9850 0.9854 0.9857 2.2 0.9861 0.9864 0.9868 0.9871 0.9875 0.9878 0.9881 0.9884 0.9887 0.9890 2.3 0.9893 0.9896 0.9898 0.9901 0.9904 0.9906 0.9909 0.9911 0.9913 0.9916 2.4 0.9918 0.9920 0.9922 0.9925 0.9927 0.9929 0.9931 0.9932 0.9934 0.9936 2.5 0.9938 0.9940 0.9941 0.9943 0.9945 0.9946 0.9948 0.9949 0.9951 0.9952 2.6 0.9953 0.9955 0.9956 0.9957 0.9959 0.9960 0.9961 0.9962 0.9963 0.9964 2.7 0.9965 0.9966 0.9967 0.9968 0.9969 0.9970 0.9971 0.9972 0.9973 0.9974 2.8 0.9974 0.9975 0.9976 0.9977 0.9977 0.9978 0.9979 0.9979 0.9980 0.9981 2.9 0.9981 0.9982 0.9982 0.9983 0.9984 0.9984 0.9985 0.9985 0.9986 0.9986 3 0.9987 0.9987 0.9987 0.9988 0.9988 0.9989 0.9989 0.9989 0.9990 0.9990 Figure 21.8: \\(P(0&lt;X&lt;x)\\) is the area under \\(\\phi(x)\\) from \\(0\\) to \\(x\\) Table 21.2: Standard Normal Cumulative Distribution Table: type 2. 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0 0.0000 0.0040 0.0080 0.0120 0.0160 0.0199 0.0239 0.0279 0.0319 0.0359 0.1 0.0398 0.0438 0.0478 0.0517 0.0557 0.0596 0.0636 0.0675 0.0714 0.0753 0.2 0.0793 0.0832 0.0871 0.0910 0.0948 0.0987 0.1026 0.1064 0.1103 0.1141 0.3 0.1179 0.1217 0.1255 0.1293 0.1331 0.1368 0.1406 0.1443 0.1480 0.1517 0.4 0.1554 0.1591 0.1628 0.1664 0.1700 0.1736 0.1772 0.1808 0.1844 0.1879 0.5 0.1915 0.1950 0.1985 0.2019 0.2054 0.2088 0.2123 0.2157 0.2190 0.2224 0.6 0.2257 0.2291 0.2324 0.2357 0.2389 0.2422 0.2454 0.2486 0.2517 0.2549 0.7 0.2580 0.2611 0.2642 0.2673 0.2704 0.2734 0.2764 0.2794 0.2823 0.2852 0.8 0.2881 0.2910 0.2939 0.2967 0.2995 0.3023 0.3051 0.3078 0.3106 0.3133 0.9 0.3159 0.3186 0.3212 0.3238 0.3264 0.3289 0.3315 0.3340 0.3365 0.3389 1 0.3413 0.3438 0.3461 0.3485 0.3508 0.3531 0.3554 0.3577 0.3599 0.3621 1.1 0.3643 0.3665 0.3686 0.3708 0.3729 0.3749 0.3770 0.3790 0.3810 0.3830 1.2 0.3849 0.3869 0.3888 0.3907 0.3925 0.3944 0.3962 0.3980 0.3997 0.4015 1.3 0.4032 0.4049 0.4066 0.4082 0.4099 0.4115 0.4131 0.4147 0.4162 0.4177 1.4 0.4192 0.4207 0.4222 0.4236 0.4251 0.4265 0.4279 0.4292 0.4306 0.4319 1.5 0.4332 0.4345 0.4357 0.4370 0.4382 0.4394 0.4406 0.4418 0.4429 0.4441 1.6 0.4452 0.4463 0.4474 0.4484 0.4495 0.4505 0.4515 0.4525 0.4535 0.4545 1.7 0.4554 0.4564 0.4573 0.4582 0.4591 0.4599 0.4608 0.4616 0.4625 0.4633 1.8 0.4641 0.4649 0.4656 0.4664 0.4671 0.4678 0.4686 0.4693 0.4699 0.4706 1.9 0.4713 0.4719 0.4726 0.4732 0.4738 0.4744 0.4750 0.4756 0.4761 0.4767 2 0.4772 0.4778 0.4783 0.4788 0.4793 0.4798 0.4803 0.4808 0.4812 0.4817 2.1 0.4821 0.4826 0.4830 0.4834 0.4838 0.4842 0.4846 0.4850 0.4854 0.4857 2.2 0.4861 0.4864 0.4868 0.4871 0.4875 0.4878 0.4881 0.4884 0.4887 0.4890 2.3 0.4893 0.4896 0.4898 0.4901 0.4904 0.4906 0.4909 0.4911 0.4913 0.4916 2.4 0.4918 0.4920 0.4922 0.4925 0.4927 0.4929 0.4931 0.4932 0.4934 0.4936 2.5 0.4938 0.4940 0.4941 0.4943 0.4945 0.4946 0.4948 0.4949 0.4951 0.4952 2.6 0.4953 0.4955 0.4956 0.4957 0.4959 0.4960 0.4961 0.4962 0.4963 0.4964 2.7 0.4965 0.4966 0.4967 0.4968 0.4969 0.4970 0.4971 0.4972 0.4973 0.4974 2.8 0.4974 0.4975 0.4976 0.4977 0.4977 0.4978 0.4979 0.4979 0.4980 0.4981 2.9 0.4981 0.4982 0.4982 0.4983 0.4984 0.4984 0.4985 0.4985 0.4986 0.4986 3 0.4987 0.4987 0.4987 0.4988 0.4988 0.4989 0.4989 0.4989 0.4990 0.4990 Example 21.3 (Using Statistical Tables) What is \\(P(-0.45&lt;X&lt;1.25)\\) for a standard normal variable \\(X\\)? Using table 21.1 \\[\\begin{eqnarray*} P(-0.45&lt;X&lt;1.25) &amp;=&amp;P(X&lt;1.25)\\\\ &amp;&amp; \\quad - P(X&lt;-0.45)\\\\ &amp;=&amp;P(X&lt;1.25)\\\\ &amp;&amp; \\quad -\\left[1 - P(X&lt;0.45)\\right]\\\\ &amp;\\approx&amp;0.8944-(1 - 0.6736)\\\\ &amp;\\approx&amp;0.568 \\end{eqnarray*}\\] Or using table 21.2 \\[\\begin{eqnarray*} P(-0.45&lt;X&lt;1.25) &amp;=&amp;P(0&lt;X&lt;1.25)\\\\ &amp;&amp; \\quad + P(0&lt;X&lt;0.45)\\\\ &amp;=&amp;0.3944+0.1736\\\\ &amp;\\approx&amp;0.568 \\end{eqnarray*}\\] We can use standard tables to find probabilities of general normal random variables. If \\(Y\\) is normal with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then \\[X=(Y-\\mu)/\\sigma\\] is standard normal. Then for \\(a&lt;b\\), \\[\\begin{eqnarray*} P(a\\le Y\\le b)&amp;=&amp;P(a\\le \\sigma X+\\mu\\le b)\\\\ &amp;=&amp;P\\left(\\frac{a-\\mu}\\sigma\\le X\\le\\frac{b-\\mu}\\sigma\\right)\\\\ &amp;=&amp;\\Phi\\left(\\frac{b-\\mu}\\sigma\\right)-\\Phi\\left(\\frac{a-\\mu}\\sigma\\right). \\end{eqnarray*}\\] Example 21.4 (Non-standard normal random variables) If \\(Y\\) is normal with mean \\(1\\) and variance \\(4=2^2\\), then \\(X=(Y-1)/2\\) is . Calculate \\(P(0&lt;Y&lt;2.5)\\). Using table 21.1 \\[\\begin{eqnarray*} P(0&lt;Y&lt;2.5)&amp;=&amp;P(-0.5&lt;X&lt;0.75)\\\\ &amp;=&amp;P(X&lt;0.75)-\\left[1 - P(X&lt;0.5)\\right]\\\\ &amp;\\approx&amp;0.7734 - (1 - 0.6915)\\approx 0.4649 \\end{eqnarray*}\\] or using table 21.2 \\[\\begin{eqnarray*} P(0&lt;Y&lt;2.5)&amp;=&amp;P(-0.5&lt;X&lt;0.75)\\\\ &amp;=&amp;P(0&lt;X&lt;0.75)+ P(0&lt;X&lt;0.5)\\\\ &amp;\\approx&amp;0.2734 + 0.1915\\approx 0.4649 \\end{eqnarray*}\\] If \\(Y\\) is normal with mean \\(3\\) and variance \\(25\\), calculate \\(P(4&lt;Y&lt;8)\\). \\[\\begin{eqnarray*} P(4&lt;Y&lt;8)&amp;=&amp;P(0.2&lt;X&lt;1)\\\\ &amp;=&amp;P(X&lt;1)- P(X&lt;0.2)\\\\ &amp;\\approx 0.8413 - 0.5793 &amp; \\approx 0.262. \\end{eqnarray*}\\] or \\[\\begin{eqnarray*} P(4&lt;Y&lt;8)&amp;=&amp;P(0.2&lt;X&lt;1)\\\\ &amp;=&amp;P(0&lt;X&lt;1)-P(0&lt;X&lt;0.2)\\\\ &amp;\\approx&amp;0.3413 - 0.0793\\approx 0.262. \\end{eqnarray*}\\] If \\(X\\) is standard normal, we find \\[\\begin{eqnarray*} P(|X|&gt;2)&amp;=&amp;1-P(-2&lt;X&lt;2)\\\\ &amp;=&amp;2 P(X &gt; 2)\\\\ &amp;=&amp;2 \\left[1 - P(X &lt; 2)\\right]\\\\ &amp;\\approx&amp; 2 \\times (1 - 0.9772)\\\\ &amp;=&amp; 0.0456. \\end{eqnarray*}\\] Hence approx. 95% of the distribution lies in the region \\(-2 &lt; X &lt; 2\\) (or in the case of a general normal random variable \\(Y\\) this region is between \\(\\mu\\pm2\\sigma\\)). Figure 21.9: Approximately 95% lies within \\(\\pm2\\sigma\\). Linear interpolation Note that if the exact value you are looking for isn’t tabulated then one option would be to round to the nearest value. A more accurate approximation is to use linear interpolation between the two nearest values given in the table e.g. you want \\(\\Phi(c)\\) and nearest values in table are \\(\\Phi(a)\\) and \\(\\Phi(b)\\) where \\(a &lt; c &lt; b\\), then approximate \\[ \\Phi(c) = \\Phi(a) + \\left(\\frac{c - a}{b - a}\\right)(\\Phi(b) - \\Phi(a)). \\] (Make sure you adjust appropriately if finding \\(1 - \\Phi(c)\\).) 21.6 The Law of Large Numbers The concept of the “law of averages” can be made mathematically respectable and precise through a result known as the law of large numbers. Suppose \\(X_1, \\dots, X_n\\) is a sequence of independent identically distributed (i.i.d.) random variables such that \\(E(X_i) = \\mu\\) and \\(\\operatorname{var}(X_i) = \\sigma^2\\) for \\(i = 1, \\dots, n\\), and let \\[ \\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i \\] denote the sample mean (so-called because one can think of the sequence \\(X_1, \\dots, X_n\\) as conceptually representing repeated independent samples (observations) from the same probability distribution). The law of large numbers then states that the probability that the difference between \\(\\bar{X}\\) and \\(\\mu\\) is arbitrarily small can be made close to 1 by taking a large enough sample. 21.7 Central Limit Theorem The reason the normal distribution is so ubiqitous is due to the Central Limit Theorem (CLT). Informally, the CLT states that the average of a set of i.i.d. random variables each of which has mean \\(\\mu\\) and variance \\(\\sigma^2\\) is approximately normally distributed with mean \\(\\mu\\) and variance \\(\\frac{\\sigma^2}{n}\\) if \\(n\\) is large. Hence, if \\(\\bar{X} = \\frac{1}{n} \\sum_{i = 1}^n X_i\\), then \\(\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\\) for large \\(n\\) whatever distribution the \\(X_i\\) have. Example 21.5 (Central Limit Theorem) You repeatedly throw a fair die \\(n\\) times and take the average of the scores. Here, \\(X_i\\) is the score on the \\(i^{\\text{th}}\\) die, and \\(\\displaystyle{\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i}\\) is the mean score, then \\(\\bar{X}\\) will approximately follow a \\(N\\left(3.5, \\frac{2.92}{n}\\right)\\) distribution for large \\(n\\). Another way of stating the CLT is that as \\(n \\to \\infty\\) the probability distribution of \\(\\left(\\frac{X - \\mu}{\\sigma / \\sqrt{n}}\\right)\\) tends to a standard normal distribution. What is remarkable about this theorem is that it applies whatever probability distribution \\(X_i\\) has. It can be discrete or continuous, and of any type, Binomial, Poisson, uniform, normal,… "],["statistics.html", "Chapter 22 Statistics 22.1 Frequency 22.2 Measures of central tendency 22.3 Measures of Dispersion", " Chapter 22 Statistics Statistics is the branch of mathematics that is primarily concerned with the collection, summarisation and interpretation of data. Data consist of sets of recorded observations or values. There are three broad types of data: Categorical. Observations that fit into qualitative categories, such as: film genres, rock types, renewable energy sources. Discrete. Observations that are from a finite or countable numerical range, such as: number of cars on a stretch of road, number of items produced in a factory. Continuous. Observations that can be from a continuum of numerical values, such as: a temperature measurement, mineral content of a rock sample. (Note that in reality such measurements may be restriced to discrete outcomes due to the limited precision of the recording instrument, but may still be modelled as continuous data.) Here we only focus on the latter two. We usually analyse a limited (finite) sample of \\(n\\) observations and assume these are a good representitive of the population of all \\(N\\) possible observations. 22.1 Frequency 22.1.1 Tables Consider the following values of the number of widgets packed into a sample of \\(30\\) boxes at a factory. 25 26 26 27 27 27 27 28 28 28 28 28 28 28 29 29 29 29 29 29 30 30 30 30 30 31 31 31 32 32 We label each of the observations \\(x_1,\\dotsc,x_{30}\\), or more generally observations are labelled \\(x_i\\) where \\(i=1,\\dotsc,n\\). We can summarise this data in a frequency distribution, which shows the frequency \\(f\\) with which each unique value \\(x\\) occurs: Value \\(x\\) Frequency \\(f(x)\\) 25 1 26 2 27 4 28 7 29 6 30 5 31 3 32 2 Note that the sum of the frequency column is the number of samples \\(n=30\\), that is \\(\\sum_x f(x) = n\\). Sometimes it is more convenient to group the values into classes, particularly with continuous variables. For example, if the lengths of a sample of \\(40\\) widgets (in mm) are 20.90 20.57 20.86 20.74 20.82 20.63 20.53 20.89 20.75 20.65 20.71 21.03 20.72 20.41 20.94 20.75 20.79 20.65 21.08 20.89 20.50 20.88 20.97 20.78 20.61 20.92 21.07 21.16 20.80 20.77 20.82 20.72 20.60 20.90 20.86 20.68 20.75 20.88 20.56 20.94 we could group these into classes of width 0.10 Class Frequency \\(f\\) 20.40-20.49 1 20.50-20.59 4 20.60-20.69 6 20.70-20.79 10 20.80-20.89 9 20.90-20.99 6 21.00-21.09 3 21.10-21.19 1 The Groups listed here are denoted by the upper and lower class limits. Due to rounding, the values counted in each group are between the class boundaries, for example the lower and upper class boundaries of 20.40-20.49 are 20.395-20.495 (note that a value equal to the upper class boundary would be rounded-up into the next class). Sometimes groups are instead listed similar to \\(a\\le x &lt;b\\), in which case the class limits coincide with the class boundaries. We could add a further column to express the relative frequency, which is \\(f/n\\) where \\(n\\) is the number of observations. This is often expressed as a percentage (i.e. multiply the fraction by 100). Class Frequency \\(f\\) Relative Frequency (%) 20.40-20.49 1 2.5 20.50-20.59 4 10.0 20.60-20.69 6 15.0 20.70-20.79 10 25.0 20.80-20.89 9 22.5 20.90-20.99 6 15.0 21.00-21.09 3 7.5 21.10-21.19 1 2.5 It can also be useful to tabulate the cumulative frequency (the “running total”), which adds the frequencies of the current value/class and all previous values/classes. For our examples, this would give Value \\(x\\) Frequency \\(f\\) Relative Frequency (%) Cumulative Frequency Relative Cumulative Frequency (%) 25 1 3.33 1 3.33 26 2 6.66 3 10.00 27 4 13.33 7 23.33 28 7 20.00 14 46.66 29 6 16.66 20 66.66 30 5 10.00 25 83.33 31 3 10.00 28 93.33 32 2 6.66 30 100.00 Class Frequency \\(f\\) Relative Frequency (%) Cumulative Frequency Relative Cumulative Frequency (%) 20.40-20.49 1 2.5 1 2.5 20.50-20.59 4 10 5 12.5 20.60-20.69 6 15 11 27.5 20.70-20.79 10 25 21 52.5 20.80-20.89 9 22.5 30 75 20.90-20.99 6 15 36 90 21.00-21.09 3 7.5 39 97.5 21.10-21.19 1 2.5 40 100 22.1.2 Graphs It is useful to summarise the data distribution graphically, since this can quickly reveal trends. Three types of graphs commonly used to present data in the frequency distribution: * Frequency Polygon * Histogram * Ogive A frequency polygon is a line graph with frequency plotted against the class midpoints. The points are connected by straight lines. A histogram is a graphical representation of a frequency table, in which vertical rectangular blocks are drawn so that: the centre of the base indicates the central value of the class and the area of the rectangle represents the class frequency. If the class intervals are regular, the frequency is then denoted by the height of the rectangle. Here we have labelled the classes using the class boundaries; an alternative is to label the class midpoints in the middle of each rectangle. Similar plots can be made using the relative frequency. This will have the same shape, but the “\\(y\\)-axis” will now be in units of the relative frequency, between 0 and 1, or 0% and 100%. The ogive is a plot of the cumulative frequency against the upper class boundaries. Connecting the points with straight lines allows us to interpolate between the values. 22.2 Measures of central tendency We will consider three measures of central tendancy: these are single values that summarise data by their “averages”. 22.2.1 Mean The mean of the population is defined as \\[\\mu = \\frac{1}{N}\\sum_{i=1}^N x_i.\\] The mean of a sample of \\(n\\) observations with values \\(x_i\\) is defined as \\[\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i.\\] If we have a frequency table, then we can find the mean as the sum over the distinct values of \\(x\\) multiplied by \\(f\\) \\[\\bar{x}=\\frac{1}{n}\\sum_x x f\\] If we add a third column \\(xf\\) to our frequency table for the number of widgets in boxes, then \\(\\bar{x}\\) is just the sum of the final column. Value \\(x\\) Frequency \\(f\\) \\(xf\\) 25 1 25 26 2 52 27 4 108 28 7 196 29 6 174 30 5 150 31 3 93 32 2 64 we have \\(\\sum xf = 862\\) hence \\(\\bar{x}=862/30=28.73\\). If we have grouped data, then we get a good approximation by taking \\(x\\) as the midpoint of the class. In our example of widget lengths, we have Class midpoint \\(x\\) Frequency \\(f\\) \\(xf\\) 20.40-20.49 20.445 1 20.445 20.50-20.59 20.545 4 82.18 20.60-20.69 20.645 6 123.87 20.70-20.79 20.745 10 207.45 20.80-20.89 20.845 9 187.605 20.90-20.99 20.945 6 125.67 21.00-21.09 21.045 3 63.135 21.10-21.19 21.145 1 21.145 then \\(\\bar{x}=\\frac{1}{n}\\sum xf = 831.5/40=20.79\\). 22.2.2 Mode The mode is the value with the greatest frequency. For example, in the values \\(2,3,3,4,4,4,5,5\\) the mode is \\(4\\). Note there could be more than one mode, as there are in the values \\(1,1,2,2,3,4\\). We can easily read the mode from a frequency table or histogram as the value (or multiple values) with the largest frequency. In the number of widgets frequency table the mode is 28. If we have grouped data, then we define the modal class (or classes) as the class with the largest frequency. In the widget length frequency table the modal class is 20.70-20.79. 22.2.3 Median The median is the value of the middle term when all observations are arranged in ascending or descending order. If we have an even number of observations then we take the mean of the two middle values. For our numbers of widgets example 25 26 26 27 27 27 27 28 28 28 28 28 28 28 29 29 29 29 29 29 30 30 30 30 30 31 31 31 32 32 we have 30 observations, so we take the average of the 15th and 16th values: \\((29+29)/2=29\\) For grouped data, the median class can be found as the class where the middle value lies. In our widget length example, this is where the 20th and 21st values lie, which is in the class 20.70-20.79. We can further interpolate to find an estimate for the median. The classes before the median class contain \\(6+4+1=11\\) of the observations and the median class contains 10 observations. The median value therefore lies between the 9th and 10th observation in the median class. We assume the 10 observations are evenly distributed through this class. We divide the class width of 0.1 in the ratio 9:1. Then the median is \\[\\text{median}\\approx 20.70 + \\frac{9}{10}\\times 0.1= 20.79.\\] As a general formula we have: \\[\\text{median}\\approx\\text{lower class boundary}+\\frac{\\frac{n}{2}-c_f}{f}\\times w\\] where \\(n\\) is the total number of observations, \\(c_f\\) is the cumulative frequency before the median class, \\(f\\) is the frequency of the median class and \\(w\\) is the class width. For our example: \\[\\text{median}\\approx 20.70+\\frac{\\frac{40}{2}-(6+4+1)}{10}\\times 0.1=20.79.\\] The median can also be read from the ogive plot, by finding the value corresponding to half the observations: draw a horizontal line from \\(n/2=20\\) to the ogive line, then vertically to the \\(x\\)-axis to read off the median. 22.3 Measures of Dispersion The mean, mode and median all give us useful information about the central values of the observations, but they do not say anything about the spread, or dispersion, of the observations. Consider the following two sets of observations \\[26, 27, 28, 29, 30\\] \\[5, 19, 20, 36, 60\\] These both have a mean of \\(28\\), but the spread of the second set is clearly wider than the spread of the first set. It is useful to have a measure that captures this. 22.3.1 Range The range is simply the difference between the highest and lowest values in the data. In our number of widgets example, this is \\(32-25=7\\). However, this does not give any indication about the general spread of the data, it only tells us about the extreme values at either end. 22.3.2 Interquartile Range and Percentiles The quartiles are the values that split the cumulative data into quarters. Lower Quartile (\\(Q_1\\)): 25% of the data falls before \\(Q_1\\) Middle Quartile = Median (\\(Q_2\\)): 50% of the data falls before \\(Q_2\\) Upper Quartile (\\(Q_3\\)): 75% of the data falls before \\(Q_3\\) These can be estimated from the ogive plot by drawing horizontal lines from the 25%, 50% and 75% values on the vertical axis to the ogive curve, and dropping vertical lines to the horizontal axis. In our widget length example, we have: with the estimates \\(Q_1\\approx 20.68\\), \\(Q_2\\approx 20.79\\), \\(Q_3\\approx 20.895\\). The interquartile range is defined as \\[IQR=Q_3-Q_1\\] and is a measure of the spread of the data. For our widget lengths we have \\(IQR\\approx 20.895-20.68=0.215\\). A related plot is the box plot, which includes \\(Q_1\\), \\(Q_2\\) (median), \\(Q_3\\) and the extreme values. More generally, we define the \\(k^\\text{th}\\) percentile \\(P_k\\) as the value for which \\(k\\)% of the data falls before \\(P_k\\). For example, the \\(25^{\\text{th}}\\) percentile is \\(P_{25}=Q_1\\). 22.3.3 Variance and Standard Deviation The variance is the average of the squared deviations from the mean. This tells us how tightly the data is clustered around the mean. If we had observations of the entire population, this is defined as \\[\\sigma^2=\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2\\] but if we only have a sample of \\(n&lt;N\\) observations, we use \\[S^2=\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\\] Why do we divide by \\(n-1\\) and not \\(n\\)? This gives a more accurate estimate of the population variance (see this wikipedia article for more details). As the units of variance are the squared units of the data, it is usually more useful to take the square root to obtain a measure with the same units as the data. This is called the standard deviation: \\[S=\\sqrt{S^2}=\\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2}.\\] We can find \\(S\\) in a convenient way by tabulating the values in the sum. For our second data set above we have \\(\\bar{x}=\\frac{1}{n}\\sum_{i=1}^nx_i=140/5=28\\). Then, \\(x_i\\) \\(x_i-\\bar{x}\\) \\((x_i-\\bar{x})^2\\) 5 -23 529 19 -9 81 20 -8 64 36 8 64 60 32 1024 \\(\\sum_{i=1}^nx_i=140\\) \\(\\sum_{i=1}^n (x_i - \\bar{x})^2=1762\\) Then we have \\[S=\\sqrt{\\frac{1}{5-1}(1762)}=\\sqrt{440.5}=20.99.\\] An alternative formula for the sample variance is \\[S^2=\\frac{\\sum_{i=1}^nx_i^2-(\\sum_{i=1}^nx_i)^2/n}{n-1}\\] which is usually easier to work with since it needs less calculations. We can find this using the table \\(x_i\\) \\(x_i^2\\) 5 25 19 361 20 400 36 1296 60 3600 \\(\\sum_{i=1}^nx_i=140\\) \\(\\sum_{i=1}^n x_i^2=5682\\) giving \\[S=\\sqrt{\\frac{5682-140^2/5}{5-1}}=\\sqrt{440.5}=20.99.\\] For grouped data, we perform these calculations using the midpoint of each class as the value of \\(x\\). The standard deviation is estimated by \\[S=\\sqrt{S^2}=\\sqrt{\\frac{1}{n-1} \\sum_{x} f(x - \\bar{x})^2}\\] For example, constructing the table for our widget lengths midpoint \\(x\\) Frequency \\(f\\) \\(xf\\) \\((x-\\bar{x})\\) \\(f(x-\\bar{x})^2\\) 20.45 1 20.45 -0.34 0.12 20.55 4 82.20 -0.24 0.24 20.65 6 123.90 -0.14 0.12 20.75 10 207.50 -0.04 0.02 20.85 9 187.65 0.06 0.03 20.95 6 125.70 0.16 0.15 21.05 3 63.15 0.26 0.20 21.15 1 21.15 0.36 0.13 \\(n=\\sum f = 40\\) \\(\\sum_{x} xf=831.7\\) \\(\\sum_x f(x-\\bar{x})^2=0.99775\\) Note \\(\\bar{x}=831.7/40=20.79\\). Hence \\[S=\\sqrt{\\frac{1}{40-1}\\times 0.99775}=0.16\\] Alternatively we use \\[S=\\sqrt{\\frac{\\sum_{x} (x^2)f-(\\sum_{x}xf)^2/n}{n-1}}.\\] For our example, we construct the table midpoint \\(x\\) Frequency \\(f\\) \\(xf\\) \\(x^2f\\) 20.45 1 20.45 418.20 20.55 4 82.2 1689.21 20.65 6 123.9 2558.54 20.75 10 207.5 4305.63 20.85 9 187.65 3912.50 20.95 6 125.7 2633.42 21.05 3 63.15 1329.31 21.15 1 21.15 447.32 \\(n=\\sum f=40\\) \\(\\sum_{x} xf=831.7\\) \\(\\sum_{x} (x^2)f=17294.12\\) Hence \\[S=\\sqrt{\\frac{17294.12-831.7^2/40}{40-1}}=0.16.\\] "],["exercise-set-1.html", "Exercise Set 1", " Exercise Set 1 These exercises cover the topics of Algebra. Simplify each of the following (Hint: use the rules of exponents where needed). \\(x = 3pq+5pr=2qr+qp-6rp\\) \\(y = 5l^2mn+2nl^2m-3mln^2+l^2nm+4n^2ml-nm^2\\) \\(z = \\dfrac{(s^\\frac{1}{3})^\\frac{3}{4}\\times (t^\\frac{1}{4})^{-1}}{(t^\\frac{1}{2}\\times (s^{-\\frac{1}{4}})^{-1})}\\) Expand the brackets in each of the following and simplify the expression. \\(-4x(2x-y)(3x+2y)\\) \\((a-2b)(2a-3b)(3a-4b)\\) \\(-\\{-2[x-3(y-4)]-5(z+6)\\}\\) \\((v^3-v^2-2)(1-3v+2v^2)\\) Simplify each of the following. \\(\\dfrac{p}{q^3}\\div\\dfrac{p^3}{q}\\) \\(\\dfrac{a^2b}{2c}\\times\\dfrac{ac^2}{2b}\\div\\dfrac{b^2c}{2a}\\) \\(\\dfrac{8x^{-3}\\times 3x^2}{6x^{-4}}\\) \\(\\dfrac{3x}{3x^2+6x}\\) Factorise the following expressions. \\(18x^2y-12xy^2\\) \\(x^3+4x^2y-3xy^2-12y^3\\) \\(25x^2-4y^2\\) The characteristic equation of a perfect gas is given by \\(P V = mRT\\) where \\(m\\) is the mass, \\(P\\) is the pressure, \\(V\\) is the volume, \\(T\\) is the temperature and \\(R\\) is the universal gas constant. Make temperature the subject of the formula. The airflow over a turbine blade causes drag \\(D\\), which is given by \\(D= \\dfrac{\\rho C v^2 A}{2}\\), where \\(\\rho\\) is fluid density, \\(C\\) is the drag coefficient, \\(v\\) is fluid velocity and \\(A\\) is the frontal area of the blade. Make the frontal area the subject of the formula. Make \\(b\\) the subject of the following formula. \\[W=\\frac{t\\sqrt{a+b^2}}{2\\pi}\\] "],["exercise-set-1-answers.html", "Exercise Set 1 Answers", " Exercise Set 1 Answers These exercises cover the topics of Algebra, Equations and Inequalities. Simplify each of the following (Hint: use the rules of exponents where needed). \\(x = 3pq+5pr=2qr+qp-6rp\\) \\(y = 5l^2mn+2nl^2m-3mln^2+l^2nm+4n^2ml-nm^2\\) \\(z = \\dfrac{(s^\\frac{1}{3})^\\frac{3}{4}\\times (t^\\frac{1}{4})^{-1}}{(t^\\frac{1}{2}\\times (s^{-\\frac{1}{4}})^{-1})}\\) Answers: We collect the so-called “like terms” (if there are any): \\[\\begin{align*} x &amp;= 3pq + 5pr - 2qr + qp -6rp = 3pq +qp +5pr - 6rp - 2qr \\\\ &amp;= 4pq - pr - 2qr \\quad\\text{ we add and/or subtract ``like terms&#39;&#39;} \\end{align*}\\] We collect the so-called “like terms” (if there are any): \\[\\begin{align} y &amp;= 5l^2 mn + 2nl^2m - 3mln^2 + l^2nm + 4n^2ml - nm^2\\\\ &amp;= 5l^2 mn + 2nl^2m + l^2nm - 3mln^2 + 4n^2ml - nm^2\\\\ &amp;= 8l^2 mn + n^2lm - nm^2 \\quad\\text{ we add and/or subtract ``like terms&#39;&#39;} \\end{align}\\] We first complete the calculation in both the numerator and the denominator using the laws &amp; rules of indices: \\[\\begin{align} z &amp;= \\frac{(s^\\frac{1}{3})^\\frac{3}{4} \\times (t^\\frac{1}{4})^{-1}}{(t^\\frac{1}{2})^4 \\times (s^{-\\frac{1}{4}})^{-1}}=\\frac{s^{\\frac{1}{3}\\times\\frac{3}{4}}\\times t^{-\\frac{1}{4}}}{t^{\\frac{1}{2} \\times 4}\\times s^{\\frac{1}{4}}}\\\\ &amp;= \\frac{s^\\frac{1}{4}\\times t^{-\\frac{1}{4}}}{t^2 \\times s^\\frac{1}{4}}\\quad \\text{we treat the powers of the same base together using laws of indices}\\\\ &amp;= s^{\\frac{1}{4}-\\frac{1}{4}} \\times t^{-\\frac{1}{4}-2} = 1 \\times t^{-\\frac{9}{4}} = \\frac{1}{t^\\frac{9}{4}} \\end{align}\\] It is best to write your final answer with positive exponents only. Expand the brackets in each of the following and simplify the expression. \\(-4x(2x-y)(3x+2y)\\) \\((a-2b)(2a-3b)(3a-4b)\\) \\(-\\{-2[x-3(y-4)]-5(z+6)\\}\\) \\((v^3-v^2-2)(1-3v+2v^2)\\) Answers: We have three factors. First we multiply \\(-4x\\) by \\(2x-y\\), then we multiply the outcome by \\((3x + 2y)\\). \\[\\begin{align*} -4x(2x-y)(3x+2y) &amp;= (-8x^2 + 4xy)(3x+2y)\\\\ &amp; = -24x^3 - 4x^2y + 8xy^2. \\end{align*}\\] Again, we have three factors, we repeat the same process (make sure you simplify the outcome in each step, i.e. add/subtract like-terms): \\[\\begin{align*} (a-2b)(2a-3b)(3a-4b) &amp;= (2a^2 - 3ab - 4ab + 6b^2)(3a - 4b)\\\\ &amp;= (2a^2 - 7ab + 6b^2)(3a - 4b)\\\\ &amp;= 6a^3 - 8a^2 b - 21a^2b + 28ab^2 + 18b^2a - 24b^3\\\\ &amp;= 6a^3 - 29a^2b + 46b^2a - 24b^3 \\end{align*}\\] We calculate the inner brackets first, then we remove the brackets. Lastly, we add/subtract like terms: \\[\\begin{align*} -\\{ -2[x - 3(y-4)]- 5(z+6)\\} &amp;= - \\{-2[x - 3y + 12] - 5(z+6)\\}\\\\ &amp;= - (-2x + 6y - 24 -5z -30)\\\\ &amp;= -(-2x + 6y -5z -54)\\\\ &amp;= 2x - 6y + 5z +54 \\end{align*}\\] \\[\\begin{align*} (v^3 - v^2 - 2)(1 - 3v + 2v^2) &amp;= v^3 - 3v^4 + 2v^5 - v^2 + 3v^3 - 2v^4 - 2 + 6v - 4v^2\\\\ &amp;= 2v^5 - 5v^4 + 4v^3 - 5v^2 + 6v - 2 \\end{align*}\\] Simplify each of the following. \\(\\dfrac{p}{q^3}\\div\\dfrac{p^3}{q}\\) \\(\\dfrac{a^2b}{2c}\\times\\dfrac{ac^2}{2b}\\div\\dfrac{b^2c}{2a}\\) \\(\\dfrac{8x^{-3}\\times 3x^2}{6x^{-4}}\\) \\(\\dfrac{3x}{3x^2+6x}\\) Answers: \\[ \\frac{p}{q^3} \\times \\frac{q}{p^3} = \\frac{pq}{q^3 p^3} = \\frac{1}{p^2 q^2} \\] We first multiply the first two fractions, then we divide the outcome by the third \\[\\begin{align*} \\left(\\frac{a^2 b}{2c} \\times \\frac{ac^2}{2b}\\right)\\div \\frac{b^2c}{2a} &amp;= \\frac{a^3 b c^2}{4cb}\\div \\frac{b^2 c}{2a}\\\\ &amp;= \\frac{a^3 b c^2}{4cb}\\times \\frac{2a}{b^2c}\\\\ &amp;= \\frac{2a^4 b c^2}{4b^3 c^2} = \\frac{a^4}{2b^2} \\end{align*}\\] \\[\\begin{align*} \\frac{8x^{-3} \\times 3x^2}{6x^{-4}} &amp;= \\frac{24x^{-3+2}}{6x^{-4}}\\\\ &amp;= 4x^{-1+4}\\\\ &amp;= 4x^3 \\end{align*}\\] \\[ \\frac{3x}{3x^2 + 6x} = \\frac{3x}{3x(x+2)} = \\frac{1}{x+2} \\] Factorise the following expressions. \\(18x^2y-12xy^2\\) \\(x^3+4x^2y-3xy^2-12y^3\\) \\(25x^2-4y^2\\) Answers: We look for the common factors between the two terms, in this case \\(6xy\\) \\[ 18x^2y - 12xy^2 = 6xy(3x-2y) \\] This expression has 4 terms, we divide them into 2 groups each of 2 terms, then factorise these groups and use the difference of two squares to factorise the term with squares \\[\\begin{align*} x^3 + 4x^2y - 3xy^2 - 12y^3 &amp;= x^2(x+4y) - 3y^2(x+4y)\\\\ &amp;= (x+4y)(x^2-3y^2)\\\\ &amp;= (x+4y)(x-\\sqrt{3}y)(x+\\sqrt{3}y) \\end{align*}\\] This is another application of the difference between two squares identity \\(a^2 - b^2 = (a-b)(a+b)\\) \\[ 25x^2 - 4y^2 = (5x+2y)(5x-2y) \\] The characteristic equation of a perfect gas is given by \\(PV = mRT\\) where \\(m\\) is the mass, \\(P\\) is the pressure, \\(V\\) is the volume, \\(T\\) is the temperature and \\(R\\) is the universal gas constant. Make temperature the subject of the formula. Answer: \\[PV = mRT\\] Divide both sides by \\(mR\\), then \\[T = \\frac{PV}{mR}\\] The airflow over a turbine blade causes drag \\(D\\), which is given by \\(D= \\frac{\\rho C v^2 A}{2}\\), where \\(\\rho\\) is fluid density, \\(C\\) is the drag coefficient, \\(v\\) is fluid velocity and \\(A\\) is the frontal area of the blade. Make the frontal area the subject of the formula. Answer: First multiply both sides by 2, then divide both sides of the outcome by \\(\\rho C v^2\\) \\[\\begin{align*} D &amp;= \\frac{\\rho C v^2 A}{2}\\\\ 2D &amp;= \\rho C v^2 A\\\\ A &amp;= \\frac{2D}{\\rho C v^2} \\end{align*}\\] Make \\(b\\) the subject of the following formula. \\[W=\\frac{t\\sqrt{a+b^2}}{2\\pi}\\] Answer: First, multiply both sides by \\(2\\pi\\) and divide both sides by \\(t\\), then square both sides and make \\(b^2\\) the subject \\[\\begin{align*} W &amp;= \\frac{t\\sqrt{a + b^2}}{2\\pi}\\\\ \\frac{2\\pi}{t} &amp;= \\sqrt{a+b^2}\\\\ \\left(\\frac{2\\pi}{t}\\right)^2 &amp;= a + b^2\\\\ b^2 &amp;= \\frac{4\\pi^2}{t^2} - a \\end{align*}\\] Now it is necessary to take the square root of both sides, recalling that there is both a positive and a negative root: \\[ b = \\pm \\sqrt{\\frac{4\\pi^2}{t^2} - a} \\] Often in applications such a quantity may have a physical significance that will force it to be only the positive root or only the negative root, for example if the quantity \\(b\\) represented a length then we would take the positive solution. "],["exercise-set-2.html", "Exercise Set 2", " Exercise Set 2 These exercises cover the topics of Functions and Graphs. Sketch the graphs of the following functions on the interval \\(-2\\le x \\le 2\\). \\(y=-\\frac{1}{2}(x+1)\\) \\(y=x^2+2\\) \\(y=-2x^2+2\\) \\(y=x^2-x-1\\) \\(y=3^x\\) \\(y=\\frac{1}{x}\\) Tips: find where the functions cross the axes; use completing the square to find the maximum or minimum of quadratics; identify any asymptotes. Sketch the following graphs (with \\(x\\) in radians): \\(y=\\sin(x)\\) \\(y=\\sin(x+\\frac{\\pi}{2})\\) (does this look familiar?) \\(y=\\sin(2x)\\) \\(y=\\sin^2(x)\\) If we had the graph of a function \\(f(x)\\), describe what would change qualitatively for the graph of \\(f(a\\times x)\\) where \\(a\\) is a constant. Consider the cases: \\(a&gt;1\\) \\(0 &lt; a &lt; 1\\) \\(-1 &lt; a &lt; 0\\) \\(a&lt;-1\\) If we had the graph of a function \\(f(x)\\), describe what would change qualitatively for the graph of \\(f(x+b)\\) where \\(b\\) is a constant. Consider the cases: \\(b&gt;0\\) \\(b&lt;0\\) If we had the graph of a function \\(f(x)\\), describe what would change qualitatively for the graph of \\(f(x)+c\\) where \\(c\\) is a constant. Consider the cases: \\(c&gt;0\\) \\(c&lt;0\\) "],["exercise-set-2-answers.html", "Exercise Set 2 Answers", " Exercise Set 2 Answers These exercises cover the topics of Functions and Graphs. Sketch the graphs of the following functions on the interval \\(-2\\le x \\le 2\\). \\(y=-\\frac{1}{2}(x+1)\\) \\(y=x^2+2\\) \\(y=-2x^2+2\\) \\(y=x^2-x-1\\) \\(y=3^x\\) \\(y=\\frac{1}{x}\\) Tips: find where the functions cross the axes; use completing the square to find the maximum or minimum of quadratics; identify any asymptotes. Answers: Expanding: \\(y=-\\frac{1}{2}x-\\frac{1}{2}\\) which we recognise as a line with gradient \\(-\\frac{1}{2}\\) and y intercept \\(-\\frac{1}{2}\\). Solving for \\(y=0\\) gives the x intercept as \\((-1,0)\\). This is a parabola shifted up by 2 units. This is an “upside down” parabola, shifted up by two units. Completing the square \\(y=(x-\\frac{1}{2})^2-\\frac{5}{4}\\). Since the squared term is always non-negative, it is smallest when it is zero at \\(x=\\frac{1}{2}\\). This is the position of the minimum, and at this point \\(y=-\\frac{5}{4}\\). Factorising: \\((x-\\frac{1+\\sqrt{5}}{2})(x-\\frac{1-\\sqrt{5}}{2})\\), so the curve crosses the x axis at \\(x=\\frac{1+\\sqrt{5}}{2}\\) and \\(x=\\frac{1-\\sqrt{5}}{2}\\). Since the coefficient of \\(x^2\\) is positive, the parabola opens upwards. This is an exponential \\(a^x\\) with \\(a&gt;1\\). All exponential functions cross the y axis at \\(a^0=1\\) and the do not cross the \\(x\\) axis. This is a rational function with a vertical asymptote at \\(x=0\\). It is small and positive for large positive values of \\(x\\) and it is small and negative for large negative values of \\(x\\): the line \\(y=0\\) is a horizontal asymptote. Sketch the following graphs (with \\(x\\) in radians): \\(y=\\sin(x)\\) \\(y=\\sin(x+\\frac{\\pi}{2})\\) (does this look familiar?) \\(y=\\sin(2x)\\) \\(y=\\sin^2(x)\\) Answers: You should be familiar with this graph and the location of maxima, minima and axis intercepts. Note that \\(\\sin(x+\\frac{\\pi}{2})=\\cos(x)\\). This is double the angular frequency of the usual sine function. Note that all the y values are non-negative. If we had the graph of a function \\(f(x)\\), describe what would change qualitatively for the graph of \\(f(a\\times x)\\) where \\(a\\) is a constant. Consider the cases: \\(a&gt;1\\) \\(0 &lt; a &lt; 1\\) \\(-1 &lt; a &lt; 0\\) \\(a&lt;-1\\) Answers: For \\(a&gt;1\\), the graph is “squeezed” along the x axis, with the value at \\(x=0\\) remaining unchanged. For \\(0 &lt; a &lt;1\\), the graph is expanded along the x axis, again with the value at \\(x=0\\) unchanged. For \\(-1 &lt; a &lt;0\\), the graph is again expanded, along the x axis, but the minus sign in \\(a\\) also means that the graph is reflected in the y axis. For \\(a&lt;-1\\), the graph is squeezed horizontally and reflected in the y axis. If we had the graph of a function \\(f(x)\\), describe what would change qualitatively for the graph of \\(f(x+b)\\) where \\(b\\) is a constant. Consider the cases: \\(b&gt;0\\) \\(b&lt;0\\) Answers: For \\(b&gt;0\\), the \\(f(x+b)\\) is the graph of \\(f(x)\\) translated to the left by distance \\(b\\) For \\(b&lt;0\\), the whole graph is translated to the right by distance \\(b\\) If we had the graph of a function \\(f(x)\\), describe what would change qualitatively for the graph of \\(f(x)+c\\) where \\(c\\) is a constant. Consider the cases: \\(c&gt;0\\) \\(c&lt;0\\) Answers: For \\(c&gt;0\\), \\(f(x)+c\\) is the graph of \\(f(x)\\) shifted vertically up along the y axis For \\(c&lt;0\\), \\(f(x)+c\\) is the graph of \\(f(x)\\) shifted vertically down along the y axis "],["exercise-set-3.html", "Exercise Set 3", " Exercise Set 3 Solve the following quadratic equations by factorisation. \\(x^2+10x+25\\) \\(x^2-28x-60=0\\) \\(p^2=8p-15\\) \\(3x^2-14x+8=0\\) Solve the following quadratic equations, giving results correct to 2 d.p. \\(4x^2+x-3=0\\) \\(x^2+x=5\\) \\(x+\\frac{1}{x}=5\\) Solve the following sets of simultaneous equations. \\(3x+4y=7\\), \\(5x+6y=11\\) \\(2x+y=7\\), \\(x^2-xy=6\\) \\(x + y=2\\), \\(x^2-xy+y^2 = 1\\) Show that the following hyperbolic identity holds: \\[\\cosh^2(x)-\\sinh^2(x)=1\\] (you will first need to find the definitions of \\(\\cosh\\) and \\(\\sinh\\) in terms of \\(e\\) - these are in the lecture notes, or use Google). Use natural logarthims to make \\(t\\) the subject of the formula \\[V=1-e^{\\frac{-t}{RC}}.\\] Find the solutions to the following equations without using a calculator. \\(x=\\log_4(64)\\) \\(x=\\log_{101}(101)\\) \\(x=\\ln(e)\\) \\(x=\\log_{56}(1)\\) \\(10^x=100000\\) \\(2^x=128\\) \\(\\log_3(x)=4\\) \\(\\log_x(125)=3\\) Calculate the following logarithms using a calculator. \\(\\ln(2)\\) \\(\\log(20)\\) \\(\\log_{16}(100)\\) - do this using your \\(\\log_a(x)\\) button and also using the change of base rule with your \\(\\log\\) or \\(\\ln\\) button. Calculate \\(4321\\times 9876\\) using logs: convert both values to logs, add, then convert back. Simplify the following expression involving logarithms. \\[\\log_a(x^2)+3\\log_a(x)-2\\log_a(4x^2).\\] Solve the following for \\(x\\). \\[2\\log_a(x)-\\log_a(x-1)=\\log_a(x+3).\\] Solve the following for \\(x\\). \\[\\log_a(x^2-10)-\\log_a(x)=2\\log_a(3).\\] Bacteria are undergoing cell division every 30 minutes. Approximating the number of bacteria as a continuous variable \\(x\\), if there are initially 5 bacteria, write an equation for the number of bacteria \\(x\\) at time \\(t\\) in the form \\[x=A2^{kt}\\] where \\(t\\) is measured in minutes. Also express this in the form \\[x=Ae^{\\lambda t}\\] by finding the appropriate value of \\(\\lambda\\). A quantity \\(x\\) is increasing exponentially with respect to time \\(t\\). We have the measurements \\(x=21\\) at \\(t=0\\) and \\(x=156\\) at \\(t=10\\). Find an equation for \\(x\\) in the form \\(x=Ae^{kt}\\). The number of specimens of an invasive plant species is observed to be increasing at a particular location. The number of plants observed last year was \\(N=52\\) and this year is \\(N=76\\). We shall approximate the number of plants as a continuous variable \\(x\\). Assuming continuous exponential growth \\(x=Ae^{\\lambda t}\\), find the growth rate \\(\\lambda\\). Approxiately how many plants are predicted by this model after 10 years from now? Solve the following inequalities. \\(7-3x&gt;x-5\\) \\(x^2\\ge 4\\) \\(x^2-x-6&lt;0\\) \\(x^2-3x-12\\le 2x+2\\) \\(\\frac{2}{2x-1} &gt; \\frac{3}{3x+1}\\) \\(\\frac{2x}{x-5}\\le 3\\) \\(x^3-9x^2&lt;0\\) "],["exercise-set-3-answers.html", "Exercise Set 3 Answers", " Exercise Set 3 Answers Solve the following quadratic equations by factorisation. \\(x^2-28x-60=0\\) \\(p^2=8p-15\\) \\(3x^2-14x+8\\) \\(x^2+10x+25\\) Answers: We are looking for two factors of 25 with summation equal to 10. Thus, these factors are 5 and 5 \\[ x^2 + 10x + 25 = (x+5)(x+5) = (x+5)^2 \\] So there is a single solution \\(x=-5\\). Factorise by inspection into the form \\((x+)(x+b)\\) where \\(ab = -60\\) and \\(a + b = -28\\) \\[\\begin{align*} x^2-28x-60 &amp;= 0\\\\ (x-30)(x+2) &amp; = 0\\\\ \\Rightarrow x=30, -2 \\end{align*}\\] First, put into quadratic form \\(ax^2 + bx + c = 0\\) and then factorise by inspection \\[\\begin{align*} p^2 = 8p - 18\\\\ p^2 - 8p + 15 &amp;= 0\\\\ (p-3)(p-5) &amp;= 0\\\\ \\Rightarrow p = 3,5 \\end{align*}\\] We are looking for two factors of \\(3\\times 8 = 24\\) with summation equals to -14. These factors are \\(-12\\) and \\(-2\\) \\[\\begin{align*} 3x^2 - 14x + 8 &amp;= 3x^2 - 12x - 2x + 8\\\\ &amp;= 3x(x-4) - 2(x-4) = (x-4)(3x-2) \\end{align*}\\] Solve the following quadratic equations, giving results correct to 2 d.p. \\(4x^2+x-3=0\\) \\(x^2+x=5\\) \\(x+\\frac{1}{x}=5\\) Answers: These questions require the application of the quadratic formula: for a quadratic which can be put into the form \\(ax^2 + bx + c = 0\\), \\[ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} \\] \\(4x^2 + x - 3\\) \\[ x = \\frac{-1 \\pm \\sqrt{1^2 - 4\\times 4 \\times (-3)}}{8}\\\\ x = 3.38, -3.63 \\] First, rearrange \\(x^2 + x = 5\\) as \\(x^2 + x - 5 =0\\), then apply the quadratic formula \\[ x = \\frac{-1 \\pm \\sqrt{1^2 - 4\\times 1 \\times (-5)}}{2}\\\\ x = 1.79, -2.79 \\] First, rearrange \\(x + \\frac{1}{x} = 5\\) into \\(x^2 + 1 - 5 = 0\\) and then apply the quadratic formula. \\[ x = \\frac{5 \\pm \\sqrt{(-5)^2 - 4\\times 1 \\times 1}}{2}\\\\ x = 4.79, 0.21 \\] Solve the following sets of simultaneous equations. \\(3x+4y=7\\), \\(5x+6y=11\\) \\(2x+y=7\\), \\(x^2-xy=6\\) \\(x + y=2\\), \\(x^2-xy+y^2 = 1\\) Answers: Because these simultaneous equations are linear in \\(x\\) and \\(y\\), they can be solved by multiplying the equations and adding or subtracting them to cancel one of \\(x\\) or \\(y\\). Here, they can be solved by multiplying the left equation by 5 and the right equation by 3, then subtracting to cancel the \\(x\\) term: \\[ 3x+4y = 7,\\quad 5x + 6y = 11\\\\ 15 x + 20y = 35,\\quad 15x + 18y = 33\\\\ \\text{subtracting the right equaltion from the left:}\\\\ 2y = 2 \\Rightarrow y=1,x=1 \\] This could also have been solved via direct substitution (e.g., \\(x = (7-4y)/3\\)). \\[ 2x + y = 7,\\quad x^2 - xy = 6\\\\ \\Rightarrow y=7-2x \\. \\text{substitute into right hand equation}\\\\ x^2 - x(7-2x) = 6\\\\ x^2 - 7x + 2x^2 = 6\\\\ 3x^2 - 7x - 6 = 0 \\] which can now be factorised by inspection to obtain the two solutions for \\(x\\) \\[ (3x+2)(x-3) = 0\\\\ \\Rightarrow x = -\\frac{2}{3},x = 3 \\] The value for \\(y\\) must be calculated for both cases of \\(x\\). It is simplest to use \\(y = 7 - 2x\\). The solutions are: \\[ x = -\\frac{2}{3},y=\\frac{25}{3},\\quad\\text{and }\\, x = 3, y = 1 \\] As before, substitute one of \\(x\\) or \\(y\\) using the linear equation \\[ x+y = 2, \\quad x^2 - xy + y^2 = 1\\\\ \\Rightarrow x = 2-y,\\quad (2-y)^2 - (2-y)y + y^2 = 1\\\\ 4 - 4y^2 + y^2 - 2y + y^2 + y^2 = 1\\\\ y^2 + 2y - 3 = 0\\\\ (y+3)(y-1) = 0\\\\ y=1, -3 \\] and again, we must give \\(x\\) for both cases. The two solutions are \\[ x=1,y=1\\quad\\text{and }x =5,y=-3 \\] Show that the following hyperbolic identity holds: \\[\\cosh^2(x)-\\sinh^2(x)=1.\\] Answer: Use the definitions of \\(\\cosh(x) = \\frac{e^x + e^-x}{2}\\) and \\(\\sinh(x) = \\frac{e^x - e^{-x}}{2}\\) \\[ \\begin{align} \\cosh^2(x) - \\sinh^2(x) &amp;=(\\cosh(x) + \\sinh{x})(\\cosh(x) - \\sinh(x))\\\\ &amp;=\\left(\\frac{e^x + e^{-x} + e^x - e^{-x}}{2}\\right)\\left(\\frac{e^x + e^{-x} - e^x + e^{-x}}{2}\\right)\\\\ &amp;=e^x e^{-x}\\\\ &amp;= 1 \\text{ as required} \\end{align} \\] Use natural logarthims to make \\(t\\) the subject of the formula \\[V=1-e^{\\frac{-t}{RC}}.\\] Answer: Make the exponential term the subject and then take the natural logarithms of both sides \\[ \\begin{align} V &amp;= 1- e^{\\frac{-t}{RC}}\\\\ e^{\\frac{-t}{RC}} &amp;= 1- v\\\\ \\ln\\left(e^{\\frac{-t}{RC}}\\right) &amp;= \\ln(1- v)\\\\ \\frac{-t}{RC} &amp;= \\ln(1-v)\\\\ t &amp;= -RC\\ln(1-v) \\end{align} \\] Find the solutions to the following equations without using a calculator. \\(x=\\log_4(64)\\) \\(x=\\log_{101}(101)\\) \\(x=\\ln(e)\\) \\(x=\\log_{56}(1)\\) \\(10^x=100000\\) \\(2^x=128\\) \\(\\log_3(x)=4\\) \\(\\log_x(125)=3\\) Answers: \\(x = \\log_4(64) = \\log_4(4^3)=3\\) \\(x = \\log_{101}(101) =\\log_{101}(101^1)=1\\) \\(x = \\ln(e) =\\log_e(e^1)= 1\\) \\(x = log_{56}(1) =\\log_{56}(56^0)=0\\) \\(10^x = 100000=10^5 \\Rightarrow x = 5\\) \\(2^x = 128=2^7\\) x = 7$ the powers of 2 are useful to know \\(3^{\\log_3(x)} = 3^4 \\Rightarrow x = 3^4 = 3^2 \\times 3^2 = 81\\) \\(\\log_x(125) = 3 \\Rightarrow x^3 = 125 \\Rightarrow x = 5\\) Calculate the following logarithms using a calculator. \\(\\ln(2)\\) \\(\\log(20)\\) \\(\\log_{16}(100)\\) - do this using your \\(\\log_a(x)\\) button and also using the change of base rule with your \\(\\log\\) or \\(\\ln\\) button. Answers: To 2 d.p. \\(\\ln(2) = 0.69\\) \\(\\log(20) = 1.30\\) \\(\\log_{16}(100) = 1.66\\) or using the change of base rule with \\(\\log_{10}\\), \\(\\log_{16}=\\frac{\\log_{10}(100)}{\\log_{10}(16)}=\\frac{2}{\\log_{10}(16)}=1.66\\) Calculate \\(4321\\times 9876\\) using logs: convert both values to logs, add, then convert back. Answer: \\[\\log(4321 \\times 9876)=\\log(4321) + \\log(9876) = 7.630165..., \\text{ the product rule of logarithms}\\\\ 4321 \\times 9876=10^{7.630165...} = 42674196 \\] Simplify the following expression involving logarithms. \\[\\log_a(x^2)+3\\log_a(x)-2\\log_a(4x^2).\\] Answer: Applying the various log rules, starting with the power rules then product and quotient rules: \\[ \\begin{aligned} &amp; \\log_a(x^2)+3\\log_a(x)-2\\log_a(4x^2)\\\\ &amp;= \\log_a(x^2) + \\log_a(x^3) - log_a(16x^4)\\\\ &amp;= \\log_a(\\frac{x^5}{16x^4})\\\\ &amp;= \\log_a(\\frac{x}{16}) \\end{aligned} \\] Solve the following for \\(x\\). \\[2\\log_a(x)-\\log_a(x-1)=\\log_a(x+3).\\] Answer: \\[ \\begin{aligned} 2 \\log_a(x) - \\log_a(x-1) &amp;= \\log_a(x+3)\\\\ \\log_a\\left(\\frac{x^2}{x-1}\\right) &amp;= \\log_a(x+3)\\\\ \\log_a\\left(\\frac{x^2}{(x-1)(x+3)}\\right) &amp;= 0, \\text{ since } \\log_a(1) = 0\\\\ \\frac{x^2}{(x-1)(x+3)} &amp;= 1\\\\ x^2 &amp;= (x-1)(x+3) = x^2 + 2x - 3\\\\ x &amp;= \\frac{3}{2} \\end{aligned} \\] Solve the following for \\(x\\). \\[\\log_a(x^2-10)-\\log_a(x)=2\\log_a(3).\\] Answer: \\[ \\begin{align} \\log_a(x^2-10)-\\log_a(x)&amp;=2\\log_a(3)\\\\ \\log_a(x^2-10) &amp;= \\log_a(x) + \\log_a(3^2)\\\\ \\log_a(x^2-10) &amp;= \\log_a(9x)\\\\ x^2-10&amp;=9x\\\\ x^2-9x-10&amp;=0\\\\ (x+1)(x-10)&amp;=0\\\\ \\end{align} \\] Hence \\(x=-1\\) or \\(x=10\\). Bacteria are undergoing cell division every 30 minutes. Approximating the number of bacteria as a continuous variable \\(x\\), if there are initially 5 bacteria, write an equation for the number of bacteria \\(x\\) at time \\(t\\) in the form \\[x=A2^{kt}\\] where \\(t\\) is measured in minutes. Also express this in the form \\[x=Ae^{\\lambda t}\\] by finding the appropriate value of \\(\\lambda\\). Answers: Since \\(t\\) is in minutes and the bacteria double every 30 mins, we have \\[x=A2^{\\frac{1}{30}t}.\\] At the initial time \\(t=0\\) \\[x=A2^{\\frac{1}{30}\\times 0}=A2^0=A\\times 1=A\\] hence \\(A=5\\) and we have \\[x=5\\times2^{\\frac{1}{30}t}.\\] We can write \\(2^{\\frac{1}{30}t}=(2^{\\frac{1}{30}})^t\\) and hence \\(\\lambda=\\ln(2^{\\frac{1}{30}})=\\frac{\\ln(2)}{30}\\). Then \\[x=5e^{\\frac{\\ln(2)}{30}t}.\\] A quantity \\(x\\) is increasing exponentially with respect to time \\(t\\). We have the measurements \\(x=21\\) at \\(t=0\\) and \\(x=156\\) at \\(t=10\\). Find an equation for \\(x\\) in the form \\(x=Ae^{kt}\\). Answers: At \\(t=0\\) \\[x=Ae^{k\\times0}=A\\times 1=21\\] so \\(A=21\\). At \\(t=10\\) \\[x=21e^{k\\times 10}=156.\\] Taking natural logs \\[\\ln(21e^{10k})=\\ln(21)+10k=\\ln(156)\\] hence \\[k=\\frac{1}{10}\\left(\\ln(\\frac{156}{21})\\right)=0.20 (2 d.p.)\\]. Then \\[x=21e^{0.2t}.\\] The number of specimens of an invasive plant species is observed to be increasing at a particular location. The number of plants observed last year was \\(N=52\\) and this year is \\(N=76\\). We shall approximate the number of plants as a continuous variable \\(x\\). Assuming continuous exponential growth \\(x=Ae^{\\lambda t}\\), find the growth rate \\(\\lambda\\). Approxiately how many plants are predicted by this model after 10 years from now? Answer: We can take last year as the starting time \\(t=0\\), so that \\(x=Ae^{\\lambda\\times 0}=A=52\\). Then taking time in units of years, we have \\[x=52e^{\\lambda\\times 1}=76.\\] Taking natural logs of both sides, \\[\\ln(52)+\\lambda=\\ln(76)\\] Hence \\[\\lambda = \\ln\\left(\\frac{76}{52}\\right)=0.38 (2 d.p.)\\] 10 years from now corresponds to \\(t=11\\), so we have \\[x=52e^{0.38\\times 11}\\approx 3380 \\text{ plants}.\\] Solve the following inequalities. \\(7-3x&gt;x-5\\) \\(x^2\\ge 4\\) \\(x^2-x-6&lt;0\\) \\(x^2-3x-12\\le 2x+2\\) \\(\\frac{2}{2x-1} &gt; \\frac{3}{3x+1}\\) \\(\\frac{2x}{x-5}\\le 3\\) \\(x^3-9x^2&lt;0\\) Answers: \\[\\begin{align*} 7-3x &amp;&gt; x-5\\\\ 13 &amp;&gt; 4x\\\\ x &amp;&lt; \\frac{13}{4} \\end{align*}\\] Here, we must include both the positive and the negative solution to the square root: \\[\\begin{align*} x^2 &amp;\\geq 4\\\\ \\pm x &amp;\\geq 2\\\\ x\\geq 2 &amp; x\\leq -2 \\end{align*}\\] It is often worth sketching the graph and examining the inequality to determine where the inequality is satisfied. \\[ x^2 - x - 6 &lt; 0 \\\\ (x+2)(x-3) &lt; 0 \\] The graph of \\(x^2\\) will form a \\(\\cup\\) shape, so the parts below the axis are between the crossing points of \\(x = -2\\) and \\(x=3\\). So the inequality is satisfied for \\[ -2&lt;x&lt;3 \\] Note the use of strict inequalities \\(x&lt;3\\) and \\(x&gt;-2\\) because the inequality is \\(&lt;0\\) (as opposed to \\(\\leq\\)). Group terms to form a quadratic, find the solutions and determine whether the interval between them or outside of them satisfied the inequality: \\[\\begin{align*} x ^2 - 3x - 12 &amp;\\leq 2x + 2\\\\ x^2 - 5x - 14 &amp;\\leq 0\\\\ (x-7)(x+2)&amp;\\leq 0 \\end{align*}\\] And the part of the curve below the axis is the range \\(-2\\leq x \\leq 7\\) Do not multiply through by a variable, since at times the term will be negative and necessitate a flip of the inequality. Instead, subtract one side from both sides: \\[\\begin{align*} \\frac{2}{2x-1} &amp;&gt; \\frac{3}{3x+1}\\\\ \\frac{2}{2x-2} - \\frac{3}{3x+1} &amp;&gt; 0\\\\ \\frac{2(3x+1) - 3(2x-1)}{(2x-1)(3x+1)} &amp;&gt; 0\\\\ \\frac{5}{(2x-1)(3x+1)} &amp;&gt; 0 \\end{align*}\\] In order for the inequality to hold, either both terms in the denominator are positive or both are negative. \\[ \\text{positve case: }2x-1&gt;0,\\quad 3x+1 &gt; 0\\\\ x &gt; \\frac{1}{2} \\text{ and } x &gt; \\frac{1}{3}\\\\ x &gt; \\frac{1}{2}\\\\ \\text{negative case: }2x-2 &lt; 0, \\quad 3x+1 &lt; 0\\\\ x&lt;\\frac{1}{2} \\text{ and } x &lt; \\frac{1}{3}\\\\ x &lt; \\frac{1}{3} \\] So the final solution is \\(x &gt; \\frac{1}{2}\\) and \\(x &lt; \\frac{1}{3}\\). \\[\\begin{align*} \\frac{2x}{x-5} &amp;\\leq 3 \\\\ \\frac{2x}{x-5} - 3 &amp;\\leq 0\\\\ \\frac{2x - 3(x-5)}{x-5} &amp; \\leq 0\\\\ \\frac{15-x}{x-5}&amp;\\leq 0 \\end{align*}\\] Which will ony old if one of the numerator or denominator is negative. So the inequality is solved by \\(x\\geq 15\\) and \\(x\\leq 5\\). Here, a cubic is presented, but a factor of \\(x^2\\) can be taken out \\[\\begin{align*} x^3 - 9x^2 &amp;&lt; 0 \\\\ x^2(x-9) &amp;&lt; 0\\\\ \\end{align*}\\] The \\(x^2\\) factor is always positive, so the whole inequality holds when \\(x-9\\) is negative. Hence, \\(x&lt;9\\) "],["exercise-set-4.html", "Exercise Set 4", " Exercise Set 4 These exercises cover the topic of Trigonometry. Tip: always start by drawing a labelled diagram in trigonometry questions. Consider the smaller of the two angles between the hour hand and minute hand of a clock. Write the angles at the following times in both degrees and radians (in terms of \\(\\pi\\)). 6:00 3:00 4:00 4:30 6:45 Convert the following angles from degrees to radians (leave your answer in terms of \\(\\pi\\) where possible, or to 2 d.p.). \\(330^\\circ\\) \\(22.5^\\circ\\) \\(27^\\circ\\) \\(35^\\circ\\) A bearing is the angle measured clockwise from North to the direction of interest. A point \\(K\\) is 12km due west of a second point \\(L\\) and 25km due south of a third point \\(M\\). Calculate the bearing of \\(L\\) from \\(M\\). Solve (i.e. find all unkown angles and side lengths) the triangle \\(ABC\\) where \\(A = 53^\\circ\\), \\(B = 61^\\circ\\) and \\(a = 12.6\\)cm. Let \\(AOB\\) be a triangle. \\(OA = 60\\)mm, \\(AB = 180\\)mm and \\(OB = 200\\)mm. Find angle \\(A\\). An angle of elevation is an angle that an imaginary straight line must be raised from the horizontal ground to line up with a point of interest above the ground. An observer is standing at a point \\(M\\) which is \\(30\\)m from the base of a tower. On top of the tower is a vertical mast. If the angles of elevation of the top of the tower and the top of the mast from \\(M\\) are \\(40^\\circ\\) and \\(50^\\circ\\) respectively, calculate the height of the mast. The small hand of a clock is 75% the length of the long hand. Calculate the distance between the ends of the hands at 5 o’clock. A student \\(1.8\\)m tall is standing \\(24\\)m away from a tree and using a eye level instrument to measure the angle of elevation. The angle measured to the top of the tree is \\(12^\\circ 34&#39;\\), calculate the height of the tree. (Degrees can be further subdivided in to minutes denoted \\(x&#39;\\) and seconds denoted \\(x&#39;&#39;\\), with \\(1&#39;\\) being \\(1/60\\) of a degree and \\(1&#39;&#39;\\) being \\(1/60\\) of a minute. To use a calculator you will first need to convert minutes and seconds to decimals.) The angles of elevation of a navigation balloon that is flying in between two points on the ground \\(A\\) and \\(B\\) are \\(48^\\circ\\) and \\(62^\\circ\\) respectively. If \\(A\\) and \\(B\\) are \\(0.3\\)km apart, calculate the height of the balloon. The figure below shows a tetrahedron with an equilateral triangle of side 2m forming the base and isosceles triangles of equal side 3m forming the slanting faces. Calculate: The height of the tetrahedron \\(ND\\); The angle that edge \\(DA\\) makes with the plane \\(ABC\\); The angle between the planes \\(ACD\\) and \\(ACB\\). Write the following in the form \\(R\\cos(\\omega t\\pm \\beta)\\). \\(-2\\sin(\\omega t) + 5\\cos(\\omega t)\\) \\(-5\\cos(\\omega t) + 5 \\sin(\\omega t)\\) In a spring-mass system the motion of the mass is described by \\[x=A\\cos(\\omega t)+B\\sin(\\omega t)\\] where \\(x\\) is the distance of the mass from its equilibrium position, \\(\\omega\\) is the natural frequency of oscillations, and \\(A\\) and \\(B\\) are constants. For \\(A=\\sqrt{3}\\), \\(B=1\\) and \\(\\omega=10\\): Write \\(x\\) in the form \\(R\\cos(\\omega t-\\beta)\\) and state the amplitude of \\(x\\). Sketch one complete cycle of \\(x\\). "],["exercise-set-4-answers.html", "Exercise Set 4 Answers", " Exercise Set 4 Answers These exercises cover the topic of Trigonometry. Tip: always start by drawing a labelled diagram in trigonometry questions. Consider the smaller of the two angles between the hour hand and minute hand of a clock. Write the angles at the following times in both degrees and radians (in terms of \\(\\pi\\)). 6:00 3:00 4:00 4:30 6:45 Answers: \\(180^\\circ\\), \\(\\pi\\text{ rad}\\) \\(90^\\circ\\), \\(\\frac{\\pi}{2}\\text{ rad}\\) \\(60^\\circ\\), \\(\\frac{2\\pi}{3}\\text{ rad}\\) \\(45^\\circ\\), \\(\\frac{\\pi}{4}\\text{ rad}\\) \\(67.5^\\circ\\), \\(\\frac{3\\pi}{8}\\text{ rad}\\) Convert the following angles from degrees to radians (leave your answer in terms of \\(\\pi\\) where possible, or to 2 d.p.). \\(330^\\circ\\) \\(22.5^\\circ\\) \\(27^\\circ\\) \\(35^\\circ\\) Answers: \\(\\frac{11}{6}\\pi\\text{ rad}\\) \\(\\frac{\\pi}{8}\\text{ rad}\\) \\(\\frac{3}{20}\\pi\\text{ rad}\\) or \\(0.47\\text{ rad}\\) \\(\\frac{7}{36}\\pi\\text{ rad}\\) or \\(0.61\\text{ rad}\\) A bearing is the angle measured clockwise from North to the direction of interest. A point \\(K\\) is 12km due west of a second point \\(L\\) and 25km due south of a third point \\(M\\). Calculate the bearing of \\(L\\) from \\(M\\). Answers: Drawing a right angled triangle \\(MKL\\) the angle \\(\\angle KML\\) is \\[\\tan(\\angle KML)=\\frac{12}{25}\\quad\\implies\\quad \\angle KML=\\tan^{-1}\\frac{12}{25}=25.6^\\circ\\] The bearing of \\(L\\) from \\(M\\) is the angle clockwise from a line pointing North from \\(M\\), so the bearing is: \\[180^\\circ -25.6^\\circ=154.4^\\circ.\\] Solve (i.e. find all unkown angles and side lengths) the triangle \\(ABC\\) where \\(A = 53^\\circ\\), \\(B = 61^\\circ\\) and \\(a = 12.6\\)cm. Answers: We first find angle \\(C\\): \\[C=180^\\circ-61^\\circ-53^\\circ=66^\\circ.\\] Now using the sine rule: \\[b=\\frac{a}{\\sin(A)}\\sin(B)=\\frac{12.6}{\\sin(53^\\circ)}\\sin(61^\\circ)=13.8\\text{ cm}\\] and \\[c=\\frac{a}{\\sin(A)}\\sin(C)=\\frac{12.6}{\\sin(66^\\circ)}\\sin(53^\\circ)=14.4\\text{ cm}.\\] Let \\(AOB\\) be a triangle. \\(OA = 60\\)mm, \\(AB = 180\\)mm and \\(OB = 200\\)mm. Find angle \\(A\\). Answers: Using the cosine rule: \\[\\begin{align*}\\cos(A)&amp;=\\frac{b^2+c^2-a^2}{2bc}\\\\ &amp;=\\frac{60^2+180^2-200^2}{2\\times 60\\times 180}\\\\ &amp;=-0.185 \\end{align*}\\] which gives \\[A=\\cos^{-1}(-0.185)=101^\\circ.\\] An angle of elevation is an angle that an imaginary straight line must be raised from the horizontal ground to line up with a point of interest above the ground. An observer is standing at a point \\(O\\) which is \\(30\\)m from the base of a tower. On top of the tower is a vertical mast. If the angles of elevation of the top of the tower and the top of the mast from \\(M\\) are \\(40^\\circ\\) and \\(50^\\circ\\) respectively, calculate the height of the mast. Answers: Let the base of the tower be point \\(B\\), the top of the tower point \\(T\\) and the top of the mast point \\(M\\). Then there are two right-angled triangles: \\(OBT\\) and \\(OBM\\). We have \\(OB=30\\)m, angle \\(\\angle BOT=40^\\circ\\) and angle \\(\\angle BOM=50^\\circ\\). We need to calculate \\(TM\\). Using trig. ratios: \\[BT=OB\\tan(\\angle BOT)=30\\tan^{-1}(40^\\circ)=25.2\\text{ m}\\] \\[BM=OB\\tan(\\angle BOM)=30\\tan^{-1}(50^\\circ)=35.8\\text{ m}\\] and hence \\[TM=OM-OT=35.8-25.2=10.6\\text{ m}.\\] The small hand of a clock is 75% the length of the long hand. Calculate the distance between the ends of the hands at 5 o’clock. Answers: Let the distance between the ends of the hands be \\(d\\) and the length of the long hand \\(x\\). Then the length of the short hand is \\(0.75x\\). The angle at 5 o’clock is \\(150^\\circ\\). Using the cosine rule: \\[d^2=(0.75x)^2+x^2-1.5x^2\\cos(150^\\circ)=2.86x^2\\] and \\(d=1.69x.\\) A student \\(1.8\\)m tall is standing \\(24\\)m away from a tree and using an eye level instrument to measure the angle of elevation. The angle measured to the top of the tree is \\(12^\\circ 34&#39;\\), calculate the height of the tree. (Degrees can be further subdivided in to minutes denoted \\(x&#39;\\) and seconds denoted \\(x&#39;&#39;\\), with \\(1&#39;\\) being \\(1/60\\) of a degree and \\(1&#39;&#39;\\) being \\(1/60\\) of a minute. To use a calculator you will first need to convert minutes and seconds to decimals.) Answers: Let the student be at position \\(O\\) with eye-level \\(E\\), the base of the tree at position \\(B\\) and the top of the tree at position \\(T\\). Drawing a line parallel to \\(OB\\) from \\(E\\) to the tree, let the intersection point be \\(S\\). We have \\(OE=BS=1.8\\text{ m}\\) (or perhaps more realistically we could use 1.7m for eye-level), \\(OB=ES=24\\text{ m}\\) and \\(\\angle SET=12^\\circ 34&#39;\\). First, we convert the angle to decimal: \\[12^\\circ 34&#39;=12^\\circ + \\frac{34}{60}=12^\\circ + 0.57^\\circ=12.57^\\circ.\\] Now, \\[ST=ES\\tan(\\angle SET)=24\\tan(12.57^\\circ)=5.4\\text{ m}\\] so \\[BT=BS+ST=5.4+1.8=7.2\\text{ m}.\\] The angles of elevation of a navigation balloon that is flying in between two points on the ground \\(A\\) and \\(B\\) are \\(48^\\circ\\) and \\(62^\\circ\\) respectively. If \\(A\\) and \\(B\\) are \\(0.3\\)km apart, calculate the height of the balloon. Answers: Let the ballon be at point \\(C\\), then we have a triangle \\(ABC\\). Angle \\(C\\) is \\(C=180-48-62=70^\\circ\\). We now find the length of \\(BC\\) using the sine rule: \\[BC=\\frac{AB}{\\sin(C)}\\sin(A)=\\frac{0.3}{\\sin(70^\\circ)}\\sin(48^\\circ)=0.237\\text{ km}\\] Now dropping a perpendicular from \\(C\\) to the ground at a point \\(D\\) (on the line \\(AB\\)) we have a right angled triangle \\(BDC\\). Using \\(\\sin(\\theta)=Opp./Hyp.\\) the height is then \\[DC=BC\\sin(C)=0.237\\sin(62^\\circ)=0.21\\text{ km}.\\] The figure below shows a tetrahedron with an equilateral triangle of side 2m forming the base and isosceles triangles of equal side 3m forming the slanting faces. Calculate: The height of the tetrahedron \\(ND\\); The angle that edge \\(DA\\) makes with the plane \\(ABC\\); The angle between the planes \\(ACD\\) and \\(ACB\\). Answers: \\(ABC\\) is an equilateral triangle, so each of its angles are \\(60^\\circ\\). By symmetry, \\(N\\) is in the centre of triangle \\(ABC\\). Therefore \\(\\angle ANB=120^\\circ\\) and \\(\\angle BAN=30^\\circ\\). Using the sine rule: \\[AN=\\frac{2}{\\sin(120^\\circ)}\\sin(30^\\circ)=1.15\\text{ m}.\\] Now using Pythagoras on right-angled triangle \\(AND\\): \\[ND=\\sqrt{AD^2-AN^2}=\\sqrt{3^2-1.15^2}=\\sqrt{7.68}=2.77\\text{ m}\\] This is given by angle \\(\\angle NAD\\), which can be found using \\(\\cos(\\theta)=Adj./Hyp.\\) \\[\\cos(\\angle NAD)=\\frac{1.15}{3}=0.385\\implies \\angle NAD=\\cos^{-1}(0.385)=67.4^\\circ.\\] By similar reasoning to the above, this is left for the reader to verify as being \\(78.2^\\circ\\). Write the following in the form \\(R\\cos(\\omega t\\pm \\beta)\\). \\(-2\\sin(\\omega t) + 5\\cos(\\omega t)\\) \\(-5\\cos(\\omega t) + 5 \\sin(\\omega t)\\) Answers: Using the compound angle identity \\[R\\cos(\\omega t+\\beta)=R(\\cos(\\omega t)\\cos(\\beta)-\\sin(\\omega t)\\sin(\\beta))\\] and comparing the r.h.s. with \\(-2\\sin(\\omega t) + 5\\cos(\\omega t)\\) and equating coefficients of sin and cos, \\[R\\cos(\\beta)=5\\quad\\text{and}\\quad R\\sin(\\beta)=2.\\] Since \\(\\sin(\\theta)\\) and \\(\\cos(\\theta)\\) are both positive only for \\(0^\\circ\\leq\\theta\\leq 90^\\circ\\) (i.e. in the first quadrant) then \\[\\beta=\\tan^{-1}\\left(\\frac{2}{5}\\right)=21.80^\\circ\\quad\\text{or}\\quad 0.38\\text{ rad}.\\] Now using \\[\\cos^2(\\theta)+\\sin^2(\\theta)=1\\] we have \\[R^2cos^2(\\beta)+R^2\\sin(\\beta)=R^2(\\cos^2(\\beta)+\\sin(\\beta))=R^2\\] so \\[R=\\sqrt{5^2+2^2}=\\sqrt{29}.\\] Finally we have \\[-2\\sin(\\omega t) + 5\\cos(\\omega t)=\\sqrt{29}\\cos(\\omega t + 0.38).\\] Using the compound angle identity \\[R\\cos(\\omega t-\\beta)=R(\\cos(\\omega t)\\cos(\\beta)+\\sin(\\omega t)\\sin(\\beta))\\] and comparing the r.h.s. with \\(-5\\cos(\\omega t) + 5\\sin(\\omega t)\\) and equating coefficients of sin and cos, \\[R\\cos(\\beta)=-5\\quad\\text{and}\\quad R\\sin(\\beta)=5.\\] Since \\(\\sin(\\theta)\\) is positive and \\(\\cos(\\theta)\\) is negative only for \\(90^\\circ\\leq\\theta\\leq 180^\\circ\\) (i.e. in the second quadrant) then \\[\\beta=180^\\circ-\\tan^{-1}\\left(\\frac{5}{5}\\right)=135^\\circ\\quad\\text{or}\\quad 2.36\\text{ rad}.\\] Now using \\[\\cos^2(\\theta)+\\sin^2(\\theta)=1\\] we have \\[R^2cos^2(\\beta)+R^2\\sin(\\beta)=R^2(\\cos^2(\\beta)+\\sin(\\beta))=R^2\\] so \\[R=\\sqrt{5^2+5^2}=5\\sqrt{2}.\\] Finally we have \\[-5\\cos(\\omega t) + 5\\sin(\\omega t)=5\\sqrt{2}\\cos(\\omega t + 2.36).\\] In a spring-mass system the motion of the mass is described by \\[x=A\\cos(\\omega t)+B\\sin(\\omega t)\\] where \\(x\\) is the distance of the mass from its equilibrium position, \\(\\omega\\) is the natural frequency of oscillations, and \\(A\\) and \\(B\\) are constants. For \\(A=\\sqrt{3}\\), \\(B=1\\) and \\(\\omega=10\\): Write \\(x\\) in the form \\(R\\cos(\\omega t-\\beta)\\) and state the amplitude of \\(x\\). Sketch one complete cycle of \\(x\\). Answers: Using the compound angle identity \\[R\\cos(\\omega t-\\beta)=R(\\cos(\\omega t)\\cos(\\beta)+\\sin(\\omega t)\\sin(\\beta))\\] and comparing the r.h.s. with \\(\\sqrt{3}\\cos(10 t) + \\sin(10 t)\\) and equating coefficients of sin and cos, \\[R\\cos(\\beta)=\\sqrt{3}\\quad\\text{and}\\quad R\\sin(\\beta)=1.\\] Since \\(\\sin(\\theta)\\) and \\(\\cos(\\theta)\\) are both positive only for \\(0^\\circ\\leq\\theta\\leq 90^\\circ\\) (i.e. in the first quadrant) then \\[\\beta=\\tan^{-1}\\left(\\frac{1}{\\sqrt{3}}\\right)=30\\circ\\quad\\text{or}\\quad \\frac{\\pi}{6}\\text{ rad}.\\] Now using \\[\\cos^2(\\theta)+\\sin^2(\\theta)=1\\] we have \\[R^2cos^2(\\beta)+R^2\\sin(\\beta)=R^2(\\cos^2(\\beta)+\\sin(\\beta))=R^2\\] so \\[R=\\sqrt{\\sqrt{3}^2+1^2}=2\\] Finally we have \\[x(t)=\\sqrt{3}\\cos(10 t) + \\sin(10 t)=2\\cos(10 t -\\frac{\\pi}{6}).\\] From this we can read off the amplitude as \\(R=2\\). The period is \\(T=\\frac{2\\pi}{10}=\\frac{\\pi}{5}\\) and the displacement of the peak at \\(0\\) is \\(\\frac{\\pi/6}{10}=\\frac{\\pi}{60}\\). "],["exercise-set-5.html", "Exercise Set 5", " Exercise Set 5 These exercises cover the topic of Complex Numbers. Let \\(u=2+3i\\) and \\(v=5+8i\\). Determine the following. \\(u+v\\) \\(u-v\\) \\(uv\\) \\(vu\\) \\(\\frac{u}{v}\\) \\(\\frac{v}{u}\\) \\(u^2\\) \\(v^2\\) \\(u^2+v^2\\) State the complex conjugates of the following numbers. Also caclulate their modulus. \\(3-4i\\) \\(2+2i\\) \\(2+15i\\) \\(3i\\) \\(i\\) \\(5\\) Let \\(z=3-i\\). Find \\(z^2+7z+13\\) in Cartesian form. Find the roots of the following quadratic equations. \\(z^2+2z+26=0\\) \\(z^2-2z+3=0\\) \\(3z^2-7z+13=0\\) Express the following complex numbers in polar form and exponential form. \\(1+i\\) \\(-1+i\\) \\(\\sqrt{3}-i\\) \\(z_1=2-3i\\) \\(z_2=3+4i\\) \\(\\frac{z_1-2}{z_2}\\) \\(z_1z_2-\\frac{z_1-z_2}{z_2}\\) \\(w_1=-\\sqrt{2}+\\sqrt{2}i\\) \\(w_2=-\\frac{1}{2}+\\frac{\\sqrt{3}}{2}i\\) \\(w_1w_2\\) \\(\\frac{w_1}{w_2}\\) Express the following complex numbers in Cartesian form. \\(2e^{i\\frac{\\pi}{12}}\\) \\(5e^{i 23^\\circ}\\) \\(2e^{i (-45^\\circ)}\\) Find the following roots and express them in Cartesian form. \\(1^\\frac{1}{3}\\) \\(1^\\frac{1}{4}\\) The cube roots of \\(\\sqrt{2}-\\sqrt{2}i\\) The square roots of \\(3-4i\\) Sketch the following complex numbers in the complex plane. \\(2+3i\\) \\(-1-i\\) \\(-1+i\\) \\(-2i\\) \\(-3\\) What is \\(i^i\\) in Cartesian form? Find all complex numbers \\(z\\) such that \\(\\overline{z}=z^2\\). "],["exercise-set-5-answers.html", "Exercise Set 5 Answers", " Exercise Set 5 Answers Let \\(u=2+3i\\) and \\(v=5+8i\\). Determine the following. \\(u+v\\) \\(u-v\\) \\(uv\\) \\(vu\\) \\(\\frac{u}{v}\\) \\(\\frac{v}{u}\\) \\(u^2\\) \\(v^2\\) \\(u^2+v^2\\) Answers: \\(u+v = (2 + 3i) + (5 + 8i) = (2 + 5) + i(3 + 8) = 7 + 11i\\) \\(u - v = (2+3i) - (5 + 8i) = -3 - 5i\\) \\[uv = (2 + 3i)(5+8i) = (2\\times 5) + i(8\\times 2) + i(3\\times 5) + i^2(2\\times 8)\\\\ = 10 + 16i + 15i + i^2 24\\\\ = 10 + 31i - 24\\\\ = -14 + 31i\\] \\(vu = (5+8i)(2 + 3i) = -14 + 31i\\), the same as \\(uv\\) \\[ \\frac{u}{v} = \\frac{2+3i}{5 + 8i} \\] rationalise the denominator by multiplying numerator and denominator by the complex conjugate of the denominator, \\(\\overline{v}=5-8i\\) \\[ \\frac{2 + 3i}{5+8i} = \\frac{(2+3i)(5-8i)}{(5+8i)(5-8i)} = \\frac{(2+3i)(5-8i)}{5^2 + 8^2} = \\frac{10 - 16i + 15i - 24i^2}{89}\\\\ = \\frac{10-i + 24}{89} = \\frac{34 - i}{89} = \\frac{34}{89} - \\frac{i}{89} = 0.382 - 0.011 i \\] Similarly \\[\\frac{v}{u} = \\frac{34}{13} + \\frac{i}{13} = 2.615 + 0.077 i \\] \\(u^2 = (2 + 3i)^2 = -5 + 12i\\) \\(v^2 = (5 + 8i)^2= -39 + 80i\\) \\(u^2 + v^2 = -44 + 92i\\) State the complex conjugates of the following numbers. Also caclulate their modulus. \\(3-4i\\) \\(2+2i\\) \\(2+15i\\) \\(3i\\) \\(i\\) \\(5\\) Answers: \\(z = 3-4i,\\quad \\bar{z} = 3 + 4i,\\quad |z| = 5\\) \\(z = 2+2i,\\quad \\bar{z} = 2 -2i,\\quad |z| = \\sqrt{8} = 2\\sqrt{2} = 2.83\\) \\(z = 2+ 15i,\\quad \\bar{z} = 2 - 15i,\\quad |z| = \\sqrt{229} = 15.13\\) \\(z=3i, \\quad \\bar{z} = -3i,\\quad |z| = 3\\) \\(z = i, \\quad \\bar{z} = -i,\\quad |z| = 1\\) \\(z = 5, \\quad \\bar{z} = 5,\\quad |z| = 5\\) Let \\(z=3-i\\). Find \\(z^2+7z+13\\) in Cartesian form. Answers: \\(z^2 + 7 z + 13 = 42 - 13 i\\) Find the roots of the following quadratic equations. \\(z^2+2z+26=0\\) \\(z^2-2z+3=0\\) \\(3z^2-7z+13=0\\) Answers: Using the quadratic formula: \\(z_1=-1-5i\\), \\(z_2=-1+5i\\) \\(z_1 = 1 - i \\sqrt{2}\\), \\(z_2 = 1 + i \\sqrt{2}\\) \\(z_1 = 7/6 - \\frac{i \\sqrt{107}}{6}\\), \\(z_2 = 7/6 - \\frac{i \\sqrt{107}}{6}\\) Note that in all cases, \\(z_1=\\overline{z}_2\\). This is not a coincidence! Extra exercise: show that if \\(z_1\\) is a root of a quadractic, then so is \\(\\overline{z}_1\\) (use the rules of complex conjugates). By the Fundamental Theorem of Algebra, these are then the only two roots of the quadratic. Express the following complex numbers in polar form and exponential form. \\(1+i\\) \\(-1+i\\) \\(\\sqrt{3}-i\\) \\(z_1=2-3i\\) \\(z_2=3+4i\\) \\(\\frac{z_1-2}{z_2}\\) \\(z_1z_2-\\frac{z_1-z_2}{z_2}\\) \\(w_1=-\\sqrt{2}+\\sqrt{2}i\\) \\(w_2=-\\frac{1}{2}+\\frac{\\sqrt{3}}{2}i\\) \\(w_1w_2\\) \\(\\frac{w_1}{w_2}\\) Answers: The polar form is \\[z=r(\\cos(\\theta)+i\\sin(\\theta))\\] and the exponential form is \\[z=re^{i\\theta}.\\] Note these both contain the polar coordinates \\((r,\\theta)\\) but the exponential form is more compact. In the answers below we will just state the values of \\(r\\) and \\(\\theta\\). This is in the first quadrant. \\(r=\\sqrt{x^2+y^2}=\\sqrt{1^2+1^2}=\\sqrt{2}\\) \\(\\theta=\\tan^{-1}\\left(\\frac{x}{y}\\right)=\\tan^{-1}\\left(\\frac{1}{1}\\right)=\\frac{\\pi}{4}\\) This is in the second quadrant. \\(r=\\sqrt{2}\\), \\(\\theta=\\)\\(-\\tan^{-1}\\left(\\frac{1}{1}\\right)=\\frac{3\\pi}{4}\\). This is in the fourth quadrant. \\(r=2\\), \\(\\theta=2\\pi - \\tan^{-1}\\left(\\frac{1}{\\sqrt{3}}\\right)=\\frac{11\\pi}{6}.\\) This is in the fourth quadrant. \\(r_1=\\sqrt{13}\\), \\(\\theta_1=2\\pi - \\tan^{-1}\\left(\\frac{3}{2}\\right)=5.30\\) to 2 d.p. This is in the first quadrant. \\(r_2=5\\), \\(\\theta_2=\\tan^{-1}\\left(\\frac{4}{3}\\right)=0.93\\) to 2 d.p. In Cartesian form: \\(\\frac{z_1-2}{z_2}=-\\frac{12}{25}-\\frac{9}{25}i\\). This is in the third quadrant. \\(r=\\frac{3}{5}\\), \\(\\theta=\\pi + \\tan^{-1}\\left(\\frac{9/25}{12/25}\\right)=3.79\\) to 2 d.p. \\(z_1z_2=-1-7i\\). Using the result from the previous part we have \\[z_1z_2-\\frac{z_1-2}{z_2}=-1-7i +\\frac{12}{25}+\\frac{9}{25}i= -\\frac{13}{25}-\\frac{166}{25}i\\] This is in the third quadrant. \\(r=\\frac{\\sqrt{1109}}{5}\\), \\(\\theta=4.63\\) to 2 d.p. This is in the second quadrant. \\(r_1=2\\), \\(\\theta_1=\\pi-\\tan^{-1}\\frac{\\sqrt{2}}{\\sqrt{2}}=\\frac{3\\pi}{4}\\). This is in the second quadrant. \\(r_2=1\\), \\(\\theta_2=\\frac{2\\pi}{3}.\\) \\(w_1w_2\\) is easy to calculate in exponential form: \\(w_1w_2=r_1e^{i\\theta_1}r_2e^{i\\theta_2}=r_1r_2e^{i(\\theta_1+\\theta_2)}=2e^{i(\\frac{17\\pi}{12})}\\). \\(\\frac{w_1}{w_2}\\) is easy to calculate in exponential form: \\(\\frac{w_1}{w_2}=r_1e^{i\\theta_1}/r_2e^{i\\theta_2}=\\frac{r_1}{r_2}e^{i(\\theta_1-\\theta_2)}=2e^{i(\\frac{\\pi}{12})}\\). Express the following complex numbers in Cartesian form. \\(2e^{i\\frac{\\pi}{12}}\\) \\(5e^{i 23^\\circ}\\) \\(2e^{i (-45^\\circ)}\\) Answers: \\(\\frac{1 + \\sqrt{3}}{\\sqrt{2}} + \\frac{\\sqrt{3}-1}{\\sqrt{2}}i\\) \\(4.60+1.95i\\) to 2 d.p. \\(\\sqrt{2} - \\sqrt{2} i\\) Find the following roots and express them in Cartesian form. \\(1^\\frac{1}{3}\\) \\(1^\\frac{1}{4}\\) The cube roots of \\(\\sqrt{2}-\\sqrt{2}i\\) The square roots of \\(3-4i\\) Answers: In exponential form the roots are: \\[1^\\frac{1}{3}= \\begin{cases} e^{i0}\\\\ e^{i\\frac{2\\pi}{3}}\\\\ e^{i\\frac{4\\pi}{3}} \\end{cases}. \\] These translate to the Cartesian forms: \\[1^\\frac{1}{3}= \\begin{cases} 1\\\\ -\\frac{1}{2} + \\sqrt{3}/2 i\\\\ -\\frac{1}{2} - \\sqrt{3}/2 i \\end{cases}. \\] In exponential form the roots are: \\[1^\\frac{1}{4}= \\begin{cases} e^{i0}\\\\ e^{i\\frac{2\\pi}{4}}=e^{i\\frac{\\pi}{2}}\\\\ e^{i\\frac{4\\pi}{4}}=e^{i\\pi}\\\\ e^{i\\frac{6\\pi}{4}}=e^{i\\frac{3\\pi}{2}}\\\\ \\end{cases}. \\] These translate to the Cartesian forms: \\[1^\\frac{1}{4}= \\begin{cases} 1\\\\ i\\\\ -1\\\\ -i \\end{cases}. \\] In exponential form the roots are: \\[(\\sqrt{2}-\\sqrt{2}i)^\\frac{1}{3}= \\begin{cases} \\sqrt[3]{2}e^{i(-\\frac{\\pi}{12})}\\\\ \\sqrt[3]{2}e^{i(-\\frac{\\pi}{12}+\\frac{2\\pi}{3})}=\\sqrt[3]{2}e^{i\\frac{7\\pi}{12}}\\\\ \\sqrt[3]{2}e^{i(-\\frac{\\pi}{12}+\\frac{4\\pi}{3})}=\\sqrt[3]{2}e^{i\\frac{5\\pi}{4}} \\end{cases}. \\] These translate to the Cartesian forms: \\[(\\sqrt{2}-\\sqrt{2}i)= \\begin{cases} \\frac{1 + \\sqrt(3)}{2^{7/6}} - \\frac{\\sqrt{3} - 1}{2^{7/6}}i\\\\ \\frac{1 - \\sqrt(3)}{2^{7/6}} - \\frac{1+\\sqrt{3}}{2^{7/6}}i\\\\ -\\frac{1}{2^{1/6}} + \\frac{1}{2^{1/6}}i\\\\ \\end{cases}. \\] This one can be factorised (relatively) easily: \\[3-4i=4-4i+i^2=(2-i)^2\\] so that \\[\\sqrt{3-4i}=\\pm(2-i)=\\begin{cases} 2-i\\\\ -2+i \\end{cases}.\\] Sketch the following complex numbers in the complex plane. \\(2+3i\\) \\(-1-i\\) \\(-1+i\\) \\(-2i\\) \\(-3\\) Answers: Figure 22.1: The numbers in Question 8 in the complex plane. What is \\(i^i\\) in Cartesian form? Hint: start by writing \\(i\\) in exponential form. Find all complex numbers \\(z\\) such that \\(\\overline{z}=z^2\\). Hint: start by writing \\(z\\) in exponential form. "],["exercise-set-6.html", "Exercise Set 6", " Exercise Set 6 These exercises cover the topic of vectors. Note that the questions are independent of one another, so the definition of a vector \\(\\mathbf{a}\\) in one question does not carry over to another question with a vector called \\(\\mathbf{a}\\). The points \\(A\\), \\(B\\) and \\(C\\) have position vectors \\[\\begin{align*} \\mathbf{a}&amp;=5\\mathbf{i}-6\\mathbf{j}+4\\mathbf{k}\\\\ \\mathbf{b}&amp;=2\\mathbf{i}+5\\mathbf{j}-3\\mathbf{k}\\\\ \\mathbf{c}&amp;=-\\mathbf{i}+4\\mathbf{k}. \\end{align*}\\] Find: \\(5\\mathbf{a}-2\\mathbf{b}-3\\mathbf{c}\\) \\(\\overrightarrow{AC}+\\overrightarrow{AB}\\) \\(\\mathbf{a}\\cdot\\mathbf{b}\\) The angle between \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) \\(\\mathbf{a}\\times\\mathbf{c}\\) Let \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\) be vectors. What is the vector \\(\\mathbf{r}\\) joining the points whose position vectors are \\(\\mathbf{p}\\) and \\(2\\mathbf{q}\\)? What is the vector \\(\\mathbf{s}\\) joing the points whose position vectors are \\(\\mathbf{2q}\\) and \\(-6\\mathbf{p}+14\\mathbf{q}\\)? What do you notice about \\(\\mathbf{r}\\) and \\(\\mathbf{s}\\)? What does this tell you about the points whose position vectors are \\(\\mathbf{p}\\), \\(2\\mathbf{q}\\) and \\(-6\\mathbf{p}+14{q}\\)? Let \\(\\mathbf{u}=5\\mathbf{i}+2\\mathbf{j}\\) and \\(\\mathbf{v}=3\\mathbf{i}-\\mathbf{j}-3\\mathbf{k}\\). Find \\((4\\mathbf{u}-6\\mathbf{v})\\cdot(2\\mathbf{u}+3\\mathbf{v})\\). Given that the position vectors of the points \\(A\\), \\(B\\), and \\(C\\) are \\(\\mathbf{a}\\), \\(\\mathbf{b}\\) and \\(\\mathbf{c}\\), write down the position vectors of the midpoints of the lines \\(BC\\) and \\(CA\\). Prove that the vector joining the midpoints of two sides of a triangle is parallel to the third side and half of its length. Show that the vectors \\[\\begin{align*} \\mathbf{a}&amp;=8\\mathbf{i}+2\\mathbf{j}-3\\mathbf{k}\\\\ \\mathbf{b}&amp;=3\\mathbf{i}-6\\mathbf{j}+4\\mathbf{k} \\end{align*}\\] are perpendicular to one another (Hint: use the dot product). A block of mass \\(m=1\\,\\text{kg}\\) is sliding down a frictionless slope under gravity. The slope is at an angle of \\(45^\\circ\\) to the horizontal. Recall that the force on the block is given by Newton’s second law: \\(\\mathbf{F}=m\\mathbf{g}\\) where \\(\\mathbf{g}=-9.8\\mathbf{k}\\,\\text{ms}^{-2}\\) is the gravitational acceleration. Resolve the force vector in the directions parallel and perpendicular to the slope. (Hint: you need to project the force vector onto unit vectors that are parallel and perpendicular to the slope.) Let \\[\\mathbf{a}=\\begin{pmatrix} 2\\\\ -1\\\\ 3 \\end{pmatrix} ,\\qquad \\mathbf{b}=\\begin{pmatrix} 5\\\\ 1\\\\ -4 \\end{pmatrix}. \\] Show that \\((\\mathbf{a}-\\mathbf{b})\\times(\\mathbf{a}+\\mathbf{b})=2\\mathbf{a}\\times\\mathbf{b}\\). Show that \\[(\\mathbf{a}+\\mathbf{b})\\cdot((\\mathbf{b}+\\mathbf{c})\\times (\\mathbf{c}+\\mathbf{a}))=2\\mathbf{a}\\cdot(\\mathbf{b}\\times\\mathbf{c}).\\] The quantity \\(\\mathbf{a}\\cdot(\\mathbf{b}\\times\\mathbf{c})\\) is known as the scalar triple product: its geometric interpretation is the volume of the parallelepiped defined by the three vectors. Let \\[\\mathbf{a}=\\begin{pmatrix} \\alpha\\\\ 0\\\\ -1 \\end{pmatrix} ,\\qquad \\mathbf{b}=\\begin{pmatrix} 3\\\\ 2\\\\ 5 \\end{pmatrix} ,\\qquad \\mathbf{c}=\\begin{pmatrix} 2\\\\ -1\\\\ 4 \\end{pmatrix}. \\] Find the values of \\(\\alpha\\) for which \\(\\mathbf{a}\\times\\mathbf{b}\\) is perpendicular to \\(\\mathbf{a}\\times\\mathbf{c}\\). The torque is the rotational equivalent of linear force. It is given by the product of the magnitude of the force and the perpendicular distance of the line of action of a force from the axis of rotation. We can calculate torque using the cross product: \\[\\boldsymbol\\tau = \\mathbf{r}\\times \\mathbf{F}\\] where \\(\\boldsymbol\\tau\\) is the torque vector, \\(\\mathbf{r}\\) is the position vector (from the axis of rotation to the point where the force is applied) and \\(\\mathbf{F}\\) is the force vector. Find the torque about the point \\(\\mathbf{i}+2\\mathbf{j}-\\mathbf{k}\\) of a force \\(\\mathbf{F}=3\\mathbf{i}+\\mathbf{k}\\) acting on a particle at position \\(2\\mathbf{i}-\\mathbf{j}+3\\mathbf{k}\\). "],["exercise-set-6-answers.html", "Exercise Set 6 Answers", " Exercise Set 6 Answers These exercises cover the topic of vectors. Note that the questions are independent of one another, so the definition of a vector \\(\\mathbf{a}\\) in one question does not carry over to another question with a vector called \\(\\mathbf{a}\\). The points \\(A\\), \\(B\\) and \\(C\\) have position vectors \\[\\begin{align*} \\mathbf{a}&amp;=5\\mathbf{i}-6\\mathbf{j}+4\\mathbf{k}\\\\ \\mathbf{b}&amp;=2\\mathbf{i}+5\\mathbf{j}-3\\mathbf{k}\\\\ \\mathbf{c}&amp;=-\\mathbf{i}+4\\mathbf{k}. \\end{align*}\\] Find: \\(5\\mathbf{a}-2\\mathbf{b}-3\\mathbf{c}\\) \\(\\overrightarrow{AC}+\\overrightarrow{AB}\\) \\(\\mathbf{a}\\cdot\\mathbf{b}\\) The angle between \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) \\(\\mathbf{a}\\times\\mathbf{c}\\) Answers: \\(5\\mathbf{a}-2\\mathbf{b}-3\\mathbf{c}=24\\mathbf{i}-40\\mathbf{j}+14\\mathbf{k}\\) \\(\\overrightarrow{AC}=\\mathbf{c}-\\mathbf{a}=-6\\mathbf{i}+6\\mathbf{j}\\) \\(\\overrightarrow{AB}=\\mathbf{b}-\\mathbf{a}=-3\\mathbf{i}+11\\mathbf{j}-7\\mathbf{k}\\) \\(\\overrightarrow{AC}+\\overrightarrow{AB}=-9\\mathbf{i}+17\\mathbf{j}-7\\mathbf{k}\\) \\(\\mathbf{a}\\cdot \\mathbf{b}=(5\\times 2)+ (-6\\times5)+(4\\times -3)=-32\\) \\(|\\mathbf{a}|=\\sqrt{77}\\) \\(|\\mathbf{b}|=\\sqrt{38}\\) \\(\\cos(\\theta)=\\frac{\\mathbf{a}\\cdot \\mathbf{b}}{|\\mathbf{a}||\\mathbf{b}|}=\\frac{-32}{\\sqrt{77}\\sqrt{38}}=-0.5916\\) \\(\\theta=\\cos^{-1}(-0.5916)=126.3^\\circ\\) \\[\\begin{align*} \\mathbf{a}\\times \\mathbf{c}&amp;=\\begin{vmatrix} \\mathbf{i}&amp;\\mathbf{j}&amp;\\mathbf{k}\\\\ 5&amp;-6&amp;4\\\\ -1&amp;0&amp;4 \\end{vmatrix}\\\\ &amp;= \\mathbf{i}\\begin{vmatrix} -6&amp;4\\\\ 0&amp;4 \\end{vmatrix} -\\mathbf{j}\\begin{vmatrix} 5&amp;4\\\\ -1&amp;4 \\end{vmatrix} +\\mathbf{k}\\begin{vmatrix} 5&amp;-6\\\\ -1&amp;0 \\end{vmatrix}\\\\ &amp;=\\mathbf{i}(-24-0)-\\mathbf{j}(20-(-4))+\\mathbf{k}(0-6)\\\\ &amp;=-24\\mathbf{i}-24\\mathbf{j}-6\\mathbf{k} \\end{align*}\\] Let \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\) be vectors. What is the vector \\(\\mathbf{r}\\) joining the points whose position vectors are \\(\\mathbf{p}\\) and \\(2\\mathbf{q}\\)? What is the vector \\(\\mathbf{s}\\) joing the points whose position vectors are \\(\\mathbf{2q}\\) and \\(-6\\mathbf{p}+14\\mathbf{q}\\)? What do you notice about \\(\\mathbf{r}\\) and \\(\\mathbf{s}\\)? What does this tell you about the points whose position vectors are \\(\\mathbf{p}\\), \\(2\\mathbf{q}\\) and \\(-6\\mathbf{p}+14{q}\\)? Answers: \\(\\mathbf{r}=2\\mathbf{q}-\\mathbf{p}\\) \\(\\mathbf{s}=(-6\\mathbf{p}+14\\mathbf{q})-2\\mathbf{q}=12\\mathbf{q}-6\\mathbf{p}\\) They are parallel: \\(\\mathbf{s}=6\\mathbf{r}\\) so they have the same direction. The points are collinear, i.e. all lie in a straight line. Let \\(\\mathbf{u}=5\\mathbf{i}+2\\mathbf{j}\\) and \\(\\mathbf{v}=3\\mathbf{i}-\\mathbf{j}-3\\mathbf{k}\\). Find \\((4\\mathbf{u}-6\\mathbf{v})\\cdot(2\\mathbf{u}+3\\mathbf{v})\\). Answers: \\((2\\mathbf{i}+14\\mathbf{j}+\\mathbf{k})\\cdot(19\\mathbf{i}+\\mathbf{j}-9\\mathbf{k})=38+14-162=-110.\\) Given that the position vectors of the points \\(A\\), \\(B\\), and \\(C\\) are \\(\\mathbf{a}\\), \\(\\mathbf{b}\\) and \\(\\mathbf{c}\\), write down the position vectors of the midpoints of the lines \\(BC\\) and \\(CA\\). Answers: \\(\\overline{BC}=\\mathbf{c}-\\mathbf{b}\\) \\(\\overline{OE}=\\mathbf{b}+\\frac{1}{2}(\\mathbf{c}-\\mathbf{b})=\\frac{1}{2}\\mathbf{c}-\\frac{1}{2}\\mathbf{b}\\) \\(\\overline{CA}=\\mathbf{a}-\\mathbf{c}\\) \\(\\overline{OF}=\\mathbf{c}+\\frac{1}{2}(\\mathbf{a}-\\mathbf{c})=\\frac{1}{2}\\mathbf{a}-\\frac{1}{2}\\mathbf{c}\\) Prove that the vector joining the midpoints of two sides of a triangle is parallel to the third side and half of its length. Answers: We need to set up some labels for the points of the triangle. Let these have position vectors \\(\\mathbf{A}, \\mathbf{B}, \\mathbf{C}\\). The vectors defining the sides of the triangle are \\(\\mathbf{a}=\\overline{BC}=\\mathbf{C}-\\mathbf{B}\\) \\(\\mathbf{b}=\\overline{CA}=\\mathbf{A}-\\mathbf{C}\\) \\(\\mathbf{c}=\\overline{AB}=\\mathbf{B}-\\mathbf{A}\\) The midpoint of side \\(CA\\) is \\(\\mathbf{C}+\\frac{1}{2}\\mathbf{b}=\\mathbf{C}+\\frac{1}{2}\\mathbf{A}-\\frac{1}{2}\\mathbf{C}=\\frac{1}{2}\\mathbf{C}+\\frac{1}{2}\\mathbf{A}\\) The midpoint of side \\(AB\\) is \\(\\mathbf{A}+\\frac{1}{2}\\mathbf{c}=\\mathbf{A}+\\frac{1}{2}\\mathbf{B}-\\frac{1}{2}\\mathbf{A}=\\frac{1}{2}\\mathbf{A}+\\frac{1}{2}\\mathbf{B}\\) The vector between these midpoints is \\[(\\frac{1}{2}\\mathbf{C}+\\frac{1}{2}\\mathbf{A})-(\\frac{1}{2}\\mathbf{A}+\\frac{1}{2}\\mathbf{B})=\\frac{1}{2}\\mathbf{C}-\\frac{1}{2}\\mathbf{B}\\] which is half of the vector \\(\\mathbf{a}=\\overline{BC}\\), as required. Show that the vectors \\[\\begin{align*} \\mathbf{a}&amp;=8\\mathbf{i}+2\\mathbf{j}-3\\mathbf{k}\\\\ \\mathbf{b}&amp;=3\\mathbf{i}-6\\mathbf{j}+4\\mathbf{k} \\end{align*}\\] are perpendicular to one another (Hint: use the dot product). Answers: Using the dot product: \\(\\mathbf{a}\\cdot\\mathbf{b}=(8\\times 3)+(2\\times-6)+(-3\\times 4)=24-12-12=0\\) and since this is zero and the vectors \\(\\mathbf{a}\\) and \\(\\mathbf{b}\\) are non-zero, these are perpendicular vectors. A block of mass \\(m=1\\,\\text{kg}\\) is sliding down a frictionless slope under gravity. The slope is at an angle of \\(45^\\circ\\) to the horizontal. Recall that the force on the block is given by Newton’s second law: \\(\\mathbf{F}=m\\mathbf{g}\\) where \\(\\mathbf{g}=-9.8\\mathbf{k}\\,\\text{ms}^{-2}\\) is the gravitational acceleration. Resolve the force vector in the directions parallel and perpendicular to the slope. (Hint: you need to project the force vector onto unit vectors that are parallel and perpendicular to the slope.) Answers: We can simplify this to a two dimensional problem by aligning the coordinate axes sensibly. Let’s align the axes so that the \\(y\\) axis is perpendicular to the slope and the slope is increasing in the \\(x\\) direction, then we just need the \\(\\mathbf{i}\\) and \\(\\mathbf{k}\\) directions. The unit vector parallel to the (increasing) slope is \\(\\mathbf{u}=\\frac{1}{\\sqrt{2}}\\mathbf{i}+\\frac{1}{\\sqrt{2}}\\mathbf{k}\\) and the unit vector perpendicular to the slope is \\(\\mathbf{v}=-\\frac{1}{\\sqrt{2}}\\mathbf{i}+\\frac{1}{\\sqrt{2}}\\mathbf{k}\\). The force vector is \\(\\mathbf{F}=m\\mathbf{g}=-9.8\\mathbf{k}\\). First projecting onto the parallel vector: \\(\\mathbf{F}\\cdot \\mathbf{u}=(0\\times \\frac{1}{\\sqrt{2}})+ (-9.8 \\times \\frac{1}{\\sqrt{2}})=-6.9\\). and then onto the perpendicular vector: \\(\\mathbf{F}\\cdot \\mathbf{v}=(0\\times -\\frac{1}{\\sqrt{2}})+ (-9.8 \\times \\frac{1}{\\sqrt{2}})=-6.9\\). Hence we have \\(\\mathbf{F}=-6.9\\mathbf{u}-6.9\\mathbf{v}\\). Let \\[\\mathbf{a}=\\begin{pmatrix} 2\\\\ -1\\\\ 3 \\end{pmatrix} ,\\qquad \\mathbf{b}=\\begin{pmatrix} 5\\\\ 1\\\\ -4 \\end{pmatrix}. \\] Show that \\((\\mathbf{a}-\\mathbf{b})\\times(\\mathbf{a}+\\mathbf{b})=2\\mathbf{a}\\times\\mathbf{b}\\). Answers: \\(\\mathbf{a}-\\mathbf{b}=-3\\mathbf{i}-2\\mathbf{j}+7\\mathbf{k}\\) \\(\\mathbf{a}+\\mathbf{b}=7\\mathbf{i}-\\mathbf{k}\\) \\[\\begin{align*} (\\mathbf{a}-\\mathbf{b})\\times(\\mathbf{a}+\\mathbf{b})&amp;= \\begin{vmatrix} \\mathbf{i}&amp;\\mathbf{j}&amp;\\mathbf{k}\\\\ -3&amp;-2&amp;7\\\\ 7&amp;0&amp;-1 \\end{vmatrix}\\\\ &amp;= \\mathbf{i}\\begin{vmatrix} -2&amp;7\\\\ 0&amp;-1 \\end{vmatrix} -\\mathbf{j}\\begin{vmatrix} -3&amp;7\\\\ 7&amp;-1 \\end{vmatrix} +\\mathbf{k}\\begin{vmatrix} -3&amp;-2\\\\ 7&amp;0 \\end{vmatrix}\\\\ &amp;=\\mathbf{i}(2-0)-\\mathbf{j}(3-49)+\\mathbf{k}(0-(-14))\\\\ &amp;=2\\mathbf{i}+46\\mathbf{j}+14\\mathbf{k} \\end{align*}\\] \\[\\begin{align*} 2\\mathbf{a}\\times\\mathbf{b}&amp;= \\begin{vmatrix} \\mathbf{i}&amp;\\mathbf{j}&amp;\\mathbf{k}\\\\ 4&amp;-2&amp;6\\\\ 5&amp;1&amp;-4 \\end{vmatrix}\\\\ &amp;= \\mathbf{i}\\begin{vmatrix} -2&amp;6\\\\ 1&amp;-4 \\end{vmatrix} -\\mathbf{j}\\begin{vmatrix} 4&amp;6\\\\ 5&amp;-4 \\end{vmatrix} +\\mathbf{k}\\begin{vmatrix} 4&amp;-2\\\\ 5&amp;1 \\end{vmatrix}\\\\ &amp;=\\mathbf{i}(8-6)-\\mathbf{j}(-16-30)+\\mathbf{k}(4-(-10))\\\\ &amp;=2\\mathbf{i}+46\\mathbf{j}+14\\mathbf{k} \\end{align*}\\] Hence \\((\\mathbf{a}-\\mathbf{b})\\times(\\mathbf{a}+\\mathbf{b})=2\\mathbf{a}\\times\\mathbf{b}\\) Show that \\[(\\mathbf{a}+\\mathbf{b})\\cdot((\\mathbf{b}+\\mathbf{c})\\times (\\mathbf{c}+\\mathbf{a}))=2\\mathbf{a}\\cdot(\\mathbf{b}\\times\\mathbf{c}).\\] The quantity \\(\\mathbf{a}\\cdot(\\mathbf{b}\\times\\mathbf{c})\\) is known as the scalar triple product: its geometric interpretation is the volume of the parallelepiped defined by the three vectors. Answers: \\[\\begin{align*} (\\mathbf{a}+\\mathbf{b})\\cdot((\\mathbf{b}+\\mathbf{c})\\times (\\mathbf{c}+\\mathbf{a}))&amp;=(\\mathbf{a}+\\mathbf{b})\\cdot(\\mathbf{b}\\times\\mathbf{c}+\\mathbf{b}\\times\\mathbf{a}+\\mathbf{c}\\times\\mathbf{c}+\\mathbf{c}\\times\\mathbf{a})\\\\ &amp;=(\\mathbf{a}+\\mathbf{b})\\cdot(\\mathbf{b}\\times\\mathbf{c}+\\mathbf{b}\\times\\mathbf{a}+\\mathbf{c}\\times\\mathbf{a})\\\\ &amp;=\\mathbf{a}\\cdot(\\mathbf{b}\\times\\mathbf{c})+(\\mathbf{a}\\cdot(\\mathbf{b}\\times\\mathbf{a})+\\mathbf{a}\\cdot(\\mathbf{c}\\times\\mathbf{a})+\\mathbf{b}\\cdot(\\mathbf{b}\\times\\mathbf{c})+(\\mathbf{b}\\cdot(\\mathbf{b}\\times\\mathbf{a})+\\mathbf{b}\\cdot(\\mathbf{c}\\times\\mathbf{a})\\\\ &amp;=\\mathbf{a}\\cdot(\\mathbf{b}\\times\\mathbf{c})+\\mathbf{b}\\cdot(\\mathbf{c}\\times\\mathbf{a})\\\\ &amp;=\\mathbf{a}\\cdot(\\mathbf{b}\\times\\mathbf{c})+\\mathbf{a}\\cdot(\\mathbf{b}\\times\\mathbf{c})\\\\ &amp;=2\\mathbf{a}\\cdot(\\mathbf{b}\\times\\mathbf{c}) \\end{align*}\\] Let \\[\\mathbf{a}=\\begin{pmatrix} \\alpha\\\\ 0\\\\ -1 \\end{pmatrix} ,\\qquad \\mathbf{b}=\\begin{pmatrix} 3\\\\ 2\\\\ 5 \\end{pmatrix} ,\\qquad \\mathbf{c}=\\begin{pmatrix} 2\\\\ -1\\\\ 4 \\end{pmatrix}. \\] Find the values of \\(\\alpha\\) for which \\(\\mathbf{a}\\times\\mathbf{b}\\) is perpendicular to \\(\\mathbf{a}\\times\\mathbf{c}\\). Answers: We find: \\(\\mathbf{a}\\times\\mathbf{b}=2\\mathbf{i}-(5\\alpha+3)\\mathbf{j}+2\\alpha\\mathbf{k}\\) and \\(\\mathbf{a}\\times\\mathbf{c}=-\\mathbf{i}-(4\\alpha+2)\\mathbf{j}+\\alpha\\mathbf{k}\\). Then for perpendicularity we solve \\((\\mathbf{a}\\times\\mathbf{b})\\cdot(\\mathbf{a}\\times\\mathbf{c})=0\\). We have \\[ (\\mathbf{a}\\times\\mathbf{b})\\cdot(\\mathbf{a}\\times\\mathbf{c})=(9\\alpha+2)(\\alpha+1) \\] Hence \\[\\alpha=-\\frac{2}{9},\\quad\\text{or}\\quad \\alpha={-1}.\\] The torque is the rotational equivalent of linear force. It is given by the product of the magnitude of the force and the perpendicular distance of the line of action of a force from the axis of rotation. We can calculate torque using the cross product: \\[\\boldsymbol\\tau = \\mathbf{r}\\times \\mathbf{F}\\] where \\(\\boldsymbol\\tau\\) is the torque vector, \\(\\mathbf{r}\\) is the position vector (from the axis of rotation to the point where the force is applied) and \\(\\mathbf{F}\\) is the force vector. Find the torque about the point \\(\\mathbf{i}+2\\mathbf{j}-\\mathbf{k}\\) of a force \\(\\mathbf{F}=3\\mathbf{i}+\\mathbf{k}\\) acting on a particle at position \\(2\\mathbf{i}-\\mathbf{j}+3\\mathbf{k}\\). Answers: \\(\\mathbf{r}=(2\\mathbf{i}-\\mathbf{j}+3\\mathbf{k})-(\\mathbf{i}+2\\mathbf{j}-\\mathbf{k})=\\mathbf{i}-3\\mathbf{j}+4\\mathbf{k}\\) Then \\[\\begin{align*} \\mathbf{r}\\times \\mathbf{F}&amp;= \\begin{vmatrix} \\mathbf{i}&amp;\\mathbf{j}&amp;\\mathbf{k}\\\\ 1&amp;-3&amp;4\\\\ 3&amp;0&amp;1 \\end{vmatrix}\\\\ &amp;=-3\\mathbf{i}+11\\mathbf{j}+9\\mathbf{k}. \\end{align*}\\] "],["exercise-set-7.html", "Exercise Set 7", " Exercise Set 7 These exercises cover solving linear equations by Gaussian elimination. Use Gaussian elimination (elementary row operations) to determine whether or not the following systems of equations have solutions, and, when they do, to find all solutions. In the cases where there is more than one solution, find the general solution and also give one particular solution. (Tip: Choosing the elementary row operations carefully can minimise the use of fractions). \\[\\begin{align*} x + y - z &amp;= -3, \\\\ 2x + 2y - z &amp;= -2, \\\\ 3x + 2y - 3z&amp;= -7; \\end{align*}\\] \\[\\begin{align*} 2x - 2y + 3z&amp;= 5, \\\\ 3x - 2y + 4z&amp;= 6, \\\\ 4x + y + 2z&amp;= 2; \\end{align*}\\] \\[\\begin{align*} 3x + 2y + 13z&amp;= 2, \\\\ 4x + 2y + 16z&amp;= 1, \\\\ x + y + 5z &amp;= 1; \\end{align*}\\] \\[\\begin{align*} 2x + z &amp;= 3, \\\\ x + y + z &amp;= 2, \\\\ x + 3y + 2z&amp;= 3; \\end{align*}\\] \\[\\begin{align*} 2x + 4y + z - 3t&amp;= 7, \\\\ 5x + 10y + 6z - 4t&amp;= 14, \\\\ 7x + 14y + 5z - 9t&amp;= 23; \\end{align*}\\] \\[\\begin{align*} 3x + 4y &amp;= 1, \\\\ 2x - 4y + 2z&amp;= 4, \\\\ 3x + z &amp;= 2, \\\\ x - 2y + z &amp;= 2; \\end{align*}\\] \\[\\begin{align*} 3x - y + 2z + t&amp;= 3, \\\\ x + 2y - z + t&amp;= -3, \\\\ 3x + y + z + t&amp;= 0, \\\\ 3x + 2y + t&amp;= -1. \\end{align*}\\] Balancing chemical equations. In the combustion of propane gas, propane (\\(C_3H_8\\)) combines with oxygen (\\(O_2\\)) to form carbon dioxide (\\(CO_2\\)) and water (\\(H_2O\\)) according to the equation \\[x_1 C_3H_8 + x_2 O_2\\to x_3CO_2+x_4H_2O.\\] To balance this equation, we must find natural numbers \\(x_1, x_2, x_3, x_4\\) such that the total numbers of \\(C\\), \\(H\\) and \\(O\\) atoms are equal on both sides. Formulate this problem as a set of linear equations and solve using Guassian elimination. Electrical networks. Consider the circuit diagram below. The voltage drop across a resistor is (by Ohm’s law) \\(V=IR\\) where \\(V\\) is in volts, the current \\(I\\) is in amps and the resistance \\(R\\) is in ohms. Kirchhoff’s junction law: the sum of currents flowing into a junction is equal to the sum of currents flowing out of that junction. Kirchoff’s Voltage law: The sum of the voltage drops in one direction around a loop equals the sum of the voltage sources in the same direction around the loop. Using these laws it is possible to derive the following set of linear equations for the currents \\(I_1, I_2, I_3\\): \\[\\begin{align*} 11I_1-3I_2&amp;=30\\\\ -3I_1+6I_2-I_3&amp;=5\\\\ -I_2+3I_3&amp;=-25. \\end{align*}\\] Determine the currents. (Extra challenge: derive the equations!). Network analysis. The diagram below represents the traffic flow in a one-way road network. Each directed edge represents a one-way road and is labelled with the flow through that road. The nodes represent road junctions. By considering the flow in and out of each node and the total flow in and out of the network, formulate a system of linear equations for the unknown flows \\(x_1,\\dotsc,x_5\\) and solve them by Gaussian elimination. You will find there is a “free variable”, but the requirement for non-negative flows puts some restrictions on the variables. In particular, what are the restrictions on \\(x_1\\) and \\(x_5\\)? "],["exercise-set-7-answers.html", "Exercise Set 7 Answers", " Exercise Set 7 Answers These exercises cover solving linear equations by Gaussian elimination. Use Gaussian elimination (elementary row operations) to determine whether or not the following systems of equations have solutions, and, when they do, to find all solutions. In the cases where there is more than one solution, find the general solution and also give one particular solution. (Tip: Choosing the elementary row operations carefully can minimise the use of fractions). \\[\\begin{align*} x + y - z &amp;= -3, \\\\ 2x + 2y - z &amp;= -2, \\\\ 3x + 2y - 3z&amp;= -7; \\end{align*}\\] \\[\\begin{align*} 2x - 2y + 3z&amp;= 5, \\\\ 3x - 2y + 4z&amp;= 6, \\\\ 4x + y + 2z&amp;= 2; \\end{align*}\\] \\[\\begin{align*} 3x + 2y + 13z&amp;= 2, \\\\ 4x + 2y + 16z&amp;= 1, \\\\ x + y + 5z &amp;= 1; \\end{align*}\\] \\[\\begin{align*} 2x + z &amp;= 3, \\\\ x + y + z &amp;= 2, \\\\ x + 3y + 2z&amp;= 3; \\end{align*}\\] \\[\\begin{align*} 2x + 4y + z - 3t&amp;= 7, \\\\ 5x + 10y + 6z - 4t&amp;= 14, \\\\ 7x + 14y + 5z - 9t&amp;= 23; \\end{align*}\\] \\[\\begin{align*} 3x + 4y &amp;= 1, \\\\ 2x - 4y + 2z&amp;= 4, \\\\ 3x + z &amp;= 2, \\\\ x - 2y + z &amp;= 2; \\end{align*}\\] \\[\\begin{align*} 3x - y + 2z + t&amp;= 3, \\\\ x + 2y - z + t&amp;= -3, \\\\ 3x + y + z + t&amp;= 0, \\\\ 3x + 2y + t&amp;= -1. \\end{align*}\\] Answers: We have the augmented matrix \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; -1 &amp; -3\\\\ 2 &amp; 2 &amp; -1 &amp; -2 \\\\ 3 &amp; 2 &amp; -3 &amp; -7 \\end{array}\\right) \\] Eliminate entries below the leading entry in the first column by performing \\(R_2 \\to R_2 - 2 R_1\\) and \\(R_3 \\to R_3 - 3R_1\\). We have \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; -1 &amp; -3\\\\ 0 &amp; 0 &amp; 1 &amp; 4 \\\\ 0 &amp; -1 &amp; 0 &amp; 2 \\end{array}\\right). \\] Swap the bottom two rows, i.e. \\(R_2 \\leftrightarrow R_3\\), to obtain \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; -1 &amp; -3\\\\ 0 &amp; -1 &amp; 0 &amp; 2 \\\\ 0 &amp; 0 &amp; 1 &amp; 4 \\end{array}\\right). \\] The matrix is now in echelon form. Eliminate the entries in column above the leading entry in column \\(3\\), that is applying \\(R_1 \\to R_1 + R_3\\) gives \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; 0 &amp; 1 \\\\ 0 &amp; -1 &amp; 0 &amp; 2 \\\\ 0 &amp; 0 &amp; 1 &amp; 4 \\end{array}\\right). \\] Then, using \\(R_2 \\to -R_2\\), we have \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; 0 &amp; 1\\\\ 0 &amp; 1 &amp; 0 &amp; -2 \\\\ 0 &amp; 0 &amp; 1 &amp; 4 \\end{array}\\right) \\] Eliminate entries in the column above the leading entry in column \\(2\\), i.e. apply \\(R_1 \\to R_1 - R_2\\) to obtain \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 0 &amp; 0 &amp; 3\\\\ 0 &amp; 1 &amp; 0 &amp; -2 \\\\ 0 &amp; 0 &amp; 1 &amp; 4 \\end{array}\\right) \\] The matrix is now in reduced echelon form and we read off the solution \\[ (x,y,z) = (3,-2,4). \\] We have the augmented matrix \\[ \\left(\\begin{array}{rrr|r} 2 &amp; -2 &amp; 3 &amp; 5\\\\ 3 &amp; -2 &amp; 4 &amp; 6\\\\ 4 &amp; 1 &amp; 2 &amp; 2 \\end{array}\\right) \\] We eliminate the entries below the leading entry in column \\(1\\). Performing \\(R_2 \\to R_2 - \\frac{3}{2}R_1\\) and \\(R_3 \\to R_3 - 2R_1\\) we arrive at \\[ \\left(\\begin{array}{rrr|r} 2 &amp; -2 &amp; 3 &amp; 5\\\\ 0 &amp; 1 &amp; -\\frac{1}{2} &amp; -\\frac{3}{2}\\\\ 0 &amp; 5 &amp; -4 &amp; -8 \\end{array}\\right). \\] Next, we eliminate the entry below the leading entry in column \\(2\\) via \\(R_3 \\to R_3 - 5R_2\\) to get \\[ \\left(\\begin{array}{rrr|r} 2 &amp; -2 &amp; 3 &amp; 5\\\\ 0 &amp; 1 &amp; -\\frac{1}{2} &amp; -\\frac{3}{2}\\\\ 0 &amp; 0 &amp; -\\frac{3}{2} &amp; -\\frac{1}{2} \\end{array}\\right). \\] The matrix is now in echelon form. We proceed to bring the matrix into reduced echelon form. Multiply Row \\(3\\) by \\(- \\frac{2}{3}\\), i.e. \\(R_2 \\to - \\frac{2}{3}R_3\\), to have \\[ \\left(\\begin{array}{rrr|r} 2 &amp; -2 &amp; 3 &amp; 5\\\\ 0 &amp; 1 &amp; -\\frac{1}{2} &amp; -\\frac{3}{2}\\\\ 0 &amp; 0 &amp; 1 &amp; \\frac{1}{3} \\end{array}\\right). \\] To eliminate the entries above the leading entry in column \\(3\\), we perform the operations \\(R_2 \\to R_2 + \\frac{1}{2}R_3\\) and \\(R_1 \\to R_1 - 3R_3\\), which give \\[ \\left(\\begin{array}{rrr|r} 2 &amp; -2 &amp; 0 &amp; 4\\\\ 0 &amp; 1 &amp; 0 &amp; -\\frac{4}{3}\\\\ 0 &amp; 0 &amp; 1 &amp; \\frac{1}{3} \\end{array}\\right) \\] To eliminate the entry above the leading entry in column \\(2\\), we perform the operation \\(R_1 \\to R_1 + 2R_2\\), which gives \\[ \\left(\\begin{array}{rrr|r} 2 &amp; 0 &amp; 0 &amp; \\frac{4}{3}\\\\ 0 &amp; 1 &amp; 0 &amp; -\\frac{4}{3}\\\\ 0 &amp; 0 &amp; 1 &amp; \\frac{1}{3} \\end{array}\\right). \\] Applying \\(R_1 \\to \\frac{1}{2}R_1\\) gives \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 0 &amp; 0 &amp; \\frac{2}{3}\\\\ 0 &amp; 1 &amp; 0 &amp; -\\frac{4}{3}\\\\ 0 &amp; 0 &amp; 1 &amp; \\frac{1}{3} \\end{array}\\right). \\] The matrix is now in reduced echelon form and we read off the solution \\[ (x,y,z) = \\frac{1}{3}(2,-4,1). \\] We have the augmented matrix \\[ \\left(\\begin{array}{rrr|r} 3 &amp; 2 &amp; 13 &amp; 2 \\\\ 4 &amp; 2 &amp; 16 &amp; 1 \\\\ 1 &amp; 1 &amp; 5 &amp; 1 \\end{array}\\right). \\] We start by swapping rows so that we have a small number in the top-left corner — this avoids having to deal with fractions — applying \\(R_1 \\leftrightarrow R_3\\) and then \\(R_2 \\leftrightarrow R_3\\) gives \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; 5 &amp; 1 \\\\ 3 &amp; 2 &amp; 13 &amp; 2 \\\\ 4 &amp; 2 &amp; 16 &amp; 1 \\end{array}\\right). \\] To eliminate the entries below the leading entry in column \\(1\\), we apply \\(R_2 \\to R_2 - 3R_1\\) and \\(R_3 \\to R_3 - 4R_1\\), which give \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; 5 &amp; 1 \\\\ 0 &amp; -1 &amp; -2 &amp; -1 \\\\ 0 &amp; -2 &amp; -4 &amp; -3 \\end{array}\\right). \\] To eliminate the entry below the leading entry in column \\(2\\), we apply \\(R_3 \\to R_3 - 2R_2\\), which gives \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; 5 &amp; 1 \\\\ 0 &amp; -1 &amp; -2 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 &amp; -1 \\end{array}\\right). \\] The matrix is now in echelon form. There is a leading entry in the right-most column (representing the solution vector), from which we may infer that the system is inconsistent (there are no solutions). We have the augmented matrix \\[ \\left(\\begin{array}{rrr|r} 2 &amp; 0 &amp; 1 &amp; 3\\\\ 1 &amp; 1 &amp; 1 &amp; 2\\\\ 1 &amp; 3 &amp; 2 &amp; 3 \\end{array}\\right) \\] We start by swapping rows, i.e. performing \\(R_1\\leftrightarrow R_3\\) and \\(R_2\\leftrightarrow R_3\\) to get \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; 1 &amp; 2\\\\ 1 &amp; 3 &amp; 2 &amp; 3 \\\\ 2 &amp; 0 &amp; 1 &amp; 3 \\end{array}\\right). \\] To eliminate the entries below the leading entry in column \\(1\\), we perform the operations \\(R_2 \\to R_2 - R_1\\) and \\(R_3 \\to R_3-2R_1\\), arriving at \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; 1 &amp; 2\\\\ 0 &amp; 2 &amp; 1 &amp; 1\\\\ 0 &amp; -2 &amp; -1 &amp; -1 \\end{array}\\right). \\] To eliminate the entry below the leading entry in column \\(2\\), we perform the operation \\(R_3 \\to R_3 + R_2\\) and arrive at \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; 1 &amp; 2\\\\ 0 &amp; 2 &amp; 1 &amp; 1\\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] The matrix is now in echelon form — the last row is consistent. We proceed to bring the matrix into reduced echelon form. Applying \\(R_2 \\to \\frac{1}{2}R_2\\), we have \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 1 &amp; 1 &amp; 2\\\\ 0 &amp; 1 &amp; \\frac{1}{2} &amp; \\frac{1}{2}\\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] To eliminate the entry above the leading entry in column \\(2\\), we perform the operation \\(R_1 \\to R_1 - R_2\\), which gives \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 0 &amp; \\frac{1}{2} &amp; \\frac{3}{2}\\\\ 0 &amp; 1 &amp; \\frac{1}{2} &amp; \\frac{1}{2}\\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] Note that there is no leading entry in column three or in the solution vector, so there are infinitely many solutions, and we can take the variable \\(z\\) to be arbitrary, say \\(z=\\lambda\\). We then read off the solutions \\[ (x,y,z)=\\frac{1}{2}(3-\\lambda,1-\\lambda,2\\lambda). \\] For a particular solution, for instance let \\(\\lambda=0\\), we get \\[ (x,y,z)= \\frac{1}{2}(3,1,0). \\] We have the augmented matrix \\[ \\left(\\begin{array}{rrrr|r} 2 &amp; 4 &amp; 1 &amp; -3 &amp; 7 \\\\ 5 &amp; 10 &amp; 6 &amp; -4 &amp; 14 \\\\ 7 &amp; 14 &amp; 5 &amp; -9 &amp; 23 \\end{array}\\right). \\] Start with \\(R_2 \\to R_2 - \\frac{5}{2}R_1\\) and \\(R_3 \\to R_3 - \\frac{7}{2}R_1\\), which give \\[ \\left(\\begin{array}{rrrr|r} 2 &amp; 4 &amp; 1 &amp; -3 &amp; 7 \\\\ 0 &amp; 0 &amp; \\frac{7}{2} &amp; \\frac{7}{2} &amp; -\\frac{7}{2} \\\\ 0 &amp; 0 &amp; \\frac{3}{2} &amp; \\frac{3}{2} &amp; -\\frac{3}{2} \\end{array}\\right), \\] and perform \\(R_3 \\to R_3 - \\frac{3}{7}R_2\\), to have \\[ \\left(\\begin{array}{rrrr|r} 2 &amp; 4 &amp; 1 &amp; -3 &amp; 7 \\\\ 0 &amp; 0 &amp; \\frac{7}{2} &amp; \\frac{7}{2} &amp; -\\frac{7}{2} \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] The above is in echelon form. We see that the right-most column contains no leading entry and neither does (at least) one of the other columns. In this case, neither column 2 nor 4 of the matrix of coefficients contains a leading entry. This means that there will be infinitely many solutions. We proceed, scaling rows \\(1\\) and \\(2\\), i.e. applying \\(R_1 \\to \\frac{1}{2}R_1\\) and \\(R_2 \\to \\frac{2}{7}R_2\\), which give \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 2 &amp; \\frac{1}{2} &amp; -\\frac{3}{2} &amp; \\frac{7}{2} \\\\ 0 &amp; 0 &amp; 1 &amp; 1 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] Then, we bring the above matrix into reduced echelon form by performing \\(R_1 \\to R_1 - \\frac{1}{2}R_2\\), that is \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 2 &amp; 0 &amp; -2 &amp; 4 \\\\ 0 &amp; 0 &amp; 1 &amp; 1 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] Now we can easily read off the solutions. As there are 2 columns of the matrix of coefficients with no leading entry, two of the variables can be chosen arbitrarily. We take \\(y\\) and \\(t\\) to be arbitrary, say \\(y=\\lambda\\) and \\(t=\\mu\\). Then the frist and second rows give us the equations \\[ x = 4 - 2\\lambda + 2\\mu \\qquad \\text{and} \\qquad z = -1 - \\mu, \\] respectively. So the parameterised solution is \\[ (4 - 2\\lambda + 2\\mu, \\lambda, -1-\\mu, \\mu) \\] where \\(\\lambda\\), \\(\\mu\\) are arbitrary. For a particular solution, let for instance \\(\\lambda = y = 0\\) and \\(\\mu = t = 0\\) to give \\[ (x,y,z,t) = (4,0,-1,0). \\] We swap the rows initially to get the augmented matrix \\[ \\left(\\begin{array}{rrr|r} 1 &amp; -2 &amp; 1 &amp; 2\\\\ 3 &amp; 4 &amp; 0 &amp; 1\\\\ 2 &amp; -4 &amp; 2 &amp; 4\\\\ 3 &amp; 0 &amp; 1 &amp; 2 \\end{array}\\right) \\] To eliminate the entries below the leading entry in column \\(1\\), we perform \\(R_2 \\to R_2 - 3R_1\\), \\(R_3 \\to R_3-2R_1\\) and \\(R_4 \\to R_4-3R_1\\) to arrive at \\[ \\left(\\begin{array}{rrr|r} 1 &amp; -2 &amp; 1 &amp; 2\\\\ 0 &amp; 10 &amp; -3 &amp; -5\\\\ 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 6 &amp; -2 &amp; -4 \\end{array}\\right). \\] To eliminate the entry below the leading entry in column \\(2\\), we perform \\(R_4 \\to R_4 - \\frac{3}{5}R_2\\) to have \\[ \\left(\\begin{array}{rrr|r} 1 &amp; -2 &amp; 1 &amp; 2\\\\ 0 &amp; 10 &amp; -3 &amp; -5\\\\ 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; -\\frac{1}{5} &amp; -1 \\end{array}\\right). \\] Applying \\(R_3 \\leftrightarrow R_4\\), we obtain \\[ \\left(\\begin{array}{rrr|r} 1 &amp; -2 &amp; 1 &amp; 2\\\\ 0 &amp; 10 &amp; -3 &amp; -5\\\\ 0 &amp; 0 &amp; - \\frac{1}{5} &amp; -1\\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] The matrix is now in echelon form. We proceed to bring the matrix into reduced echelon form. Applying \\(R_3 \\to -5R_3\\), gives \\[ \\left(\\begin{array}{rrr|r} 1 &amp; -2 &amp; 1 &amp; 2\\\\ 0 &amp; 10 &amp; -3 &amp; -5\\\\ 0 &amp; 0 &amp; 1 &amp; 5\\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] To eliminate the entries above the leading entry in column \\(3\\), we perform \\(R_2 \\to R_2 + 3R_3\\) and \\(R_1 \\to R_1-1R_3\\) to arrive at \\[ \\left(\\begin{array}{rrr|r} 1 &amp; -2 &amp; 0 &amp; -3\\\\ 0 &amp; 10 &amp; 0 &amp; 10\\\\ 0 &amp; 0 &amp; 1 &amp; 5\\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] Applying \\(R_2 \\to \\frac{1}{10}R_2\\), gives \\[ \\left(\\begin{array}{rrr|r} 1 &amp; -2 &amp; 0 &amp; -3\\\\ 0 &amp; 1 &amp; 0 &amp; 1\\\\ 0 &amp; 0 &amp; 1 &amp; 5\\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] To eliminate the entry above the leading entry in column \\(2\\), we perform \\(R_1 \\to R_1 + 2R_2\\) to arrive at \\[ \\left(\\begin{array}{rrr|r} 1 &amp; 0 &amp; 0 &amp; -1\\\\ 0 &amp; 1 &amp; 0 &amp; 1\\\\ 0 &amp; 0 &amp; 1 &amp; 5\\\\ 0 &amp; 0 &amp; 0 &amp; 0 \\end{array}\\right). \\] This matrix is in reduced echelon form. Note that even though there is no leading entry in the right hand column, it is the case that every other column contains a leading entry. This means that there is a unique solution to this system of equations. We read off the solution \\[ (x,y,z) = (-1,1,5). \\] We swap the rows initially to get the augmented matrix \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 2 &amp; -1 &amp; 1 &amp; -3\\\\ 3 &amp; -1 &amp; 2 &amp; 1 &amp; 3\\\\ 3 &amp; 1 &amp; 1 &amp; 1 &amp; 0\\\\ 3 &amp; 2 &amp; 0 &amp; 1 &amp; -1 \\end{array}\\right) \\] To eliminate the entries below the leading entry in column \\(1\\), we perform \\(R_2 \\to R_2-3R_1\\), \\(R_3 \\to R_3-3R_1\\) and \\(R_4 \\to R_4-3R_1\\), which give \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 2 &amp; -1 &amp; 1 &amp; -3\\\\ 0 &amp; -7 &amp; 5 &amp; -2 &amp; 12\\\\ 0 &amp; -5 &amp; 4 &amp; -2 &amp; 9\\\\ 0 &amp; -4 &amp; 3 &amp; -2 &amp; 8 \\end{array}\\right). \\] To avoid fractions, we now perform \\(R_4 \\to R_4 - R_3\\) and then \\(R_4 \\leftrightarrow R_2\\) to obtain \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 2 &amp; -1 &amp; 1 &amp; -3\\\\ 0 &amp; 1 &amp; -1 &amp; 0 &amp; -1\\\\ 0 &amp; -5 &amp; 4 &amp; -2 &amp; 9\\\\ 0 &amp; -7 &amp; 5 &amp; -2 &amp; 12 \\end{array}\\right). \\] To eliminate the entries below the leading entry in column \\(2\\), we perform \\(R_3 \\to R_3 + 5R_2\\) and \\(R_4 \\to R_4+7R_2\\) to arrive at \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 2 &amp; -1 &amp; 1 &amp; -3\\\\ 0 &amp; 1 &amp; -1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; -1 &amp; -2 &amp; 4\\\\ 0 &amp; 0 &amp; -2 &amp; -2 &amp; 5 \\end{array}\\right). \\] To eliminate the entry under the leading entry in column \\(3\\), we perform \\(R_4 \\to R_4 - 2R_3\\) to have \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 2 &amp; -1 &amp; 1 &amp; -3\\\\ 0 &amp; 1 &amp; -1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; -1 &amp; -2 &amp; 4\\\\ 0 &amp; 0 &amp; 0 &amp; 2 &amp; -3 \\end{array}\\right). \\] The matrix is now in echelon form. We proceed to put the matrix into reduced echelon form. Applyin \\(R_4 \\to \\frac{1}{2}R_4\\) gives \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 2 &amp; -1 &amp; 1 &amp; -3\\\\ 0 &amp; 1 &amp; -1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; -1 &amp; -2 &amp; 4\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -\\frac{3}{2} \\end{array}\\right). \\] To eliminate the entries above the leading entry in column \\(4\\), we perform \\(R_3 \\to R_3 + 2R_4\\) and \\(R_1 \\to R_1 - R_4\\) to obtain \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 2 &amp; -1 &amp; 0 &amp; -\\frac{3}{2}\\\\ 0 &amp; 1 &amp; -1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; -1 &amp; 0 &amp; 1\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -\\frac{3}{2} \\end{array}\\right). \\] Perform by \\(R_3 \\to -R_3\\) to get \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 2 &amp; -1 &amp; 0 &amp; -\\frac{3}{2}\\\\ 0 &amp; 1 &amp; -1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -\\frac{3}{2} \\end{array}\\right). \\] To eliminate the entries above the leading entry in column \\(3\\), we perform \\(R_2 \\to R_2+R_3\\) and \\(R_1 \\to R_1+R_3\\) which give \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 2 &amp; 0 &amp; 0 &amp; -\\frac{5}{2}\\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; -2\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -\\frac{3}{2} \\end{array}\\right). \\] Then, we eliminate the entry above the leading entry in column \\(2\\), performing \\(R_1 \\to R_1 - 2R_2\\) and arrive at the reduced echolon form \\[ \\left(\\begin{array}{rrrr|r} 1 &amp; 0 &amp; 0 &amp; 0 &amp; \\frac{3}{2}\\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; -2\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -\\frac{3}{2} \\end{array}\\right). \\] We read off the (unique) solution \\[ (x,y,z,t) = \\left(\\tfrac{3}{2},-2,-1,-\\tfrac{3}{2}\\right). \\] Balancing chemical equations. In the combustion of propane gas, propane (\\(C_3H_8\\)) combines with oxygen (\\(O_2\\)) to form carbon dioxide (\\(CO_2\\)) and water (\\(H_2O\\)) according to the equation \\[x_1 C_3H_8 + x_2 O_2\\to x_3CO_2+x_4H_2O.\\] To balance this equation, we must find natural numbers \\(x_1, x_2, x_3, x_4\\) such that the total numbers of \\(C\\), \\(H\\) and \\(O\\) atoms are equal on both sides. Formulate this problem as a set of linear equations and solve using Guassian elimination. Answer: Write both the left and the right side of the chemical reaction equation as linear equations: \\[ \\begin{pmatrix} 3 &amp; 0 &amp; 0 &amp; 0\\\\ 8 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 2 &amp; 0 &amp; 0\\end{pmatrix} \\begin{pmatrix}x_1\\\\x_2\\\\x_3\\\\x_4\\end{pmatrix} = \\begin{pmatrix} 0 &amp; 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 2\\\\ 0 &amp; 0 &amp; 2 &amp; 1\\end{pmatrix}\\begin{pmatrix}x_1\\\\x_2\\\\x_3\\\\x_4\\end{pmatrix} \\] Now subtract one side from the other to give an equation equal to zero \\[ \\begin{pmatrix} 3 &amp; 0 &amp; -1 &amp; 0\\\\ 8 &amp; 0 &amp; 0 &amp; -2\\\\ 0 &amp; 2 &amp; -2 &amp; -1\\end{pmatrix}\\begin{pmatrix}x_1\\\\x_2\\\\x_3\\\\x_4\\end{pmatrix} = \\begin{pmatrix}0\\\\0\\\\0\\end{pmatrix} \\] with each row stating (respectively) that the number \\(C\\), \\(H\\), and \\(O\\) atoms are conserved as required. Next, we write the augmented matrix and perform Gaussian Elimination. \\[ R_2 \\rightarrow R_2 - \\frac{8}{3}R_1\\\\ \\left( \\begin{array}{c c c c | c} 3 &amp; 0 &amp; -1 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; \\frac{8}{3} &amp; -2 &amp; 0\\\\ 0 &amp; 2 &amp; -2 &amp; -1 &amp; 0\\end{array} \\right)\\\\ R_2 \\leftrightarrow R_3\\\\ \\left( \\begin{array}{c c c c | c} 3 &amp; 0 &amp; -1 &amp; 0 &amp; 0\\\\ 0 &amp; 2 &amp; -2 &amp; -1 &amp; 0\\\\ 0 &amp; 0 &amp; \\frac{8}{3} &amp; -2 &amp; 0 \\end{array} \\right)\\\\ R_1 \\rightarrow \\frac{1}{3}R_1,\\ R_2 \\rightarrow \\frac{1}{2}R_2,\\ R_3\\rightarrow \\frac{3}{8}R_3\\\\ \\left( \\begin{array}{c c c c | c} 1 &amp; 0 &amp; -\\frac{1}{3} &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; -1 &amp; -\\frac{1}{2} &amp; 0\\\\ 0 &amp; 0 &amp; 1 &amp; -\\frac{3}{4} &amp; 0\\end{array} \\right). \\] Which is in echelon form. To put into reduced echelon form, we need to work back up the rows and eliminate entries above the pivot, starting with rightmost leading value \\[ R_2 \\rightarrow R_2 + R_3\\\\ \\left(\\begin{array}{c c c c|c} 1 &amp; 0 &amp; -\\frac{1}{3} &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0 &amp; -\\frac{5}{4} &amp; 0\\\\ 0 &amp; 0 &amp; 1 &amp; -\\frac{3}{4} &amp; 0\\end{array}\\right)\\\\ R_1 \\rightarrow R_1 + \\frac{1}{3}R_3\\\\ \\left( \\begin{array}{c c c c|c} 1 &amp; 0 &amp; 0 &amp; -\\frac{1}{4} &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; -\\frac{5}{4} &amp; 0\\\\ 0 &amp; 0 &amp; 1 &amp; -\\frac{3}{4} &amp; 0\\end{array}\\right) \\] which is now in reduced echelon form with \\(x_4\\) being a free variable, which we call \\(\\alpha\\). Hence, the solutions are \\[ \\begin{align} x_1 &amp;= \\frac{1}{4}\\alpha\\\\ x_2 &amp;= \\frac{5}{4}\\alpha\\\\ x_3 &amp;= \\frac{3}{4}\\alpha\\\\ x_4 &amp; = \\alpha \\end{align} \\] The smallest \\(\\alpha\\) that gives all \\(x_i\\) as natural numbers is 4. Hence, \\((x_1,x_2,x_3,x_4) = (1,5,3,4)\\). It makes sense that one of the chemical amounts was a free variable, since it is the ratio of chemicals that is important in balancing the equations, not their absolute value. There were also only three linear equations in four unknowns, so a unique solution was not expected. Electrical networks. Consider the circuit diagram below. The voltage drop across a resistor is (by Ohm’s law) \\(V=IR\\) where \\(V\\) is in volts, the current \\(I\\) is in amps and the resistance \\(R\\) is in ohms. Kirchhoff’s junction law: the sum of currents flowing into a junction is equal to the sum of currents flowing out of that junction. Kirchoff’s Voltage law: The sum of the voltage drops in one direction around a loop equals the sum of the voltage sources in the same direction around the loop. Using these laws it is possible to derive the following set of linear equations for the currents \\(I_1, I_2, I_3\\): \\[\\begin{align*} 11I_1-3I_2&amp;=30\\\\ -3I_1+6I_2-I_3&amp;=5\\\\ -I_2+3I_3&amp;=-25. \\end{align*}\\] Determine the currents. (Extra challenge: derive the equations!). Answer: Form the linear equations into matrix form, and then perform Gaussian elimination on the augmented matrix. \\[ \\begin{pmatrix} 11 &amp; -3 &amp; 0 \\\\ -3 &amp; 6 &amp; -1 \\\\ 0 &amp; -1 &amp; 3\\end{pmatrix} \\begin{pmatrix}I_1\\\\I_2\\\\I_3\\end{pmatrix} = \\begin{pmatrix}30\\\\5\\\\-25\\end{pmatrix}\\\\ \\left(\\begin{array}{c c c | c} 11 &amp; -3 &amp; 0 &amp; 30 \\\\ -3 &amp; 6 &amp; -1 &amp; 5\\\\ 0 &amp; -1 &amp; 3 &amp; -25 \\end{array}\\right)\\\\ R_2 \\rightarrow R_2 + \\frac{3}{11}R_1\\\\ \\left(\\begin{array}{c c c | c} 11 &amp; -3 &amp; 0 &amp; 30 \\\\ 0 &amp; \\frac{57}{11} &amp; -1 &amp; \\frac{145}{11}\\\\ 0 &amp; -1 &amp; 3 &amp; -25\\end{array}\\right)\\\\ R_3 \\rightarrow R_3 + \\frac{11}{57}R_2\\\\ \\left(\\begin{array}{c c c | c} 11 &amp; -3 &amp; 0 &amp; 30\\\\ 0 &amp; \\frac{57}{11} &amp; -1 &amp; \\frac{145}{11}\\\\ 0 &amp; 0 &amp; \\frac{160}{57} &amp; -\\frac{1280}{57}\\end{array}\\right)\\\\ R_1 \\rightarrow \\frac{1}{11}R_1,\\ R_2 \\rightarrow \\frac{11}{57}R_2,\\ R_3 \\rightarrow \\frac{57}{160}R_3\\\\ \\left(\\begin{array}{c c c |c} 1 &amp; -\\frac{3}{11} &amp; 0 &amp; \\frac{30}{11}\\\\ 0 &amp; 1 &amp; -\\frac{11}{57} &amp; \\frac{145}{57}\\\\ 0 &amp; 0 &amp; 1 &amp; -8\\end{array}\\right) \\] This is now in echelon form, and can be brought to reduced echelon form by eliminating the column values above the pivot point, starting with the rightmost leading value. \\[ R_2 \\rightarrow R_2 + \\frac{11}{57}R_3\\\\ \\left(\\begin{array}{c c c |c} 1 &amp; -\\frac{3}{11} &amp; 0 &amp; \\frac{30}{11}\\\\ 0 &amp; 1 &amp; 0 &amp; 1\\\\ 0 &amp; 0 &amp; 1 &amp; -8\\end{array}\\right)\\\\ R_1 \\rightarrow R_1 + \\frac{3}{11}R_2\\\\ \\left(\\begin{array}{c c c |c} 1 &amp; 0 &amp; 0 &amp; 3\\\\ 0 &amp; 1 &amp; 0 &amp; 1\\\\ 0 &amp; 0 &amp; 1 &amp; -8\\end{array}\\right) \\] So \\(I_1 = 3, I_2 = 1, I_3 = -8\\). Network analysis. The diagram below represents the traffic flow in a one-way road network. Each directed edge represents a one-way road and is labelled with the flow through that road. The nodes represent road junctions. By considering the flow in and out of each node and the total flow in and out of the network, formulate a system of linear equations for the unknown flows \\(x_1,\\dotsc,x_5\\) and solve them by Gaussian elimination. You will find there is a “free variable”, but the requirement for non-negative flows puts some restrictions on the variables. In particular, what are the restrictions on \\(x_1\\) and \\(x_5\\)? Answer: The five equations characterising the flow of traffic on the network are \\[\\begin{align*} x_1 + x_2 &amp;= 30\\\\ x_2 + x_3 &amp;= 100\\\\ x_3 + 20 &amp;= x_4\\\\ x_4 + 10 &amp;= x_5\\\\ 100 + x_1 &amp;= x_5 \\end{align*}\\] the first four coming from conservation of flow in and out of each node and the last coming from the total flow in and out of the network. Which can be placed into augmented matrix form as \\[ \\left(\\begin{array}{c c c c c |c} 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 30\\\\ 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 100\\\\ 0 &amp; 0 &amp; -1 &amp; 1 &amp; 0 &amp; 20\\\\ 0 &amp; 0 &amp; 0 &amp; -1 &amp; 1 &amp; 10\\\\ -1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 100\\end{array}\\right), \\] which is already not far from echelon form. Due to the simple nature of the matrix, the bottom row can be eliminated with the following operations \\[ R_5 \\rightarrow R_5 + R_1 - R_2 - R_3 - R_4\\\\ \\left(\\begin{array}{c c c c c |c} 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 30\\\\ 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 100\\\\ 0 &amp; 0 &amp; -1 &amp; 1 &amp; 0 &amp; 20\\\\ 0 &amp; 0 &amp; 0 &amp; -1 &amp; 1 &amp; 10\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\end{array}\\right). \\] Now, to move to reduced echelon form \\[ R_3 \\rightarrow -R_3,\\ R_4 \\rightarrow -R_4\\\\ \\left(\\begin{array}{c c c c c |c} 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 30\\\\ 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 100\\\\ 0 &amp; 0 &amp; 1 &amp; -1 &amp; 0 &amp; -20\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -1 &amp; -10\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\end{array}\\right). \\] \\[ R_3 \\rightarrow R_3 + R_4\\\\ \\left(\\begin{array}{c c c c c |c} 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 30\\\\ 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 100\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 &amp; -30\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -1 &amp; -10\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\end{array}\\right)\\\\ R_2 \\rightarrow R_2 - R_3\\\\ \\left(\\begin{array}{c c c c c |c} 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 30\\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 130\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 &amp; -30\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -1 &amp; -10\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\end{array}\\right)\\\\ R_1 \\rightarrow R_1 - R_2\\\\ \\left(\\begin{array}{c c c c c |c} 1 &amp; 0 &amp; 0 &amp; 0 &amp; -1 &amp; -100\\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 130\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; -1 &amp; -30\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; -1 &amp; -10\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\end{array}\\right). \\] Here, \\(x_5\\) is a free variable, let’s call it \\(\\alpha\\). This means that the solutions for \\(x_1,x_2,x_3,x_4,x_5\\) are \\[ \\begin{align} x_1 &amp;= \\alpha - 100\\\\ x_2 &amp;= 130 - \\alpha\\\\ x_3 &amp;= -30 + \\alpha\\\\ x_4 &amp;= -10 + \\alpha\\\\ x_5 &amp;= \\alpha\\ . \\end{align} \\] The requirement for non-negative flows of cars means that \\(100\\leq \\alpha \\leq 130\\), hence \\(0\\leq x_1 \\leq 30\\) and \\(100 \\leq x_5 \\leq 130\\). This is reasonable since \\(x_5\\) can never be lower than the 100 flowing into the network on the left, and any contribution from \\(x_1\\) must also leave via \\(x_5\\). "],["exercise-set-8.html", "Exercise Set 8", " Exercise Set 8 Write down the \\(2\\times 2\\) matrix \\(R_\\pi\\) that rotates a vector anticlockwise by \\(\\pi\\). Apply this to a vector \\(\\mathbf{v}=\\left(\\begin{smallmatrix}v_1\\\\v_2\\end{smallmatrix}\\right)\\). Write down the \\(2\\times 2\\) matrix \\(M_x\\) that reflects a vector in the \\(x\\)-axis. Similarly write down the \\(2\\times 2\\) matrix \\(M_y\\) that reflects a vector in the \\(y\\)-axis. Multiply these two matrices to find the transformation that first reflects in the \\(x\\)-axis and then reflects in the \\(y\\)-axis. Compare this to the matrix \\(R_\\pi\\). Note that \\(R^2_\\theta=R_{2\\theta}\\) (why?). Use this to find the “double angle identity” for \\(\\cos\\) and \\(\\sin\\). Can you find other trigonometric identities using \\(R_\\theta\\)? For each of the following pairs of matrices \\(A\\) and \\(B\\), find (when possible), \\(A+B\\), \\(A-B\\), \\(A^2\\), \\(B^2\\), \\(AB\\), \\(BA\\). \\(A = \\begin{pmatrix} 2 &amp; 3 \\\\ 4 &amp; 1 \\end{pmatrix}\\qquad B = \\begin{pmatrix} -1 &amp; 2 \\\\ -2 &amp; 0 \\end{pmatrix}\\) \\(A = \\begin{pmatrix} 4 &amp; -5 \\\\ 6 &amp; 1 \\\\ 0 &amp; 1 \\end{pmatrix}\\qquad B = \\begin{pmatrix} 5 &amp; 2 &amp; -3 \\\\ 1 &amp; 3 &amp; -1 \\\\ 2 &amp; 2 &amp; -1 \\end{pmatrix}\\) \\(A = \\begin{pmatrix} 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1\\\\ 1 &amp; 0 &amp; 1 \\end{pmatrix} \\qquad B = \\begin{pmatrix} 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\end{pmatrix}\\) \\(A = \\begin{pmatrix} -1 &amp; 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 &amp; 1\\\\ 1 &amp; 0 &amp; 1 &amp; 0\\\\ 1 &amp; 1 &amp; 1 &amp; -1 \\end{pmatrix} \\qquad B = \\begin{pmatrix} 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; -1 &amp; 1 \\end{pmatrix}\\). Find two \\(3 \\times 3\\) matrices \\(A\\) and \\(B\\) such that \\(AB=BA\\). Now find two \\(3 \\times 3\\) matrices such that \\(AB\\neq BA\\). For any two numbers \\(a\\) and \\(b\\), if \\(ab=0\\) then at least one of \\(a\\) or \\(b\\) must be \\(0\\). Does an analagous result hold for matrices? That is, if \\(AB=0_{n\\times m}\\) must at least one of the matrices \\(A\\) or \\(B\\) be the zero matrix? Determine whether the following matrices are invertible or singular by computing their determinants. If they are invertible, find the inverse. \\(\\begin{pmatrix} 2 &amp; 1 \\\\ 1 &amp; 1 \\end{pmatrix}\\) \\(\\begin{pmatrix} 6 &amp; 3 \\\\ -4 &amp; -2 \\end{pmatrix}\\) \\(\\begin{pmatrix} 4 &amp; -28 &amp; 48 \\\\ -27 &amp; 162 &amp; -216 \\\\ 32 &amp; -160 &amp; 192 \\end{pmatrix}\\) \\(\\begin{pmatrix} \\cos(\\theta) &amp; -\\sin(\\theta) \\\\ \\sin(\\theta) &amp; \\cos(\\theta)\\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; 3 &amp; -5 \\\\ -2 &amp; 1 &amp; 4 \\\\ 1 &amp; 2 &amp; -4 \\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; -1 &amp; 4 \\\\ 2 &amp; 3 &amp; 3 \\\\ 3 &amp; 1 &amp; 8 \\end{pmatrix}\\) Find the eigenvalues and eigenvectors of each of the following matrices \\(A\\). Determine whether the matrix is diagonalisable and, if so, find the matrices \\(D\\) and \\(P\\) in the diagonalisation \\(D=P^{-1}AP\\). \\(\\begin{pmatrix} 1 &amp; 0 \\\\ 2 &amp; 2 \\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; 2 \\\\ 0 &amp; 1 \\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; 2 \\\\ 2 &amp; -2 \\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; -2 &amp; -1 \\\\ 2 &amp; 6 &amp; 2 \\\\ -1 &amp; -2 &amp; 1 \\end{pmatrix}\\) \\(\\begin{pmatrix} -2 &amp; 1 &amp; 1 \\\\ -11 &amp; 4 &amp; 5 \\\\ -1 &amp; 1 &amp; 0 \\end{pmatrix}\\) \\(\\begin{pmatrix} 2 &amp; \\sqrt 2 &amp; 0 \\\\ \\sqrt 2 &amp; 2 &amp; \\sqrt 2 \\\\ 0 &amp; \\sqrt 2 &amp; 2 \\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; -1 &amp; -1 \\\\ 1 &amp; -1 &amp; 0 \\\\ 1 &amp; 0 &amp; -1 \\end{pmatrix}\\) \\(\\begin{pmatrix} 5 &amp; 5 &amp; 1 \\\\ -2 &amp; -1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 \\end{pmatrix}\\). For the matrices in a. and d. in the previous question, find a formula for \\(A^n\\). Linear Difference Equations. A population of Wildebeest can be classified into two life stages: juvenile and adult. Each year \\(60\\%\\) of the juveniles survive to become adults, adults give birth on average to \\(0.5\\) juvelines and \\(70\\%\\) of adults survive the year. If there are \\(200\\) juveniles and \\(200\\) adults in one year, what is the long term population of juveniles and adults? What is the long term ratio of juveniles to adults? Hint: write this as a matrix equation and use diagonalisation (save some time and use a computer to find the eigenvalues and eigenvectors for this question). How about in the case when the adult survival rate increases to \\(80\\%\\)? In this case also give the long term growth rate of the juvenile and adult populations. What happens in the case that the adult survival rate drops to \\(60\\%\\)? "],["exercise-set-8-answers.html", "Exercise Set 8 Answers", " Exercise Set 8 Answers Write down the \\(2\\times 2\\) matrix \\(R_\\pi\\) that rotates a vector anticlockwise by \\(\\pi\\). Apply this to a vector \\(\\mathbf{v}=\\left(\\begin{smallmatrix}v_1\\\\v_2\\end{smallmatrix}\\right)\\). Answers: The matrix \\(R_\\theta\\) for anticlockwise rotation by angle \\(\\theta\\) is \\[ R_\\theta = \\begin{pmatrix}\\cos \\theta &amp; - \\sin \\theta \\\\ \\sin\\theta &amp; \\cos\\theta\\end{pmatrix}\\] So the matrix that rotates a vector anticlockwise by \\(\\pi\\) is \\[R_\\pi = \\begin{pmatrix}-1 &amp; 0 \\\\ 0 &amp; -1\\end{pmatrix}\\] Applying this to a vector: \\[\\begin{pmatrix}-1 &amp; 0 \\\\ 0 &amp; -1\\end{pmatrix}\\begin{pmatrix}v_1\\\\v_2\\end{pmatrix} = \\begin{pmatrix}-v_1\\\\-v_2\\end{pmatrix}\\] Write down the \\(2\\times 2\\) matrix \\(M_x\\) that reflects a vector in the \\(x\\)-axis. Similarly write down the \\(2\\times 2\\) matrix \\(M_y\\) that reflects a vector in the \\(y\\)-axis. Multiply these two matrices to find the transformation that first reflects in the \\(x\\)-axis and then reflects in the \\(y\\)-axis. Compare this to the matrix \\(R_\\pi\\). Answers: \\[M_x = \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; -1\\end{pmatrix}\\] \\[M_y = \\begin{pmatrix} -1 &amp; 0 \\\\0 &amp; 1\\end{pmatrix}\\] \\[M_xM_y = \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; -1\\end{pmatrix}\\begin{pmatrix} -1 &amp; 0 \\\\0 &amp; 1\\end{pmatrix} = \\begin{pmatrix}-1 &amp; 0 \\\\ 0 &amp; -1\\end{pmatrix} = R_\\pi\\] Note that \\(R^2_\\theta=R_{2\\theta}\\) (why?). Use this to find the “double angle identity” for \\(\\cos\\) and \\(\\sin\\). Can you find other trigonometric identities using \\(R_\\theta\\)? Answers: \\(R^2_\\theta=R_\\theta R_\\theta\\), that is, apply \\(R_\\theta\\) twice: this is the same as rotating by \\(2\\theta\\). \\[R_{2\\theta} = R_\\theta^2 = R_\\theta R_\\theta\\\\ \\begin{pmatrix}\\cos (2\\theta) &amp; -\\sin(2\\theta) \\\\ \\sin(2\\theta) &amp; \\cos(2\\theta)\\end{pmatrix} = \\begin{pmatrix}\\cos \\theta &amp; - \\sin \\theta \\\\ \\sin\\theta &amp; \\cos\\theta\\end{pmatrix}\\begin{pmatrix}\\cos \\theta &amp; - \\sin \\theta \\\\ \\sin\\theta &amp; \\cos\\theta\\end{pmatrix}\\\\ \\begin{pmatrix}\\cos (2\\theta) &amp; -\\sin(2\\theta) \\\\ \\sin(2\\theta) &amp; \\cos(2\\theta)\\end{pmatrix} = \\begin{pmatrix} \\cos^2(\\theta) - \\sin^2(\\theta) &amp; -2\\cos(\\theta)\\sin(\\theta) \\\\ 2\\cos(\\theta)\\sin(\\theta) &amp; \\cos^2(\\theta) - \\sin^2(\\theta)\\end{pmatrix}\\] Where each entry gives the double angle formula for \\(\\sin\\) and \\(\\cos\\). The general sum and difference identities for \\(\\sin\\) and \\(\\cos\\) can be derived by noting that \\(R_{a+b} = R_a R_b\\) and \\(R_{a-b} = R_a R_{-b}\\). Similarly, any identity for positive integer multiples \\(n\\theta\\) can be derived from \\(R_{n\\theta}=R^n_{\\theta}\\). For each of the following pairs of matrices \\(A\\) and \\(B\\), find (when possible), \\(A+B\\), \\(A-B\\), \\(A^2\\), \\(B^2\\), \\(AB\\), \\(BA\\). \\(A = \\begin{pmatrix} 2 &amp; 3 \\\\ 4 &amp; 1 \\end{pmatrix}\\qquad B = \\begin{pmatrix} -1 &amp; 2 \\\\ -2 &amp; 0 \\end{pmatrix}\\) \\(A = \\begin{pmatrix} 4 &amp; -5 \\\\ 6 &amp; 1 \\\\ 0 &amp; 1 \\end{pmatrix}\\qquad B = \\begin{pmatrix} 5 &amp; 2 &amp; -3 \\\\ 1 &amp; 3 &amp; -1 \\\\ 2 &amp; 2 &amp; -1 \\end{pmatrix}\\) \\(A = \\begin{pmatrix} 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1\\\\ 1 &amp; 0 &amp; 1 \\end{pmatrix} \\qquad B = \\begin{pmatrix} 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\end{pmatrix}\\) \\(A = \\begin{pmatrix} -1 &amp; 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 &amp; 1\\\\ 1 &amp; 0 &amp; 1 &amp; 0\\\\ 1 &amp; 1 &amp; 1 &amp; -1 \\end{pmatrix} \\qquad B = \\begin{pmatrix} 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; -1 &amp; 1 \\end{pmatrix}\\). Answers: We have \\[\\begin{align*} &amp;A + B = \\begin{pmatrix} 1 &amp; 5 \\\\ 2 &amp; 1 \\end{pmatrix}, \\qquad A - B = \\begin{pmatrix} 3 &amp; 1 \\\\ 6 &amp; 1 \\end{pmatrix}, \\\\ &amp;A^2 = \\begin{pmatrix} 16 &amp; 9 \\\\ 12 &amp; 13 \\end{pmatrix}, \\qquad B^2 = \\begin{pmatrix} -3 &amp; -2 \\\\ 2 &amp; -4 \\end{pmatrix},\\\\ &amp;AB = \\begin{pmatrix} -8 &amp; 4 \\\\ -6 &amp; 8\\end{pmatrix}, \\qquad BA = \\begin{pmatrix} 6 &amp; -1 \\\\ -4 &amp; -6 \\end{pmatrix}. \\end{align*}\\] Because \\(A\\) is a \\(3\\times 2\\) and \\(B\\) is a \\(3\\times 3\\) matrix, \\(A + B\\), \\(A - B\\), \\(A^2\\) and \\(AB\\) are not defined. We have \\[\\begin{align*} B^2 = \\begin{pmatrix} 21 &amp; 10 &amp; -14 \\\\ 6 &amp; 9 &amp; -5 \\\\ 10 &amp; 8 &amp; -7 \\end{pmatrix}, \\qquad BA = \\begin{pmatrix} 32 &amp; -26 \\\\ 22 &amp; -3 \\\\ 20 &amp; -9 \\end{pmatrix}. \\end{align*}\\] We have \\[\\begin{align*} &amp;A + B = \\begin{pmatrix} 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 \\\\ 2 &amp; 1 &amp; 1 \\end{pmatrix}, \\qquad A - B = \\begin{pmatrix} 1 &amp; 1 &amp; -1 \\\\ -1 &amp; 0 &amp; 1 \\\\ 0 &amp; -1 &amp; 1 \\end{pmatrix}, \\\\ &amp;A^2 = \\begin{pmatrix} 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 \\\\ 2 &amp; 1 &amp; 1 \\end{pmatrix}, \\qquad B^2 = \\begin{pmatrix} 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 \\end{pmatrix}, \\\\ &amp;AB = \\begin{pmatrix} 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 \\end{pmatrix}, \\qquad BA = \\begin{pmatrix} 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 \\end{pmatrix}. \\end{align*}\\] Because \\(A\\) is a \\(4\\times 4\\) and \\(B\\) is a \\(4\\times 3\\) matrix, \\(A + B\\), \\(A - B\\), \\(B^2\\), and \\(BA\\) are not defined. We have \\[\\begin{align*} A^2 = \\begin{pmatrix} 3 &amp; 0 &amp; 1 &amp; -2\\\\ 1 &amp; 2 &amp; 2 &amp; 0\\\\ 0 &amp; 1 &amp; 1 &amp; 1\\\\ 0 &amp; 0 &amp; 1 &amp; 1 \\end{pmatrix}, \\qquad AB = \\begin{pmatrix} 2 &amp; -1 &amp; 0\\\\ 2 &amp; 0 &amp; 2\\\\ 1 &amp; 1 &amp; 1\\\\ 1 &amp; 2 &amp; 0 \\end{pmatrix}. \\end{align*}\\] Find two \\(3 \\times 3\\) matrices \\(A\\) and \\(B\\) such that \\(AB=BA\\). Now find two \\(3 \\times 3\\) matrices such that \\(AB\\neq BA\\). Answers: Two diagonal matrices will always commute: \\[ \\begin{pmatrix}a &amp; 0 &amp; 0 \\\\ 0 &amp; b &amp; 0 \\\\ 0 &amp; 0 &amp; c\\end{pmatrix}\\begin{pmatrix}d &amp; 0 &amp; 0 \\\\ 0 &amp; e &amp; 0 \\\\ 0 &amp; 0 &amp; f\\end{pmatrix} = \\begin{pmatrix}d &amp; 0 &amp; 0 \\\\ 0 &amp; e &amp; 0 \\\\ 0 &amp; 0 &amp; f\\end{pmatrix} \\begin{pmatrix}a &amp; 0 &amp; 0 \\\\ 0 &amp; b &amp; 0 \\\\ 0 &amp; 0 &amp; c\\end{pmatrix} = \\begin{pmatrix}ad &amp; 0 &amp; 0 \\\\ 0 &amp; be &amp; 0 \\\\ 0 &amp; 0 &amp;cf\\end{pmatrix}\\] but there are also non-diagonal matrices that commute. Two matrices that do not commute are \\[A = \\begin{pmatrix}0 &amp; 0 &amp; a \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0\\end{pmatrix}, \\quad B = \\begin{pmatrix}0 &amp; 0 &amp; 0 \\\\0 &amp; 0 &amp; 0\\\\b &amp; 0 &amp; 0\\end{pmatrix}\\] \\[AB = \\begin{pmatrix}ab &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\neq BA = \\begin{pmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\\\0 &amp; 0 &amp; ab\\end{pmatrix}\\] For any two numbers \\(a\\) and \\(b\\), if \\(ab=0\\) then at least one of \\(a\\) or \\(b\\) must be \\(0\\). Does an analagous result hold for matrices? That is, if \\(AB=0_{n\\times m}\\) must at least one of the matrices \\(A\\) or \\(B\\) be the zero matrix? Answers: A similar result does not hold for matrices, neither \\(A\\) nor \\(B\\) must be zero if \\(AB=0_{n\\times m}\\). This occurs when the columns of \\(B\\) are in the null space of \\(A\\), that is to say, they are mapped to zero. For instance: \\[\\begin{pmatrix} a &amp; b &amp; 0 \\\\ c &amp; d &amp; 0 \\\\ e &amp; f &amp; 0\\end{pmatrix}\\begin{pmatrix}0 &amp; 0 \\\\ 0 &amp; 0 \\\\g &amp; h\\end{pmatrix} = \\begin{pmatrix} 0 &amp; 0 \\\\ 0 &amp; 0 \\\\ 0 &amp; 0 \\end{pmatrix}\\] Determine whether the following matrices are invertible or singular by computing their determinants. If they are invertible, find the inverse. \\(\\begin{pmatrix} 2 &amp; 1 \\\\ 1 &amp; 1 \\end{pmatrix}\\) \\(\\begin{pmatrix} 6 &amp; 3 \\\\ -4 &amp; -2 \\end{pmatrix}\\) \\(\\begin{pmatrix} 4 &amp; -28 &amp; 48 \\\\ -27 &amp; 162 &amp; -216 \\\\ 32 &amp; -160 &amp; 192 \\end{pmatrix}\\) \\(\\begin{pmatrix} \\cos(\\theta) &amp; -\\sin(\\theta) \\\\ \\sin(\\theta) &amp; \\cos(\\theta)\\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; 3 &amp; -5 \\\\ -2 &amp; 1 &amp; 4 \\\\ 1 &amp; 2 &amp; -4 \\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; -1 &amp; 4 \\\\ 2 &amp; 3 &amp; 3 \\\\ 3 &amp; 1 &amp; 8 \\end{pmatrix}\\) Answers: We have \\(\\det(A) = 2\\times 1 - 1\\times 1 = 1\\), so using the formula for the inverse of a \\(2\\times 2\\) matrix: \\[ A^{-1} = \\begin{pmatrix} 1 &amp; -1 \\\\ -1 &amp; 2 \\end{pmatrix}. \\] Alternatively, using the Gaussian elmination method \\[ \\left(\\begin{array}{cc|cc} 2 &amp; 1 &amp; 1 &amp; 0 \\\\ 1 &amp; 1 &amp; 0 &amp; 1 \\end{array}\\right), \\] we perform the EROs \\(R_1 \\to R_1 - R_2\\) and \\(R_2 \\to R_2 - R_1\\) to obtain \\[ \\left(\\begin{array}{cc|cc} 1 &amp; 0 &amp; 1 &amp; -1 \\\\ 0 &amp; 1 &amp; -1 &amp; 2 \\end{array}\\right), \\] as required. We have \\(\\det(A) = 0\\), so the matrix is singular. Alternatively, using the Gaussian elmination method \\[ \\left(\\begin{array}{cc|cc} 6 &amp; 3 &amp; 1 &amp; 0 \\\\ -4 &amp; -2 &amp; 0 &amp; 1 \\end{array}\\right), \\] we perform the EROs \\(R_1 \\to \\frac{1}{6}R_1\\) and then \\(R_2 \\to R_2 + 4R_1\\) to obtain \\[ \\left(\\begin{array}{cc|cc} 1 &amp; \\frac{1}{2} &amp; \\frac{1}{6} &amp; 0 \\\\ 0 &amp; 0 &amp; \\frac{4}{6} &amp; 1 \\end{array}\\right), \\] which has leading entries in the solution vectors, hence shows that the system of equations is inconsistent, and therefore that \\(A\\) is singular. We have the augmented matrix \\[ \\left(\\begin{array}{ccc|ccc} 4 &amp; -28 &amp; 48 &amp; 1 &amp; 0 &amp; 0\\\\ -27 &amp; 162 &amp; -216 &amp; 0 &amp; 1 &amp; 0\\\\ 32 &amp; -160 &amp; 192 &amp; 0 &amp; 0 &amp; 1 \\end{array}\\right). \\] Performing the EROs \\(R_1 \\to 27\\times 8\\times R_1\\), \\(R_2 \\to -32 R_2\\) and \\(R_3 \\to 27 R_3\\) gives \\[ \\left(\\begin{array}{ccc|ccc} 864 &amp; -6048 &amp; 10368 &amp; 216 &amp; 0 &amp; 0\\\\ 864 &amp; -5184 &amp; 6912 &amp; 0 &amp; -32 &amp; 0\\\\ 864 &amp; -4320 &amp; 5184 &amp; 0 &amp; 0 &amp; 27 \\end{array}\\right). \\] Then, performing \\(R_2 \\to R_2 - R_1\\) and \\(R_3 \\to R_3 - R_1\\) gives \\[ \\left(\\begin{array}{ccc|ccc} 864 &amp; -6048 &amp; 10368 &amp; 216 &amp; 0 &amp; 0\\\\ 0 &amp; 864 &amp; -3456 &amp; -216 &amp; -32 &amp; 0\\\\ 0 &amp; 1728 &amp; -5184 &amp; -216 &amp; 0 &amp; 27 \\end{array}\\right). \\] Then, performing \\(R_3 \\to R_3 + 2R_2\\) and \\(R_1 \\to R_1 + 7R_3\\) gives \\[ \\left(\\begin{array}{ccc|ccc} 864 &amp; 0 &amp; 13824 &amp; -1296 &amp; -224 &amp; 0\\\\ 0 &amp; 864 &amp; -3456 &amp; -216 &amp; -32 &amp; 0\\\\ 0 &amp; 0 &amp; 1728 &amp; 216 &amp; 64 &amp; 27 \\end{array}\\right). \\] Then, performing \\(R_1 \\to R_1 + 8R_3\\) and \\(R_2 \\to R_2 + 2R_3\\) gives \\[ \\left(\\begin{array}{ccc|ccc} 864 &amp; 0 &amp; 0 &amp; 432 &amp; 288 &amp; 216\\\\ 0 &amp; 864 &amp; 0 &amp; 216 &amp; 96 &amp; 54\\\\ 0 &amp; 0 &amp; 1728 &amp; 216 &amp; 64 &amp; 27 \\end{array}\\right). \\] Finally, performing \\(R_1 \\to \\frac{1}{864} R_1\\), \\(R_2 \\to \\frac{1}{864} R_2\\) and \\(R_3 \\to \\frac{1}{1728} R_3\\) gives \\[ \\left(\\begin{array}{ccc|ccc} 1 &amp; 0 &amp; 0 &amp; \\frac{1}{2} &amp; \\frac{1}{3} &amp; \\frac{1}{4}\\\\ 0 &amp; 1 &amp; 0 &amp; \\frac{1}{4} &amp; \\frac{1}{9} &amp; \\frac{1}{16}\\\\ 0 &amp; 0 &amp; 1 &amp; \\frac{1}{8} &amp; \\frac{1}{27} &amp; \\frac{1}{64} \\end{array}\\right) \\] and we read of \\[ A^{-1} = \\begin{pmatrix} \\frac{1}{2} &amp; \\frac{1}{3} &amp; \\frac{1}{4}\\\\ \\frac{1}{4} &amp; \\frac{1}{9} &amp; \\frac{1}{16}\\\\ \\frac{1}{8} &amp; \\frac{1}{27} &amp; \\frac{1}{64} \\end{pmatrix}. \\] We have \\(\\det(A) = \\cos^2 \\theta + \\sin^2 \\theta = 1\\), so \\[ A^{-1} = \\begin{pmatrix} \\cos(\\theta) &amp; \\sin(\\theta) \\\\ -\\sin(\\theta) &amp; \\cos(\\theta) \\end{pmatrix}. \\] Alternatively, using the Gaussian elmination method \\[ \\left(\\begin{array}{cc|cc} \\cos(\\theta) &amp; -\\sin(\\theta) &amp; 1 &amp; 0 \\\\ \\sin(\\theta) &amp; \\cos(\\theta) &amp; 0 &amp; 1 \\end{array}\\right), \\] we perform the EROs \\(R_1 \\to \\cos(\\theta)R_1\\), \\(R_2 \\to \\sin(\\theta)R_2\\) to obtain \\[ \\left(\\begin{array}{cc|cc} \\cos^2(\\theta) &amp; -\\cos(\\theta)\\sin(\\theta) &amp; \\cos(\\theta) &amp; 0 \\\\ \\sin^2(\\theta) &amp; \\cos(\\theta)\\sin(\\theta) &amp; 0 &amp; \\sin(\\theta) \\end{array}\\right), \\] and then \\(R_1 \\to R_1 + R_2\\) to obtain \\[ \\left(\\begin{array}{cc|cc} 1 &amp; 0 &amp; \\cos(\\theta) &amp; \\sin(\\theta) \\\\ \\sin^2(\\theta) &amp; \\cos(\\theta)\\sin(\\theta) &amp; 0 &amp; \\sin(\\theta) \\end{array}\\right), \\] and then \\(R_2 \\to R_2 - \\sin^2(\\theta)R_1\\) and \\(R_2 \\to \\frac{1}{\\sin(\\theta)\\cos(\\theta)}R_2\\) to arrive at \\[ \\left(\\begin{array}{cc|cc} 1 &amp; 0 &amp; \\cos(\\theta) &amp; \\sin(\\theta)\\\\ 0 &amp; 1 &amp; -\\sin(\\theta) &amp; \\frac{\\sin(\\theta)(1 - \\sin^2(\\theta))}{\\sin(\\theta)\\cos(\\theta)} \\end{array}\\right), \\] which, by substituting \\(1 = \\sin^2(\\theta) + \\cos^2(\\theta)\\) second entry of the fourth columns, is equal to \\[ \\left(\\begin{array}{cc|cc} 1 &amp; 0 &amp; \\cos(\\theta) &amp; \\sin(\\theta)\\\\ 0 &amp; 1 &amp; -\\sin(\\theta) &amp; \\cos(\\theta) \\end{array}\\right), \\] as required. Note that \\(A\\) is the rotation anticlockwise by an angle \\(\\theta\\) and \\(A^{-1}\\) is simply rotation clockwise by the angle \\(\\theta\\), i.e. the matrix \\(R_{-\\theta}\\) where one uses the facts that \\(\\cos(-\\theta)=\\cos(\\theta)\\) and \\(\\sin(-\\theta)=-\\sin(\\theta)\\). We have the augmented matrix \\[ \\left(\\begin{array}{ccc|ccc} 1 &amp; 3 &amp; -5 &amp; 1 &amp; 0 &amp; 0 \\\\ -2 &amp; 1 &amp; 4 &amp; 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 2 &amp; -4 &amp; 0 &amp; 0 &amp; 1 \\end{array}\\right). \\] We perform EROs \\(R_2 \\to R_2 + 2R_1\\) and \\(R_3 \\to R_3 - R_1\\) to obtain \\[ \\left(\\begin{array}{ccc|ccc} 1 &amp; 3 &amp; -5 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 7 &amp; -6 &amp; 2 &amp; 1 &amp; 0 \\\\ 0 &amp; -1 &amp; 1 &amp; -1 &amp; 0 &amp; 1 \\end{array}\\right) \\] Swap the second and third rows, i.e. perform ERO \\(R_2 \\leftrightarrow R_3\\), and the perform \\(R_2 \\to -R_2\\) to have \\[ \\left(\\begin{array}{ccc|ccc} 1 &amp; 3 &amp; -5 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; -1 &amp; 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 7 &amp; -6 &amp; 2 &amp; 1 &amp; 0 \\end{array}\\right). \\] Then, perform \\(R_3 \\to R_3 - 7R_2\\) and \\(R_1 \\to R_1 - 3R_2\\) to obtain \\[ \\left(\\begin{array}{ccc|ccc} 1 &amp; 0 &amp; -2 &amp; -2 &amp; 0 &amp; 3 \\\\ 0 &amp; 1 &amp; -1 &amp; 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 0 &amp; 1 &amp; -5 &amp; 1 &amp; 7 \\end{array}\\right). \\] Then, perform \\(R_1 \\to R_1 + 2R_3\\) and \\(R_2 \\to R_2 + R_3\\) to obtain \\[ \\left(\\begin{array}{ccc|ccc} 1 &amp; 0 &amp; 0 &amp; -12 &amp; 2 &amp; 17 \\\\ 0 &amp; 1 &amp; 0 &amp; -4 &amp; 1 &amp; 6 \\\\ 0 &amp; 0 &amp; 1 &amp; -5 &amp; 1 &amp; 7 \\end{array}\\right). \\] So \\[ A^{-1} = \\begin{pmatrix} -12 &amp; 2 &amp; 17 \\\\ -4 &amp; 1 &amp; 6\\\\ -5 &amp; 1 &amp; 7 \\end{pmatrix}. \\] We have the augmented matrix \\[ \\left(\\begin{array}{ccc|ccc} 1 &amp; -1 &amp; 4 &amp; 1 &amp; 0 &amp; 0 \\\\ 2 &amp; 3 &amp; 3 &amp; 0 &amp; 1 &amp; 0 \\\\ 3 &amp; 1 &amp; 8 &amp; 0 &amp; 0 &amp; 1 \\end{array}\\right). \\] We perform EROs \\(R_2 \\to R_2 - 2R_1\\) and \\(R_3 \\to R_3 - 3R_1\\) to obtain \\[ \\left(\\begin{array}{ccc|ccc} 1 &amp; -1 &amp; 4 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 5 &amp; -5 &amp; -2 &amp; 1 &amp; 0 \\\\ 0 &amp; 4 &amp; -4 &amp; -3 &amp; 0 &amp; 1 \\end{array}\\right), \\] Then, we perform \\(R_3 \\to R_3 - \\frac{4}{5}R_2\\) to obtain \\[ \\left(\\begin{array}{ccc|ccc} 1 &amp; -1 &amp; 4 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 5 &amp; -5 &amp; -2 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; -\\frac{7}{5} &amp; -\\frac{4}{5} &amp; 1 \\end{array}\\right), \\] which is in echelon form with (at least one) leading entries in the solution vectors, thus shows that the system of equations is inconsistent, therefore the matrix is singular. Find the eigenvalues and eigenvectors of each of the following matrices \\(A\\). Determine whether the matrix is diagonalisable and, if so, find the matrices \\(D\\) and \\(P\\) in the diagonalisation \\(D=P^{-1}AP\\). \\(\\begin{pmatrix} 1 &amp; 0 \\\\ 2 &amp; 2 \\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; 2 \\\\ 0 &amp; 1 \\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; 2 \\\\ 2 &amp; -2 \\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; -2 &amp; -1 \\\\ 2 &amp; 6 &amp; 2 \\\\ -1 &amp; -2 &amp; 1 \\end{pmatrix}\\) \\(\\begin{pmatrix} -2 &amp; 1 &amp; 1 \\\\ -11 &amp; 4 &amp; 5 \\\\ -1 &amp; 1 &amp; 0 \\end{pmatrix}\\) \\(\\begin{pmatrix} 2 &amp; \\sqrt 2 &amp; 0 \\\\ \\sqrt 2 &amp; 2 &amp; \\sqrt 2 \\\\ 0 &amp; \\sqrt 2 &amp; 2 \\end{pmatrix}\\) \\(\\begin{pmatrix} 1 &amp; -1 &amp; -1 \\\\ 1 &amp; -1 &amp; 0 \\\\ 1 &amp; 0 &amp; -1 \\end{pmatrix}\\) \\(\\begin{pmatrix} 5 &amp; 5 &amp; 1 \\\\ -2 &amp; -1 &amp; 0 \\\\ 1 &amp; 1 &amp; 1 \\end{pmatrix}\\). Answers: In the following, we always let \\(B_{\\lambda} = \\lambda I - A\\) and denote the characteristic polynomial \\(p_{A}(\\lambda) = \\det(\\lambda I - A)\\). The characteristic polynomial \\(p_{A}(\\lambda)\\) of \\(A\\) is defined by \\[ p_{A}(\\lambda) = \\begin{vmatrix} \\lambda - 1 &amp; 0 \\\\ -2 &amp; \\lambda - 2 \\end{vmatrix} = (\\lambda-1)(\\lambda-2). \\] Thus, the eigenvalues are \\(\\lambda_1 = 1\\) and \\(\\lambda_2 = 2\\). For \\(\\lambda_1 = 1\\), substitute \\(\\lambda = \\lambda_1 = 1\\) into \\(B_{\\lambda}\\) and solve \\(B_{1}\\mathbf{x} = \\mathbf{0}\\), that is \\[ \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 &amp; 0 \\\\ -2 &amp; -1 \\end{pmatrix}\\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -2x -y \\end{pmatrix}. \\] Thus, \\(y = -2x\\) (with \\(x\\) arbitrary) and the set of eigenvectors corresponding to the eigenvalue \\(\\lambda_1 = 1\\) is given by \\[ \\begin{pmatrix} \\alpha \\\\ -2\\alpha \\end{pmatrix} \\colon \\alpha \\neq 0. \\] For \\(\\lambda_2 = 2\\), substitute \\(\\lambda = \\lambda_2 = 2\\) into \\(B_{\\lambda}\\) and solve \\(B_{2}\\mathbf{x} = \\mathbf{0}\\), that is \\[ \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 &amp; 0 \\\\ -2 &amp; 0 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} x \\\\ -2x \\end{pmatrix}, \\] so the solution is \\(x = 0\\), with \\(y\\) arbitrary. The set of eigenvectors corresponding to the eigenvalue \\(\\lambda_2 = 2\\) is \\[ \\begin{pmatrix} 0 \\\\ \\beta \\end{pmatrix} \\colon \\beta \\neq 0 \\] Taking \\(\\alpha = \\beta = 1\\), we have the eigenvectors \\[ \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} \\qquad\\text{and} \\qquad \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\] corresponding to the eigenvalues \\(\\lambda_1 = 1\\) and \\(\\lambda_2 = 2\\), respectively. Let \\[ P = \\begin{pmatrix} 1 &amp; 0 \\\\ -2 &amp; 1 \\end{pmatrix}, \\] the matrix whose columns are the eigenvectors listed above. Then we have \\[ D = \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 2 \\end{pmatrix}. \\] We have \\[ p_{A}(\\lambda) = \\begin{vmatrix} \\lambda - 1 &amp; -2 \\\\ 0 &amp; \\lambda - 1 \\end{vmatrix} = (\\lambda - 1)^2. \\] so the only eigenvalue is \\(\\lambda = \\lambda_{1,2} = 1\\). To find the eigenvectors, we solve \\[ \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 &amp; -2 \\\\ 0 &amp; 0 \\end{pmatrix}\\begin{pmatrix} x \\\\ y \\end{pmatrix} = \\begin{pmatrix} -2y \\\\ 0 \\end{pmatrix}. \\] Thus, we have \\(y = 0\\) and the eigenvectors are given by the set \\[ \\begin{pmatrix} \\alpha \\\\ 0 \\end{pmatrix} \\colon \\alpha \\neq 0. \\] Since there is a repeated eigenvalue \\(\\lambda_{1,2} = 1\\) and there does not exists a set of two linearly independent eigenvectors for \\(\\lambda_{1,2}\\), \\(A\\) is not diagonalisable. We have \\[\\begin{align*} p_{A}(\\lambda) =\\det(\\lambda I - A) &amp;= \\begin{vmatrix} \\lambda-1 &amp; -2 \\\\ -2 &amp; \\lambda+2 \\end{vmatrix} \\\\ &amp;= (\\lambda-1)(\\lambda+2)-4 \\\\ &amp;= \\lambda^2+\\lambda-6 \\\\ &amp;= (\\lambda+3)(\\lambda-2), \\end{align*}\\] hence, the eigenvalues are \\(\\lambda_1 = -3\\) and \\(\\lambda_2 = 2\\). For \\(\\lambda_1 = -3\\), substitute \\(\\lambda = \\lambda_1 = -3\\) into \\(B_{\\lambda}\\) and solve \\(B_{-3}\\mathbf{x} = \\mathbf{0}\\), that is \\[ \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -4 &amp; -2 \\\\ -2 &amp; -1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix}. \\] We note that the top row is twice the bottom row, the solutions satisfy \\(y = -2x\\). We take \\(x = \\alpha\\) to be arbitrary, whence the set of eigenvectors corresponding to the eigenvalue \\(\\lambda_1 = -3\\) is \\[ \\begin{pmatrix} \\alpha \\\\ -2\\alpha \\end{pmatrix} \\colon \\alpha \\neq 0 \\] For \\(\\lambda_2 = 2\\), substitute \\(\\lambda = \\lambda_2 = 2\\) into \\(B_{\\lambda}\\) and solve \\(B_{2}\\mathbf{x} = \\mathbf{0}\\), that is \\[ \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 &amp; -2 \\\\ -2 &amp; 4 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix}. \\] Again, we note that the bottom row is \\(-2\\) times the top row, thus solutions satisfy \\(x = 2y\\). We take \\(y = \\beta\\) to be arbitrary, whence the set of eigenvectors corresponding to the eigenvalue \\(\\lambda_2 = 2\\) is \\[ \\begin{pmatrix} 2\\beta\\\\ \\beta \\end{pmatrix} \\colon \\beta \\neq 0. \\] Taking \\(\\alpha = \\beta = 1\\), we have the eigenvectors \\[ \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} \\qquad\\text{and}\\qquad \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} \\] corresponding to the eigenvalues \\(\\lambda_1 = -3\\) and \\(\\lambda_2 = 2\\), respectively. Let \\[ P = \\begin{pmatrix} 1 &amp; 2 \\\\ -2 &amp; 1 \\end{pmatrix}, \\] then we have \\[ D= \\begin{pmatrix} -3 &amp; 0 \\\\ 0 &amp; 2 \\end{pmatrix}. \\] We have \\[\\begin{align*} p_{A}(\\lambda) = \\det(\\lambda I - A) &amp;= \\begin{vmatrix} \\lambda-1 &amp; 2 &amp; 1 \\\\ -2 &amp; \\lambda - 6 &amp; -2 \\\\ 1 &amp; 2 &amp; \\lambda -1 \\end{vmatrix} \\\\ &amp;= (\\lambda-2)^2(\\lambda-4) \\end{align*}\\] hence, the eigenvalues are \\(\\lambda_{1,2} = 2\\) and \\(\\lambda_3 = 4\\) (note that there are only two distinct eigenvalues). For \\(\\lambda_{1,2} = 2\\), substitute \\(\\lambda = \\lambda_{1,2} = 2\\) into \\(B_{\\lambda}\\) and solve \\(B_{-3}\\mathbf{x} = \\mathbf{0}\\), that is \\[ \\begin{pmatrix} 0 \\\\ 0\\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 &amp; 2 &amp; 1 \\\\ -2 &amp; -4 &amp; -2 \\\\ 1 &amp; 2 &amp; 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix}. \\] Here the second and third rows are multiples of the first row, so the general solution to the above system of equations is \\(x + 2y + z = 0\\). We can take \\(y = \\alpha\\) and \\(z = \\beta\\) to be arbitrary, and get the set of corresponding eigenvectors \\[ \\begin{pmatrix} -2\\alpha-\\beta \\\\ \\alpha \\\\ \\beta \\end{pmatrix} \\colon \\text{$\\alpha, \\beta$ not both equal to zero.} \\] In particular, note that \\[ \\mathbf{v}_1 = \\begin{pmatrix} -2 \\\\ 1 \\\\ 0 \\end{pmatrix} \\qquad\\text{and}\\qquad \\mathbf{v}_2 = \\begin{pmatrix} -1 \\\\ 0 \\\\ 1 \\end{pmatrix} \\] are two linearly independent eigenvectors corresponding to the eigenvalue \\(\\lambda_{1,2} = 2\\), where we take \\((\\alpha,\\beta) = (1,0)\\) to get \\(\\mathbf{v}_1\\) and \\((\\alpha,\\beta) = (0,1)\\) to get \\(\\mathbf{v}_2\\). For \\(\\lambda_3 = 4\\), substitute \\(\\lambda = \\lambda_3 = 4\\) into \\(B_{\\lambda}\\) and solve \\(B_{4}\\mathbf{x} = \\mathbf{0}\\), that is \\[ \\begin{pmatrix} 0 \\\\ 0 \\\\ 0\\end{pmatrix} = \\begin{pmatrix} 3 &amp; 2 &amp; 1 \\\\ -2 &amp; -2 &amp; -2 \\\\ 1 &amp; 2 &amp; 3\\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix}. \\] Applying EROs \\(R_1 \\to R_1 - 3R_3\\) and \\(R_2 \\to R_2 + 2R_3\\) gives \\[ \\begin{pmatrix} 0 &amp; -4 &amp; -8 \\\\ 0 &amp; 2 &amp; 4 \\\\ 1 &amp; 2 &amp; 3 \\end{pmatrix}. \\] Then, applying \\(R_1 \\leftrightarrow R_3\\), \\(R_2 \\to \\frac{1}{2}R_2\\) and \\(R_3 \\to -\\frac{1}{4}R_3\\) gives \\[ \\begin{pmatrix} 1 &amp; 2 &amp; 3 \\\\ 0 &amp; 1 &amp; 2 \\\\ 0 &amp; 1 &amp; 2 \\end{pmatrix}, \\] and performing \\(R_3 \\to R_3 - R_2\\) and \\(R_1 \\to R_1 - 2R_2\\), we arrive at the reduced echelon form \\[ \\begin{pmatrix} 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 1 &amp; 2 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}. \\] There is no leading entry in the third column of the matrix of coefficients, so we may take \\(z = \\gamma\\) to be arbitrary and hence read off the the set of eigenvectors corresponding to the eigenvalue \\(\\lambda_3 = 4\\) as \\[ \\begin{pmatrix} \\gamma \\\\ -2 \\gamma \\\\ \\gamma \\end{pmatrix} \\colon \\gamma \\neq 0. \\] In particular, taking \\(\\gamma = 1\\), we get the eigenvector \\[ \\mathbf{v}_3 = \\begin{pmatrix} 1 \\\\ -2 \\\\ 1 \\end{pmatrix}. \\] We define the matrix \\(P\\) by \\[ P = (\\mathbf{v}_1 \\ \\mathbf{v}_2\\ \\mathbf{v}_3) = \\begin{pmatrix} -2 &amp; -1 &amp; 1\\\\ 1 &amp; 0 &amp; -2 \\\\ 0 &amp; 1 &amp; 1 \\end{pmatrix}, \\] then \\[ D = \\begin{pmatrix} 2 &amp; 0 &amp; 0 \\\\ 0 &amp; 2 &amp; 0 \\\\ 0 &amp; 0 &amp; 4 \\end{pmatrix} \\] Note: In this example, we are able to diagonalise the \\(3 \\times 3\\) matrix \\(A\\) even though it only had two distinct eigenvalues. This is because we can find two linearly independent eigenvectors corresponding to one of the eigenvalues. We have \\[\\begin{align*} p_{A}(\\lambda) &amp;= \\det(\\lambda I - A) &amp;= \\begin{vmatrix} \\lambda+2 &amp; -1 &amp; -1 \\\\ 11 &amp; \\lambda -4 &amp; -5 \\\\ 1 &amp; -1 &amp; \\lambda \\end{vmatrix}\\\\ &amp;= (\\lambda+1)(\\lambda-1)(\\lambda-2), \\end{align*}\\] hence the eigenvalues of \\(A\\) are \\(\\lambda_1 = -1\\), \\(\\lambda_2 = 1\\), and \\(\\lambda_3 = 2\\). For \\(\\lambda_1 = -1\\), we substitute \\(\\lambda = \\lambda_1 = -1\\) into the matrix \\(B_{\\lambda}\\) and solve \\(B_{-1}\\mathbf{x} = \\mathbf{0}\\). The augmented matrix is \\[ \\begin{pmatrix} 1 &amp; -1 &amp; -1 \\\\ 11 &amp; -5 &amp; -5 \\\\ 1 &amp; -1 &amp; -1 \\end{pmatrix} \\] We perform EROs as follows: \\[\\begin{align*} \\text{$R_2 \\to R_2 - 11R_1$ and $R_3 \\to R_3 - R_1$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; -1 &amp; -1\\\\ 0 &amp; 6 &amp; 6 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}; \\\\ \\text{$R_2 \\to \\frac{1}{6}R_2$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; -1 &amp; -1 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}; \\\\ \\text{$R_1 \\to R_1 + R_2$ and $R_3 \\to R_3 - R_1$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}. \\end{align*}\\] There is no leading entry in the last column so we take \\(z = \\alpha\\) to be arbitrary. The set of eigenvectors corresponding to the eigenvalue \\(\\lambda_1 = -1\\) is thus given by \\[ \\alpha \\begin{pmatrix} 0 \\\\ -1 \\\\ 1 \\end{pmatrix} \\colon \\alpha \\neq 0. \\] For \\(\\lambda_2 = 1\\), we substitute \\(\\lambda = \\lambda_2 = 1\\) into \\(B_{\\lambda}\\) and solve \\(B_{1}\\mathbf{x} = \\mathbf{0}\\). We have the augmented matrix \\[ \\begin{pmatrix} 3 &amp; -1 &amp; -1 \\\\ 11 &amp; -3 &amp; -5 \\\\ 1 &amp; -1 &amp; 1 \\\\ \\end{pmatrix}, \\] which we bring into reduced echelon form as follows: \\[\\begin{align*} \\text{$R_1 \\leftrightarrow R_3$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; -1 &amp; 1 \\\\ 11 &amp; -3 &amp; -5 \\\\ 3 &amp; -1 &amp; -1 \\end{pmatrix}; \\\\ \\text{$R_2 \\to R_2 - 11R_1$ and $R_3 \\to R_3 - 3R_1$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; -1 &amp; 1 \\\\ 0 &amp; 8 &amp; -16 \\\\ 0 &amp; 2 &amp; -4 \\end{pmatrix}; \\\\ \\text{$R_2 \\to R_2 - 11R_1$ and $R_3 \\to R_3 - R_1$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; -1 &amp; 1 \\\\ 0 &amp; 1 &amp; -2 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}; \\\\ \\text{$R_1 \\to R_1 + R_2$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 1 &amp; -2 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}. \\end{align*}\\] There is no leading entry in the last column so we take \\(z = \\beta\\) to be arbitrary. The set of eigenvectors corresponding to the eigenvalue \\(\\lambda_2 = 1\\) is thus given by \\[ \\beta \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix} \\colon \\beta \\neq 0. \\] For \\(\\lambda_3 = 2\\), we substitute \\(\\lambda = \\lambda_3 = 2\\) into \\(B_{\\lambda}\\) and solve \\(B_{3}\\mathbf{x} = \\mathbf{0}\\). We have the augmented matrix \\[ \\begin{pmatrix} 4 &amp; -1 &amp; -1 \\\\ 11 &amp; -2 &amp; -5 \\\\ 1 &amp; -1 &amp; 2 \\end{pmatrix} \\] which we transform into reduced echelon form via the following process: \\[\\begin{align*} \\text{$R_1 \\leftrightarrow R_3$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; -1 &amp; 2 \\\\ 11 &amp; -2 &amp; -5 \\\\ 4 &amp; -1 &amp; -1 \\end{pmatrix}; \\\\ \\text{$R_2 \\to R_2 - 11R_1$ and $R_3 \\to R_3 - 4R_1$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; -1 &amp; 2 \\\\ 0 &amp; 9 &amp; -27 \\\\ 0 &amp; 3 &amp; -9 \\end{pmatrix}; \\\\ \\text{$R_2 \\to \\frac{1}{9}R_2$ and $R_3 \\to R_3 - 3R_2$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; -1 &amp; 2 \\\\ 0 &amp; 1 &amp; -3 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}; \\\\ \\text{$R_1 \\to R_1 + R_2$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 1 &amp; -3 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}. \\end{align*}\\] Again, there is no leading entry in the last column, thus, taking \\(z = \\gamma\\), we read off that the set eigenvectors corresponding to \\(\\lambda_3 = 2\\) is given by \\[ \\gamma \\begin{pmatrix} 1 \\\\ 3 \\\\ 1 \\end{pmatrix} \\colon \\gamma\\neq 0. \\] Let \\[ P = (\\mathbf{v}_1 \\ \\ \\mathbf{v}_2 \\ \\ \\mathbf{v}_3) = \\begin{pmatrix} 0 &amp; 1 &amp; 1 \\\\ -1 &amp; 2 &amp; 3 \\\\ 1 &amp; 1 &amp; 1 \\end{pmatrix}, \\] where, for \\(\\alpha = \\beta = \\gamma = 1\\), \\(\\mathbf{v}_1, \\mathbf{v}_2\\), and \\(\\mathbf{v}_3\\) are eigenvectors corresponding to the eigenvalues \\(\\lambda_1\\), \\(\\lambda_2\\) and \\(\\lambda_3\\), respectively. Then \\[ P^{-1}AP = D, \\] where \\[ D = \\begin{pmatrix} -1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 2 \\end{pmatrix}. \\] We have \\[\\begin{align*} p_{A}(\\lambda) = \\det(\\lambda I - A) &amp;= \\begin{vmatrix} \\lambda-2 &amp; -\\sqrt{2} &amp; 0 \\\\ - \\sqrt{2} &amp; \\lambda -2 &amp; - \\sqrt{2} \\\\ 0 &amp; - \\sqrt{2} &amp; \\lambda - 2 \\end{vmatrix} \\\\ &amp;= (\\lambda-2)\\begin{vmatrix} \\lambda -2 &amp; -\\sqrt{2} \\\\ -\\sqrt{2} &amp; \\lambda -2 \\end{vmatrix} + \\sqrt{2} \\begin{vmatrix} -\\sqrt{2} &amp; - \\sqrt{2} \\\\ 0 &amp; \\lambda-2 \\end{vmatrix} \\\\ &amp;= (\\lambda-2)\\left[(\\lambda-2)^2-2\\right] + \\sqrt{2} \\left[-\\sqrt{2} (\\lambda-2) \\right] \\\\ &amp;= (\\lambda-2)\\left[ \\lambda^2 - 4 \\lambda\\right] \\\\ &amp;= \\lambda(\\lambda-2)(\\lambda-4), \\end{align*}\\] so the eigenvalues are \\(\\lambda_1=0\\), \\(\\lambda_2=2\\), and \\(\\lambda_3=4\\). For \\(\\lambda_1 = 0\\), we substitute \\(\\lambda = \\lambda_1 = 0\\) into \\(B_{\\lambda}\\) and solve \\(B_{0}\\mathbf{x} = \\mathbf{0}\\). We have the augmented matrix \\[ \\begin{pmatrix} -2 &amp; - \\sqrt{2} &amp; 0 \\\\ -\\sqrt{2} &amp; -2 &amp; -\\sqrt{2} \\\\ 0 &amp; -\\sqrt{2} &amp; -2 \\end{pmatrix} \\] which we bring into reduced echelon form as follows: \\[\\begin{align*} \\text{$R_1 \\leftrightarrow R_2$} \\colon\\quad &amp; \\begin{pmatrix} - \\sqrt{2} &amp; - 2 &amp; -\\sqrt{2} \\\\ -2 &amp; -\\sqrt{2} &amp; 0 \\\\ 0 &amp; -\\sqrt{2} &amp; -2 \\end{pmatrix};\\\\ \\text{$R_1 \\to -\\frac{1}{\\sqrt{2}}R_1$ and $R_2 \\to R_2 + 2R_1$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; \\sqrt{2} &amp; 1 \\\\ 0 &amp; \\sqrt{2} &amp; 2 \\\\ 0 &amp; -\\sqrt{2} &amp; -2 \\end{pmatrix}; \\\\ \\text{$R_1 \\to R_1 - R_2$ and $R_3 \\to R_3 + R_2$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; 0 &amp; -1 \\\\ 0 &amp; \\sqrt{2} &amp; 2 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}; \\\\ \\text{$R_2 \\to \\frac{1}{\\sqrt{2}}R_2$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 1 &amp; \\sqrt{2} \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\end{align*}\\] Thus, the eigenvectors corresponding to the eigenvalue \\(\\lambda_1=0\\) are given by as the set \\[ \\alpha \\begin{pmatrix} 1 \\\\ -\\sqrt{2} \\\\ 1 \\end{pmatrix} \\colon \\alpha \\neq 0. \\] Note, that this example shows that it is possible for an eigen to be zero, even though eigen are prohibited from being zero. Note also, that for any eigenvector \\(\\mathbf{x}\\) corresponding to a zero eigenvalue, we have \\(A\\mathbf{x} = \\mathbf{0}\\). For \\(\\lambda_2 = 2\\), we substitute \\(\\lambda = \\lambda_2 =2\\) into \\(B_{\\lambda}\\) and solve \\(B_2\\mathbf{x} = \\mathbf{0}\\). We have the augmented matrix \\[ \\begin{pmatrix} 0 &amp; -\\sqrt{2} &amp; 0 \\\\ -\\sqrt{2} &amp; 0 &amp; -\\sqrt{2} \\\\ 0 &amp; - \\sqrt{2} &amp; 0 \\end{pmatrix}, \\] which, applying EROs \\(R_1 \\leftrightarrow R_2\\) and \\(R_3 \\to R_3 - R_2\\) we transform to \\[ \\begin{pmatrix} -\\sqrt{2} &amp; 0 &amp; -\\sqrt{2} \\\\ 0 &amp; - \\sqrt{2} &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}, \\] and, performing \\(R_i \\to -\\frac{1}{\\sqrt{2}}R_i\\), for \\(i=1,2\\), to \\[ \\begin{pmatrix} 1 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}. \\] Thus, the set of eigenvectors corresponding to the eigenvalue \\(\\lambda_2 = 2\\), is given as \\[ \\beta \\begin{pmatrix} -1 \\\\0 \\\\ 1 \\end{pmatrix} \\colon \\beta \\neq 0. \\] For \\(\\lambda_3=4\\), we substitute \\(\\lambda = \\lambda_3 = 4\\) into the matrix \\(B_{\\lambda}\\) and solve \\(B_4\\mathbf{x} = \\mathbf{0}\\). We get the augmented matrix \\[ \\begin{pmatrix} 2 &amp; - \\sqrt{2} &amp; 0\\\\ - \\sqrt{2} &amp; 2 &amp; -\\sqrt{2} \\\\ 0 &amp; -\\sqrt{2} &amp; 2 \\end{pmatrix} \\] which, applying EROs, can be transformed into REF as follows: \\[\\begin{align*} \\text{$R_1 \\leftrightarrow R_2$} \\colon\\quad &amp; \\begin{pmatrix} -\\sqrt{2} &amp; 2 &amp; -\\sqrt{2} \\\\ 2 &amp; -\\sqrt{2} &amp; 0 \\\\ 0 &amp; -\\sqrt{2} &amp; 2 \\end{pmatrix} \\\\ \\text{$R_2 \\to R_2 + \\sqrt{2}R_1$} \\colon\\quad &amp; \\begin{pmatrix} -\\sqrt{2} &amp; 2 &amp; -\\sqrt{2} \\\\ 0 &amp; \\sqrt{2} &amp; - 2 \\\\ 0 &amp; -\\sqrt{2} &amp; 2 \\end{pmatrix} \\\\ \\text{$R_3 \\to R_3 + R_2$ and $R_1 \\to -\\frac{1}{\\sqrt{2}} R_1$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; -\\sqrt{2} &amp; 1 \\\\ 0 &amp; \\sqrt{2} &amp; - 2 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix} \\\\ \\text{$R_1 \\to R_1 + R_2$ and $R_2 \\to \\frac{1}{\\sqrt{2}} R_2$} \\colon\\quad &amp; \\begin{pmatrix} 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 1 &amp; -\\sqrt{2} \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}. \\end{align*}\\] Thus, the eigenvectors corresponding to the eigenvalue \\(\\lambda_3=4\\) are given by as the set \\[ \\gamma \\begin{pmatrix} 1 \\\\ \\sqrt{2} \\\\ 1 \\end{pmatrix} \\colon \\gamma \\neq 0. \\] Using \\(\\alpha = \\beta = \\gamma = 1\\) in the above sets to obtain particular eigenvectors \\(\\mathbf{v}_1, \\mathbf{v}_2\\) and \\(\\mathbf{v}_3\\), respectively, define the matrix \\(P\\) by \\[ P = (\\mathbf{v}_1 \\ \\ \\mathbf{v}_2 \\ \\ \\mathbf{v}_3) = \\begin{pmatrix} 1 &amp; -1 &amp; 1 \\\\ -\\sqrt{2} &amp; 0 &amp; \\sqrt{2} \\\\ 1 &amp; 1 &amp; 1 \\end{pmatrix}. \\] Then, \\[ P^{-1}AP = D, \\] where \\[ D = \\begin{pmatrix} 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 2 &amp; 0 \\\\ 0 &amp; 0 &amp; 4 \\end{pmatrix}. \\] We have \\[\\begin{align*} p_{A}(\\lambda) = \\det(\\lambda I - A) &amp;= \\begin{vmatrix} \\lambda-1 &amp; 1 &amp; 1 \\\\ -1 &amp; \\lambda+1 &amp; 0 \\\\ -1 &amp; 0 &amp; \\lambda +1 \\end{vmatrix}\\\\ &amp;= (\\lambda-1) \\begin{vmatrix} \\lambda +1 &amp; 0 \\\\ 0 &amp; \\lambda+1 \\end{vmatrix} - \\begin{vmatrix} -1 &amp; 0 \\\\ -1 &amp; \\lambda+1 \\end{vmatrix} + \\begin{vmatrix} -1 &amp; \\lambda+1 \\\\ -1 &amp; 0 \\end{vmatrix} \\\\ &amp;= (\\lambda-1)(\\lambda+1)^2 + (\\lambda+1) + (\\lambda+1) \\\\ &amp;= (\\lambda+1)(\\lambda^2+1), \\end{align*}\\] thus the eigenvalues are \\(\\lambda_1 = -1\\), \\(\\lambda_2 = i\\) and \\(\\lambda_3 = -i\\) (where \\(i^2=-1\\)). For \\(\\lambda_1 = -1\\), we substitute \\(\\lambda = \\lambda_1 = -1\\) into \\(B_{\\lambda}\\) and solve \\(B_{-1}\\mathbf{x} = \\mathbf{0}\\). We have the augmented matrix \\[ \\begin{pmatrix} -2 &amp; 1 &amp; 1 \\\\ -1 &amp; 0 &amp; 0 \\\\ -1 &amp; 0 &amp; 0 \\end{pmatrix}, \\] which we transform into reduced echelon form via \\(R_3 \\to R_3 - R_2\\), \\(R_1 \\to R_1 - 2R_2\\) and \\(R_1 \\leftrightarrow R_2\\) to obtain \\[ \\begin{pmatrix} -1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}, \\] and thus find the set of eigenvectors \\[ \\alpha \\begin{pmatrix} 0 \\\\ -1 \\\\ 1 \\end{pmatrix} \\colon \\alpha \\neq 0 \\] corresponding to \\(\\lambda_1 = -1\\). For \\(\\lambda_2 = i\\), we substitute \\(\\lambda = \\lambda_2 = i\\) into \\(B_{\\lambda}\\) and solve \\(B_{i}\\mathbf{x} = \\mathbf{0}\\). We have the augmented matrix \\[ \\begin{pmatrix} i-1 &amp; 1 &amp; 1 \\\\ -1 &amp; i+1 &amp; 0 \\\\ -1 &amp; 0 &amp; i+1 \\end{pmatrix}. \\] First, performing \\(R_1 \\leftrightarrow R_2\\), \\(R_2 \\to R_2 + (i-1)R_1\\) and \\(R_3 \\to R_3 - R_1\\) gives \\[ \\begin{pmatrix} -1 &amp; i+1 &amp; 0 \\\\ 0 &amp; 1 + (i+1)(i-1) &amp; 1 \\\\ 0 &amp; -i-1 &amp; i+1 \\end{pmatrix} = \\begin{pmatrix} -1 &amp; i+1 &amp; 0 \\\\ 0 &amp; -1 &amp; 1 \\\\ 0 &amp; -(i+1) &amp; i+1 \\end{pmatrix}, \\] and applying \\(R_3 \\to R_3 - (i+1)R_2\\) and \\(R_1 \\to R_1 + (i+1)R_2\\) gives \\[ \\begin{pmatrix} -1 &amp; 0 &amp; (i+1) \\\\ 0 &amp; -1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}, \\] which is in REF and thus we find the set of eigenvectors \\[ \\beta \\begin{pmatrix} (i+1) \\\\ 1 \\\\ 1 \\end{pmatrix} \\colon \\beta \\neq 0 \\] corresponding to \\(\\lambda_2 = i\\). For \\(\\lambda_3 = -i\\), we substitute \\(\\lambda = \\lambda_3 = -i\\) into \\(B_{\\lambda}\\) and solve \\(B_{-i}\\mathbf{x} = \\mathbf{0}\\). We have the augmented matrix \\[ \\begin{pmatrix} -i-1 &amp; 1 &amp; 1 \\\\ -1 &amp; -i+1 &amp; 0 \\\\ -1 &amp; 0 &amp; -i+1 \\end{pmatrix}. \\] First, performing \\(R_1 \\leftrightarrow R_2\\), \\(R_2 \\to R_2 - (i+1)R_1\\) and \\(R_3 \\to R_3 - R_1\\) gives \\[ \\begin{pmatrix} -1 &amp; -(i-1) &amp; 0 \\\\ 0 &amp; 1 + (i+1)(i-1) &amp; 1 \\\\ 0 &amp; i-1 &amp; -i+1 \\end{pmatrix} = \\begin{pmatrix} -1 &amp; -(i-1) &amp; 0 \\\\ 0 &amp; -1 &amp; 1 \\\\ 0 &amp; i-1 &amp; -(i-1) \\end{pmatrix}, \\] and applying \\(R_3 \\to R_3 + (i-1)R_2\\) and \\(R_1 \\to R_1 - (i-1)R_2\\) gives \\[ \\begin{pmatrix} -1 &amp; 0 &amp; -(i-1) \\\\ 0 &amp; -1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}, \\] which is in REF and thus we find the set of eigenvectors \\[ \\gamma \\begin{pmatrix} -(i-1) \\\\ 1 \\\\ 1 \\end{pmatrix} \\colon \\gamma \\neq 0 \\] corresponding to \\(\\lambda_3 = -i\\). Setting \\(\\alpha = \\beta = \\gamma = 1\\), we find that the matrix \\[ P = \\begin{pmatrix} 0 &amp; i+1 &amp; -i+1 \\\\ -1 &amp; 1 &amp; 1 \\\\ 1 &amp; 1 &amp; 1 \\end{pmatrix} \\] satisfies \\[ P^{-1}AP = D, \\] where \\[ D = \\begin{pmatrix} -1 &amp; 0 &amp; 0 \\\\ 0 &amp; i &amp; 0 \\\\ 0 &amp; 0 &amp; -i \\end{pmatrix}. \\] We have \\[\\begin{align*} p_{A}(\\lambda) = \\det(\\lambda I - A) &amp;= \\begin{vmatrix} \\lambda-5 &amp; -5 &amp; -1 \\\\ 2 &amp; \\lambda+1 &amp; 0 \\\\ -1 &amp; -1 &amp; \\lambda-1 \\end{vmatrix}\\\\ &amp;= (\\lambda-5)\\begin{vmatrix} \\lambda+1 &amp; 0 \\\\ -1 &amp; \\lambda-1 \\end{vmatrix} - (-5) \\begin{vmatrix} 2 &amp; 0 \\\\ -1 &amp; \\lambda-1 \\end{vmatrix} \\\\ &amp;\\phantom{={}} + (-1) \\begin{vmatrix} 2 &amp; \\lambda+1 \\\\ -1 &amp; -1 \\end{vmatrix} \\\\ &amp;= (\\lambda-5)(\\lambda+1)(\\lambda-1) + 5(2(\\lambda-1)) - (-2 + \\lambda + 1) \\\\ &amp;= (\\lambda-1)\\big((\\lambda-5)(\\lambda+1) + 10 - 1\\big) \\\\ &amp;= (\\lambda-1)\\big(\\lambda^2 - 4\\lambda + 4\\big) \\\\ &amp;= (\\lambda-1)(\\lambda - 2)^2, \\end{align*}\\] thus the eigenvalues are \\(\\lambda_1 = 1\\), \\(\\lambda_{2,3} = 2\\). For \\(\\lambda_1 = 1\\), we substitute \\(\\lambda = \\lambda_1 = 1\\) into \\(B_{\\lambda}\\) and solve \\(B_{1}\\mathbf{x} = \\mathbf{0}\\). We have the augmented matrix \\[ \\begin{pmatrix} -4 &amp; -5 &amp; -1 \\\\ 2 &amp; 2 &amp; 0 \\\\ -1 &amp; -1 &amp; 0 \\end{pmatrix}. \\] Applying EROs \\(R_1 \\to R_1 + 2R_2\\) and \\(R_3 \\to R_3 + \\frac{1}{2}R_2\\) gives \\[ \\begin{pmatrix} 0 &amp; -1 &amp; -1 \\\\ 2 &amp; 2 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}. \\] Performing \\(R_1 \\leftrightarrow R_2\\), \\(R_1 \\to R_1 + 2R_2\\) and \\(R_1 \\to \\frac{1}{2}R_1\\) and \\(R_2 \\to -R_2\\) gives \\[ \\begin{pmatrix} 1 &amp; 0 &amp; -1 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}, \\] which is in REF and thus we find the set of eigenvectors \\[ \\alpha\\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\end{pmatrix} \\colon \\alpha \\neq 0 \\] corresponding to \\(\\lambda_1 = 1\\). For \\(\\lambda_{2,3} = 2\\), we substitute \\(\\lambda = \\lambda_{2,3} = 2\\) into \\(B_{\\lambda}\\) and solve \\(B_{2}\\mathbf{x} = \\mathbf{0}\\). We have the augmented matrix \\[ \\begin{pmatrix} -3 &amp; -5 &amp; -1 \\\\ 2 &amp; 3 &amp; 0 \\\\ -1 &amp; -1 &amp; 1 \\end{pmatrix}. \\] Performing \\(R_1\\leftrightarrow R_3\\), \\(R_2 \\to R_2 + 2R_1\\) and \\(R_3 \\to R_3 - 3R_1\\), we have \\[ \\begin{pmatrix} -1 &amp; -1 &amp; 1 \\\\ 0 &amp; 1 &amp; 2 \\\\ 0 &amp; -2 &amp; -4 \\end{pmatrix}, \\] and further, performing \\(R_3 \\to R_3 + 2R_2\\), \\(R_1 \\to -R_1\\) and \\(R_1 \\to R_1 - R_2\\) gives \\[ \\begin{pmatrix} 1 &amp; 0 &amp; -3 \\\\ 0 &amp; 1 &amp; 2 \\\\ 0 &amp; 0 &amp; 0 \\end{pmatrix}, \\] which is in REF and thus we find the set of eigenvectors \\[ \\beta\\begin{pmatrix} 3 \\\\ -2 \\\\ 1 \\end{pmatrix} \\colon \\beta \\neq 0 \\] corresponding to \\(\\lambda_{2,3} = 2\\). This shows that there are only two linearly independent eigenvectors, hence \\(A\\) is not diagonalisable. For the matrices in a. and d. in the previous question, find a formula for \\(A^n\\). Answers: First, note that \\(P^{-1}AP = D\\) and thus \\(A = PDP^{-1}\\). Then, \\[\\begin{align*} A^2 &amp;= \\left(PDP^{-1}\\right)^2 \\\\ &amp;= \\left(PDP^{-1}\\right)\\left(PDP^{-1}\\right) \\\\ &amp;= PDP^{-1}PDP^{-1} \\\\ &amp;= PD I_n DP^{-1} \\\\ &amp;= P D^{2} P^{-1}. \\end{align*}\\] and more generally \\(A^n = P D^{n} P^{-1}\\). Now for a. \\[\\begin{align*} A^n &amp;= \\begin{pmatrix} 1 &amp; 0 \\\\ -2 &amp; 1 \\end{pmatrix} \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 2^n \\end{pmatrix} \\begin{pmatrix} 1 &amp; 0 \\\\ 2 &amp; 1\\end{pmatrix} \\\\ &amp;= \\begin{pmatrix} 1 &amp; 0 \\\\ -2 &amp; 2^n \\end{pmatrix} \\begin{pmatrix} 1 &amp; 0 \\\\ 2 &amp; 1 \\end{pmatrix} \\\\ &amp;= \\begin{pmatrix} 1 &amp; 0 \\\\ 2^{n+1}-2 &amp; 2^n \\end{pmatrix}. \\end{align*}\\] For d., first compute \\(P^{-1}\\) using Gaussian elimination. Starting with the augmented matrix \\[\\left(\\begin{array}{rrr|rrr} 2 &amp; -1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\\\ -1 &amp; 0 &amp; -2 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 \\end{array}\\right).\\] Applying \\(R_1 \\leftrightarrow R_2\\) gives \\[\\left(\\begin{array}{rrr|rrr} -1 &amp; 0 &amp; -2 &amp; 0 &amp; 1 &amp; 0 \\\\ 2 &amp; -1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 \\end{array}\\right),\\] performing \\(R_2 \\to R_2 + 2R_1\\) gives \\[\\left(\\begin{array}{rrr|rrr} -1 &amp; 0 &amp; -2 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; -1 &amp; -3 &amp; 1 &amp; 2 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 \\end{array}\\right),\\] performing \\(R_3 \\to R_3 + R_2\\) gives \\[\\left(\\begin{array}{rrr|rrr} -1 &amp; 0 &amp; -2 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; -1 &amp; -3 &amp; 1 &amp; 2 &amp; 0 \\\\ 0 &amp; 0 &amp; -2 &amp; 1 &amp; 2 &amp; 1 \\end{array}\\right),\\] performing \\(R_1 \\to -R_1\\), \\(R_2 \\to -R_2\\) and \\(R_3 \\to -\\frac{1}{2}R_3\\) gives \\[\\left(\\begin{array}{rrr|rrr} 1 &amp; 0 &amp; 2 &amp; 0 &amp; -1 &amp; 0 \\\\ 0 &amp; 1 &amp; 3 &amp; -1 &amp; -2 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; -\\frac{1}{2} &amp; -1 &amp; -\\frac{1}{2} \\end{array}\\right),\\] and with \\(R_2 \\to R_2 - 3R_3\\) and \\(R_1 \\to R_1 - 2R_3\\) we arrive at \\[\\left(\\begin{array}{rrr|rrr} 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 &amp; \\frac{1}{2} &amp; 1 &amp; \\frac{3}{2} \\\\ 0 &amp; 0 &amp; 1 &amp; -\\frac{1}{2} &amp; -1 &amp; -\\frac{1}{2} \\end{array}\\right).\\] We deduce that \\[ P^{-1} = \\frac{1}{2} \\begin{pmatrix} 2 &amp; 2 &amp; 2 \\\\ 1 &amp; 2 &amp; 3 \\\\ -1 &amp; -2 &amp; -1 \\end{pmatrix}. \\] We have \\[ D^n = \\begin{pmatrix} 2^n &amp; 0 &amp; 0\\\\ 0 &amp; 2^n &amp; 0 \\\\ 0 &amp; 0 &amp; 4^n \\end{pmatrix}, \\] and so \\[\\begin{align*} A^n &amp;= P D^n P^{-1} \\\\ &amp;=\\frac{1}{2} \\begin{pmatrix} 2^{n+2}-2^n-4^n &amp;2^{n+2}-2^{n+1}-2^{2 n+1} &amp; 2^{n+2}-3\\times 2^n-4^n \\\\ -2^{n+1}+2^{2 n+1} &amp;-2^{n+1}+2^{2 n+2} &amp;-2^{n+1}+2^{2 n+1} \\\\ 2^n-4^n &amp; 2^{n+1}-2^{2 n+1} &amp; 3\\times 2^n-4^n \\end{pmatrix}. \\end{align*}\\] Linear Difference Equations. A population of Wildebeest can be classified into two life stages: juvenile and adult. Each year \\(60\\%\\) of the juveniles survive to become adults, adults give birth on average to \\(0.5\\) juvelines and \\(70\\%\\) of adults survive the year. If there are \\(200\\) juveniles and \\(200\\) adults in one year, what is the long term population of juveniles and adults? What is the long term ratio of juveniles to adults? Hint: write this as a matrix equation and use diagonalisation (save some time and use a computer to find the eigenvalues and eigenvectors for this question). How about in the case when the adult survival rate increases to \\(80\\%\\)? In this case also give the long term growth rate of the juvenile and adult populations. What happens in the case that the adult survival rate drops to \\(60\\%\\)? Answers: Let \\(x_1(n)\\) denote the population of juveniles and \\(x_2(n)\\) the population of adults in year \\(n\\). Then we can formulate this as the coupled system of linear difference equations: \\[ \\begin{pmatrix} x_1(n)\\\\ x_2(n) \\end{pmatrix} = \\begin{pmatrix} 0&amp;0.5\\\\ 0.6&amp;0.7 \\end{pmatrix} \\begin{pmatrix} x_1(n-1)\\\\ x_2(n-1) \\end{pmatrix}. \\] Let \\[ \\mathbf{x}(n)= \\begin{pmatrix} x_1(n)\\\\ x_2(n) \\end{pmatrix} \\quad \\text{and} \\quad A= \\begin{pmatrix} 0&amp;0.5\\\\ 0.6&amp;0.7 \\end{pmatrix} \\] then the solution is \\[ \\mathbf{x}(n)=A^n\\mathbf{x}(0). \\] If the matrix \\(A\\) is diagonalisable, then we can find \\(A^n\\) by diagonalisation. We find that \\(A\\) has eigenvalues \\(\\lambda_1=1\\) and \\(\\lambda_2=-\\frac{3}{10}\\) with corresponding eigenvectors \\[\\mathbf{v}_1=\\begin{pmatrix}1\\\\2\\end{pmatrix},\\quad \\mathbf{v}_2\\begin{pmatrix}1\\\\-3/5\\end{pmatrix}.\\] So \\[ A^n=\\frac{1}{13} \\begin{pmatrix} 1&amp;1\\\\ 2&amp;-\\frac{3}{5} \\end{pmatrix} \\begin{pmatrix} 1&amp;0\\\\ 0&amp;-\\frac{3}{10} \\end{pmatrix}^n \\begin{pmatrix} 3&amp;5\\\\ 10&amp;-5 \\end{pmatrix} \\] and \\[\\begin{align} \\mathbf{x}(n)&amp;=\\frac{1}{13}\\times 1^n \\times (3x_1(0)+5x_2(0)) \\begin{pmatrix} 1\\\\ 2 \\end{pmatrix} \\\\ &amp;+\\frac{1}{13}\\times\\left(-\\frac{3}{10}\\right)^n\\times(10x_1(0)-5x_2(0)) \\begin{pmatrix} 1\\\\ -\\frac{3}{5} \\end{pmatrix}\\tag{22.1} \\end{align}\\] or writing each population separately \\[ \\begin{aligned} x_1(n)&amp;=\\frac{1}{13}(3x_1(0)+5x_2(0))+\\frac{1}{13}\\left(-\\frac{3}{10}\\right)^n(10x_1(0)-5x_2(0))\\\\ x_2(n)&amp;=\\frac{2}{13}(3x_1(0)+5x_2(0))+\\frac{1}{13}\\left(-\\frac{3}{10}\\right)^n\\left( -\\frac{3}{5}\\right)(10x_1(0)-5x_2(0)). \\end{aligned} \\] From (22.1) we can see that in the long term the populations settle down to: \\[\\begin{equation} \\lim\\limits_{n\\to\\infty}\\mathbf{x}(n)=\\frac{1}{13}(3x_1(0)+5x_2(0)) \\begin{pmatrix} 1\\\\ 2 \\end{pmatrix}\\tag{22.2} \\end{equation}\\] that is, \\[\\begin{align*} \\lim\\limits_{n\\to\\infty}x_1(n)&amp;=\\frac{1}{13}(3x_1(0)+5x_2(0))\\approx 123,\\\\ \\lim\\limits_{n\\to\\infty}x_2(n)&amp;=\\frac{2}{13}(3x_1(0)+5x_2(0))\\approx 246. \\end{align*}\\] From (22.2) the long term ratio of juveniles to adults is \\[ \\lim\\limits_{n\\to\\infty}\\frac{x_1(n)}{x_2(n)}=\\frac{1}{2} \\] i.e. \\(1:2\\). Now when the survival rate increases to 80% the matrix \\(A\\) becomes \\[ A= \\begin{pmatrix} 0&amp;0.5\\\\ 0.6&amp;0.8 \\end{pmatrix} \\] which is still diagonalisable and has eigenvalues and corresponding eigenvectors \\[\\begin{align*} \\lambda_1=\\frac{1}{10} (4 + \\sqrt{46})\\approx 1.08,\\quad &amp; \\quad\\lambda_2=\\frac{1}{10} (4 - \\sqrt{46})\\approx-0.28,\\\\ \\mathbf{v}_1= \\begin{pmatrix} \\frac{1}{6}(-4 + \\sqrt{46})\\\\ 1 \\end{pmatrix},\\quad &amp; \\quad \\mathbf{v}_2=\\begin{pmatrix} \\frac{1}{6}(-4 - \\sqrt{46})\\\\ 1 \\end{pmatrix}. \\end{align*}\\] If we let \\(\\mathcal{P}=(\\mathbf{v}_1,\\mathbf{v}_2)\\) and write \\[ \\mathbf{x}(0)_\\mathcal{P}=\\begin{pmatrix} \\mu_1\\\\ \\mu_2 \\end{pmatrix} \\] then \\[ \\mathbf{x}(n)=\\mu_1\\lambda_1^n\\mathbf{v}_1+\\mu_2\\lambda_2^n\\mathbf{v}_2. \\] Since \\(|\\lambda_1|&gt;1\\) and \\(|\\lambda_2|&lt;1\\), for large \\(n\\) \\[ \\mathbf{x}(n)\\approx\\mu_1\\lambda_1^nv_1 \\] and hence both \\(x_1(n)\\to\\infty\\) and \\(x_2(n)\\to \\infty\\), with the long term ratio \\(x_1:x_2\\) being \\(\\frac{1}{6}(-4 + \\sqrt{46}):1\\), or approximately \\(1:2.2\\). In the case that the adult survival rate drops to 60%, we have \\[ A= \\begin{pmatrix} 0&amp;0.5\\\\ 0.6&amp;0.6 \\end{pmatrix} \\] which is diagonalisable and has eigenvalues and corresponding eigenvectors \\[\\begin{align*} \\lambda_1=\\frac{1}{10} (3 + \\sqrt{39})\\approx 0.92,\\quad &amp; \\quad\\lambda_2=\\frac{1}{10} (3 - \\sqrt{39})\\approx-0.32,\\\\ \\mathbf{v}_1= \\begin{pmatrix} \\frac{1}{6}(-3 + \\sqrt{39})\\\\ 1 \\end{pmatrix},\\quad &amp; \\quad \\mathbf{v}_2=\\begin{pmatrix} \\frac{1}{6}(-3 - \\sqrt{39})\\\\ 1 \\end{pmatrix}. \\end{align*}\\] If we let \\(\\mathcal{P}=(\\mathbf{v}_1,\\mathbf{v}_2)\\) and write \\[ \\mathbf{x}(0)_\\mathcal{P}=\\begin{pmatrix} \\mu_1\\\\ \\mu_2 \\end{pmatrix} \\] then \\[ \\mathbf{x}(n)=\\mu_1\\lambda_1^nv_1+\\mu_2\\lambda_2^nv_2, \\] but now since both \\(|\\lambda_1|&lt;1\\) and \\(|\\lambda_2|&lt;1\\), \\[ \\lim\\limits_{n\\to\\infty}x(n)=\\lim\\limits_{n\\to\\infty}\\begin{pmatrix} x_1(n)\\\\ x_2(n) \\end{pmatrix} = \\begin{pmatrix} 0\\\\ 0 \\end{pmatrix} \\] and the population dies out. "],["exercise-set-9.html", "Exercise Set 9", " Exercise Set 9 Find the first and second dervatives of the following expressions. \\(y=3x^5+2x-1\\) \\(y=4x^{-1}\\) \\(y=x^{\\frac{1}{2}}+x^{\\frac{1}{3}}\\) \\(y=x^7+\\sin(x)\\) \\(y=e^x+5\\) Find the derivative of \\((1+2x)(x-x^2)\\) in two ways: first, expand and find the derivative; second, use the product rule. Your answers should agree! Use the product rule to show that \\((af)&#39;(x)=af&#39;(x)\\) for any differentiable function \\(f\\) and number \\(a\\). Use the chain rule to show that \\((f(ax+b))&#39;=af&#39;(ax+b)\\) for any differentiable function \\(f\\) and numbers \\(a\\) and \\(b\\). Find the derivatives of the following functions (you may like to use the additional rules you have just derived in the previous two questions). \\(f(x)=\\sqrt{2}\\sin(x)\\) \\(f(x)=\\ln(2)\\ln(x)\\) \\(f(x)=\\cos(3x)\\) \\(f(x)=\\sin(5x+2)\\) \\(f(x)=3e^{2x}\\) \\(f(x)=3e^{2x+1}\\) Find the derivatives of the following functions using the product rule. \\(f(x)=3x^2\\sin(x)\\) \\(f(x)=\\sin(x)\\cos(x)\\) \\(f(x)=(x^3-x)e^x\\) \\(f(x)=x\\ln(x)\\) Find the derivatives of the following functions using the chain rule. \\(f(x)=\\cos(x^2)\\) \\(f(x)=\\sin(\\cos(x))\\) \\(f(x)=e^{\\sin(x)}\\) \\(f(x)=\\sin^{100}(x)\\) Find the derivatives of the following functions using the quotient rule. \\(f(x)=\\dfrac{1}{1+x^2}\\) \\(f(x)=\\dfrac{x^2}{1+x^2}\\) \\(f(x)=\\dfrac{x^3}{e^{3x}}\\) \\(f(x)=\\dfrac{x-\\sqrt{x}}{x^2}\\) \\(f(x)=\\dfrac{\\sin(x)}{\\cos(x)}\\) Find the derivatives of the following functions. \\(f(x)=\\sin^2(\\sin(x))\\) \\(f(x)=\\ln(x^2)\\) \\(f(x)=a^x\\) for any \\(a&gt;0\\) \\(f(x)=e^x\\sin(x^2)\\) Show that \\(\\frac{d}{dx}\\sinh(x)=\\cosh(x)\\) and \\(\\frac{d}{dx}\\cosh(x)=\\sinh(x)\\). Find all local maxima and minima of the following functions. Are there any global maxima or minima? Also sketch their graphs. \\(f(x)=x^2+3x+1\\) \\(f(x)=x^3-3x\\) A particle moving in a straight line has displacement \\(x\\) as a function of time \\(t\\geq 0\\) given by \\[x=-t^{3}+5t^{2}+t.\\] Find the velocity \\(v\\) and acceleration \\(a\\). What is the initial velocity? What is the largest positive displacement? At what time does the particle return to the origin? Find the points of inflection of the following functions. \\(f(x)=\\dfrac{x^3}{3}-\\dfrac{x^2}{2}-2x+5\\) \\(f(x)=x+\\sin(x)\\) A rectangular box with no lid is made from a thin sheet of metal. The base is \\(2x\\text{ mm}\\) long and \\(x\\text{ mm}\\) wide, and the volume is \\(48000\\text{ mm}^3\\). Show that the area \\(A\\) of metal used is given by \\[A=2x^2+144000x^{-1} \\text{ mm}^2.\\] Find the value of \\(x\\) for which the minimum area of metal is used along with the value of the minimum area. "],["exercise-set-9-answers.html", "Exercise Set 9 Answers", " Exercise Set 9 Answers Find the first and second dervatives of the following expressions. \\(y=3x^5+2x-1\\) \\(y=4x^{-1}\\) \\(y=x^{\\frac{1}{2}}+x^{\\frac{1}{3}}\\) \\(y=x^7+\\sin(x)\\) \\(y=e^x+5\\) Answers: \\[\\begin{align*} y &amp;= 3x^5 + 2x -1$\\\\ \\frac{dy}{dx} &amp;= 15x + 2\\\\ \\frac{d^2y}{dx^2} &amp;= 15 \\end{align*}\\] \\[\\begin{align*} y&amp;=4x^{-1}\\\\ \\frac{dy}{dx} &amp;= -4x^{-2}\\\\ \\frac{d^2y}{dx^2} &amp;= 8x^{-3} \\end{align*}\\] \\[\\begin{align*} y &amp;= x^\\frac{1}{2} + x^\\frac{1}{3}\\\\ \\frac{dy}{dx} &amp;= \\frac{1}{2}x^{-\\frac{1}{2}} + \\frac{1}{3}x^{-\\frac{2}{3}}\\\\ \\frac{d^2y}{dx^2} &amp;= -\\frac{1}{4}x^{-\\frac{3}{2}} + -\\frac{2}{9}x^{-\\frac{5}{3}} \\end{align*}\\] \\[\\begin{align*} y &amp;= x^6 \\sin(x)\\\\ \\frac{dy}{dx} &amp;= 7x^6 + \\cos (x)\\\\ \\frac{d^2y}{dx^2} &amp;= 42x^5 - \\sin(x) \\end{align*}\\] \\[\\begin{align*} y &amp;= e^x + 5\\\\ \\frac{dy}{dx} &amp;= e^x\\\\ \\frac{d^2y}{dx^2} &amp;= e^x \\end{align*}\\] Find the derivative of \\((1+2x)(x-x^2)\\) in two ways: first, expand and find the derivative; second, use the product rule. Your answers should agree! Answer: Method 1, expand and find the derivative: \\[\\begin{align*} y &amp;= (1+2x)(x-x^2)\\\\ &amp;=x - x^2 + 2x^2 - 2x^3\\\\ &amp;=-2x^3 + x^2 + x\\\\ \\frac{dy}{dx} &amp;= -6x^2 + 2x + 1 \\end{align*}\\] Method 2, product rule. Let \\(y=h(x) = f(x)g(x)\\) where \\(f(x) = (1+2x)\\) and \\(g(x) = (x-x^2)\\) \\[\\begin{align*} y &amp;= (1+2x)(x-x^2)\\\\ y&#39; &amp;= 2(x-x^2)+(1+2x)(1-2x)\\\\ &amp;=-6x^2 + 2x + 1 \\end{align*}\\] And as expected, we have obtained the same answer with both methods. Use the product rule to show that \\((af)&#39;(x)=af&#39;(x)\\) for any differentiable function \\(f\\) and number \\(a\\). Answer: We wish to show that \\((af)&#39;(x) = a f(x)\\), or in Leibniz notation, \\(\\frac{d}{dx}af(x)=a \\frac{d}{dx}f(x)\\). This can be shown using product rule, where one of the functions is \\(f(x)\\) and the other is simply the constant function \\(g(x)=a\\) \\[\\begin{align*} (gf)&#39;(x) &amp;= g(x)&#39; f(x) + g(x)f&#39;(x)\\\\ &amp;= 0f(x)+g(x)f&#39;(x)\\\\ &amp;=a f&#39;(x) \\end{align*}\\] or in Leibniz notation \\[\\begin{align*} \\frac{d}{dx}(g(x)f(x))&amp;=\\frac{d}{dx}(g(x))f(x)+g(x)\\frac{d}{dx}f(x)\\\\ &amp;=0f(x)+g(x)\\frac{d}{dx}f(x)\\\\ &amp;=a\\frac{d}{dx}f(x) \\end{align*}\\] using \\(g&#39;(x)=\\frac{d}{dx}g(x)=0\\) because the derivative of a constant function is zero. Use the chain rule to show that \\((f(ax+b))&#39;=af&#39;(ax+b)\\) for any differentiable function \\(f\\) and numbers \\(a\\) and \\(b\\). Answer: To show \\((f(ax+b))&#39; = a f&#39;(ax+b)\\), we can recognise the derivative as an application of chain rule: \\((f(g(x)))&#39; = g&#39;(x)f&#39;(g(x))\\), where \\(g(x) = ax+b\\). Since \\(g&#39;(x) = a\\), we have that \\[(f(ax+b))&#39;= a (f&#39;(ax+b))\\] Find the derivatives of the following functions (you may like to use the additional rules you have just derived in the previous two questions). \\(f(x)=\\sqrt{2}\\sin(x)\\) \\(f(x)=\\ln(2)\\ln(x)\\) \\(f(x)=\\cos(3x)\\) \\(f(x)=\\sin(5x+2)\\) \\(f(x)=3e^{2x}\\) \\(f(x)=3e^{2x+1}\\) Answers: \\[f(x)= \\sqrt{2} \\sin (x)\\\\ f&#39;(x) = \\sqrt{2} \\cos (x)\\] \\[f(x) = \\ln (2) \\ln(x)\\\\ f&#39;(x) = \\frac{\\ln 2}{x}\\] \\[f(x) = \\cos (3x)\\\\ f&#39;(x) = -3 \\sin (3x)\\] \\[f(x) = \\sin (5x+2)\\\\ f&#39;(x) = 5 \\cos (5x+2)\\] \\[f(x) = 3e^{2x}\\\\ f&#39;(x) = 6e^{2x}\\] \\[f(x) = 3e^{2x+1}\\\\ f&#39;(x) = 6e^{2x+1}\\] Find the derivatives of the following functions using the product rule. \\(f(x)=3x^2\\sin(x)\\) \\(f(x)=\\sin(x)\\cos(x)\\) \\(f(x)=(x^3-x)e^x\\) \\(f(x)=x\\ln(x)\\) Answers: \\[f(x) = 3x^2 \\sin (x)\\\\ f&#39;(x) = 6x \\sin(x) + 3x^2 \\cos(x)\\] \\[ f(x) = \\sin(x)\\cos(x) \\quad(=\\frac{1}{2}\\sin(2x))\\\\ f&#39;(x) = \\cos^2(x) - \\sin^2(x) = \\cos(2x)\\] \\[f(x) = (x^3 - x)e^x\\\\ f&#39;(x) = (3x^2 - 1)e^x + (x^3 - x)e^x\\\\ = (x^3 + 3x^2 - x - 1)e^x\\] \\[f(x) = x \\ln (x)\\\\ f&#39;(x) = \\ln(x) + 1\\] Find the derivatives of the following functions using the chain rule. \\(f(x)=\\cos(x^2)\\) \\(f(x)=\\sin(\\cos(x))\\) \\(f(x)=e^{\\sin(x)}\\) \\(f(x)=\\sin^{100}(x)\\) Answers: These are all applications of chain rule for taking derivatives of functions of the from \\(f(x) = h(g(x))\\) This is a composition of two functions, \\(h(x) = \\cos(x)\\), \\(g(x) = x^2\\) \\[f&#39;(x) = -2x \\sin(x^2)\\] Taking the derivative of \\(h(g(x))\\) where \\(h(x) = \\sin(x)\\) and \\(g(x) = \\cos(x)\\) \\[f&#39;(x) = -\\sin(x)\\cos(\\cos(x))\\] \\(f&#39;(x) = (h(g(x)))&#39;\\) where \\(h(x) = e^x\\) and \\(g(x) = \\sin(x)\\) \\[f&#39;(x) = \\cos(x)e^{\\sin(x)}\\] Here, \\(h(x) = x^{100}\\) and \\(g(x) = \\sin(x)\\) \\[f&#39;(x) = 100\\cos(x)\\sin^{99}(x)\\] Find the derivatives of the following functions using the quotient rule. \\(f(x)=\\dfrac{1}{1+x^2}\\) \\(f(x)=\\dfrac{x^2}{1+x^2}\\) \\(f(x)=\\dfrac{x^3}{e^{3x}}\\) \\(f(x)=\\dfrac{x-\\sqrt{x}}{x^2}\\) \\(f(x)=\\dfrac{\\sin(x)}{\\cos(x)}\\) Answers: \\(f(x) = \\frac{1}{1+x^2}\\). Applying quotient rule: \\[f&#39;(x) = \\frac{-2x}{(1+x^2)^2}\\] \\(f(x) = \\frac{x^2}{1+x^2}\\). \\[f&#39;(x) = \\frac{2x(1+x^2) - x^2(2x)}{(1+x^2)^2} = \\frac{2x}{(1+x^2)^2}\\] \\(f(x) = \\frac{x^3}{e^{3x}}\\) \\[f&#39;(x) = \\frac{3x^2 \\times e^{3x} - x^3\\times 3e^{3x}}{e^{6x}} = \\frac{3(x-1)x^2}{e^{3x}}\\] \\(f(x) = \\frac{x-x^{\\frac{1}{2}}}{x^2}\\) \\[f&#39;(x) = \\frac{(1-\\frac{1}{2}x^{-\\frac{1}{2}})\\times x^2 - (x-x^\\frac{1}{2})\\times 2x}{x^4}\\\\ = \\frac{x^2 - \\frac{1}{2}x^{\\frac{3}{2}} - 2x^2 + 2x^{\\frac{3}{3}}}{x^4}\\\\ =\\frac{-x^2 + \\frac{3}{2}x^{\\frac{3}{2}}}{x^4} = -x^{-2} + \\frac{3}{2}x^{-\\frac{5}{2}}\\] \\(f(x) = \\frac{\\sin(x)}{\\cos{x}}\\) \\[f&#39;(x) = \\frac{\\cos^2(x) + \\sin^2(x)}{\\cos^2 (x)} = \\frac{1}{\\cos^2(x)} = \\sec^2(x)\\] Find the derivatives of the following functions. \\(f(x)=\\sin^2(\\sin(x))\\) \\(f(x)=\\ln(x^2)\\) \\(f(x)=a^x\\) for any \\(a&gt;0\\) \\(f(x)=e^x\\sin(x^2)\\) Answers: We recognise this as a composition of three functions \\(f(x)=s(t(u(x)))\\) with \\(u(x)=\\sin(x)\\) \\(t(x)=\\sin(x)\\) \\(s(x)=x^2\\) First applying the chain rule to \\(s\\) and \\(t\\) \\[\\frac{df(x)}{dx}=\\frac{ds(t)}{dt}\\frac{dt(u(x))}{dx}\\] Then applying the chain rule to \\(t\\) and \\(u\\) \\[\\frac{df(x)}{dx}=\\frac{ds(t)}{dt}\\left(\\frac{dt(u)}{du}\\frac{du(x)}{dx}\\right)\\] so we have \\[\\frac{df(x)}{dx}=2\\sin(\\sin(x))\\times \\cos(\\sin(x))\\times\\cos(x).\\] We could first turn the power into a product to obtain \\(f(x)=2\\ln(x)\\), then the derivative is \\[\\frac{df(x)}{dx}=2\\frac{1}{x}.\\] Alternatively, we could use the chain rule. Letting \\(u(x)=x^2\\) we have \\[\\begin{align*} \\frac{df(x)}{dx}&amp;=\\frac{\\ln(u)}{du}\\frac{du(x)}{dx}\\\\ &amp;=\\frac{1}{u}2x\\\\ &amp;=\\frac{2x}{x^2}\\\\ &amp;=\\frac{2}{x}. \\end{align*}\\] We can use the natural logarithm to obtain \\[f(x)=e^{\\ln(a^x)}=e^{x\\ln(a)}.\\] Then \\[\\frac{df(x)}{dx}=\\ln(a)e^{x\\ln(a)}=\\ln(a)e^{\\ln(a^x)}=\\ln(a)a^x.\\] We have \\(f(x)=s(x)t(u(x))\\) with \\(s(x)=e^x\\), \\(t(x)=\\sin(x)\\), \\(u(x)=x^2\\). We have a product and a composition. First applying the product rule \\[\\frac{df(x)}{dx}=\\frac{ds(x)}{dx}t(u(x))+s(x)\\frac{dt(u(x))}{dx}.\\] Then appying the chain rule \\[ \\frac{df(x)}{dx}=\\frac{ds(x)}{dx}t(u(x))+s(x)\\frac{dt(u)}{du}\\frac{du(x)}{dx}.\\] So, we have \\[\\begin{align*} \\frac{df(x)}{dx}&amp;=e^x\\sin(x^2)+e^x\\cos(x^2)2x\\\\ &amp;=e^x(\\sin(x^2)+2x\\cos(x^2)) \\end{align*}\\] Show that \\(\\frac{d}{dx}\\sinh(x)=\\cosh(x)\\) and \\(\\frac{d}{dx}\\cosh(x)=\\sinh(x)\\). Answer: \\(\\dfrac{d}{dx}\\sinh(ax)=\\dfrac{d}{dx}\\dfrac{e^{ax}-e^{-ax}}{2}=\\dfrac{ae^{ax}-(-a)e^{-ax}}{2}=a\\dfrac{e^{ax}+e^{-ax}}{2}=a\\cosh(ax)\\) and \\(\\dfrac{d}{dx}\\cosh(ax)=\\dfrac{d}{dx}\\dfrac{e^{ax}+e^{-ax}}{2}=\\dfrac{ae^{ax}+(-a)e^{-ax}}{2}=a\\dfrac{e^{ax}-e^{-ax}}{2}=a\\sinh(ax)\\). Find all local maxima and minima of the following functions. Are there any global maxima or minima? Also sketch their graphs. \\(f(x)=x^2+3x+1\\) \\(f(x)=x^3-3x\\) Answers: For graph sketching we want to find the following: Where the curve crosses the \\(x\\)-axis and \\(y\\)-axis. The coordinates of any local maxima and minima. The general shape of the curve. Any asymptotes. We have \\(f&#39;(x)=2x+3\\). Stationary points are where \\(f&#39;(x)=0 \\implies x=\\frac{-3}{2}\\). To check for local maxima and minima we find the second derivative: \\(f&#39;&#39;(x)=2\\). Since this is always postive, we only have one local minimum at \\(x=\\frac{-3}{2}\\), \\(y=-\\frac{5}{4}\\). From the dominant \\(x^2\\) term being positive, we see this is a parabola which opens upwards, hence this minimum will be the global minimum and there are no local or global maxima. The curve crosses the \\(x\\)-axis where \\(f(x)=0\\). Using the quadratic formula: \\[x=\\frac{-3\\pm\\sqrt{9-4}}{2}=\\frac{-3\\pm\\sqrt{5}}{2}\\] so the approximate solutions are \\(x_1=-2.618\\) and \\(x_2=-0.382\\). The curve crosses the \\(y\\)-axis at \\(f(0)=1\\). Sketch: We have \\(f&#39;(x)=3x^2-3\\). Stationary points are where \\(f&#39;(x)=0 \\implies x=\\pm 1\\). To check for local maxima and minima we find the second derivative: \\(f&#39;&#39;(x)=6x\\). This implies that \\((-1,2)\\) is a local maximum and \\((1,-2)\\) is a local minimum. From the dominant \\(x^3\\) term, we see that \\(f(x)\\) can take arbitrarily large positive and negative values, hence there are no global maxima or minima. The curve crosses the \\(x\\)-axis where \\(f(x)=0\\). Factorising the cubic, we have: \\[f(x)=x(x-\\sqrt{3})(x+\\sqrt{3})\\] so the solutions are \\(x_0=0\\) and approximately \\(x_1=-1.732\\), \\(x_2=1.732\\). The curve crosses the \\(y\\)-axis at \\(f(0)=0\\). Sketch: A particle moving in a straight line has displacement \\(x\\) as a function of time \\(t\\geq 0\\) given by \\[x=-t^{3}+5t^{2}+t.\\] Find the velocity \\(v\\) and acceleration \\(a\\). What is the initial velocity? What is the largest positive displacement? At what time does the particle return to the origin? Answers: \\[\\begin{align*} x &amp;= -t^3 + 5t^2 + t\\\\ v &amp;= \\frac{dx}{dt} = -3t^2 + 10t + 1\\\\ a &amp;= \\frac{dv}{dt} = \\frac{d^2x}{dt^2} = -6t + 10 \\end{align*}\\] \\(v(0) = 1\\) To find the largest positive displacement, we must find the turning points of \\(x\\). These times are found by solving for \\(v(t) = 0\\) \\[v = -3t^2 + 10t + 1 = 0\\\\ \\text{solved by } t = \\frac{5}{3}\\pm \\frac{2\\sqrt{7}}{3}\\] The solution \\(\\frac{5}{3}-\\frac{2\\sqrt{7}}{3}\\) is in negative time, and the shape of the dominant \\(-t^3\\) term in \\(x\\) suggests that the maximum will be at time \\(\\frac{5}{3}+\\frac{2\\sqrt{7}}{3}\\), but it is prudent to check the second derivative of \\(x\\) (which is \\(a\\)). \\[a(\\frac{5}{3}-\\frac{2\\sqrt{7}}{3}) = 4\\sqrt{7}\\\\ a(\\frac{5}{3}+\\frac{2\\sqrt{7}}{3}) = -4\\sqrt{7}\\] And hence the maximum displacement does indeed occur at time \\(t=\\frac{5}{3}+\\frac{2\\sqrt{7}}{3}\\), and \\(x(\\frac{5}{3}+\\frac{2\\sqrt{7}}{3}) \\approx 21.9\\) To find when the particle returns to the origin, we must solve for \\(x(t) = 0\\). \\[-t^3 + 5t^2 + t = 0\\\\ -t^2 + 5t + 1 = 0\\\\ t = \\frac{5 \\pm \\sqrt{29}}{2}\\] Where one solution is for a negative \\(t\\), so the particle returns to the origin at \\(t = \\frac{5 +\\sqrt{29}}{2} \\approx 5.19\\) Find the points of inflection of the following functions. \\(f(x)=\\dfrac{x^3}{3}-\\dfrac{x^2}{2}-2x+5\\) \\(f(x)=x+\\sin(x)\\) Answer: To find points of inflection, we find the points at which the second derivative is zero and the third derivative is non-zero. \\[f(x) = \\frac{x^3}{3} - \\frac{x^2}{2} - 2x + 5\\\\ f&#39;(x) = x^2 - x - 2\\\\ f&#39;(x) = 0 = x^2 - x- 2 = (x+1)(x-2)\\\\ f&#39;&#39;(x) = 2x-1\\\\ f&#39;&#39;&#39;(x)=2\\] The second derivative is zero at \\(x=\\frac{1}{2}\\), and the second derivative also changes signs either side of this point. Alternatively we simply note that \\(f&#39;&#39;(x=\\frac{1}{2}) = 0\\) and \\(f&#39;&#39;&#39;(x=\\frac{1}{2})\\neq 0\\), so it is an inflection point by the Third Derivative Test for Inflection Points. \\[f(x) = \\sin (x) + x\\\\ f&#39;(x) = \\cos(x)+1\\] So there are stationary points at \\(x = \\frac{\\pi}{2} + 2\\pi k\\) for any integer \\(k\\). \\(f&#39;&#39;(x) = -\\sin(x)\\), which is zero whenever \\(x = k\\pi\\) for integer \\(k\\). The third derivative, \\(f&#39;&#39;&#39;(x) = -\\cos(x)\\) is non zero whenever \\(x \\neq \\frac{\\pi}{2} + 2\\pi k\\). So the points of inflection, by the Third Derivative Test, are whenever \\(x=2\\pi k\\) for integer \\(k\\). Note that half of these are also stationary points. A rectangular box with no lid is made from a thin sheet of metal. The base is \\(2x\\text{ mm}\\) long and \\(x\\text{ mm}\\) wide, and the volume is \\(48000\\text{ mm}^3\\). Show that the area \\(A\\) of metal used is given by \\[A=2x^2+144000x^{-1} \\text{ mm}^2.\\] Find the value of \\(x\\) for which the minimum area of metal is used along with the value of the minimum area. Answer: The volume of the box is given by \\(2x\\times x \\times h = 48000\\text{ mm}^3\\). We write the height in terms of volume and base area: \\(h = \\frac{48000}{2x^2}\\) The area of metal used is given by \\[A = 2x^2 + 2\\times 2x\\times \\frac{48000}{x^2} + 2 \\times x \\times \\frac{48000}{2x^2}\\\\ =2x^2 + \\frac{96000}{x} + \\frac{48000}{x}\\\\ = 2x^2 + \\frac{144000}{x}\\] We wish to minimise the area of metal used to create the appropriate volume of box. This requires finding the minimum of the Area function. \\[A&#39; = 4x - \\frac{144000}{x^2}\\\\ A&#39; = 0 \\Rightarrow 4x^3 = 144000\\\\ \\Rightarrow x = 33.019mm\\] We check this is a minimum by looking at the second derivative \\[A&#39;&#39;=4+\\frac{288000}{x^3}\\] which is positive for any postive \\(x\\) value, hence we do have a minimum by the second derivative test. The corresponding area is \\[ A= 6541.63\\text{mm}^3.\\] "],["exercise-set-10.html", "Exercise Set 10", " Exercise Set 10 Find \\(\\dfrac{dy}{dx}\\) for the following by implicit differentiation. \\(x^2y+3xy^3-x=3\\) \\(\\sin(x^2y^2)=x\\) \\(xy^2=y+e^{xy}\\) Consider the curve \\(x^2+3xy+y^2+2x-7=0\\). Use implicit differentiation to find \\(\\dfrac{dy}{dx}\\) and hence compute the equation of the tangent at the point \\((1,1)\\). Find the slope of the circle \\(x^2+y^2=25\\) at the point \\((-3,-4)\\). Hence find the equations of the tangent and normal at that point. Find \\(\\dfrac{dy}{dx}\\) and \\(\\dfrac{d^2y}{dx^2}\\) for the following by implicit differentiation. \\(y+\\sin(y)=x\\) \\(x^2-xy+y^2=3\\) Find \\(\\dfrac{dy}{dx}\\) and \\(\\dfrac{d^2y}{dx^2}\\) for the following parametric equations. \\(y=\\cos(2t)\\) and \\(x=\\sin(t)\\) \\(y=\\dfrac{3+2t}{1+t}\\) and \\(x=\\dfrac{2-3t}{1+t}\\) \\(y=3\\sin(\\theta)-\\sin^3(\\theta)\\) and \\(x=\\cos^3(\\theta)\\) Find the derivative of the following inverse functions by implicit differentiation. \\(y=\\sin^{-1}(x)\\) \\(y=\\cosh^{-1}(3x)\\) \\(y=\\tan^{-1}(4x^2)\\) Find \\(\\dfrac{dy}{dx}\\) for the following using logarithmic differentiation. \\(y=a^x\\) \\(y=\\dfrac{(x-4)^7(2x+3)^2}{(4x+7)^3}\\) Find \\(\\dfrac{dy}{dx}\\) for the following. \\(y=x^x\\) \\(y=(\\tanh(x))^x\\) \\(x^3+\\sin(xy)=xy^2\\) "],["exercise-set-10-answers.html", "Exercise Set 10 Answers", " Exercise Set 10 Answers Find \\(\\dfrac{dy}{dx}\\) for the following by implicit differentiation. \\(x^2y+3xy^3-x=3\\) \\(\\sin(x^2y^2)=x\\) \\(xy^2=y+e^{xy}\\) Answers: \\[\\begin{align*} 2xy+x^2\\frac{dy}{dx}+3y^3+9xy^2\\frac{dy}{dx}-1&amp;=0\\\\ (x^2+9xy^2)\\frac{dy}{dx}&amp;=1-2xy-3y^3\\\\ \\frac{dy}{dx}&amp;=\\frac{1-2xy-3y^3}{x^2+9xy^2} \\end{align*}\\] \\[\\begin{align*} \\cos(x^2y^2)\\left(2xy^2+2x^2y\\frac{dy}{dx}\\right)&amp;=1\\\\ \\frac{dy}{dx}&amp;=\\frac{1-2xy^2\\cos(x^2y^2)}{2x^2y\\cos(x^2y^2)} \\end{align*}\\] \\[\\begin{align*} \\frac{d}{dx}(xy^2)&amp;=\\frac{d}{dx}(y+e^{xy})\\\\ 2xy\\frac{dy}{dx}+y^2&amp;=\\frac{dy}{dx}+\\frac{d}{dx}e^{xy}\\\\ 2xy\\frac{dy}{dx}+y^2&amp;=\\frac{dy}{dx}+e^{xy}\\frac{d}{dx}(xy)\\\\ 2xy\\frac{dy}{dx}+y^2&amp;=\\frac{dy}{dx}+e^{xy}\\left(x\\frac{dy}{dx}+y\\right)\\\\ 2xy\\frac{dy}{dx}-xe^{xy}\\frac{dy}{dx}-\\frac{dy}{dx}&amp;=ye^{xy}-y^2\\\\ \\frac{dy}{dx}(2xy-xe^{xy}-1)&amp;=ye^{xy}-y^2\\\\ \\frac{dy}{dx}&amp;=\\frac{ye^{xy}-y^2}{(2xy-1-xe^{xy})}. \\end{align*}\\] Consider the curve \\(x^2+3xy+y^2+2x-7=0\\). Use implicit differentiation to find \\(\\dfrac{dy}{dx}\\) and hence compute the equation of the tangent at the point \\((1,1)\\). Answers: \\[\\begin{align*} 2x+3y+3x\\frac{dy}{dx}+2\\frac{dy}{dx}+2&amp;=0\\\\ \\frac{dy}{dx}&amp;=-\\frac{2x+3y+2}{3x+2}.\\\\ \\end{align*}\\] At the point \\((1,1)\\) \\[\\begin{equation*} \\frac{dy}{dx}\\Bigr|_{\\substack{(1,1)}}=-\\frac{2+3+2}{3+2}=-\\frac{7}{5} \\end{equation*}\\] then the equation of the tangent line is \\[\\begin{equation*} y=1-\\frac{7}{5}(x-1). \\end{equation*}\\] Find the slope of the circle \\(x^2+y^2=25\\) at the point \\((-3,-4)\\). Hence find the equations of the tangent and normal at that point. Answers: By implicit differentiation \\[2x+2y\\frac{dy}{dx}=0\\] hence \\[\\frac{dy}{dx}=-\\frac{x}{y}\\] and at \\((-3,-4)\\) \\[\\frac{dy}{dx}=-\\frac{3}{4}.\\] The equation of the tangent line is given by \\[y-(-4)=-\\frac{3}{4}(x-(-3))\\] or \\[y=-\\frac{3}{4}x-\\frac{25}{4}.\\] The equation of the normal line is \\[y-(-4)=\\frac{4}{3}(x-(-3))\\] or \\[y=\\frac{4}{3}x.\\] Find \\(\\dfrac{dy}{dx}\\) and \\(\\dfrac{d^2y}{dx^2}\\) for the following by implicit differentiation. \\(y+\\sin(y)=x\\) \\(x^2-xy+y^2=3\\) Answers: \\[\\begin{align*} \\frac{dy}{dx}+\\cos(y)\\frac{dy}{dx}&amp;=1\\\\ \\frac{dy}{dx}&amp;=\\frac{1}{1+\\cos(y)} \\end{align*}\\] \\[\\begin{align*} 2x-y-x\\frac{dy}{dx}+2y\\frac{dy}{dx}&amp;=0\\\\ (x-2y)\\frac{dy}{dx}&amp;=2x-y\\\\ \\frac{dy}{dx}&amp;=\\frac{2x-y}{x-2y} \\end{align*}\\] Find \\(\\dfrac{dy}{dx}\\) and \\(\\dfrac{d^2y}{dx^2}\\) for the following parametric equations. \\(y=\\cos(2t)\\) and \\(x=\\sin(t)\\) \\(y=\\dfrac{3+2t}{1+t}\\) and \\(x=\\dfrac{2-3t}{1+t}\\) \\(y=3\\sin(\\theta)-\\sin^3(\\theta)\\) and \\(x=\\cos^3(\\theta)\\) Answers: \\[\\begin{align*} \\frac{dy}{dt}=-2\\sin(2t)&amp;&amp;\\frac{dx}{dt}=\\cos(t) \\end{align*}\\] The first derivative is \\[\\begin{align*} \\frac{dy}{dx}&amp;=\\frac{\\dfrac{dy}{dt}}{\\dfrac{dx}{dt}}\\\\ &amp;=\\frac{-2\\sin(2t)}{\\cos(t)}\\\\ &amp;=\\frac{-4\\sin(t)\\cos(t)}{\\cos(t)}\\\\ &amp;=-4\\sin(t). \\end{align*}\\] The second derivative is (using the chain rule) \\[\\begin{align*} \\frac{d^2y}{dx^2}&amp;=\\frac{d}{dt}\\left(\\frac{dy}{dx}\\right)\\frac{dt}{dx}\\\\ &amp;=\\frac{d}{dt}(-4\\sin(t))\\cdot \\frac{1}{\\cos(t)}\\\\ &amp;=-4\\cos(t)\\cdot \\frac{1}{\\cos(t)}\\\\ &amp;=-4. \\end{align*}\\] \\[\\begin{align*} \\frac{dy}{dt}=-\\frac{1}{(1+t)^2}&amp;&amp;\\frac{dx}{dt}=-\\frac{5}{(1+t)^2} \\end{align*}\\] The first derivative is \\[\\begin{align*} \\frac{dy}{dx}&amp;=\\frac{\\dfrac{dy}{dt}}{\\dfrac{dx}{dt}}\\\\ &amp;=\\frac{1}{(1+t)^2}\\cdot \\frac{(1+t)^2}{5}\\\\ =\\frac{1}{5} \\end{align*}\\] then the second derivative \\[\\begin{equation*} \\frac{d^2y}{dx^2}=0. \\end{equation*}\\] \\[\\begin{align*} \\frac{dy}{d\\theta}=3\\cos^3(\\theta)&amp;&amp;\\frac{dx}{d\\theta}=-3\\cos^2(\\theta)\\sin(\\theta) \\end{align*}\\] The first derivative is \\[\\begin{align*} \\frac{dy}{dx}&amp;=\\frac{\\dfrac{dy}{d\\theta}}{\\dfrac{dx}{d\\theta}}\\\\ &amp;=\\frac{3\\cos^3(\\theta)}{-3\\cos^2(\\theta)\\sin(\\theta)}\\\\ &amp;=-\\cot(t) \\end{align*}\\] and the second derivative \\[\\begin{align*} \\frac{d^2y}{dx^2}&amp;=\\frac{d}{d\\theta}\\left(\\frac{dy}{dx}\\right)\\frac{d\\theta}{dx}\\\\ &amp;=\\frac{d}{d\\theta}(-\\cot(t))\\cdot \\frac{1}{-3\\cos^2(\\theta)\\sin(\\theta)}\\\\ &amp;=\\frac{1}{\\sin^2(\\theta)}\\cdot \\frac{1}{-3\\cos^2(\\theta)\\sin(\\theta)}\\\\ &amp;=\\frac{-1}{3\\cos^2(\\theta)\\sin^3(\\theta)}, \\end{align*}\\] where we have used \\[\\begin{align*} \\frac{d}{d\\theta}(-\\cot(t))&amp;=\\frac{d}{d\\theta}\\frac{-\\cos(\\theta)}{\\sin(\\theta)}\\\\ &amp;=\\frac{\\sin(\\theta)\\sin(\\theta)-(-\\cos(\\theta))\\cos(\\theta)}{\\sin^2(\\theta)}\\\\ &amp;=\\frac{1}{\\sin^2(\\theta)}. \\end{align*}\\] Find the derivative of the following inverse functions by implicit differentiation. \\(y=\\sin^{-1}(x)\\) \\(y=\\cosh^{-1}(3x)\\) \\(y=\\tan^{-1}(4x^2)\\) Answers: We have that \\[\\begin{equation*} \\sin(y)=x \\end{equation*}\\] then by implicit differentiation \\[\\begin{align*} \\cos(y)\\dfrac{dy}{dx}=1\\\\ \\dfrac{dy}{dx}=\\dfrac{1}{\\cos(y)}. \\end{align*}\\] Using the identity \\(\\cos^2(y)+\\sin^2(y)=1\\) \\[\\begin{align*} \\cos(y)&amp;=\\sqrt{1-\\sin^2(y)}\\\\ &amp;=\\sqrt{1-x^2} \\end{align*}\\] so, \\[\\begin{equation*} \\dfrac{dy}{dx}=\\dfrac{1}{\\sqrt{1-x^2}}. \\end{equation*}\\] We have \\[\\begin{equation*} \\cosh(y)=3x \\end{equation*}\\] then by implicit differentiation \\[\\begin{align*} \\sinh(y)\\dfrac{dy}{dx}&amp;=3\\\\ \\dfrac{dy}{dx}&amp;=\\dfrac{3}{\\sinh(y)}. \\end{align*}\\] Since \\(\\cosh^2(y)-\\sinh^2(y)=1\\) \\[\\begin{equation*} \\sinh(y)=\\sqrt{\\cosh^2(y)-1}=\\sqrt{(3x)^2-1}. \\end{equation*}\\] So, \\[\\begin{equation*} \\dfrac{dy}{dx}=\\frac{3}{\\sqrt{9x^2-1}}. \\end{equation*}\\] We have \\[\\begin{equation*} \\tan(y)=4x^2. \\end{equation*}\\] By implicit differentiation, \\[\\begin{align*} \\sec^2(y)\\dfrac{dy}{dx}&amp;=8x\\\\ \\dfrac{dy}{dx}&amp;=\\dfrac{8x}{\\sec^2(y)} \\end{align*}\\] Using \\[\\begin{align*} \\cos^2(y)+\\sin^2(y)&amp;=1\\\\ 1+\\tan^2(y)&amp;=\\sec^2(y) \\end{align*}\\] we have \\(\\sec^2(y)=1+(4x^2)^2\\), and then \\[\\begin{equation*} \\dfrac{dy}{dx}=\\dfrac{8x}{1+16x^4}. \\end{equation*}\\] Find \\(\\dfrac{dy}{dx}\\) for the following using logarithmic differentiation. \\(y=a^x\\) \\(y=\\dfrac{(x-4)^7(2x+3)^2}{(4x+7)^3}\\) Answers: Taking logs and differentiating implicitly \\[\\begin{align*} \\ln(y)=\\ln(a^x)&amp;=x\\ln(a)\\\\ \\frac{1}{y}\\dfrac{dy}{dx}&amp;=\\ln(a)\\\\ \\dfrac{dy}{dx}&amp;=y\\ln(a)\\\\ \\dfrac{dy}{dx}&amp;=a^x\\ln(a). \\end{align*}\\] Taking logs \\[\\begin{align*} \\ln(y)&amp;=\\ln\\left[\\dfrac{(x-4)^7(2x+3)^2}{(4x+7)^3}\\right]\\\\ &amp;=\\ln(x-4)^7+\\ln(2x+3)^2-\\ln(4x+7)^3\\\\ &amp;=7\\ln(x-4)+2\\ln(2x+3)-3\\ln(4x+7) \\end{align*}\\] Then differentiating \\[\\begin{align*} \\frac{1}{y}\\dfrac{dy}{dx}&amp;=\\frac{7}{x-4}+\\frac{2}{2x+3}\\cdot 2-\\frac{3}{4x-7}\\cdot 4\\\\ \\dfrac{dy}{dx}&amp;=\\dfrac{(x-4)^7(2x+3)^2}{(4x+7)^3}\\left[ \\frac{7}{x-4}+\\frac{4}{2x+3}-\\frac{12}{4x-7}\\right] \\end{align*}\\] Find \\(\\dfrac{dy}{dx}\\) for the following. \\(y=x^x\\) \\(y=(\\tanh(x))^x\\) \\(x^3+\\sin(xy)=xy^2\\) Answers: First take the natural logarithm: \\[\\begin{equation*} \\ln(y)=x\\ln(x), \\end{equation*}\\] then differentiate implicitly: \\[\\begin{align*} \\frac{d}{dx}(\\ln(y))&amp;=\\frac{d}{dx}(x\\ln(x))\\\\ \\frac{1}{y}\\frac{dy}{dx}&amp;=\\frac{dx}{dx}\\ln(x)+x\\frac{d}{dx}\\ln(x)\\\\ \\frac{1}{y}\\frac{dy}{dx}&amp;=\\ln(x)+x\\frac{1}{x}\\\\ \\frac{dy}{dx}&amp;=y(\\ln(x)+1)=x^x(\\ln(x)+1). \\end{align*}\\] Important! The derivative of \\(x^x\\) is not \\(x\\cdot x^{x-1}=x^x\\). We can’t treat variable exponents like constant exponents! Taking logs \\[\\begin{equation*} \\ln(y)=x\\ln(\\tanh(x)), \\end{equation*}\\] then differentiating \\[\\begin{align*} \\frac{1}{y}\\dfrac{dy}{dx}&amp;=\\ln(\\tanh(x))+\\frac{x}{\\tanh(x)}\\textrm{sech}^2(x)\\\\ &amp;=\\ln(\\tanh(x))+\\frac{x\\cosh(x)}{\\sinh(x)\\cosh^2(x)}\\\\ &amp;=\\ln(\\tanh(x))+\\frac{x}{\\sinh(x)\\cosh(x)}\\\\ &amp;=\\ln(\\tanh(x))+\\frac{2x}{\\sinh(2x)}.\\\\ \\end{align*}\\] So, \\[\\begin{equation*} \\dfrac{dy}{dx}=(\\tanh(x))^x\\left[ \\ln(\\tanh(x))+\\frac{2x}{\\sinh(2x)}\\right]. \\end{equation*}\\] By implicit differentiation and using the product rule \\[\\begin{align*} 3x^2+\\cos(xy)\\left(y+x\\dfrac{dy}{dx} \\right)&amp;=y^2+2xy\\dfrac{dy}{dx}\\\\ 3x^2+y\\cos(xy)-y^2&amp;=2xy\\dfrac{dy}{dx}-x\\cos(xy)\\dfrac{dy}{dx} \\end{align*}\\] so, \\[\\begin{equation*} \\dfrac{dy}{dx}=\\frac{3x^2+y\\cos(xy)-y^2}{2xy-x\\cos(xy)} \\end{equation*}\\] "],["exercise-set-11.html", "Exercise Set 11", " Exercise Set 11 Write the series \\[\\begin{equation*} \\frac{1}{1\\cdot 2}+\\frac{1}{2\\cdot 3}+\\frac{1}{3\\cdot 4}+\\frac{1}{4\\cdot 5}+\\frac{1}{5\\cdot 6} \\end{equation*}\\] using Sigma notation in the forms \\(\\displaystyle\\sum_{k=1}^{n}(\\dots)\\) and \\(\\displaystyle\\sum_{l=0}^{m}(\\dots)\\). Evaluate \\(\\displaystyle\\sum_{n=1}^{10}\\frac{2}{3^n}\\) and \\(\\displaystyle\\sum_{n=0}^{9}\\frac{2}{3^n}\\) using the formula for the \\(n^{\\text{th}}\\) partial sum of a geometric series. Do the following geometric series converge or diverge? If they converge, find their sum. \\(\\displaystyle\\sum_{n=1}^{\\infty}\\frac{2}{3^n}\\) \\(\\displaystyle\\sum_{n=1}^{\\infty}(-1)^{n-1}\\frac{1}{2^{n-1}}\\) \\(\\displaystyle\\sum_{n=1}^{\\infty}\\left( \\dfrac{\\pi}{2}\\right)^n\\) Find the \\(3^{\\text{rd}}\\) degree Taylor polynomials of the following functions. \\(f(x)=2x^3-x^2+4x+5\\) at \\(a=0\\) \\(f(x)=\\dfrac{1}{1+x}\\) at \\(a=0\\). \\(f(x)=\\sqrt{x}\\) at \\(a=1\\) Derive the Taylor series for \\(e^x\\) at \\(a=0\\) (this converges for all \\(x\\)). Derive the Taylor series for \\(\\sin(x)\\) at \\(a=\\dfrac{\\pi}{2}\\) (this converges for all \\(x\\)). From the Taylor series of \\(f(x)=\\ln(x+1)\\) at zero (this converges for \\(-1 &lt; x \\le 1\\)), show that: \\[\\begin{equation*} \\sum_{n=1}^{\\infty}\\frac{(-1)^{n+1}}{n}=\\ln(2). \\end{equation*}\\] The Taylor series for \\(\\tan^{-1}\\) at zero is \\[\\tan^{-1}(x) = \\sum_{n=0}^\\infty \\frac{(-1)^n x^{2n+1}}{2n+1}\\] which converges for \\(|x|\\leq 1\\). Use this to approximate \\(\\pi\\) (you could do this in MATLAB/Python using a for loop to easily experiment with the number of terms in the sum). Prove Euler’s formula for complex numbers using the Taylor series for \\(e^x\\), \\(\\cos(x)\\) and \\(\\sin(x)\\) at \\(0\\), . Find the Taylor series for \\(\\cos(x)\\) at zero by differentiating the Taylor series for \\(\\sin(x)\\) at zero term by term (we can differentiate any power series term by term for values of \\(x\\) where the series converges). Find the Taylor series of \\(\\dfrac{1}{1-x}\\) at \\(a=0\\) (this converges for \\(|x|&lt;1\\)). Hence find the Taylor series of \\(\\dfrac{1}{(1-x)^2}\\) at \\(a=0\\). "],["exercise-set-11-answers.html", "Exercise Set 11 Answers", " Exercise Set 11 Answers Write the series \\[\\begin{equation*} \\frac{1}{1\\cdot 2}+\\frac{1}{2\\cdot 3}+\\frac{1}{3\\cdot 4}+\\frac{1}{4\\cdot 5}+\\frac{1}{5\\cdot 6} \\end{equation*}\\] using Sigma notation in the forms \\(\\displaystyle\\sum_{k=1}^{n}(\\dots)\\) and \\(\\displaystyle\\sum_{l=0}^{m}(\\dots)\\). Answers: \\[\\sum_{k=1}^{5}\\frac{1}{k(k+1)}\\] \\[\\sum_{l=0}^{4}\\frac{1}{(l+1)(l+2)}\\] Evaluate \\(\\displaystyle\\sum_{n=1}^{10}\\frac{2}{3^n}\\) and \\(\\displaystyle\\sum_{n=0}^{9}\\frac{2}{3^n}\\) using the formula for the \\(n^{\\text{th}}\\) partial sum of a geometric series. Answers: The geometric series \\(\\displaystyle\\sum_{n=1}^{10}\\dfrac{2}{3^n}\\) has first term \\(a=\\dfrac{2}{3^1}=\\dfrac{2}{3}\\) and second term \\(ar=\\dfrac{2}{3^2}\\) and therefore the common ratio is \\(r=\\dfrac{ar}{a}=\\dfrac{1}{3}\\). Since the sum is for \\(n=1\\) to \\(n=10\\), it is the sum of the first \\(10\\) terms, \\[ S_{10}=\\frac{a(1-r^{10})}{1-r}=\\frac{2\\left (1-\\dfrac{1}{3^{10}}\\right)}{3\\left (1-\\dfrac{1}{3}\\right )}=1-\\dfrac{1}{3^{10}}. \\] The geometric series \\(\\displaystyle\\sum_{n=0}^{9}\\frac{2}{3^n}\\) has first term \\(a=\\dfrac{2}{3^0}=2\\) and second term \\(ar=\\dfrac{2}{3^1}\\), and therefore the common ratio is \\(r=\\dfrac{ar}{a}=\\dfrac{1}{3}\\). Since the sum is for \\(n=0\\) to \\(n=9\\), it is the sum of the first \\(10\\) terms, \\[ S_{10}=\\dfrac{a(1-r^{10})}{1-r}=\\dfrac{2\\left(1-\\dfrac{1}{3^{10}}\\right)}{\\left(1-\\dfrac{1}{3}\\right)}=3\\left(1-\\dfrac{1}{3^{10}}\\right). \\] Do the following geometric series converge or diverge? If they converge, find their sum. \\(\\displaystyle\\sum_{n=1}^{\\infty}\\frac{2}{3^n}\\) \\(\\displaystyle\\sum_{n=1}^{\\infty}(-1)^{n-1}\\frac{1}{2^{n-1}}\\) \\(\\displaystyle\\sum_{n=1}^{\\infty}\\left( \\dfrac{\\pi}{2}\\right)^n\\) Answers: We already know that the first term is \\(a=\\dfrac{2}{3}\\) and the common ratio is \\(r=\\dfrac{1}{3}\\). Since \\(|r|&lt;1\\), the geometric series converges, with sum \\[ \\sum_{n=1}^{\\infty}\\frac{2}{3^n}=\\frac{a}{1-r}=\\frac{\\frac{2}{3}}{1-\\frac{1}{3}}=1. \\] The first term of the series is \\(a=1\\) and the common ratio is \\(r=-\\dfrac{1}{2}\\). Since \\(|r|&lt;1\\) the series converges, and the sum is \\[ \\sum_{n=1}^{\\infty}(-1)^{n-1}\\frac{1}{2^{n-1}}=\\frac{1}{1+\\frac{1}{2}}=\\frac{2}{3}. \\] The first term of the series is \\(a=\\dfrac{\\pi}{2}\\), and the common ratio is also \\(r=\\dfrac{\\pi}{2}\\). Since \\(|r|&gt;1\\), the series diverges. Find the \\(3^{\\text{rd}}\\) degree Taylor polynomials of the following functions. \\(f(x)=2x^3-x^2+4x+5\\) at \\(a=0\\) \\(f(x)=\\dfrac{1}{1+x}\\) at \\(a=0\\). \\(f(x)=\\sqrt{x}\\) at \\(a=1\\) Answers: The \\(3^{\\text{rd}}\\) degree polynomial of this polynomial at \\(a=0\\) will simply be equal to the polynomial itself. For completeness, we still derive the Taylor series to demonstrate this \\[\\begin{align} f(x)&amp;=2x^3 - x^2 + 4x + 5 &amp; f(0)&amp;=5\\\\ f&#39;(x)&amp;= 6x^2 - 2x + 4 &amp; f&#39;(0)&amp;=4\\\\ f&#39;&#39;(x)&amp;= 12x - 2 &amp; f&#39;&#39;(0) &amp;= -2\\\\ f&#39;&#39;&#39;(x) &amp;= 12 &amp; f&#39;&#39;&#39;(0) &amp;= 12 \\end{align}\\] Substituting these into the Taylor series about \\(x=0\\) \\[ f(x) = \\sum_{n=0}^\\infty \\frac{f^{(n)}(a)}{n!}x\\\\ f(x) = f(0) + \\frac{f&#39;(0)}{1}x + \\frac{f&#39;&#39;(0)}{2}x^2 + \\frac{f&#39;&#39;&#39;(0)}{6}x^3\\\\ f(x) = 5 + 4x - x^2 + 2 x^3 \\] since the Taylor series terminates after the \\(x^3\\) term. The original polynomial has been recovered. We start by finding the first 3 derivatives. \\[ \\begin{align} f(x) &amp;= \\frac{1}{x+1} &amp; f(0) &amp;= 1\\\\ f&#39;(x) &amp;= \\frac{-1}{(x+1)^2} &amp; f&#39;(0) &amp;= -1\\\\ f&#39;&#39;(x) &amp; = \\frac{2}{(x+1)^3} &amp; f&#39;&#39;(0) &amp;= 2\\\\ f&#39;&#39;&#39;(x) &amp;= \\frac{-6}{(x+1)^4} &amp; f&#39;&#39;&#39;(0) &amp;= -6 \\end{align} \\] Substituting these terms into the Taylor series expansion about \\(x=0\\), up to the \\(3^\\text{rd}\\) degree term.: \\[f(x) = \\sum_{n=0}^\\infty \\frac{f^{(n)}(a)}{n!}x\\\\ f(x) = 1 - x + x^2 - x^3 + \\cdots \\] Having just included the first few terms. Note that it is not possible to take the Taylor series about \\(x=0\\) because the derivative of \\(\\sqrt{x}\\) does not exist at \\(0\\). Taking the expansion about \\(x=1\\). \\[ \\begin{align} f(x) &amp;= \\sqrt{x} = x^\\frac{1}{2} &amp; f(1) &amp;= 1\\\\ f&#39;(x) &amp;= \\frac{1}{2}x^{-\\frac{1}{2}} &amp; f&#39;(1) &amp;= \\frac{1}{2}\\\\ f&#39;&#39;(x) &amp; = -\\frac{1}{4}x^{-\\frac{3}{2}} &amp; f&#39;&#39;(1) &amp;= -\\frac{1}{4}\\\\ f&#39;&#39;&#39;(x) &amp;= \\frac{3}{8}x^{-\\frac{5}{2}} &amp; f&#39;&#39;&#39;(1) &amp;= \\frac{3}{8} \\end{align} \\] Substituting these into the first few terms of the Taylor series about \\(x=a\\) \\[ f(x-1) = \\sum_{n=0}^\\infty \\frac{f^{(n)}(1)}{n!}(x-1)^n\\\\ f(x-1) = 1 + \\frac{1}{2}(x-1) -\\frac{1}{4}\\frac{(x-1)^2}{2!} + \\frac{3}{8}\\frac{(x-1)^3}{3!} + \\cdots\\\\ f(x-1) = 1 + \\frac{1}{2}(x-1) - \\frac{(x-1)^2}{8} + \\frac{(x-1)^3}{16} + \\cdots\\] Derive the Taylor series for \\(e^x\\) at \\(a=0\\) (this converges for all \\(x\\)). Answers: Let \\(f(x)=e^x\\). \\[\\begin{align*} f(x)&amp;=e^x &amp; f(0)&amp;=1\\\\ f&#39;(x)&amp;=e^x &amp; f&#39;(0)&amp;=1\\\\ f^{(n)}(x)&amp;=e^x &amp; f^{(n)}(0)&amp;=1 \\end{align*}\\] The \\(n^{\\text{th}}\\) degree Taylor polynomial is \\[ P_{n,0}(x)=1+x+\\frac{x^2}{2!}+\\frac{x^3}{3!}+\\dotsb+\\frac{x^n}{n!} \\] and the Taylor series is \\[ \\sum_{n=0}^{\\infty}\\frac{x^n}{n!}. \\] Derive the Taylor series for \\(\\sin(x+a)\\) at \\(a=\\dfrac{\\pi}{2}\\) (this converges for all \\(x\\)). Answers: The derivatives at \\(\\dfrac{\\pi}{2}\\) form a periodic sequence of period \\(4\\) \\[\\begin{align*} f(x)&amp;=\\sin(x) &amp; f\\left(\\frac{\\pi}{2}\\right)&amp;=1\\\\ f^{(1)}(x)&amp;=\\cos(x) &amp; f^{(1)}\\left(\\frac{\\pi}{2}\\right)&amp;=0\\\\ f^{(2)}(x)&amp;=-\\sin(x) &amp; f^{(2)}\\left(\\frac{\\pi}{2}\\right)&amp;=-1\\\\ f^{(3)}(x)&amp;=-\\cos(x) &amp; f^{(3)}\\left(\\frac{\\pi}{2}\\right)&amp;=0\\\\ f^{(4)}(x)&amp;=\\sin(x) &amp; f^{(4)}\\left(\\frac{\\pi}{2}\\right)&amp;=1 \\end{align*}\\] and the Taylor series is \\[ \\sum_{n=0}^{\\infty}(-1)^{n}\\frac{x^{2n}}{(2n)!} \\] which we recognise as the Taylor series for \\(\\cos\\) about \\(0\\), which should be unsurprising since \\(\\sin\\left(x+\\frac{\\pi}{2}\\right)=\\cos(x)\\). From the Taylor series of \\(f(x)=\\ln(x+1)\\) at zero (this converges for \\(-1 &lt; x \\le 1\\)), show that: \\[ \\sum_{n=1}^{\\infty}\\frac{(-1)^{n+1}}{n}=\\ln(2). \\] Answers: Since we are told that the Taylor series equals \\(f(x)\\) for \\(-1 &lt; x\\le 1\\) and \\(f(1)=\\ln(2)\\), we have \\[ \\sum_{n=1}^{\\infty}(-1)^{n+1}\\frac{1}{n}=\\ln(2). \\] The Taylor series for \\(\\tan^{-1}\\) at zero is \\[\\tan^{-1}(x) = \\sum_{n=0}^\\infty \\frac{(-1)^n x^{2n+1}}{2n+1}\\] which converges for \\(|x|\\leq 1\\). Use this to approximate \\(\\pi\\) (you could do this in MATLAB/Python using a for loop to easily experiment with the number of terms in the sum). Answer: We have that \\(\\tan^{-1}(1)=\\frac{\\pi}{4}\\), so can find \\(\\pi\\) as \\(4\\tan^{-1}(1)=4\\sum_{n=0}^\\infty \\frac{(-1)^n}{2n+1}\\). We can get an approximation by summing over the first \\(N\\) terms of this infinite series. For N=1000 we get $… $ Prove Euler’s formula for complex numbers using the Taylor series for \\(e^x\\), \\(\\cos(x)\\) and \\(\\sin(x)\\) at \\(0\\), . Answer: First, recall the Taylor series for \\(e^x\\) \\[ e_x = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\frac{x^4}{4!} + \\cdots \\] And now let \\(x = i\\theta\\). The odd terms will become imaginary, while the even powers will have changing signs with \\(i^2\\): \\[\\begin{align} e^{i\\theta} &amp;= 1 + i\\theta + \\frac{i^2 \\theta^2}{2!} + \\frac{i^3 \\theta^3}{3!} + \\frac{i^4 \\theta^4}{4!} + \\cdots \\\\ &amp;= 1 + i\\theta - \\frac{\\theta^2}{2!} - i\\frac{\\theta^3}{3!} + \\frac{\\theta^4}{4!} + \\cdots \\end{align}\\] Now, group every second term together to identify the Tarlor series of \\(\\cos(x)\\) and \\(i\\sin(x)\\). \\[ e^x = \\left(1 - \\frac{\\theta^2}{2!} + \\frac{\\theta^4}{4!} + \\cdots \\right) + i\\left(\\theta - \\frac{\\theta^3}{3!} + \\frac{x^5}{5!} + \\cdots\\right)\\\\ e^x = \\cos(\\theta) + i \\sin(\\theta) \\] Find the Taylor series for \\(\\cos(x)\\) at zero by differentiating the Taylor series for \\(\\sin(x)\\) at zero term by term (we can differentiate any power series term by term for values of \\(x\\) where the series converges). Answers: Taking the derivative of the power series, and noting that \\(\\frac{n}{n!} = \\frac{1}{(n-1)!}\\) \\[ \\sin(x) = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots\\\\ \\frac{d}{dx}\\sin (x)= 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} + \\cdots = \\cos(x) \\] Find the Taylor series of \\(\\dfrac{1}{1-x}\\) at \\(a=0\\) (this converges for \\(|x|&lt;1\\)). Hence find the Taylor series of \\(\\dfrac{1}{(1-x)^2}\\) at \\(a=0\\). Answers: \\[\\begin{align*} f(x)&amp;=(1-x)^{-1} &amp; f(0)&amp;=1\\\\ f^{(1)}(x)&amp;=(1-x)^{-2} &amp; f^{(1)}(0)&amp;=1\\\\ f^{(2)}(x)&amp;=2(1-x)^{-3} &amp; f^{(2)}(0)&amp;=2\\\\ f^{(3)}(x)&amp;=6(1-x)^{-4} &amp; f^{(3)}(0)&amp;=6=3!\\\\ f^{(4)}(x)&amp;=24(1-x)^{-5} &amp; f^{(4)}(0)&amp;=24=4! \\end{align*}\\] so the Taylor Series is \\[\\begin{equation*} \\sum_{n=0}^{\\infty}x^n. \\end{equation*}\\] Now to find the Taylor series of \\(\\frac{1}{(1-x)^2}\\) at \\(0\\), we note that \\(\\frac{d}{dx}\\frac{1}{(1-x)}=\\frac{1}{(1-x)^2}\\), hence we can obtain the Taylor series by differentiating the series for \\(\\frac{1}{(1-x)}\\) term by term, obtaining: \\[\\begin{equation*} \\sum_{n=1}^{\\infty}nx^{n-1}. \\end{equation*}\\] "],["exercise-set-12.html", "Exercise Set 12", " Exercise Set 12 Determine the following indefinite integrals \\(\\int 2x^7\\; dx\\) \\(\\int 5x^2+2x-1 \\; dx\\) \\(\\int \\sin(\\theta)+\\cos(\\theta) \\; d\\theta\\) \\(\\int 3e^t + \\frac{2}{t} \\; d t\\) \\(\\int x^\\frac{1}{2} \\; dx\\) Determine the following definite integrals \\(\\int_0^2 x^2-2x\\; dx\\) \\(\\int_4^{16} \\frac{2}{\\sqrt{x}} \\; dx\\) \\(\\int_{-r}^r \\frac{mx^2}{2r}\\: dx\\) \\(\\int_{-\\frac{\\pi}{2}}^\\frac{\\pi}{2}\\cos(x)\\; dx\\) \\(\\int_{\\ln(2)}^{\\ln(3)} e^x\\; dx\\) Find the area between the curve and the \\(x\\)-axis of the function \\(f(x)=x^3-x\\) and the lines \\(x=0\\) and \\(x=2\\). The velocity \\(v\\) (\\(\\text{ms}^{-1}\\)) of a particle moving in a straight line at time \\(t\\) (\\(\\text{s}\\)) is given by: \\[v=6t^2-30t-36\\quad t&gt;0\\] By integrating, find the distance travelled by the particle between \\(t=3\\) and \\(t=5\\) seconds. Find the following integrals using a suitable substitution. \\(\\int (4x-3)^5 \\; dx\\) \\(\\int 4\\sin(3x+2)\\; dx\\) \\(\\int_2^5 \\frac{1}{1-2x} \\; dx\\) \\(\\int \\frac{1}{\\sqrt{(5-3x)^3}}\\; dx\\) \\(\\int \\frac{4x}{\\sqrt{(x^2+3)^3}}\\; dx\\) \\(\\int 2xe^{x^2-5}\\; dx\\) \\(\\int \\frac{\\sqrt{x}}{\\sqrt{x}}\\; dx\\) \\(\\int \\cos(\\theta)\\sin(\\theta)\\; d\\theta\\) \\(\\int \\frac{\\cos(x)}{1+\\sin(x)}\\; dx\\) The Root Mean Square (RMS) value of a signal over the interval \\(a\\) to \\(b\\) is defined as \\[\\left(\\frac{1}{b-a}\\int_{a}^{b} (f(x))^2 \\; dx\\right)^\\frac{1}{2}\\] Find the RMS of the voltage signal \\[V(t)=3\\sin(2t)+5\\cos(4t)\\] between \\(a=0\\) and \\(b=2\\pi\\). The volume of revolution of a curve is defined as \\[\\int_a^b \\pi (f(x))^2 \\; dx\\] Find the volume of revolution of the curve \\[f(x)=e^{-2x}\\] between \\(a=1\\) and \\(b=2\\). The points \\((1,1)\\) and \\((2,8)\\) on the curve \\(y=x^3\\) are joined by a straight line. Calculate the area between the line and the curve. "],["exercise-set-12-answers.html", "Exercise Set 12 Answers", " Exercise Set 12 Answers Determine the following indefinite integrals \\(\\int 2x^7\\; dx\\) \\(\\int 5x^2+2x-1 \\; dx\\) \\(\\int \\sin(\\theta)+\\cos(\\theta) \\; d\\theta\\) \\(\\int 3e^t + \\frac{2}{t} \\; d t\\) \\(\\int x^\\frac{1}{2} \\; dx\\) Answers: \\(\\int 2x^7 \\; dx = \\frac{1}{4}x^8 + c\\) \\(\\int 5x^2 + 2x-1\\; dx = \\frac{5}{3}x^3 + x^2 - x + c\\) \\(\\int \\sin(\\theta)+\\cos(\\theta) \\; d\\theta = -\\cos(\\theta) + \\sin(\\theta) + c\\) \\(\\int 3e^t + \\frac{2}{t} \\; dt = 3e^t + 2\\ln(t) + c\\) \\(\\int x^\\frac{1}{2} \\; dx = \\frac{2}{3}x^{\\frac{3}{2}} + c\\) Determine the following definite integrals \\(\\int_0^2 x^2-2x\\; dx\\) \\(\\int_4^{16} \\frac{2}{\\sqrt{x}} \\; dx\\) \\(\\int_{-r}^r \\frac{mx^2}{2r}\\: dx\\) \\(\\int_{-\\frac{\\pi}{2}}^\\frac{\\pi}{2}\\cos(x)\\; dx\\) \\(\\int_{\\ln(2)}^{\\ln(3)} e^x\\; dx\\) Answers: \\(\\int_0^2 x^2-2x\\; dx = \\left[\\frac{x^3}{3} - x^2\\right]_0^2 = \\left(\\frac{2^3}{3} - 2^2\\right) - 0 = -\\frac{4}{3}\\) \\(\\int_4^{16} \\frac{2}{\\sqrt{x}} \\; dx = \\int_4^16 2x^{-\\frac{1}{2}}\\;dx = \\left[4x^{\\frac{1}{2}}\\right]_4^16 = 16 - 8 = 8\\) Note that the limit, \\(r\\), appears inside the integral, but it is just a constant. It is explicitly taken out of the integral here \\(\\int_{-r}^r \\frac{mx^2}{2r}\\:dx = \\frac{m}{2r}\\int_{-r}^r x^2 \\: dx = \\frac{m}{2r}\\left[\\frac{1}{3}x^3\\right]_{-r}^r = \\frac{m}{2r}\\left(\\frac{r^3}{3} + \\frac{r^3}{3}\\right) = \\frac{mr^2}{3}\\) \\(\\int_{-\\frac{\\pi}{2}}^\\frac{\\pi}{2}\\cos(x)\\; dx = \\left[\\sin(x)\\right]_{-\\frac{\\pi}{2}}^\\frac{\\pi}{2} = \\sin(\\pi/2) - \\sin(\\pi/2) = 2\\) \\(\\int_{\\ln(2)}^{\\ln(3)} e^x\\; dx = \\left[e^x\\right]_{\\ln(2)}^{\\ln(3)} = e^{\\ln(3)} - e^{\\ln(2)} = 3-2 = 1\\) Find the area between the curve and the \\(x\\)-axis of the function \\(f(x)=x^3-x\\) and the lines \\(x=0\\) and \\(x=2\\). Answer: We are looking for the area enclosed by the function and the \\(x\\)-axis, but we cannot simply take the definite integral from \\(0\\) to \\(2\\) as the function is negative at some points on this interval. The roots of \\(f(x)=x^3-x=x(x+1)(x-1)\\) are \\(-1,0,1\\) and these are where the function changes sign. We can plug in values between the roots to see where \\(f(x)\\) is positive and where it is negative. Since we are interested in the interval from \\(0\\) to \\(2\\) we check \\(f(0.5)=-3.75\\) and \\(f(2)=6\\). So the area will be given by \\[A=\\int_0^1 -f(x)\\, dx + \\int_1^2 f(x)\\, dx.\\] Hence \\[A=\\left[-\\frac{1}{4}x^4 + \\frac{1}{2}x^2\\right]_0^1 + \\left[\\frac{1}{4}x^4 - \\frac{1}{2}x^2\\right]_1^2 = (\\frac{1}{4}-0) + (2 - (-1/4)) = \\frac{5}{2}.\\] The velocity \\(v\\) (\\(\\text{ms}^{-1}\\)) of a particle moving in a straight line at time \\(t\\) (\\(\\text{s}\\)) is given by: \\[v=6t^2-30t-36\\quad t&gt;0\\] By integrating, find the distance travelled by the particle between \\(t=3\\) and \\(t=5\\) seconds. Answer: \\[\\int_3^5 6t^2 - 30t - 36\\: dt = \\left[2t^3 - 15t^2 - 36t\\right]_3^5 = -116\\] Since we are looking for a distance, we take the absolute value: \\(116\\text{m}\\). Find the following integrals using a suitable substitution. \\(\\int (4x-3)^5 \\; dx\\) \\(\\int 4\\sin(3x+2)\\; dx\\) \\(\\int_2^5 \\frac{1}{1-2x} \\; dx\\) \\(\\int \\frac{1}{\\sqrt{(5-3x)^3}}\\; dx\\) \\(\\int \\frac{4x}{\\sqrt{(x^2+3)^3}}\\; dx\\) \\(\\int 2xe^{x^2-5}\\; dx\\) \\(\\int \\frac{\\sin(\\sqrt{x})}{\\sqrt{x}}\\; dx\\) \\(\\int \\cos(\\theta)\\sin(\\theta)\\; d\\theta\\) \\(\\int \\frac{\\cos(x)}{1+\\sin(x)}\\; dx\\) Answers: \\(\\int (4x-3)^5\\:dx\\). Let \\(u=4x-3\\), so \\(\\frac{du}{dx}=4 \\Rightarrow dx = \\frac{1}{4}du\\) \\[ \\int (4x-3)^5\\;dx = \\int u^5 \\frac{1}{4}du =\\frac{u^6}{24} +c = \\frac{(4x-3)^6}{24} + c\\] \\(\\int 4\\sin(3x+2)\\;dx\\). Let \\(u=3x+2\\), so \\(\\frac{du}{dx} = 3 \\Rightarrow dx = \\frac{1}{3}du\\), \\[ \\int 4\\sin(3x+2)\\;dx = \\frac{4}{3}\\int\\sin(u)\\:du = -\\frac{4}{3}\\cos(u) + c = -\\frac{4}{3}\\cos(3x+2) + c \\] \\(\\int_2^5\\frac{1}{1-2x}\\:dx\\). Let \\(u=1-2x\\), so \\(\\frac{du}{dx} = -2 \\Rightarrow dx = -\\frac{1}{2}du\\). This is a definite integral, so the limits must also be given in terms of u: \\[\\begin{align*} \\int_{x=2}^{x=5} \\frac{1}{1-2x}\\:dx &amp;= -\\frac{1}{2}\\int_{u=-3}^{u=5}\\frac{du}{u} = -\\frac{1}{2}\\left[\\ln(u)\\right]_{-3}^{-9}\\\\ &amp;= -\\frac{1}{2}(\\ln(-9) - \\ln(-3)) = -\\frac{1}{2}\\ln\\left(\\frac{-9}{-3}\\right) = -\\frac{1}{2}\\ln(3) \\end{align*}\\] \\(\\int\\frac{1}{\\sqrt{(5-3x)^3}}\\:dx\\). Let \\(u=5-3x\\), so \\(\\frac{du}{dx} = -3 \\Rightarrow dx = -\\frac{du}{3}\\) \\[ \\int\\frac{1}{\\sqrt{(5-3x)^3}}\\:dx = \\int u^{-\\frac{3}{2}}\\:du = \\frac{2}{3}u^{-\\frac{1}{2}} + c = \\frac{2}{3}(5-3x)^{-\\frac{1}{2}} + c \\] \\(\\int\\frac{4x}{\\sqrt{(x^2 + 3)^3}}\\:dx\\). Let \\(u=x^2 +3\\), so \\(\\frac{du}{dx} = 2x \\Rightarrow dx = \\frac{du}{2x}\\). Here, the \\(4x\\) term remains in the denominator after substituting, but will be cancelled out once \\(dx\\) is substituted. \\[ \\int\\frac{4x}{\\sqrt{(x^2 + 3)^3}}\\:dx = \\int\\frac{4x}{u^{\\frac{3}{2}}}\\frac{du}{2x} = \\int 2u^{-\\frac{3}{2}} = -4u^{-\\frac{1}{2}} + c = -4(x^2+3)^{-\\frac{1}{2}} + c \\] This could also have been solved by reverse chain rule (think about how the answer would be differentiated, and see that the integral was of the form \\(g&#39;(x)f(g(x))\\). \\(\\int 2x e^{x^2-5}\\:dx\\). Let \\(u=x^2 - 5\\) so \\(\\frac{du}{dx} = 2x \\Rightarrow dx = \\frac{du}{2x}\\). Again, the remaining term in \\(x\\) is removed after substituting for \\(u\\) without needed to take a square root. \\[ \\int 2x e^u \\frac{du}{2x} = \\int e^u \\: du = e^u + c = e^{x^2 -5} + c \\] Which could have been solved by identifying reverse chain rule. \\(\\int \\frac{\\sin(\\sqrt{x})}{\\sqrt{x}} dx\\). Let \\(u= \\sqrt{x}\\) so \\(\\frac{du}{dx} = \\frac{1}{2\\sqrt{x}} \\Rightarrow \\frac{1}{\\sqrt{x}}dx = 2du\\). \\[\\int \\frac{\\sin(\\sqrt{x})}{\\sqrt{x}} dx=2\\int \\sin(u) du = -2\\cos(u)+c=-2\\sin(\\sqrt{x})+c.\\] \\(\\int \\cos(\\theta)\\sin(\\theta)\\: d\\theta\\). Let \\(u= \\sin(\\theta)\\) so \\(\\frac{du}{d\\theta} = \\cos(\\theta) \\Rightarrow d\\theta = \\frac{du}{\\cos(\\theta)}\\). \\[ \\int \\cos(\\theta)\\sin(\\theta)\\: d\\theta = \\int \\cos(\\theta)u\\frac{du}{\\cos(\\theta)} = \\int u\\: du = \\frac{1}{2}u^2 + c = \\frac{1}{2}\\sin^2(\\theta) + c \\] \\(\\int \\frac{\\cos(x)}{1+\\sin(x)}\\:dx\\). Let \\(u=1+\\sin(x)\\) so \\(\\frac{du}{dx} = \\cos(x) \\Rightarrow dx = \\frac{du}{\\cos(x)}\\) \\[ \\int \\frac{\\cos(x)}{1+\\sin(x)}\\:dx = \\int \\frac{1}{u}\\:du = \\ln(u)+c = \\ln(1+\\sin(x)) + c\\] The Root Mean Square (RMS) value of a signal over the interval \\(a\\) to \\(b\\) is defined as \\[\\left(\\frac{1}{b-a}\\int_{a}^{b} (f(x))^2 \\; dx\\right)^\\frac{1}{2}\\] Find the RMS of the voltage signal \\[V(t)=3\\sin(2t)+5\\cos(4t)\\] between \\(a=0\\) and \\(b=2\\pi\\). Answer: Firstly, multiply out the square term inside the integral, so \\[\\begin{align*} v(t)^2 &amp;= (3\\sin(2t) + 5\\cos(4t))(3\\sin(2t) + 5\\cos(4t))\\\\ &amp;= 9\\sin^2(2t) + 30\\sin(2t)\\cos(4t) + 25\\cos^2(4t) \\end{align*}\\] So the individual terms in the integral, with constants taken outside of the integral, are \\[ \\int_0^{2\\pi} (v(t))^2\\:dt = 9\\int_0^{2\\pi} \\sin^2(2t)\\:dt + 30\\int_0^{2\\pi} \\sin(2t)\\cos(4t)\\:dt + 25 \\int_0^{2\\pi}\\cos^2(4t)\\:dt \\] We evaluate each of the terms separately: \\[ 9\\int_0^{2\\pi} \\sin^2(2t)\\:dt = 9\\int_0^{2\\pi}\\frac{1-\\cos(4t)}{2}\\:dt\\] having used the cosine double-angle formula: \\(\\cos(2\\theta) = 1- 2\\sin^2(\\theta)\\). \\[ \\frac{9}{2}\\left[t - \\frac{1}{4}\\sin(4t)\\right]_0^{2\\pi} = \\frac{9}{2}(2\\pi - 0) = 9\\pi\\] For the second term, we again need a trigonometric identity, in this case the product to sum formula \\(\\sin(\\theta)\\cos(\\phi) = \\frac{1}{2}(\\sin(\\theta + \\phi) + \\sin(\\theta - \\phi))\\): \\[ 30\\int_0^{2\\pi} \\sin(2t)\\cos(4t)\\: dt = \\frac{30}{2}\\int_0^{2\\pi} = \\sin(6t) + \\sin(-2t)\\:dt = 15\\int_0^{2\\pi}\\sin(6t) - \\sin(2t)\\:dt \\\\= 15\\left[-\\frac{1}{6}\\cos(6t) + \\frac{1}{2}\\cos(2t)\\right]_0^{2\\pi} = 0 \\] And finally, using \\(\\cos^2(4t) = \\frac{1}{2}(\\cos(8t)+1)\\): \\[ 25\\int_0^{2\\pi}\\cos^2(4t)\\: dt = \\frac{25}{2}\\int_0^{2\\pi}\\cos(8t) + 1\\:dt \\\\= \\frac{25}{2}\\left[\\frac{1}{8}\\sin(8t) + t\\right]_0^{2\\pi} = 25\\pi \\] Putting these three terms together: \\[ \\int_0^{2\\pi}(v(t))^2\\:dt = 34\\pi\\\\ \\left(\\frac{1}{2\\pi - 0}\\int_0^{2\\pi}(v(t))^2\\:dt\\right)^{\\frac{1}{2}} = \\left(\\frac{34\\pi}{2\\pi}\\right)^\\frac{1}{2} = \\sqrt{17} \\] The volume of revolution of a curve is defined as \\[\\int_a^b \\pi (f(x))^2 \\; dx\\] Find the volume of revolution of the curve \\[f(x)=e^{-2x}\\] between \\(a=1\\) and \\(b=2\\). Answer: If \\(f(x) = e^{-2x}\\) then \\((f(x))^2 = e^{-4x}\\). So the voume of revolution of the curve \\(f(x)\\) between \\(a=1\\) and \\(b=2\\) is \\[ \\int_1^2 \\pi e^{-4x}\\;dx = \\pi\\left[-\\frac{1}{4}e^{-4x}\\right]_1^2 = \\pi\\left(\\frac{-e^{-8}}{4} - \\frac{-e^{-4}}{4}\\right) =0.0141 \\text{ to 3d.p.} \\] The points \\((1,1)\\) and \\((2,8)\\) on the curve \\(y=x^3\\) are joined by a straight line. Calculate the area between the line and the curve. Answer: The area between two curves described by funtions \\(f_1(x)\\) and \\(f_2(x)\\) is the area between the function \\((f_1(x) - f_2(x))\\) and the \\(x\\)-axis. First, find the equation of the line between the points \\((1,1)\\) and \\((2,8)\\): \\[ f_1(x) = 7x - 6, \\quad \\text{since the gradient is } \\frac{8-1}{2-1}. \\] So the area between the line \\(y=f_1(x)\\) and the line \\(y=f_2(x) = x^3\\) is \\[\\begin{align*} \\int_1^2 (f_1(x)-f_2(x))\\;dx &amp;= \\int_1^2 7x-6-x^3\\;dx\\\\ &amp;= \\left[\\frac{7}{2}x^2 - 6x - \\frac{1}{4}x^4\\right]_1^2\\\\ &amp;= (14-12-4)-(\\frac{7}{2} - 6 -\\frac{1}{4})\\\\ &amp;= \\frac{3}{4} \\end{align*}\\] "],["exercise-set-13.html", "Exercise Set 13", " Exercise Set 13 Determine the following integrals by making use of trigonometric or hyperbolic identities. \\(\\displaystyle \\int_0^{\\pi/4}4\\sin(3\\theta)\\cos(\\theta)d\\theta\\) \\(\\displaystyle \\int \\left( \\cos\\left(\\frac{x}{2}\\right) - \\sin\\left(\\frac{x}{2}\\right)\\right)^2 \\, dx\\) \\(\\displaystyle \\int \\sin^3(x)\\, dx\\) \\(\\displaystyle \\int \\frac{ \\cos(2x)} { \\cos^2(x) \\sin^2(x)} \\, dx\\) \\(\\displaystyle \\int \\cos(x) \\sin(2x) \\, dx\\) \\(\\displaystyle \\int \\tan(2x) \\,dx\\) \\(\\displaystyle \\int \\sinh^3(x) \\cosh^2(x)\\) Determine the following integrals using the method of partial fractions. \\(\\displaystyle \\int \\frac{1}{x^2+x-6} \\, dx\\) \\(\\displaystyle \\int \\frac{-12u-13}{(2u+1)(u-3)} \\, du\\) \\(\\displaystyle \\int \\frac{4x^2+13x-4}{2x^2+5x-3}\\, dx\\) \\(\\displaystyle \\int \\frac{x^3}{x^2-1}\\, dx\\) \\(\\displaystyle \\int \\frac{x^5-2x^2}{x^2-1} \\, dx\\) \\(\\displaystyle \\int \\frac{z+1}{(z-1)^2} \\, dz\\) \\(\\displaystyle \\int \\frac{5y^2}{(y^2+1)(2y-1)} \\, dy\\) Determine the following integrals using the method of integration by parts. \\(\\displaystyle \\int x \\cos(x) \\,dx\\) \\(\\displaystyle \\int t^2 e^{t} \\, dt\\) \\(\\displaystyle \\int e^{x}\\sin(x) \\, dx\\) \\(\\displaystyle \\int (x+1)^2 e^{-2x} \\, dx\\) $^{-1}(x) , dx $. "],["exercise-set-13-answers.html", "Exercise Set 13 Answers", " Exercise Set 13 Answers Determine the following integrals by making use of trigonometric or hyperbolic identities. \\(\\displaystyle \\int_0^{\\pi/4}4\\sin(3\\theta)\\cos(\\theta)d\\theta\\) \\(\\displaystyle \\int \\left( \\cos\\left(\\frac{x}{2}\\right) - \\sin\\left(\\frac{x}{2}\\right)\\right)^2 \\, dx\\) \\(\\displaystyle \\int \\sin^3(x)\\, dx\\) \\(\\displaystyle \\int \\frac{ \\cos(2x)} { \\cos^2(x) \\sin^2(x)} \\, dx\\) \\(\\displaystyle \\int \\cos(x) \\sin(2x) \\, dx\\) \\(\\displaystyle \\int \\tan(2x) \\,dx\\) \\(\\displaystyle \\int \\sinh^3(x) \\cosh^2(x)\\) Answers: \\[\\int_0^{\\frac{\\pi}{4}}4\\sin(3\\theta)\\cos(\\theta)\\, d\\theta\\] Use the product to sum trigonometric identity: \\(\\sin(A)\\cos(B) = \\frac{1}{2}\\left(\\sin(A+B) + \\sin(A+B)\\right)\\). \\[\\begin{align*} 2\\int_0^{\\frac{\\pi}{4}}\\sin(4\\theta) + \\sin(2\\theta)\\, d\\theta &amp;= 2\\left[\\frac{-\\cos(4\\theta)}{4} + \\frac{-\\cos(2\\theta)}{2}\\right]_0^{\\frac{\\pi}{4}}\\\\ &amp; = 2\\left(\\frac{1}{4} - 0 + \\frac{1}{4}+\\frac{1}{2}\\right)\\\\ &amp; = 2 \\end{align*}\\] \\[\\begin{align*} \\int \\left( \\cos \\frac{x}{2} - \\sin \\frac{x}{2}\\right)^2 \\, dx &amp;= \\int \\left(\\cos^2 \\frac{x}{2}+\\sin^2 \\frac{x}{2}- \\sin x \\right) \\, dx\\\\ &amp;= \\int \\left(1 - \\sin x \\right) \\, dx\\\\ &amp;= x+\\cos x+ C \\end{align*}\\] \\[\\begin{align*} \\int \\sin^3 x \\, dx &amp;= \\int \\sin x (1 - \\cos^2 x) \\, dx\\\\ &amp; = -\\cos x + \\frac{1}{3} \\cos^3 x + C \\end{align*}\\] \\[\\begin{align*} \\int \\frac{ \\cos 2x} { \\cos^2 x \\sin^2 x} \\, dx&amp;= \\int \\frac{\\cos^2x - \\sin^2 x} { \\cos^2 x \\sin^2 x} \\, dx\\\\ &amp;=\\int \\left( \\frac{1} { \\sin^2 x } - \\frac{1} { \\cos^2 x} \\right) \\, dx\\\\ &amp;= -\\cot x -\\tan x+C \\end{align*}\\] \\[\\begin{align*} \\int \\cos x \\sin 2x \\, dx = \\int 2 \\sin x \\cos^2 x \\, dx = -{2 \\over 3} \\cos^3 x + C \\end{align*}\\] Having used \\(\\sin(2x) = 2\\sin(x)\\cos(x)\\) and using reverse chain rule, identifying that the integral was of the form \\(g&#39;(x)f&#39;(g(x))\\), with \\(g&#39;(x) = \\cos(x)\\), \\(f&#39;(x) = \\cos^2(x)\\), \\(\\int g&#39;(x)f&#39;(g(x))\\, dx = f(g(x))\\), since \\(\\frac{d}{dx} (f(g(x))) = g&#39;(x)f&#39;(g(x))\\). Or, can use the product to sum identity again: \\[\\int \\cos x \\sin 2x \\, dx = \\int \\frac{1}{2} (\\sin 3 x +\\sin x) \\, dx = - \\frac{1}{6} \\cos 3x - {1 \\over 2} \\cos x + C.\\] \\[\\int \\tan 2x \\,dx = - {1 \\over 2} \\ln \\vert \\cos 2x \\vert + C = {1 \\over 2} \\ln \\vert \\sec 2 x \\vert +C\\] Where \\(\\int\\tan(x)dx\\) can be solved with substitution, by letting \\(t =\\cos(t)\\) and \\(dx = \\frac{dt}{-\\sin(x)}\\), so \\(\\int \\frac{-1}{t}\\, dt = -\\ln(t) + C = \\ln(\\csc(x)) + c\\). Alternatively, the integral of \\(\\tan(x)\\) can be identified as reverse chain rule: \\(\\int g&#39;(x)f&#39;(g(x))\\,dx = f(g(x))\\). \\[\\begin{align*} \\int \\sinh^3 x \\cosh^2 x \\, dx &amp;= \\int \\sinh x (\\cosh^2 x - 1) \\cosh^2 x \\, dx\\\\ &amp;= - {1 \\over 3} \\cosh^3 x +{1 \\over 5} \\cosh^5 x +C \\end{align*}\\] having used \\(\\sinh^2(x) = 1 - \\cosh^2(x)\\) and reverse chain rule, or substitution with \\(u = \\cosh(x)\\) and \\(du = \\sinh(x)dx\\). Determine the following integrals using the method of partial fractions. \\(\\displaystyle \\int \\frac{1}{x^2+x-6} \\, dx\\) \\(\\displaystyle \\int \\frac{-12u-13}{(2u+1)(u-3)} \\, du\\) \\(\\displaystyle \\int \\frac{4x^2+13x-4}{2x^2+5x-3}\\, dx\\) \\(\\displaystyle \\int \\frac{x^3}{x^2-1}\\, dx\\) \\(\\displaystyle \\int \\frac{x^5-2x^2}{x^2-1} \\, dx\\) \\(\\displaystyle \\int \\frac{z+1}{(z-1)^2} \\, dz\\) \\(\\displaystyle \\int \\frac{5y^2}{(y^2+1)(2y-1)} \\, dy\\) Answers: \\[\\frac{1}{x^2+x-6} = \\frac{1}{(x+3)(x-2)} = \\frac{A}{x+3}+\\frac{B}{x-2} \\frac{A(x-2) + B(x+3)}{(x+3)(x-2)}\\] Equating the powers of \\(x\\) and solving the resulting simultaneous equations gives \\(A + B = 0\\) and \\(3B-2A = 1\\), so \\(A = -\\frac{1}{5}. B = \\frac{1}{5}\\). So \\[\\int\\frac{1}{x^2+x-6}\\,dx = \\int \\frac{-1}{5(x+3)} + \\frac{1}{5(x-2)}\\, dx = -\\frac{1}{5}\\ln(x+3) + \\frac{1}{5}\\ln(x-2) + c\\] \\[\\frac{-12u - 13}{(2u+1)(u-3)} = \\frac{A}{2u+1} + \\frac{B}{u-3} = \\frac{A(u-3) + B(2u+1)}{(2u+1)(u-3)}\\] With the numerator given two simultaneous equations solved by \\(A=2,B=-7\\). So \\[\\int\\frac{-12u-13}{(2u+1)(u-3)}\\,du = \\int \\frac{2}{2u+1} + \\frac{-7}{u-2}\\,du = \\ln(2u+1) - 7\\ln(u-3) + c\\] \\[\\frac{4x^2 + 13x - 4}{2x^2 + 5x - 3} = \\frac{A}{2x-1} + \\frac{B}{x+3} + C\\] Since the order of the numerator is equal to the order of the denominator, a constant term must be included. This gives three equations in \\(A,B,C\\), which are solved by \\(A=1,B=1,C=2\\). So \\[\\begin{align*} \\int\\frac{4x^2 + 13x - 4}{2x^2 + 5x - 3}\\, dx &amp;= \\int \\frac{1}{2x-2} + \\frac{1}{x+3} + 2 \\, dx\\\\ &amp;= \\frac{1}{2}\\ln(2x-1) + \\ln(x+3) + 2x + c \\end{align*}\\] \\[\\frac{x^3}{x^2-1} = \\frac{x^3}{(x+1)(x-1)} = \\frac{A}{x+1} + \\frac{B}{x-1} + Cx + D\\] since the numerator is one order higher than the denominator, a linear term must be included. \\[\\frac{A(x-1) + B(x+1) + Cx(x^2-1) + D(x^2-1)}{x^2-1} = \\frac{x^3}{x^2-1}\\] Giving \\(A+B=1, B-A = 0\\) and \\(C=1\\). So \\(A=\\frac{1}{2}, B=\\frac{1}{2}, C=1\\) and \\[\\begin{align*} \\int\\frac{x^3}{x^2-1}\\, dx &amp;= \\int \\frac{1}{2(x+1)} + \\frac{1}{2(x-1)} + 1\\, dx\\\\ &amp;= \\frac{1}{2}\\ln(x+1) + \\frac{1}{2}\\ln(x-1) + x + c\\\\ &amp;= \\frac{1}{2}\\ln(x^2-1) + x + c = \\ln((x^2-1)^{\\frac{1}{2}}) + x + c \\end{align*}\\] \\[\\frac{z+1}{(x-1)^2} = \\frac{A}{z-1} + \\frac{B}{(x-1)^2}\\] Since there is a repeated root of the form \\((z-\\alpha)^n\\), so the first \\(n\\) powers of \\((z-\\alpha)\\) must appear as denominators in the partial fractions exapnsion. \\[\\frac{A}{z-1} + \\frac{B}{(z-1)^2} = \\frac{A(z-1) + B}{(z-1)^2} = \\frac{z+1}{(z-1)^2}\\] The numerator is solved by \\(A=1\\) and \\(B=3\\), so \\[\\int \\frac{z+1}{(z-1)^2}\\,dz = \\int \\frac{1}{z-1} + \\frac{3}{(z-1)^2} \\, dz = \\ln(z-1) - (z-1)^{-3} + c\\] \\[\\frac{5y^2}{(y^2+1)(2y-1)} = \\frac{Ay+B}{y^2+1} + \\frac{C}{2y-1}\\] with the numerator of the first partial fraction being a linear polynomial since the quadratic in the denominator is irreducible. \\[ \\frac{(Ay+B)(2y-1) + C(y^2+1)}{(y^2+1)(2y-1)} = \\frac{2Ay^2 - Ay + 2By - B + Cy^2 + 1}{(y^2+1)(2y-1)} = \\frac{5y^2}{(y^2+1)(2y-1)}\\] Equating the powers of \\(y\\) gives \\[2A+C = 5,\\quad 2B-A = 0,\\quad 1-B = 0\\\\ \\Rightarrow A=2,B=1,C=1\\] so the integral can be rewritten as the partial fractions \\[ \\int \\frac{5y^2}{(y^2+1)(2y-1)}\\;dy = \\int \\frac{2y+1}{y^2+1} + \\frac{1}{2y-1}\\, dy = \\tan^{-1}(y) + \\ln(y^2+1) + \\frac{1}{2}\\ln(2y-1) + c\\] Determine the following integrals using the method of integration by parts. \\(\\displaystyle \\int x \\cos(x) \\,dx\\) \\(\\displaystyle \\int t^2 e^{t} \\, dt\\) \\(\\displaystyle \\int e^{x}\\sin(x) \\, dx\\) \\(\\displaystyle \\int (x+1)^2 e^{-2x} \\, dx\\) $^{-1}(x) , dx $. Answers: Using integration by parts, \\(\\int u\\,dv = uv - \\int v\\,du\\) with \\(u=x\\) and \\(dv = \\cos(x)\\) \\[\\int x \\cos (x) \\, dx = x \\sin (x) - \\int \\sin (x) \\, dx = x \\sin (x) + \\cos (x) + C \\] Let \\(u = t^2, du = 2t, dv = e^t, v = e^t\\) \\[\\int t^2 e^t \\,dt = t^2e^t - \\int 2te^t \\,dt\\] Here, perform integration by parts once again. Let \\(u=t, du = 1, dv = e^t, v = e^t\\) \\[\\int te^t \\,dt = te^t - \\int e^t \\,dt = (t-1)e^t\\] and the orignal integral becomes \\[\\int t^2 e^t\\,dt = t^2 e^t - 2\\int te^t\\,dt = t^2 e^t - 2(t-1)e^t = (t^2 -2t + 2)e^t + c\\] Integrating by parts, \\(\\int f\\,dg = fg - \\int g\\,df\\) with \\(f = \\sin(x),df = \\cos(x), dv = e^x, v = e^x\\). \\[ \\int e^x \\sin(x)\\,dx = e^x \\sin(x) - \\int e^x \\cos(x)\\,dx\\] And we are still left with an integral that must be solved by parts. It looks like this cycle might keep repeating, but in fact, trying out the next step will reveal the answer. Let \\(u= \\cos(x),du=-\\sin(x), dv=e^x,v=e^x\\) \\[\\int e^x \\cos(x) \\,dx = e^x \\cos(x) + \\int e^x \\sin(x)\\,dx\\] And examining the original integral we see that \\(\\int e^x \\sin(x)\\,dx\\) appears on both sides: \\[ \\int e^x \\sin(x)\\,dx = e^x\\sin(x) - \\left(e^x\\cos(x)+\\int e^x \\sin(x)\\,dx\\right)\\\\ 2\\int e^x \\sin(x)\\,dx = e^x\\sin(x) - e^x\\cos(x)\\\\ \\int e^x \\sin(x)\\,dx = \\frac{1}{2}e^x\\left(\\sin(x)-\\cos(x)\\right) + c\\] \\[\\int (x+1)^2 e^{-2x} \\, dx = -{1 \\over 2}(x+1)^2 e^{-2x} + \\int (x+1) e^{-2x} \\, dx = -{1 \\over 2}(x+1)^2 e^{-2x} - {1 \\over 2}(x+1) e^{-2x}\\] \\[y = \\sin^{-1} x \\Rightarrow \\sin y = x \\Rightarrow \\cos y {\\frac{dy}{dx}} = 1 \\Rightarrow {\\frac{dy}{dx}} = (1 - x^2)^{-1/2},\\] so \\[\\int \\sin^{-1} x \\, dx = x \\sin^{-1} x - \\int x (1-x^2)^{-1/2} \\, dx = x \\sin^{-1} x + (1 - x^2)^{1/2} + C \\] "],["exercise-set-14.html", "Exercise Set 14", " Exercise Set 14 Using the method of separation of variables, find the general solutions of the following first order differential equations and the particular solutions in those cases where initial conditions are specified: \\(\\displaystyle x^2\\frac{dy}{dx}=(y+xy)\\) \\(\\displaystyle \\frac{dy}{dx}=\\frac{y-1}{x-1},\\; y(2)=3\\) \\(\\displaystyle \\frac{dy}{dx}=\\frac{y+2}{x-2}\\) Using the integrating factor method, find the general solutions of the following linear first order differential equations and the particular solutions in those cases where initial conditions are specified: \\(\\displaystyle \\frac{dy}{dx}+\\frac{3}{x}y=4+x^2,\\;y(1)=1\\) \\(\\displaystyle x\\frac{dy}{dx}+2y=x^{-4},\\;y(1)=-\\frac{1}{2}\\) \\(\\displaystyle \\frac{dy}{dx}+\\frac{y}{x}=\\cos(x),\\;y\\left(\\frac{\\pi}{2}\\right)=0\\) \\(\\displaystyle \\frac{dy}{dx}=e^{-x}-2y,\\;y(0)=0\\) \\(\\displaystyle \\frac{dy}{dx}=y\\tan(x)+\\sin(x)\\) Find the general solutions of the following constant coefficient, linear, homogeneous differential equations, and the particular solutions in those cases where initial conditions are specified: \\(\\displaystyle \\frac{d^2y}{dx^2}+5\\frac{dy}{dx}+6y=0,\\;y(0)=0,\\; \\frac{dy(0)}{dx}=1\\) \\(\\displaystyle \\frac{d^2y}{dx^2}+8\\frac{dy}{dx}+25y=0,\\;y(0)=1,\\; \\frac{dy(0)}{dx}=0\\) \\(\\displaystyle \\frac{d^2y}{dx^2}+2\\frac{dy}{dx}+y=0\\) For each of the following differential equations, find: the Complementary Function; a Particular Integral; and the Particular Solution corresponding to the given initial conditions: \\(\\displaystyle \\frac{d^2y}{dx^2}+\\frac{dy}{dx}+y=36e^{5x}\\) \\(\\displaystyle \\frac{d^2y}{dx^2}+3\\frac{dy}{dx}-4y=-34\\sin(x)\\) \\(\\displaystyle \\frac{d^2y}{dx^2}+3\\frac{dy}{dx}-4y=24e^{-x},\\;y(0)=0,\\; \\frac{dy(0)}{dx}=10\\) \\(\\displaystyle \\frac{d^2y}{dx^2}-3\\frac{dy}{dx}+2y=x^2-2x+3,\\;y(0)=\\frac{3}{4},\\; \\frac{dy(0)}{dx}=\\frac{3}{2}.\\) "],["exercise-set-14-answers.html", "Exercise Set 14 Answers", " Exercise Set 14 Answers Using the method of separation of variables, find the general solutions of the following first order differential equations and the particular solutions in those cases where initial conditions are specified: \\(\\displaystyle x^2\\frac{dy}{dx}=(y+xy)\\) \\(\\displaystyle \\frac{dy}{dx}=\\frac{y-1}{x-1},\\; y(2)=3\\) \\(\\displaystyle \\frac{dy}{dx}=\\frac{y+2}{x-2}\\) Answers: First we separate the variables \\[ x^2\\frac{dy}{dx} = y(1+x)\\\\ \\Rightarrow \\frac{1}{y}\\frac{dy}{dx} = \\frac{1+x}{x^2} = \\frac{1}{x^2} + \\frac{1}{x}\\] Now integrating both sides with respect to \\(x\\) \\[\\int \\frac{1}{y}\\frac{dy}{dx} \\, dx = \\int \\left(\\frac{1}{x^2} + \\frac{1}{x}\\right) \\, dx \\Rightarrow \\int \\frac{1}{y}\\, dy\\\\ \\int \\frac{1}{y} = \\int \\left(\\frac{1}{x^2} + \\frac{1}{x}\\right)\\, dx\\\\ \\ln(y) = -\\frac{1}{x} + \\ln(x) + c\\] Which can be rewritten as \\(\\ln(y)-\\ln(x) = -x^{-1} + c\\) and then, by applying the logarithmic rule \\(\\ln(B) - \\ln(C) = \\ln(\\tfrac{B}{C})\\) \\[ \\ln\\left(\\frac{y}{x}\\right) = -\\frac{1}{x} + c\\] Which can be written in terms of the exponential (raise \\(e\\) to the power of both sides) \\[ \\frac{y}{x} = e^{-\\frac{1}{x} + c} = Ae^{-\\frac{1}{x}}\\\\ y = Axe^{-\\frac{1}{x}}\\] Where \\(A = e^c\\). First, separate the variables and integrate \\[ \\int\\frac{dy}{y-1} =\\int\\frac{dx}{x-1}+C, \\] so the general solution is \\[ \\ln|y-1|=\\ln|x-1|+C \\implies \\quad \\left|\\frac{y-1}{x-1}\\right| = B, \\] where \\(C\\) and \\(B=e^C\\) are constants. This means that \\(\\frac{y-1}{x-1}= A\\), where \\(A\\) is another constant, giving the general solution \\(y=A(x-1)+1\\). Because \\(y(2) = 3\\), we have that \\(3 = A + 1\\), so the particular solution is \\[ y(x) = 2x+1 \\] Separatating the variables yields \\[ \\frac{1}{y+2} \\frac{dy}{dx} = \\frac{1}{x-2}\\] And now integrating with respect to \\(x\\) \\[\\int \\frac{1}{y+2} \\frac{dy}{dx}\\, dx = \\int \\frac{1}{x-2}\\,dx\\\\ = \\int \\frac{1}{y+2} dy = \\int \\frac{1}{x-2} dx\\\\ \\Rightarrow \\ln(y+2) = \\ln(x-2) + c\\] Letting \\(c = \\ln (A)\\), with \\(A\\) another constant, then \\[\\ln(y+2) = \\ln(x-2) + \\ln(A) = \\ln((x-2)A)\\] So \\(y+2 = A(x-2)\\) and \\(y = Ax-2A -2\\). Using the integrating factor method, find the general solutions of the following linear first order differential equations and the particular solutions in those cases where initial conditions are specified: \\(\\displaystyle \\frac{dy}{dx}+\\frac{3}{x}y=4+x^2,\\;y(1)=1\\) \\(\\displaystyle x\\frac{dy}{dx}+2y=x^{-4},\\;y(1)=-\\frac{1}{2}\\) \\(\\displaystyle \\frac{dy}{dx}+\\frac{y}{x}=\\cos(x),\\;y\\left(\\frac{\\pi}{2}\\right)=0\\) \\(\\displaystyle \\frac{dy}{dx}=e^{-x}-2y,\\;y(0)=0\\) \\(\\displaystyle \\frac{dy}{dx}=y\\tan(x)+\\sin(x)\\) Answers: Recall that for a first order differential equation of the form \\[\\frac{dy}{dx} + p(x)y = r(x)\\] The integrating factor \\(u(x)\\) is given by \\[ u(x) = \\exp\\left(\\int p(x)\\, dx\\right) \\] and then \\[\\frac{d}{dx}(u(x)y(x)) = u(x)r(x)\\] and \\[ y(x) = \\left[ \\int e^{\\int p(x)dx} r(x) \\,dx + C\\right] e^{-\\int p(x) dx}. \\] See the lecture notes for details for why this is the case. Here, \\(u(x) = \\exp\\left(\\int \\frac{3}{x}dx\\right) = e^{\\ln(x^3)} = x^3\\), and we have that \\[ \\frac{d}{dx}(x^3y) = x^3 (4+x^2) = x^5 + 4x^3\\\\ \\Rightarrow x^3y = \\int x^5 + 4x^3 \\, dx = \\frac{1}{6}x^6 + x^4 + c \\Rightarrow y = \\frac{1}{6} x^3 + x + \\frac{c}{x^3} \\] And from the initial condition \\(y(1) = 1\\) \\[1 = \\frac{1}{6} + 1 + c \\Rightarrow c = -\\frac{1}{6}\\] so \\[y(x) = \\frac{1}{6}x^3 + x -\\frac{1}{6X^3}\\] \\[x \\frac{dy}{dx} + 2y = x^{-4}\\] Whic is equivalent to \\[\\frac{dy}{dx} + 2\\frac{y}{x} = x^{-5}\\] Here, the integrating factor is \\[u(x) = \\exp\\left(\\int \\frac{2}{x}dx\\right) = e^{ln(x^2)} = x^2\\] and \\[\\frac{d}{dx}(x^2y) = x^2x^{-5} = x^{-3}\\\\ \\Rightarrow x^2y = \\int x^{-3} \\, dx = -\\frac{1}{2}x^{-2} + C\\] And with the initial conditions \\(y(1)=-\\frac{1}{2}\\), \\(c = 0\\), and the particular solution is \\[y(x) = -\\frac{1}{2}x^{-4}\\] \\[\\frac{dy}{dx} + \\frac{y}{x} = \\cos(x)\\] In this case, the integrating factor is \\[u(x) = \\exp\\left(\\int\\frac{1}{x}dx\\right) = e^{\\ln(x)} = x\\\\ \\Rightarrow \\frac{d}{dx}(e^xy) = e^x\\cos(x)\\\\ x y = \\int x\\cos(x)\\, dx\\] And the inegral can be solved by parts: \\(\\int uv&#39; = uv - \\int u&#39;v\\). Let \\(u=x, u&#39;=1, v&#39; = \\cos(x), v = \\sin(x)\\). So \\[ x y = x\\sin(x) - \\int \\sin(x)\\,dx = x\\sin(x) + \\cos(x) + c\\\\ y = \\sin(x) + \\frac{\\cos(x)}{x} + \\frac{c}{x}\\] With \\(y(\\frac{\\pi}{2}) = 0\\), \\(c=-\\frac{\\pi}{2}\\) so the particular solution is \\[ y(x) = \\sin(x) + \\frac{\\cos(x)}{x} + \\frac{\\pi}{2x}\\] First rearrange to \\[\\frac{dy}{dx} + 2y = e^{-x}\\] The integrating factor is \\[u(x) = \\exp\\left(\\int 2 dx\\right) = e^{2x}\\] Then the general solution is \\[ y = \\frac{1}{e^{2x}}\\int e^{2x}e^{-x} \\, dx = \\frac{1}{e^{2x}}(e^x + c) = \\frac{1}{e^x} + \\frac{c}{e^{2x}}\\] And to find the particular solution with the intial condition \\(y(0) = 0\\), \\(c=-1\\) and he particular solution is \\[ y = e^{-x} - e^{-2x}\\] \\[\\frac{dy}{dx} - y\\tan(x) = \\sin(x)\\] Here, the integrating factor (taking care with the minus sign which must be included in \\(p(x)\\)) is \\[ \\begin{align} u(x) &amp;= \\exp\\left(\\int -\\tan(x)\\,dx\\right) = \\exp\\left(\\int -\\frac{\\sin(x)}{\\cos(x)}dx\\right)\\\\ &amp;= \\exp\\left(\\ln(\\cos(x))\\right) = \\exp\\left(\\ln(\\cos(x))\\right) = \\cos(x)\\end{align} \\] and the general solution is \\[ \\begin{align} y(x) &amp;= \\int \\cos(x)\\sin(x)\\frac{1}{\\cos(x)}\\\\ &amp;= \\left(\\frac{1}{2}\\cos^2(x) + c\\right)\\frac{1}{\\cos(x)}\\\\ &amp;= \\frac{\\cos(x)}{2} + c \\sec(x) \\end{align} \\] Note that there are other forms for the solution, since \\(\\cos(x)\\sin(x) = \\frac{1}{2}\\sin(2x)\\). Find the general solutions of the following constant coefficient, linear, homogeneous differential equations, and the particular solutions in those cases where initial conditions are specified: \\(\\displaystyle \\frac{d^2y}{dx^2}+5\\frac{dy}{dx}+6y=0,\\;y(0)=0,\\; \\frac{dy(0)}{dx}=1\\) \\(\\displaystyle \\frac{d^2y}{dx^2}+8\\frac{dy}{dx}+25y=0,\\;y(0)=1,\\; \\frac{dy(0)}{dx}=0\\) \\(\\displaystyle \\frac{d^2y}{dx^2}+2\\frac{dy}{dx}+y=0\\) Answers: Recall that for second order homogeneous differential equations, we standard form is \\[\\frac{d^2y}{dx^2} + p \\frac{dy}{dx} + qy = 0\\] and we consider the possible solution \\(y = e^{mx}\\). Substitution yields \\[(m^2 + pm + q)e^{mx} = 0 \\text{ hence, because $e^{mx}$ is never zero, } m^2 + pm + q = 0.\\] Solving this auxiliary (or characteristic) equation gives the two roots, and there are three possible cases for obtaining the two linearly independent solutions—see the lecture notes. The auxiliary equation is given by \\[ m^2 + 5m + 6 = 0\\\\ (m+3)(m+2) = 0\\\\ m_1 = -3, m_2 = -2 \\] And the general solution is \\[y(X) = Ae^{-3x} + B e^{-2x}.\\] We have the intial conditions \\(y(0) = 0\\) and \\(\\frac{dy(0)}{dx} = 1\\), so \\(A+B = 0\\) and \\(-3A -2B = 1\\). This gives \\(A=-1\\) and \\(B = 1\\). So the particular solution is \\[ y(x) = -e^{-3x} + e^{-2x} \\] Here, the auxiliary (or characteristic) equation is \\[ m^2 + 8m + 25 = 0\\\\ m = \\frac{-8 \\pm \\sqrt{64 - 100}}{2}\\\\ m_1 = \\frac{-8 + 6i}{2} = -4+3i\\\\ m_2 = \\frac{-8 - 6i}{2} = -4-3i \\] The general solution is therefore \\(y= e^{-4x}(A \\cos 3x + B \\sin 3x)\\). \\(y(0)=1 \\implies A=1\\). \\(y&#39; = -4 e^{-4x}(A \\cos 3x + B \\sin 3x) + e^{-4x}(-3A \\sin 3x + 3B \\cos 3x)\\). Thus, \\(y&#39;(0)=0 \\implies -4A +3B = 0 \\implies B= \\frac{4}{3}\\), giving the particular solution \\[ y = \\frac{1}{3} e^{-4x}(3 \\cos 3x + 4 \\sin 3x). \\] \\(m^2 +2m+1 = 0 \\implies (m+1)^2=0\\), so \\(m=-1\\) twice. The general solution is then \\[ y = (A + Bx) e^{-x}. \\] For each of the following differential equations, find: the Complementary Function; a Particular Integral; and the Particular Solution corresponding to the given initial conditions: \\(\\displaystyle \\frac{d^2y}{dx^2}+\\frac{dy}{dx}+y=36e^{5x}\\) \\(\\displaystyle \\frac{d^2y}{dx^2}+3\\frac{dy}{dx}-4y=-34\\sin(x)\\) \\(\\displaystyle \\frac{d^2y}{dx^2}+3\\frac{dy}{dx}-4y=24e^{-x},\\;y(0)=0,\\; \\frac{dy(0)}{dx}=10\\) \\(\\displaystyle \\frac{d^2y}{dx^2}-3\\frac{dy}{dx}+2y=x^2-2x+3,\\;y(0)=\\frac{3}{4},\\; \\frac{dy(0)}{dx}=\\frac{3}{2}.\\) Answers: First, find the complementary function (the solution to the homogeneous differential equation). The characteristic equation for the homogeneous part is \\[m^2 + 2m + 1 = 0 \\\\(m+1)^2 = 0\\\\m=-1 \\text{equal roots}\\] Therefore, \\(y_{CF} = (A+Bx)e^{-x}\\) Now for the particular integral, the solution to the nonhomogeneous part of the differential equation. Since the right hand side is \\(36e^{5x}\\), take the trial (ansatz) particular integral \\(y_{PI} = Ce^{5x}\\). Substituting this into the differential equation gives \\[\\frac{d^2y_{PI}}{dx^2}+\\frac{dy_{PI}}{dx}+y_{PI}=36e^{5x}\\\\ 25Ce^{5x} + 2(5Ce^{5x}) + Ce^{5x} = 36Ce^{5x} = 36e^{5x}\\] and we have \\(C=1\\). Therefore, the particular integral is \\(y_{PI} = e^{5x}\\) and the general solution is \\[ y = (A+Bx)e^{-x} + e^{5x}. \\] Proceeding the same way, the characteristic equation is \\[ m^2 + 3m - 4 = 0\\\\ (m+4)(m-1) = 0\\\\ m_1 = -4, m_2 = 1 \\] so there are two distinct roots, and \\[y_{CF} = Ae^{-4x} + B e^x\\] For the particular integral, the right hand side is \\(-34\\sin(x)\\), so try the function \\[ \\begin{align} y_{PI} &amp;= a \\cos(x)+ b\\sin(x)\\\\ \\frac{dy_{PI}}{dx} &amp;= -a \\sin(x) + b\\cos(x)\\\\ \\frac{d^2y_{PI}}{dx^2} &amp;= -a \\cos(x) - b\\sin(X) \\end{align} \\] And substituting these into the differential equation \\[ \\left(-a\\cos(x) - b\\sin(x)\\right) + 3 \\left(-a \\sin(x) + b\\cos(x)\\right) - 4\\left(a\\cos(x) + b\\sin(x)\\right) = -34\\sin(x)\\\\ (3b-5a)\\cos(x) + (-5b - 3a)\\sin(x) = -34\\sin(x)\\] Equating the coefficients of \\(\\sin(x)\\) and \\(\\cos(x)\\), since the above must hold for all \\(x\\): \\[ \\begin{align} 3b-5a &amp;= 0\\\\ -5b - 3a &amp;= 0 \\end{align} \\] Solving these simultaneos equations gives \\(a=3, b=5\\). Therefore the particular integral is \\[y_{PI} = 3\\cos(x) + 5\\sin(x)\\] and the general solution \\(y = y_{CF} + y_{PI}\\) is \\[ y(x) = Ae^{-4x} + Be^x + 3\\cos(x) + 5\\sin(x) \\] The characteristic equation is solved by \\[ m^2 + 3m - 4 = 0\\\\ (m+4)(m-1) = 0\\\\ m_1 = -4, m_2 = 1 \\] There are two distinct roots and \\(y_{CF} = Ae^{-4x} = Be^x\\). For the particular integral, since the right hand side is \\(24e^{-x}\\), try the function \\[ \\begin{align} y_{PI} &amp;= Ce^{-x}\\\\ \\frac{dy_{PI}}{dx} &amp;= -Ce^{-x}\\\\ \\frac{d^2y_{PI}}{dx} &amp;= Ce^{-x} \\end{align} \\] Upon substituting into the differential equation \\[ Ce^{-x} - 3(Ce^{-x}) - 4Ce^{-x} = 24e^{-x}\\] so -6C = 25$ and \\(C = -4\\). The general solution is then \\(y = y_{CF} + y_{PI}\\) \\[ y(x) = Ae^{-4x} + B e^{-x} - 4e^{-x}\\] The initial conditions are \\(y(0) = 0\\) and \\(\\frac{dy(0)}{dx} = 0\\), which can be used to solve for \\(A\\) and \\(B\\). \\[ A+B - 4 = 0\\\\ -4a + B + 4 = 10 \\] and \\(A = -0.4\\), \\(B=4.4\\) so the particular solution is \\[ y(x) = -0.4 e^{-4x} + 4.4 e^x - 4e^{-x} \\] The characteristic equation is given by \\[ m^2 - 3m + 2 = 0\\\\ (m-2)(m-1) = 0\\\\ m_1 = 2, m_2 = 1 \\] There are two distinct roots, so the complementary function is \\[y_{CF} = Ae^{2x} + Be^x\\] Because the right hand side is a quadratic, take the particular integral to also be a quadratic. \\[ \\begin{align} y_{PI} &amp;= Cx^2 +Dx + E\\\\ \\frac{y_{PI}}{dx} &amp;= 2Cx + D\\\\ \\frac{d^2 y_{PI}}{dx^2} &amp;= 2C \\end{align} \\] Substituting into the homogeneous part of the differential equation and grouping terms in powers of \\(x\\): \\[ 2cx^2 + (2D - 6C)x + 2C - 3D + 2E = 3 \\] Which gives \\(C = \\frac{1}{2},D=\\frac{1}{2},E = \\frac{7}{4}\\). Therefrore the general solution is \\[ y = Ae^{2x} + Be^x + \\frac{x^2}{2} + \\frac{x}{2} + \\frac{7}{4} \\] For the particualr solution, find \\(A\\) and \\(B\\) given the initial conditions \\(y(0) = \\frac{3}{4}\\) and \\(\\frac{dy(0)}{dx} = \\frac{3}{2}\\) \\[ \\begin{align} A + B + \\frac{7}{4} &amp;= \\frac{3}{4} &amp;\\Rightarrow &amp; A+B &amp; = -1\\\\ 2A + B + \\frac{1}{2} &amp;= \\frac{3}{2} &amp;\\Rightarrow &amp; 2A + B &amp;=1 \\end{align} \\] From these, \\(A=2\\) and \\(B=-3\\), so the particular solution is \\[ y(x) = 2e^{2x} - 3e^x +\\frac{x^2}{2} + \\frac{x}{2} + \\frac{7}{4} \\] "],["exercise-set-15.html", "Exercise Set 15", " Exercise Set 15 Consider the experiment of multiplying the score on two fair dice. What is the sample space? What is the event of obtaining an odd number, and what is its probability? What is the event of obtaining a number that is square and odd? What is the event of obtaining a number that is square or odd? Consider the experiment of tossing a fair coin three times. Find the following probabilities: obtaining 2 heads obtaining at least 1 head obtaining at least 1 head and at least 1 tail How many ways are there of arranging the letters in the word MATHS? How many four letter arrangements are there of letters from the word UNCOPYRIGHTABLE? In a meal deal you can choose any 3 items from: sandwich, wrap, pasta, sushi, crisps, drink, chocolate. How many different meal deals are there? How many arrangements of he word MISSISSIPPI are there? How many of these contain the “word” SSSS? You roll ten fair dice. Assume that the scores of each of the ten dice are independent. What are the the probabilities that you roll exactly two sixes? you roll no sixes? you roll at least two sixes? A poker hand consists of 5 cards from a standard 52 card deck. How many diferent poker hands are there? How many poker hands are there of each of the following types? four-of-a-kind: four cards of one value, the other being another value, for instance \\(5\\spadesuit\\,5\\heartsuit\\,5\\diamondsuit\\,5\\clubsuit\\,7\\clubsuit\\) two-pairs: two cards of the same value, another two cards of a second value, and the last card being of a third value, for instance \\(Q\\heartsuit\\, Q\\clubsuit\\, 8\\spadesuit\\,8\\clubsuit\\,9\\diamondsuit\\) straight: five cards of sequential rank, but not all of the same suit, for instance, \\(A\\spadesuit\\,2\\heartsuit\\,3\\spadesuit\\,4\\clubsuit\\,5\\diamondsuit\\) A box contains 7 rock samples; 4 have an independent property set A and the other 3 have a property set B. We withdraw two rock samples one at a time without replacement. Find the probabilities: the samples have different property sets at least one rock sample has property set A if a third sample is drawn from the box, the probability of all the samples having property set B. Derive Bayes’ Theorem from the definition of conditional probability. A test is 99% effective at detecting drug use in active users and 99% effective at finding negative results for non-drug users. At a given time, 0.1% of the population are active drug users. What is the probability that a randomly selected individual who tests positive is actually a drug user? A product tester employed by the Gizmo Corporation tests the company’s gizmos. A gizmo has 3% probability of being defective. The tester’s test registers a defective gizmo as being defective with 95% probability, but it registers a non-defective gizmo as being defective with 2% probability. The tester performs a test on a gizmo drawn at random. Their test indicates the gizmo is defective.What is the probability that it really is defective? "],["exercise-set-15-answers.html", "Exercise Set 15 Answers", " Exercise Set 15 Answers Consider the experiment of multiplying the score on two fair dice. What is the sample space? What is the event of obtaining an odd number, and what is its probability? What is the event of obtaining a number that is square and odd? What is the event of obtaining a number that is square or odd? Answers: \\(S=\\{1,2,3,4,5,6,8,9,10,12,15,16,18,20,24,25,30,36\\}\\) \\(A=\\{1,3,5,9,15,25\\}\\), \\(P(A)=\\frac{1+2+2+1+2+1}{36}=\\frac{1}{4}\\) \\(B=\\{1,4,9,16,25,36\\}\\), \\(A\\cap B=\\{1,9,25\\}\\) (also \\(P(A\\cap B)=\\frac{3}{36}=\\frac{1}{12}\\)) \\(A\\cup B=\\{1,3,4,5,9,15,16,25,36\\}\\) (also \\(P(A\\cup B)=\\frac{1+2+1+2+1+2+1+1+1}{36}=\\frac{1}{3}\\)) Consider the experiment of tossing a fair coin three times. Find the following probabilities: obtaining 2 heads obtaining at least 1 head obtaining at least 1 head and at least 1 tail Answers: There are 4 ways of getting 2 heads and \\(2^3=8\\) equally likely outcomes. Hence \\(P(\\text{2 Heads})=\\frac{4}{8}=\\frac{1}{2}\\). Obtaining at least one head (call this event \\(A\\)) is the same as the complement of obtaining all tails (call this event \\(B\\)). Since the coin tosses are independent, \\(P(B)=\\left(\\frac{1}{2}\\right)^3=\\frac{1}{8}\\) and then \\(P(A)=1-P(B)=\\frac{7}{8}\\). Obtaining at least 1 head and at least 1 tail (call this event \\(A\\)) is the complement of obtaining all tails (\\(B\\)) or all heads (\\(C\\)), which are mutually exclusive. Hence \\(P(B\\cup C)=P(B)+P(C)\\) and \\(P(A)=1-P(B\\cup C)=1-\\frac{1}{8}-\\frac{1}{8}=\\frac{3}{4}\\). How many ways are there of arranging the letters in the word MATHS? Answer: There are 5 distinct letters, hence the number of arrangements is \\(5!=120\\). How many four letter arrangements are there of letters from the word UNCOPYRIGHTABLE? Answer: There are 15 distinct letters and we are choosing 4. We are interested in the different orders, so this is a question about permutations. The number of permutations is: \\[{}_{15} P_4=\\frac{15!}{(15-4)!}=\\frac{15!}{11!}=32760.\\] In a meal deal you can choose any 3 items from: sandwich, wrap, pasta, sushi, crisps, drink, chocolate. How many different meal deals are there? Answer: In this case, we are not interested in the ordering of the three items when buying them, so this is a question about combinations. The number of combinations is \\[{}_7 C_3={7 \\choose 3}=\\frac{7!}{3!4!}=35.\\] How many arrangements of he word MISSISSIPPI are there? How many of these contain the “word” SSSS? Answers: In this case, we are interested in different orderings, but there are identical letters that do not contribute to the different arrangements. We have the frequencies #M=1, #I=4, #S=4, #P=2, and we need to factor out the repeats. Hence the number of arrangements is \\[\\displaystyle{\\frac{11!}{4!4!2!}} = 34650.\\] The number of these arrangements that contain the word SSSS are the arrangements of the blocks: SSSS, M, I, I, I, P, P, I: \\[ \\frac{8!}{4!2!} = 840. \\] You roll ten fair dice. Assume that the scores of each of the ten dice are independent. What are the the probabilities that you roll exactly two sixes? you roll no sixes? you roll at least two sixes? Answers: \\({10 \\choose 2} \\left(\\frac{1}{6}\\right)^2\\left(\\frac{5}{6}\\right)^8 = 0.29 \\text{ to 2 s.f.}\\) \\(\\left(\\frac{5}{6}\\right)^{10} = 0.16 \\text{ to 2 s.f.}\\) \\(1 - \\left(\\frac{5}{6}\\right)^{10} - {10 \\choose 1} \\left(\\frac{1}{6}\\right)\\left(\\frac{5}{6}\\right)^9 = 0.52 \\text{ to 2 s.f.}\\) A poker hand consists of 5 cards from a standard 52 card deck. How many diferent poker hands are there? How many poker hands are there of each of the following types? four-of-a-kind: four cards of one value, the other being another value, for instance \\(5\\spadesuit\\,5\\heartsuit\\,5\\diamondsuit\\,5\\clubsuit\\,7\\clubsuit\\) two-pairs: two cards of the same value, another two cards of a second value, and the last card being of a third value, for instance \\(Q\\heartsuit\\, Q\\clubsuit\\, 8\\spadesuit\\,8\\clubsuit\\,9\\diamondsuit\\) straight: five cards of sequential rank, but not all of the same suit, for instance, \\(A\\spadesuit\\,2\\heartsuit\\,3\\spadesuit\\,4\\clubsuit\\,5\\diamondsuit\\) Answers: four-of-a-kind: There are \\({13 \\choose 1}\\) way of choosing the number on the four-of-a-kind, and then given the number, there are \\({4 \\choose 4} = 1\\) ways to choose the suits. Then we have \\({12 \\choose 1}\\) ways to choose the number for the remaining card, and \\({4 \\choose 1}\\) ways to choose the suit. Hence the answer is: \\[ {13 \\choose 1}{12 \\choose 1}{4 \\choose 1} = 13 \\times 12 \\times 4 = 624. \\] two pairs: Here we have \\({13 \\choose 2}\\) ways of choosing two distinct numbers from 13, corresponding to the numbers on both pairs. Then we have \\({4 \\choose 2}\\) ways of choosing the suits for each pair in turn. Then we have \\({11 \\choose 1}\\) ways of choosing the number for the remaining card, and \\({4 \\choose 1}\\) ways of choosing the suit. Hence the answer is: \\[ {13 \\choose 2}{4 \\choose 2}^2{11 \\choose 1}{4 \\choose 1} = 78 \\times 36 \\times 11 \\times 4 = 123552. \\] straight: Here there are \\({10 \\choose 1}\\) ways to choose the value of the starting card for the straight (\\(A, 2, 3, \\dots, 10\\)). Once the starting card is chosen, then there is only one way to choose the remaining values for the straight. If we include straight flushes, then there are then \\({4 \\choose 1}^5\\) ways to choose the combination of suits for the straight. However, \\({10 \\choose 1} \\times 4 = 40\\) of these correspond to straight (and royal) flushes (i.e. all with the same suit), hence the answer is: \\[ {10 \\choose 1}{4 \\choose 1}^5 - 40 = (10 \\times 1,024) - 40 = 10200. \\] A box contains 7 rock samples; 4 have an independent property set A and the other 3 have a property set B. We withdraw two rock samples one at a time without replacement. Find the probabilities: the samples have different property sets at least one rock sample has property set A if a third sample is drawn from the box, the probability of all the samples having property set B. Answers: Perhaps the easiest way of answering this question is by drawing out a “probability tree” and adding together the probabilities that give the required outcomes. \\(P(\\text{A,B})+P(\\text{B,A})=\\frac{2}{7}+\\frac{2}{7}=\\frac{4}{7}\\) \\(P(\\text{A,B})+P(\\text{B,A})+P(\\text{A,A})=1-P(\\text{B,B})=1-\\frac{1}{7}=\\frac{6}{7}\\) \\(P(\\text{B,B,B})=\\frac{1}{35}\\) We can also think in terms of arrangements. Firstly, if we were to pick out all 7 rocks the number of arrangements would be \\[ \\frac{7!}{4!\\times 3!}=35 \\] where we have divided by \\(4!\\) to account for the 4 arrangements of rocks with property A being the same, and similarly by \\(3!\\) to account for the rocks with property set B. Now we have: The first two rocks are either (A, B) or (B, A) – 2 mutually exclusive possibilities. The number of arrangements of the remaining 5 rocks are \\[ \\frac{5!}{3!\\times 2!}=10. \\] Hence the probability is \\[ \\frac{2 \\times 10}{35}=\\frac{4}{7} \\] Now we have the three possibilities (A, B), (B, A) or (A, A). This is the complement of obtaining (B, B), then looking for all arrangements of the remaining 5 rocks: \\[ \\frac{5!}{4!\\times 1!}=5. \\] So the number of ways of getting at least one A are \\(35 - 5 = 30\\) and the probability is \\[\\frac{30}{35}=\\frac{6}{7}.\\] In this case we obtain (B, B, B) and there is only 1 arrangement of the remaining 4 rocks, (A, A, A, A). Hence the probability is \\[\\frac{1}{35}.\\] Derive Bayes’ Theorem from the definition of conditional probability. Answer: From the definition of conditional probability we have \\[P(A|B)=\\frac{P(A\\cap B)}{P(B)}\\] and swapping \\(A\\) and \\(B\\), also \\[P(B|A)=\\frac{P(A\\cap B)}{P(A)}\\] where we have used \\(B\\cap A=A\\cap B\\). Re-arranging the first equation to give \\[P(A\\cap B)=P(A|B)P(B)\\] and substituting this into the second equation gives \\[P(B|A)=\\frac{P(A|B)P(B)}{P(A)}\\] which is Bayes’ Theorem. A test is 99% effective at detecting drug use in active users and 99% effective at finding negative results for non-drug users. At a given time, 0.1% of the population are active drug users. What is the probability that a randomly selected individual who tests positive is actually a drug user? Answer: Here, drug users and non-users form a partition of the sample space. Let \\(+\\) denote the event of a positive test result, so by the law of total probability we have: \\[\\begin{eqnarray*} P(+) &amp;=&amp; P(+ | \\mbox{user})P(\\mbox{user}) + P(+ | \\mbox{non-user})P(\\mbox{non-user})\\\\ &amp;=&amp; 0.99 \\times 0.001 + 0.01 \\times 0.999\\\\ &amp;=&amp; 0.011 \\text{ to 2 s.f.} \\end{eqnarray*}\\] By Bayes’ Theorem we have: \\[ P(\\mbox{user} | +) = \\frac{P(+ | \\mbox{user})P(\\mbox{user})}{P(+)}. \\] Hence the answer is: \\[\\begin{eqnarray*} P(\\mbox{user} | +) &amp;=&amp; \\frac{0.99 \\times 0.001}{0.99 \\times 0.001 + 0.01 \\times 0.999}\\\\ &amp;=&amp; 0.090 \\text{ to 2 s.f.} \\end{eqnarray*}\\] A product tester employed by the Gizmo Corporation tests the company’s gizmos. A gizmo has 3% probability of being defective. The tester’s test registers a defective gizmo as being defective with 95% probability, but it registers a non-defective gizmo as being defective with 2% probability. The tester performs a test on a gizmo drawn at random. Their test indicates the gizmo is defective.What is the probability that it really is defective? Answers: Let \\(A\\) be the event that the gizmo is defective, and let \\(B\\) be the event that the test picks this up. We have: \\[\\begin{eqnarray*} P(A) &amp;=&amp; 0.03\\\\ P(A^c) &amp;=&amp; 0.97\\\\ P(B | A) &amp;=&amp; 0.95\\\\ P(B | A^c) &amp;=&amp; 0.02, \\end{eqnarray*}\\] and we want \\(P(A | B)\\), and by Bayes’ Theorem: \\[\\begin{eqnarray*} P(A | B) &amp;=&amp; \\frac{P(B | A)P(A)}{P(B)}\\\\ &amp;=&amp; \\frac{P(B | A)P(A)}{P(B | A)P(A) + P(B | A^c)P(A^c)}\\qquad \\mbox{by law of total probability}\\\\ &amp;=&amp; \\frac{0.95 \\times 0.03}{0.95 \\times 0.03 + 0.02 \\times 0.97}\\\\ &amp;=&amp; 0.59\\text{ to 2 s.f.}. \\end{eqnarray*}\\] "],["exercise-set-16.html", "Exercise Set 16", " Exercise Set 16 You throw five fair dice and count the number of sixes you get. Let \\(X\\) be the number of sixes. Tabulate \\(P(X=x)\\) for \\(x=0, 1,\\dots,5\\). A random variable \\(X\\) has Poisson distribution with rate parameter \\(\\lambda=2\\). Find: \\(P(X \\le 2)\\) \\(P(X=3)\\) \\(P(X \\ge 4)\\) A discrete random variable \\(X\\) takes values in the set \\(\\{1,2,3,4\\}\\) and has \\(P(X=x)=x/10\\) for each \\(x\\) in this set. Find: \\(\\operatorname{E}(X)\\) \\(\\operatorname{E}(X^2)\\) \\(\\operatorname{var}(X)\\) A discrete random variable \\(X\\) takes values in the set \\(\\{1,2,3\\}\\) and has \\(P(X=x)=c/x\\) for each \\(x\\) in this set, where \\(c\\) is some suitable constant. Find \\(c\\) and so find \\(\\operatorname{E}(X)\\) \\(\\operatorname{E}(X^2)\\) \\(\\operatorname{var}(X)\\) You throw two fair dice. Let \\(X\\) denote the sum of the two numbers thrown. Find: \\(\\operatorname{E}(X)\\) \\(\\operatorname{E}(X^2)\\) \\(\\operatorname{var}(X)\\) 2% of packages produced by a packaging machine have defective seals. What is the probability that a batch will contain more than 2 defective packages if the batch size is (a) 20 (b) 50? A rifle range competitor scores one hit in every 4 shots, on the average. Assuming that the binomial distribution is applicable, if they have four shots in a session what is: the probability that they will get exactly one hit? the probability that they will get at least one hit? 2% of cans leaving a canning factory have a defective paint finish. Cans are packed in boxes in groups of 50. Determine the mean and standard deviation of the number of cans in a box which have a defective finish. Sheets of metal have a plating fault which occurs randomly at an average rate of 1 per \\(\\text{m}^2\\). What is the probability that a sheet \\(1.5\\text{m} \\times 2 \\text{m}\\) will have: At most one fault? At least one fault? 250 litres of water have been polluted with \\(10^6\\) bacteria. What is the probability that a sample of 1 ml of the water contains no bacteria? An average of 264 vehicles an hour pass along a stretch of road each taking 30 seconds to travel along it. What is the probability that at a given instant there will be no vehicles in the road? "],["exercise-set-16-answers.html", "Exercise Set 16 Answers", " Exercise Set 16 Answers You throw five fair dice and count the number of sixes you get. Let \\(X\\) be the number of sixes. Tabulate \\(P(X=x)\\) for \\(x=0, 1,\\dots,5\\). Answers: Here \\(X\\) is a binomial random variable with \\(n = 5\\) and \\(p = \\frac{1}{6}\\). Hence we have p.m.f. \\[ P(X = x) = {n \\choose x}p^x(1-p)^{n - x} \\qquad \\mbox{for}~x = 0, 1, 2, \\dots, 5. \\] This gives (to 3 s.f.): \\(X\\) \\(P(X = x)\\) 0 0.402 1 0.402 2 0.161 3 0.0322 4 0.00322 5 0.000129 A random variable \\(X\\) has Poisson distribution with rate parameter \\(\\lambda=2\\). Find: \\(P(X \\le 2)\\) \\(P(X=3)\\) \\(P(X \\ge 4)\\) Answers: Here \\(X\\) is a Poisson random variable with rate \\(\\lambda = 2\\) and p.m.f. \\[ P(X = x) = \\frac{2^x e^{-2}}{x!} \\qquad \\mbox{for}~x = 0, 1, 2, \\dots \\] \\(P(X \\le 2) = e^{-2} + 2 \\times e^{-2} + \\frac{4 \\times e^{-2}}{2} = 0.677\\text{ to 3 s.f.}\\) \\(P(X=3) = \\frac{2^3 e^{-2}}{3!} = \\frac{8 \\times e^{-2}}{6} = 0.180\\text{ to 3 s.f.}\\) \\(P(X \\ge 4) = 1 - P(X &lt; 4) = 1 - \\left(e^{-2} + 2 \\times e^{-2} + \\frac{4 \\times e^{-2}}{2} + \\frac{8 \\times e^{-2}}{6}\\right) = 1 - 0.857 = 0.143\\text{ to 3 s.f.}\\) A discrete random variable \\(X\\) takes values in the set \\(\\{1,2,3,4\\}\\) and has \\(P(X=x)=x/10\\) for each \\(x\\) in this set. Find: \\(E(X)\\) \\(E(X^2)\\) \\(\\operatorname{Var}(X)\\) Answers: \\(E(X) = \\sum_{x = 1}^4 \\frac{x^2}{10} = \\frac{1}{10}(1 + 4 + 9 + 16) = \\frac{30}{10} = 3\\); \\(E(X^2) = \\sum_{x = 1}^4 \\frac{x^3}{10} = \\frac{1}{10}(1 + 8 + 27 + 64) = \\frac{100}{10} = 10\\); \\(\\operatorname{Var}(X) = E(X^2) - E^2(X) = 10 - 3^2 = 1\\); A discrete random variable \\(X\\) takes values in the set \\(\\{1,2,3\\}\\) and has \\(P(X=x)=c/x\\) for each \\(x\\) in this set, where \\(c\\) is some suitable constant. Find \\(c\\) and so find \\(E(X)\\) \\(E(X^2)\\) \\(\\operatorname{Var}(X)\\) Answers: By the axioms of probability we know that \\[\\begin{eqnarray*} \\sum_{x = 1}^3 \\frac{c}{x} &amp;=&amp; 1\\\\ c\\left(1 + \\frac{1}{2} + \\frac{1}{3}\\right) &amp;=&amp; 1 \\\\ c\\left(\\frac{6}{6} + \\frac{3}{6} + \\frac{2}{6}\\right) &amp;=&amp; 1 \\\\ c\\left(\\frac{11}{6}\\right) &amp;=&amp; 1 \\\\ c &amp;=&amp; \\frac{6}{11} \\end{eqnarray*}\\] Therefore, \\(E(X) = \\sum_{x = 1}^3 \\frac{6}{11} = 3 \\times \\frac{6}{11} = 1.64~\\text{ to 3 s.f.}\\); \\(E(X^2) = \\sum_{x = 1}^3 \\frac{6x}{11} = \\frac{6}{11}\\left( 1 + 2 + 3\\right) = 3.27~\\text{ to 3 s.f.}\\); \\(\\operatorname{Var}(X) = E(X^2) - E^2(X) = 0.595~\\text{ to 3 s.f.}\\); You throw two fair dice. Let \\(X\\) denote the sum of the two numbers thrown. Find: \\(E(X)\\) \\(E(X^2)\\) \\(\\operatorname{Var}(X)\\) Answers: Let \\(X_1\\) be the score on the first die, and \\(X_2\\) be the score on the second die, therefore \\(X = X_1 + X_2\\) and \\(E(X_1) = E(X_2) = \\frac{1 + 2 + 3 + \\dots + 6}{6} = \\frac{7}{2}\\). Also, \\(E(X_1^2) = E(X_2^2) = \\frac{1 + 4 + 9 + \\dots + 36}{6} = \\frac{91}{6}\\) \\(E(X) = E(X_1 + X_2) = E(X_1) + E(X_2) = 7\\); \\[\\begin{eqnarray*} E(X^2) &amp;=&amp; E\\left[(X_1 + X_2)^2\\right]\\\\ &amp;=&amp; E\\left(X_1^2 + 2 X_1 X_2 + X_2^2\\right)\\\\ &amp;=&amp; E\\left(X_1^2\\right) + 2 E\\left(X_1 X_2\\right) + E\\left(X_2^2\\right) \\\\ &amp;=&amp; E\\left(X_1^2\\right) + 2 E\\left(X_1\\right)E\\left(X_2\\right) + E\\left(X_2^2\\right) \\quad \\mbox{since $X_1$, $X_2$ independent}\\\\ &amp;=&amp; 2\\cdot\\frac{91}{6} + 2 \\left(\\frac{7}{2}\\right)^2\\\\ &amp;=&amp; \\frac{91}{3} + \\frac{49}{2}\\\\ &amp;=&amp; 54.8~\\text{ to 3 s.f.}. \\end{eqnarray*}\\] \\(\\operatorname{Var}(X) = E(X^2) - E^2(X) = 54.8 - 49 = 5.83~\\text{ to 3 s.f.}\\). 2% of packages produced by a packaging machine have defective seals. What is the probability that a batch will contain more than 2 defective packages if the batch size is (a) 20 (b) 50? Answers: Here we will use the binomial distribution. Let a defective seal be a “success”, then \\(p=0.02\\), \\(q=1-p=0.98\\) and the number of trials are (a) \\(n=20\\) and (b) \\(n=50\\). We want to find \\(P(X&gt;2)\\), but it is simpler to calculate this via the complement as \\(1-P(X\\leq 2)\\). We have \\[\\begin{align*} P(X=0)&amp;={20 \\choose 0}0.02^0 0.98^{20}=0.6676\\\\ P(X=1)&amp;={20 \\choose 1}0.02^1 0.98^{19}=0.2725\\\\ P(X=2)&amp;={20 \\choose 2}0.02^2 0.98^{18}=0.0528 \\end{align*}\\] \\(P(X\\le 2)=0.6676 + 0.2725 + 0.0528 = 0.9929\\) and \\(P(X&gt;2)=1-0.9929=0.0071\\) or \\(0.71\\%\\) A similar calculation with \\(n=20\\) replaced by \\(n=50\\) gives \\(0.078\\). A rifle range competitor scores one hit in every 4 shots, on the average. Assuming that the binomial distribution is applicable, if they have four shots in a session what is: the probability that they will get exactly one hit? the probability that they will get at least one hit? Answer: Let a hit correspond to a “success”, then \\(p=0.25\\) and \\(q=1-p=0.75\\). The number of trials is \\(n=4\\). We have \\[P(X=x)={4 \\choose x}0.25^x 0.75^{4-x}\\] \\(P(X=1)={4 \\choose 1}0.25^1 0.75^{3}=0.422\\). \\(P(X\\ge 1)=P(X=1)+P(X=2)+P(X=3)+P(X=4)\\) or it will be simpler to calculate via the complement: \\(P(X\\ge 1)=1-P(X&lt;1)\\) =1 - P(X=0)$ \\[P(X=0)={4 \\choose 0}0.25^0 0.75^4=0.3164\\] Hence \\[P(X\\ge 1)=1-0.3164=0.6836\\] 2% of cans leaving a canning factory have a defective paint finish. Cans are packed in boxes in groups of 50. Determine the mean and standard deviation of the number of cans in a box which have a defective finish. Answer: Let finding a defective can be a “success”, which has probability \\(p=0.02\\). The number of trials is \\(n=50\\). The mean is given by \\(np=50\\times 0.02=1\\). The standard deviation is \\(\\sqrt{np(1-p)}=\\sqrt{50\\times 0.02\\times 0.98}=0.99\\) Sheets of metal have a plating fault which occurs randomly at an average rate of 1 per \\(\\text{m}^2\\). What is the probability that a sheet \\(1.5\\text{m} \\times 2 \\text{m}\\) will have: At most one fault? At least one fault? Answers: Here we assume a Poisson distribution with rate \\(\\lambda = 1\\,\\text{m}^{-2}\\). \\[\\begin{align*} P(X\\le 1)&amp;=P(X=0)+P(X=1)\\\\ &amp;=\\frac{\\lambda^0 e^{-\\lambda}}{0!}+\\frac{\\lambda^1 e^{-\\lambda}}{1!}\\\\ &amp;=0.0498 + 0.1494 \\end{align*}\\] \\[\\begin{align*} P(X\\ge 1)&amp;=1-P(X&lt;1)\\\\ &amp;=1-P(X=0)\\\\ &amp;=1-0.0498\\\\ &amp;=0.9502 \\end{align*}\\] 250 litres of water have been polluted with \\(10^6\\) bacteria. What is the probability that a sample of 1 ml of the water contains no bacteria? Answer: 250 L contains \\(10^6\\) bacteria, so assuming a Poisson distribution with rate \\(\\dfrac{10^6}{250\\times 10^3}=4\\) bacterial per ml. Hence, \\[P(X=0)=\\frac{4^0e^{-4}}{0!}=0.0183.\\] An average of 264 vehicles an hour pass along a stretch of road each taking 30 seconds to travel along it. What is the probability that at a given instant there will be no vehicles in the road? Answer: The road will have no vehicles if none entered in the previous 30 seconds. We first determine the mean: There are 264 vehicles per hour on average, therefore in 30 seconds we would expect \\(264\\times 30/3600 = 2.2\\) cars per 30 seconds, that is, \\(\\lambda=2.2\\) \\[P(X=0)=e^{-2.2}=0.1108.\\] "],["exercise-set-17.html", "Exercise Set 17", " Exercise Set 17 A normally distributed random variable \\(X\\) has mean \\(1\\) and variance \\(4\\). Using tables, find \\(P(X&gt;0)\\) \\(P(X&lt;2)\\) \\(P(|X|&lt;1)\\) the value of \\(c\\) such that \\(P(X&lt;c)=0.0643\\) A normally distributed random variable \\(X\\) has mean 1 and variance 5. Using tables, find: \\(P(X &gt; 1)\\) \\(P(|X| &lt; 0.1)\\) The value of \\(c\\) such that \\(P(X &lt; c) = 0.01287\\) A thermostat is set to switch at \\(20^\\circ\\,\\text{C}\\) operates in a range of temperatures with a mean value of \\(20.4^\\circ\\,\\text{C}\\) and a standard deviation of \\(1.3^\\circ\\,\\text{C}\\). What is the probability that its operating temperature will fall between \\(19.5^\\circ\\,\\text{C}\\) and \\(20.5^\\circ\\,\\text{C}\\)? The life of a drill has a mean of 16 hours and a standard deviation of 2.6 hours. Assuming it is normally distributed determine the probability of a bit lasting More than 20 hours. Less than 14 hours. "],["exercise-set-17-answers.html", "Exercise Set 17 Answers", " Exercise Set 17 Answers A normally distributed random variable \\(X\\) has mean \\(1\\) and variance \\(4\\). Using tables, find \\(P(X&gt;0)\\) \\(P(X&lt;2)\\) \\(P(|X|&lt;1)\\) the value of \\(c\\) such that \\(P(X&lt;c)=0.0643\\) Answers: Let \\(Y = \\frac{X - \\mu}{\\sigma}\\), where \\(\\mu = 1\\) and \\(\\sigma = 2\\). Therefore \\(Y\\) is a standard normal random variable, and \\(X = \\sigma Y + \\mu\\). \\[\\begin{eqnarray*} P(X &gt; 0) &amp;=&amp; P([2 Y + 1] &gt; 0)\\\\ &amp;=&amp; P(Y &gt; -1/2) \\\\ &amp;=&amp; 1 - P(Y &gt; 1/2) \\qquad \\mbox{due to symmetry}\\\\ &amp;=&amp; 1 - 0.3085 \\qquad \\mbox{from tables}\\\\ &amp;=&amp; 0.692~\\text{(3 s.f.)} \\end{eqnarray*}\\] \\[\\begin{eqnarray*} P(X &lt; 2) &amp;=&amp; P([2 Y + 1] &lt; 2)\\\\ &amp;=&amp; P(Y &lt; 1/2) \\\\ &amp;=&amp; 1 - P(Y &gt; 1/2) \\qquad \\mbox{due to symmetry}\\\\ &amp;=&amp; 0.692~\\text{(3 s.f.)}\\qquad~\\mbox{from tables}. \\end{eqnarray*}\\] \\[\\begin{eqnarray*} P(|X| &lt; 1) &amp;=&amp; P(-1 &lt; X &lt; 1)\\\\ &amp;=&amp; P(-1 &lt; 2 Y + 1 &lt; 1)\\\\ &amp;=&amp; P(-1 &lt; Y &lt; 0)\\\\ &amp;=&amp; \\frac{1}{2} - P(Y &gt; 1) \\qquad \\mbox{due to symmetry}\\\\ &amp;=&amp; 0.5 - 0.1587 \\qquad \\mbox{from tables}\\\\ &amp;=&amp; 0.341~\\text{(3 s.f.)}. \\end{eqnarray*}\\] \\[\\begin{eqnarray*} P(X &lt; c) &amp;=&amp; P([2 Y + 1] &lt; c)\\\\ &amp;=&amp; P(Y &lt; (c - 1) / 2)\\\\ &amp;=&amp; P(Y &gt; (1 - c) / 2) \\qquad \\mbox{due to symmetry}. \\end{eqnarray*}\\] From tables we have that \\(P(Y &gt; 1.52) = 0.0643\\), and hence we want the value of \\(c\\) such that \\[\\begin{eqnarray*} (1 - c) / 2 &amp;=&amp; 1.52\\\\ c &amp;=&amp; -2.04. \\end{eqnarray*}\\] A normally distributed random variable \\(X\\) has mean 1 and variance 5. Using tables, find: \\(P(X &gt; 1)\\) \\(P(|X| &lt; 0.1)\\) The value of \\(c\\) such that \\(P(X &lt; c) = 0.01287\\) Answers: \\[\\begin{eqnarray*} P(X &gt; 1) &amp;=&amp; P(Z &gt; \\frac{1 - 1}{\\sqrt{5}}) \\quad \\mbox{where $Z \\sim N(0, 1)$}\\\\ &amp;=&amp; P(Z &gt; 0) \\\\ &amp;=&amp; 0.5 \\quad \\mbox{from tables}. \\end{eqnarray*}\\] (Or could answer this by noting a symmetry argument with \\(E(X) = 1\\) and therefore by definition \\(P(X &gt; 1) = 0.5\\) since the normal distribution is symmetric about the mean.) \\[\\begin{eqnarray*} P(|X| &lt; 0.1) &amp;=&amp; P(-0.1 &lt; X &lt; 0.1)\\\\ &amp;=&amp; P(\\frac{-0.1 - 1}{\\sqrt{5}} &lt; Z &lt; \\frac{0.1 - 1}{\\sqrt{5}}) \\quad \\mbox{where $Z \\sim N(0, 1)$}\\\\ &amp;=&amp; P(-0.4919 &lt; Z &lt; -0.4025)\\\\ &amp;=&amp; P(Z &gt; 0.4025) - P(Z &gt; 0.4919) \\quad \\mbox{by symmetry}. \\end{eqnarray*}\\] To calculate \\(P(Z &gt; 0.4025)\\) and \\(P(Z &gt; 0.4919)\\) we need to use linear interpolation. Firstly, we note that \\(P(Z &gt; 0.40) = 0.3446\\) and \\(P(Z &gt; 0.41) = 0.3409\\), and therefore \\[\\begin{eqnarray*} P(Z &gt; 0.4025) &amp;=&amp; P(Z &gt; 0.40) - \\frac{0.4025 - 0.4}{0.41 - 0.4}\\left[P(Z &gt; 0.40) - P(Z &gt; 0.41)\\right]\\\\ &amp;=&amp; 0.3446 - 0.25 \\times 0.0037\\\\ &amp;=&amp; 0.3437~\\text{(4 s.f.)}. \\end{eqnarray*}\\] Secondly, we note that \\(P(Z &gt; 0.49) = 0.3121\\) and \\(P(Z &gt; 0.5) = 0.3085\\), and therefore \\[\\begin{eqnarray*} P(Z &gt; 0.4919) &amp;=&amp; P(Z &gt; 0.49) - \\frac{0.4919 - 0.49}{0.5 - 0.49}\\left[P(Z &gt; 0.49) - P(Z &gt; 0.5)\\right]\\\\ &amp;=&amp; 0.3121 - 0.19 \\times 0.0036\\\\ &amp;=&amp; 0.3114~\\text{(4 s.f.)}. \\end{eqnarray*}\\] Therefore, \\[ P(|X| &lt; 0.1) = P(Z &gt; 0.4025) - P(Z &gt; 0.4919) = 0.3437 - 0.3114 = 0.0323~\\text{(4 s.f.)}. \\] From tables we have that \\(P(Z &gt; 2.23) = 0.01287\\) and so by symmetry \\(P(Z &lt; -2.23) = 0.01287\\). Therefore, \\[ P(X &lt; c) = P\\left(Z &lt; \\frac{c - 1}{\\sqrt{5}}\\right), \\] and this implies that \\[\\begin{eqnarray*} \\frac{c - 1}{\\sqrt{5}} &amp;=&amp; -2.23\\\\ c &amp;=&amp; -2.23 \\times \\sqrt{5} + 1\\\\ &amp;=&amp; -3.986~\\text{(4 s.f.)}. \\end{eqnarray*}\\] A thermostat is set to switch at \\(20^\\circ\\,\\text{C}\\) operates in a range of temperatures with a mean value of \\(20.4^\\circ\\,\\text{C}\\) and a standard deviation of \\(1.3^\\circ\\,\\text{C}\\). What is the probability that its operating temperature will fall between \\(19.5^\\circ\\,\\text{C}\\) and \\(20.5^\\circ\\,\\text{C}\\)? Answers: The operating temperature is a normal random variable \\(X\\) with mean \\(\\mu=20.4\\) and standard deviation \\(\\sigma=1.3\\). We are looking for \\(P(19.5&lt;X&lt;20.5)\\). The equivalent probability of a standard normal random variable \\(Z\\) is given by the limits \\[ z_1 = \\frac{19.5 - 20.4}{1.3}=-0.69 \\quad\\text{and}\\quad z_2=\\frac{20.5-20.4}{1.3}=0.08\\] that is \\(P(-0.69&lt; Z &lt;0.08)\\). Using standard normal distribution tables: \\[\\begin{align*} P(-0.69&lt; Z &lt;0.08)&amp;=P(0&lt;Z&lt;0.69)+P(0&lt;Z&lt;0.08)\\\\ &amp;= 0.2549 + 0.0319\\\\ &amp;= 0.2868. \\end{align*}\\] The life of a drill has a mean of 16 hours and a standard deviation of 2.6 hours. Assuming it is normally distributed determine the probability of a bit lasting More than 20 hours. Less than 14 hours. Answers: The time is a normal random variable \\(X\\) with mean \\(\\mu=16\\) and standard deviation \\(\\sigma=2.6\\). \\(P(X&gt;20)\\). The equivalent probability of a standard normal random variable \\(Z\\) is given by the limit \\[ z = \\frac{20 - 16}{2.6}=1.54\\] that is \\(P(Z &gt;1.54)\\). Using standard normal distribution tables: \\[\\begin{align*} P(Z&gt;1.54)&amp;=1-(P(0&lt;Z&lt;1.54)+0.5)\\\\ &amp;= 0.5 - 0.4382\\\\ &amp;= 0.0618. \\end{align*}\\] \\(P(X&lt;14)\\). The equivalent probability of a standard normal random variable \\(Z\\) is given by the limit \\[ z = \\frac{14 - 16}{2.6}=-0.77\\] that is \\(P(Z &lt;-0.77)\\). Using standard normal distribution tables: \\[\\begin{align*} P(Z&lt;-0.77)&amp;=1-(P(0&lt;Z&lt;0.77)+0.5)\\\\ &amp;= 0.5 - 0.2794\\\\ &amp;= 0.2206. \\end{align*}\\] "],["exercise-set-18.html", "Exercise Set 18", " Exercise Set 18 The following table contains students’ exam marks. 75 85 59 73 88 65 60 86 72 63 78 61 75 78 74 67 60 68 74 66 82 78 94 73 71 83 79 96 67 62 75 81 75 71 65 79 73 80 78 72 74 53 76 65 73 67 72 63 Create a frequency distribution table with classes 50-59, 60-69,… etc. Draw a histogram from the table. The following table shows the results of 178 measurements of the carbon content of a mixed powder fed to a plant over a period of one month. Range of values of Carbon (%) Frequency 4.10-4.19 1 4.20-4.29 2 4.30-4.39 7 4.40-4.49 20 4.50-4.59 24 4.60-4.69 31 4.70-4.79 38 4.80-4.89 24 4.90-4.99 21 5.00-5.09 7 5.10-5.19 3 Total 178 From this frequency distribution, construct: a histogram a frequency polygon an ogive From the ogive, estimate the percentage of measurements showing a carbon content below 5.00%. The following numbers are the marks obtained by 50 students in an examination: 57 60 37 74 62 40 56 59 80 60 62 94 78 73 56 68 67 79 83 87 90 93 58 46 77 63 66 66 56 71 51 77 53 69 70 69 70 70 47 54 49 54 68 35 64 67 76 73 68 61 Reduce these marks to a frequency distribution, with equal class widths, having as the first interval 35-44 inclusive. Draw an ogive for the distribution. Using the graph, what is the median mark? Use your graph to estimate what % of students pass the examination if the pass mark is 55. A sample of underweight babies was fed a special diet and the following weight gains (lbs) were observed at the end of three months: 6.7, 2.7, 2.5, 3.6, 3.4, 4.1, 4.8, 5.9, 8.3. What are the mean and standard deviation? In an examination, the marks awarded to the first 40 scripts were: 32, 57, 43, 65, 28, 60, 47, 52, 39, 48, 25, 53, 47, 52, 62, 31, 38, 46, 72, 51, 29, 45, 54, 48, 50, 66, 63, 36, 23, 43, 32, 39, 58, 55, 29, 48, 37, 43, 54, 40. Taking classes 14.5-24.5, 24.5-34.5, 34.5-44.5 etc, draw up a frequency distribution table for the marks. Also estimate the relative frequency, cumulative frequency and relative cumulative frequency. Draw a histogram, frequency polygon and ogive for this frequency distribution. From the frequency table, estimate the mean, variance and standard deviation of the marks. A city has been criticized for its excessive discharges of untreated sewage into the nearby river. A microbiologist take 45 samples of water downstream from the treated sewage outlet and measures the number of bacteria present. A summary table is as follows: Number of Bacteria Number of Samples 20-30 5 30-40 20 40-50 15 50-60 5 What are the \\(25^{\\text{th}}\\) and \\(75^{\\text{th}}\\) percentiles? "],["exercise-set-18-answers.html", "Exercise Set 18 Answers", " Exercise Set 18 Answers The following table contains students’ exam marks. 75 85 59 73 88 65 60 86 72 63 78 61 75 78 74 67 60 68 74 66 82 78 94 73 71 83 79 96 67 62 75 81 75 71 65 79 73 80 78 72 74 53 76 65 73 67 72 63 Create a frequency distribution table with classes 50-59, 60-69,… etc. Draw a histogram from the table. Answers: Class Frequency 50-59 2 60-69 14 70-79 23 80-89 7 90-99 2 The following table shows the results of 178 measurements of the carbon content of a mixed powder fed to a plant over a period of one month. Range of values of Carbon (%) Frequency 4.10-4.19 1 4.20-4.29 2 4.30-4.39 7 4.40-4.49 20 4.50-4.59 24 4.60-4.69 31 4.70-4.79 38 4.80-4.89 24 4.90-4.99 21 5.00-5.09 7 5.10-5.19 3 Total 178 From this frequency distribution, construct: a histogram a frequency polygon an ogive From the ogive, estimate the percentage of measurements showing a carbon content below 5.00%. Answers: Approximately 169 samples have a carbon content less than 5%. The following numbers are the marks obtained by 50 students in an examination: 57 60 37 74 62 40 56 59 80 60 62 94 78 73 56 68 67 79 83 87 90 93 58 46 77 63 66 66 56 71 51 77 53 69 70 69 70 70 47 54 49 54 68 35 64 67 76 73 68 61 Reduce these marks to a frequency distribution, with equal class widths, having as the first interval 35-44 inclusive. Draw an ogive for the distribution. Using the graph, what is the median mark? Use your graph to estimate what % of students pass the examination if the pass mark is 55. Answers: Class Frequency Cumulative Frequency 35-44 3 3 45-54 7 10 55-64 13 23 65-74 16 39 75-84 7 46 85-94 4 50 The median can be estimated by drawing a horizontal line from the vertical axis at \\(50/2=25\\) and reading of the corresponding value on the horiztonal axis (blue lines on the plot above). We find the median is approximately 66. Drawing a vertical line from 55 to the curve and reading from the vertical axis gives the cumulative frequency up to 55 marks as approximately 11 students (red lines on the plot above). Therefore \\(50-11=39\\) students pass. As a percentage, we have \\(39/50 \\times 100= 78\\%\\). A sample of underweight babies was fed a special diet and the following weight gains (lbs) were observed at the end of three months: 6.7, 2.7, 2.5, 3.6, 3.4, 4.1, 4.8, 5.9, 8.3. What are the mean and standard deviation? Answer: \\(\\bar{x} = 4.67\\), \\(S= 1.95\\) lbs. In an examination, the marks awarded to the first 40 scripts were: 32, 57, 43, 65, 28, 60, 47, 52, 39, 48, 25, 53, 47, 52, 62, 31, 38, 46, 72, 51, 29, 45, 54, 48, 50, 66, 63, 36, 23, 43, 32, 39, 58, 55, 29, 48, 37, 43, 54, 40. Taking classes 14.5-24.5, 24.5-34.5, 34.5-44.5 etc, draw up a frequency distribution table for the marks. Also estimate the relative frequency, cumulative frequency and relative cumulative frequency. Draw a histogram, frequency polygon and ogive for this frequency distribution. From the frequency table, estimate the mean, variance and standard deviation of the marks. Answers: Frequency distribution: Table 22.1: Frequency Table Class Frequency Relative Frequency Cumulative Frequency Relative Cumulative Frequency (14.5,24.5] 1 0.025 1 0.025 (24.5,34.5] 7 0.175 8 0.200 (34.5,44.5] 9 0.225 17 0.425 (44.5,54.5] 14 0.350 31 0.775 (54.5,64.5] 6 0.150 37 0.925 (64.5,74.5] 3 0.075 40 1.000 Plots: Table to calculate mean, variance and standard deviation: Class Midpoint \\(x\\) Frequency \\(f\\) \\(xf\\) \\(x-\\bar{x}\\) \\((x-\\bar{x})^2\\) \\(f(x-\\bar{x})^2\\) 14.5-24.5 19.5 1 19.5 -26.5 702.25 702.25 24.5-34.5 29.5 7 206.5 -16.5 272.25 1905.75 34.5-44.5 39.5 9 355.5 -6.5 42.25 380.25 44.5-54.5 49.5 14 693 3.5 12.25 171.5 54.5-64.5 59.5 6 357 13.5 182.25 1093.5 64.5-74.5 69.5 3 208.5 23.5 552.25 1656.75 Total 40 1840 5910 \\(\\bar{x}=\\frac{1}{N}\\sum_x xf=\\frac{1}{40}\\times 1840 = 46\\) \\(S^2=\\frac{1}{N-1}\\sum_x f(x-\\bar{x})^2 = \\frac{1}{39}\\times 5910=151.54\\) \\(S=\\sqrt{S^2}=\\sqrt{151.54}=12.31\\) A city has been criticized for its excessive discharges of untreated sewage into the nearby river. A microbiologist take 45 samples of water downstream from the treated sewage outlet and measures the number of bacteria present. A summary table is as follows: Number of Bacteria Number of Samples 20-30 5 30-40 20 40-50 15 50-60 5 What are the \\(25^{\\text{th}}\\) and \\(75^{\\text{th}}\\) percentiles? Answers: Note \\(P_{25}=Q_1\\) and \\(P_{75}=Q_3\\). \\(Q_1\\) is between item 11 and 12, which lies in class 30-40. Within this class, there are 6 values before \\(Q_1\\) and 14 values after: that is, \\(\\frac{3}{10}\\) of the interval lies before and \\(\\frac{7}{10}\\) after. The class width is 10. Therefore, \\(Q_1=30+3=33\\). \\(Q_3\\) is between item 34 and 35, which lies in class 40-50. Within this class, there are 9 values before \\(Q_3\\) and 6 values after: that is, \\(\\frac{6}{10}\\) of the interval lies before and \\(\\frac{4}{10}\\) after. The class width is 10. Therefore, \\(Q_3=40+6=46\\). "],["notation.html", "Notation", " Notation A summary of notation used in these notes. “\\(A \\implies B\\)” is read as “statement \\(A\\) implies statement \\(B\\)”. \\(\\approx\\) means approximately equal to. We often use Greek letters for mathematical symbols. Capital letter Small letter Name \\(A\\) \\(\\alpha\\) Alpha \\(B\\) \\(\\beta\\) Beta \\(\\Gamma\\) \\(\\gamma\\) Gamma \\(\\Delta\\) \\(\\delta\\) Delta \\(E\\) \\(\\epsilon\\), \\(\\varepsilon\\) Epsilon \\(Z\\) \\(\\zeta\\) Zeta \\(H\\) \\(\\eta\\) Eta \\(\\Theta\\) \\(\\theta\\), \\(\\vartheta\\) Theta \\(I\\) \\(\\iota\\) Iota \\(K\\) \\(\\kappa\\) Kappa \\(\\Lambda\\) \\(\\lambda\\) Lambda \\(M\\) \\(\\mu\\) Mu \\(N\\) \\(\\nu\\) Nu \\(\\Xi\\) \\(\\xi\\) Xi \\(O\\) \\(\\omicron\\) Omicron \\(\\Pi\\) \\(\\pi\\) Pi \\(R\\) \\(\\rho\\), \\(\\varrho\\) Rho \\(\\Sigma\\) \\(\\sigma\\) Sigma \\(T\\) \\(\\tau\\) Tau \\(\\Upsilon\\) \\(\\upsilon\\) Upsilon \\(\\Phi\\) \\(\\phi\\), \\(\\varphi\\) Phi \\(X\\) \\(\\chi\\) Chi \\(\\Psi\\) \\(\\psi\\) Psi \\(\\Omega\\) \\(\\omega\\) Omega "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
