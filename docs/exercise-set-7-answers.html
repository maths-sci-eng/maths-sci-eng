<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Exercise Set 7 Answers | Mathematics for Scientists and Engineers</title>
  <meta name="description" content="Mathematics Lecture Notes for UoE Penryn Science and Engineering Disciplines." />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Exercise Set 7 Answers | Mathematics for Scientists and Engineers" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Mathematics Lecture Notes for UoE Penryn Science and Engineering Disciplines." />
  <meta name="github-repo" content="maths-sci-eng/maths-sci-eng.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Exercise Set 7 Answers | Mathematics for Scientists and Engineers" />
  
  <meta name="twitter:description" content="Mathematics Lecture Notes for UoE Penryn Science and Engineering Disciplines." />
  

<meta name="author" content="Dr Mark Callaway" />


<meta name="date" content="2022-12-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="exercise-set-7.html"/>
<link rel="next" href="exercise-set-8.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Mathematics for Scientists and Engineers</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="foundations.html"><a href="foundations.html"><i class="fa fa-check"></i><b>1</b> Foundations</a>
<ul>
<li class="chapter" data-level="1.1" data-path="foundations.html"><a href="foundations.html#numbers"><i class="fa fa-check"></i><b>1.1</b> Numbers</a></li>
<li class="chapter" data-level="1.2" data-path="foundations.html"><a href="foundations.html#algebra"><i class="fa fa-check"></i><b>1.2</b> Algebra</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="foundations.html"><a href="foundations.html#exponents"><i class="fa fa-check"></i><b>1.2.1</b> Rules of Exponents</a></li>
<li class="chapter" data-level="1.2.2" data-path="foundations.html"><a href="foundations.html#brackets"><i class="fa fa-check"></i><b>1.2.2</b> Brackets</a></li>
<li class="chapter" data-level="1.2.3" data-path="foundations.html"><a href="foundations.html#simplifiying-expressions"><i class="fa fa-check"></i><b>1.2.3</b> Simplifiying Expressions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="equations-and-inequalities.html"><a href="equations-and-inequalities.html"><i class="fa fa-check"></i><b>2</b> Equations and Inequalities</a>
<ul>
<li class="chapter" data-level="2.1" data-path="equations-and-inequalities.html"><a href="equations-and-inequalities.html#equations"><i class="fa fa-check"></i><b>2.1</b> Equations</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="equations-and-inequalities.html"><a href="equations-and-inequalities.html#formulas"><i class="fa fa-check"></i><b>2.1.1</b> Formulas</a></li>
<li class="chapter" data-level="2.1.2" data-path="equations-and-inequalities.html"><a href="equations-and-inequalities.html#conditional-equations"><i class="fa fa-check"></i><b>2.1.2</b> Conditional equations</a></li>
<li class="chapter" data-level="2.1.3" data-path="equations-and-inequalities.html"><a href="equations-and-inequalities.html#quad-eqs"><i class="fa fa-check"></i><b>2.1.3</b> Quadratic equations</a></li>
<li class="chapter" data-level="2.1.4" data-path="equations-and-inequalities.html"><a href="equations-and-inequalities.html#simultaneous-equations"><i class="fa fa-check"></i><b>2.1.4</b> Simultaneous equations</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="equations-and-inequalities.html"><a href="equations-and-inequalities.html#inequalities"><i class="fa fa-check"></i><b>2.2</b> Inequalities</a></li>
<li class="chapter" data-level="2.3" data-path="equations-and-inequalities.html"><a href="equations-and-inequalities.html#common-mistakes"><i class="fa fa-check"></i><b>2.3</b> Common mistakes!</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="functions-and-graphs.html"><a href="functions-and-graphs.html"><i class="fa fa-check"></i><b>3</b> Functions and Graphs</a>
<ul>
<li class="chapter" data-level="3.1" data-path="functions-and-graphs.html"><a href="functions-and-graphs.html#lines"><i class="fa fa-check"></i><b>3.1</b> Lines</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="functions-and-graphs.html"><a href="functions-and-graphs.html#parallel-lines"><i class="fa fa-check"></i><b>3.1.1</b> Parallel lines</a></li>
<li class="chapter" data-level="3.1.2" data-path="functions-and-graphs.html"><a href="functions-and-graphs.html#perpendicular-lines"><i class="fa fa-check"></i><b>3.1.2</b> Perpendicular lines</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="functions-and-graphs.html"><a href="functions-and-graphs.html#polynomials"><i class="fa fa-check"></i><b>3.2</b> Polynomials</a></li>
<li class="chapter" data-level="3.3" data-path="functions-and-graphs.html"><a href="functions-and-graphs.html#rational-functions"><i class="fa fa-check"></i><b>3.3</b> Rational functions</a></li>
<li class="chapter" data-level="3.4" data-path="functions-and-graphs.html"><a href="functions-and-graphs.html#root-functions"><i class="fa fa-check"></i><b>3.4</b> Root functions</a></li>
<li class="chapter" data-level="3.5" data-path="functions-and-graphs.html"><a href="functions-and-graphs.html#trigonometric-functions"><i class="fa fa-check"></i><b>3.5</b> Trigonometric functions</a></li>
<li class="chapter" data-level="3.6" data-path="functions-and-graphs.html"><a href="functions-and-graphs.html#exponentials-and-logarithms"><i class="fa fa-check"></i><b>3.6</b> Exponentials and logarithms</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="functions-and-graphs.html"><a href="functions-and-graphs.html#logarthmic-plots"><i class="fa fa-check"></i><b>3.6.1</b> Logarthmic plots</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="functions-and-graphs.html"><a href="functions-and-graphs.html#hyperbolic-functions"><i class="fa fa-check"></i><b>3.7</b> Hyperbolic functions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="trigonometry.html"><a href="trigonometry.html"><i class="fa fa-check"></i><b>4</b> Trigonometry</a>
<ul>
<li class="chapter" data-level="4.1" data-path="trigonometry.html"><a href="trigonometry.html#pythagoras"><i class="fa fa-check"></i><b>4.1</b> Pythagoras</a></li>
<li class="chapter" data-level="4.2" data-path="trigonometry.html"><a href="trigonometry.html#degrees-and-radians"><i class="fa fa-check"></i><b>4.2</b> Degrees and radians</a></li>
<li class="chapter" data-level="4.3" data-path="trigonometry.html"><a href="trigonometry.html#trigonometric-ratios"><i class="fa fa-check"></i><b>4.3</b> Trigonometric ratios</a></li>
<li class="chapter" data-level="4.4" data-path="trigonometry.html"><a href="trigonometry.html#sine-and-cosine-rules"><i class="fa fa-check"></i><b>4.4</b> Sine and cosine rules</a></li>
<li class="chapter" data-level="4.5" data-path="trigonometry.html"><a href="trigonometry.html#trigonometric-waveforms"><i class="fa fa-check"></i><b>4.5</b> Trigonometric waveforms</a></li>
<li class="chapter" data-level="4.6" data-path="trigonometry.html"><a href="trigonometry.html#trigonometric-identities"><i class="fa fa-check"></i><b>4.6</b> Trigonometric identities</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="trigonometry.html"><a href="trigonometry.html#pythagorean-identities"><i class="fa fa-check"></i><b>4.6.1</b> Pythagorean identities</a></li>
<li class="chapter" data-level="4.6.2" data-path="trigonometry.html"><a href="trigonometry.html#compound-angle-formulae"><i class="fa fa-check"></i><b>4.6.2</b> Compound angle formulae</a></li>
<li class="chapter" data-level="4.6.3" data-path="trigonometry.html"><a href="trigonometry.html#double-angle-formulae"><i class="fa fa-check"></i><b>4.6.3</b> Double angle formulae</a></li>
<li class="chapter" data-level="4.6.4" data-path="trigonometry.html"><a href="trigonometry.html#product-to-sum-formulae"><i class="fa fa-check"></i><b>4.6.4</b> Product to sum formulae</a></li>
<li class="chapter" data-level="4.6.5" data-path="trigonometry.html"><a href="trigonometry.html#sum-to-product-formulae"><i class="fa fa-check"></i><b>4.6.5</b> Sum to product formulae</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="complex.html"><a href="complex.html"><i class="fa fa-check"></i><b>5</b> Complex Numbers</a>
<ul>
<li class="chapter" data-level="5.1" data-path="complex.html"><a href="complex.html#i-and-complex-numbers"><i class="fa fa-check"></i><b>5.1</b> <span class="math inline">\(i\)</span> and complex numbers</a></li>
<li class="chapter" data-level="5.2" data-path="complex.html"><a href="complex.html#complex-arithmetic"><i class="fa fa-check"></i><b>5.2</b> Complex arithmetic</a></li>
<li class="chapter" data-level="5.3" data-path="complex.html"><a href="complex.html#the-argument-polar-and-exponential-form-for-complex-numbers"><i class="fa fa-check"></i><b>5.3</b> The argument, polar and exponential form for complex numbers</a></li>
<li class="chapter" data-level="5.4" data-path="complex.html"><a href="complex.html#roots-of-complex-numbers"><i class="fa fa-check"></i><b>5.4</b> Roots of complex numbers</a></li>
<li class="chapter" data-level="5.5" data-path="complex.html"><a href="complex.html#eitheta-and-trigonometric-identities"><i class="fa fa-check"></i><b>5.5</b> <span class="math inline">\(e^{i\theta}\)</span> and trigonometric identities</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="vectors.html"><a href="vectors.html"><i class="fa fa-check"></i><b>6</b> Vectors</a>
<ul>
<li class="chapter" data-level="6.1" data-path="vectors.html"><a href="vectors.html#vector-addition"><i class="fa fa-check"></i><b>6.1</b> Vector addition</a></li>
<li class="chapter" data-level="6.2" data-path="vectors.html"><a href="vectors.html#scalar-multiplication"><i class="fa fa-check"></i><b>6.2</b> Scalar multiplication</a></li>
<li class="chapter" data-level="6.3" data-path="vectors.html"><a href="vectors.html#vectors-in-cartesian-coordinates"><i class="fa fa-check"></i><b>6.3</b> Vectors in Cartesian coordinates</a></li>
<li class="chapter" data-level="6.4" data-path="vectors.html"><a href="vectors.html#vector-products"><i class="fa fa-check"></i><b>6.4</b> Vector products</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="vectors.html"><a href="vectors.html#dot-product"><i class="fa fa-check"></i><b>6.4.1</b> Dot product</a></li>
<li class="chapter" data-level="6.4.2" data-path="vectors.html"><a href="vectors.html#cross-product"><i class="fa fa-check"></i><b>6.4.2</b> Cross product</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="systems-of-linear-equations.html"><a href="systems-of-linear-equations.html"><i class="fa fa-check"></i><b>7</b> Systems of Linear Equations</a>
<ul>
<li class="chapter" data-level="7.1" data-path="systems-of-linear-equations.html"><a href="systems-of-linear-equations.html#lines-and-planes"><i class="fa fa-check"></i><b>7.1</b> Lines and planes</a></li>
<li class="chapter" data-level="7.2" data-path="systems-of-linear-equations.html"><a href="systems-of-linear-equations.html#solving-linear-systems---gaussian-elimination"><i class="fa fa-check"></i><b>7.2</b> Solving linear systems - Gaussian elimination</a></li>
<li class="chapter" data-level="7.3" data-path="systems-of-linear-equations.html"><a href="systems-of-linear-equations.html#echelon-form"><i class="fa fa-check"></i><b>7.3</b> Echelon Form</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="matrices.html"><a href="matrices.html"><i class="fa fa-check"></i><b>8</b> Matrices</a>
<ul>
<li class="chapter" data-level="8.1" data-path="matrices.html"><a href="matrices.html#linearrevisited"><i class="fa fa-check"></i><b>8.1</b> Solving linear systems revisited</a></li>
<li class="chapter" data-level="8.2" data-path="matrices.html"><a href="matrices.html#determinants"><i class="fa fa-check"></i><b>8.2</b> Determinants</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="linear-transformations.html"><a href="linear-transformations.html"><i class="fa fa-check"></i><b>9</b> Linear Transformations</a>
<ul>
<li class="chapter" data-level="9.1" data-path="linear-transformations.html"><a href="linear-transformations.html#matrix-algebra"><i class="fa fa-check"></i><b>9.1</b> Matrix Algebra</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="linear-transformations.html"><a href="linear-transformations.html#addition-and-subtraction"><i class="fa fa-check"></i><b>9.1.1</b> Addition and Subtraction</a></li>
<li class="chapter" data-level="9.1.2" data-path="linear-transformations.html"><a href="linear-transformations.html#multiplication-by-a-scalar"><i class="fa fa-check"></i><b>9.1.2</b> Multiplication by a scalar</a></li>
<li class="chapter" data-level="9.1.3" data-path="linear-transformations.html"><a href="linear-transformations.html#matrix-multiplication"><i class="fa fa-check"></i><b>9.1.3</b> Matrix multiplication</a></li>
<li class="chapter" data-level="9.1.4" data-path="linear-transformations.html"><a href="linear-transformations.html#functional-interpretations"><i class="fa fa-check"></i><b>9.1.4</b> Functional interpretations</a></li>
<li class="chapter" data-level="9.1.5" data-path="linear-transformations.html"><a href="linear-transformations.html#two-special-matrices"><i class="fa fa-check"></i><b>9.1.5</b> Two special matrices</a></li>
<li class="chapter" data-level="9.1.6" data-path="linear-transformations.html"><a href="linear-transformations.html#some-further-properties"><i class="fa fa-check"></i><b>9.1.6</b> Some further properties</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="linear-transformations.html"><a href="linear-transformations.html#matrix-inverse"><i class="fa fa-check"></i><b>9.2</b> Matrix inverse</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="linear-transformations.html"><a href="linear-transformations.html#finding-the-inverse-of-a-2times-2-matrix"><i class="fa fa-check"></i><b>9.2.1</b> Finding the inverse of a <span class="math inline">\(2\times 2\)</span> matrix</a></li>
<li class="chapter" data-level="9.2.2" data-path="linear-transformations.html"><a href="linear-transformations.html#finding-the-inverse-of-an-ntimes-n-matrix"><i class="fa fa-check"></i><b>9.2.2</b> Finding the inverse of an <span class="math inline">\(n\times n\)</span> matrix</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="eigenvalues-and-eigenvectors.html"><a href="eigenvalues-and-eigenvectors.html"><i class="fa fa-check"></i><b>10</b> Eigenvalues and Eigenvectors</a>
<ul>
<li class="chapter" data-level="10.1" data-path="eigenvalues-and-eigenvectors.html"><a href="eigenvalues-and-eigenvectors.html#matrix-diagonalisation"><i class="fa fa-check"></i><b>10.1</b> Matrix Diagonalisation</a></li>
<li class="chapter" data-level="10.2" data-path="eigenvalues-and-eigenvectors.html"><a href="eigenvalues-and-eigenvectors.html#finding-eigenvalues"><i class="fa fa-check"></i><b>10.2</b> Finding Eigenvalues</a></li>
<li class="chapter" data-level="10.3" data-path="eigenvalues-and-eigenvectors.html"><a href="eigenvalues-and-eigenvectors.html#finding-eigenvectors"><i class="fa fa-check"></i><b>10.3</b> Finding Eigenvectors</a></li>
<li class="chapter" data-level="10.4" data-path="eigenvalues-and-eigenvectors.html"><a href="eigenvalues-and-eigenvectors.html#powers-of-diagonalisable-matrices"><i class="fa fa-check"></i><b>10.4</b> Powers of diagonalisable matrices</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="differentiation.html"><a href="differentiation.html"><i class="fa fa-check"></i><b>11</b> Differentiation</a>
<ul>
<li class="chapter" data-level="11.1" data-path="differentiation.html"><a href="differentiation.html#concept"><i class="fa fa-check"></i><b>11.1</b> Concept</a></li>
<li class="chapter" data-level="11.2" data-path="differentiation.html"><a href="differentiation.html#standard-derivatives"><i class="fa fa-check"></i><b>11.2</b> Standard derivatives</a></li>
<li class="chapter" data-level="11.3" data-path="differentiation.html"><a href="differentiation.html#rules"><i class="fa fa-check"></i><b>11.3</b> Rules</a></li>
<li class="chapter" data-level="11.4" data-path="differentiation.html"><a href="differentiation.html#higher-order-derivatives"><i class="fa fa-check"></i><b>11.4</b> Higher order derivatives</a></li>
<li class="chapter" data-level="11.5" data-path="differentiation.html"><a href="differentiation.html#further-techniques"><i class="fa fa-check"></i><b>11.5</b> Further Techniques</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="differentiation.html"><a href="differentiation.html#implicit-differentiation"><i class="fa fa-check"></i><b>11.5.1</b> Implicit Differentiation</a></li>
<li class="chapter" data-level="11.5.2" data-path="differentiation.html"><a href="differentiation.html#logarithmic-differentiation"><i class="fa fa-check"></i><b>11.5.2</b> Logarithmic Differentiation</a></li>
<li class="chapter" data-level="11.5.3" data-path="differentiation.html"><a href="differentiation.html#parametric-differentiation"><i class="fa fa-check"></i><b>11.5.3</b> Parametric Differentiation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="applications-of-differentiation.html"><a href="applications-of-differentiation.html"><i class="fa fa-check"></i><b>12</b> Applications of Differentiation</a>
<ul>
<li class="chapter" data-level="12.1" data-path="applications-of-differentiation.html"><a href="applications-of-differentiation.html#maxima-and-minima"><i class="fa fa-check"></i><b>12.1</b> Maxima and Minima</a></li>
<li class="chapter" data-level="12.2" data-path="applications-of-differentiation.html"><a href="applications-of-differentiation.html#points-of-inflection"><i class="fa fa-check"></i><b>12.2</b> Points of Inflection</a></li>
<li class="chapter" data-level="12.3" data-path="applications-of-differentiation.html"><a href="applications-of-differentiation.html#higher-order-derivative-test"><i class="fa fa-check"></i><b>12.3</b> Higher Order Derivative Test</a></li>
<li class="chapter" data-level="12.4" data-path="applications-of-differentiation.html"><a href="applications-of-differentiation.html#graph-sketching"><i class="fa fa-check"></i><b>12.4</b> Graph Sketching</a></li>
<li class="chapter" data-level="12.5" data-path="applications-of-differentiation.html"><a href="applications-of-differentiation.html#optimisation"><i class="fa fa-check"></i><b>12.5</b> Optimisation</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="sequences.html"><a href="sequences.html"><i class="fa fa-check"></i><b>13</b> Sequences</a>
<ul>
<li class="chapter" data-level="13.1" data-path="sequences.html"><a href="sequences.html#limits-of-sequences"><i class="fa fa-check"></i><b>13.1</b> Limits of Sequences</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="series.html"><a href="series.html"><i class="fa fa-check"></i><b>14</b> Series</a>
<ul>
<li class="chapter" data-level="14.1" data-path="series.html"><a href="series.html#sigma-notation"><i class="fa fa-check"></i><b>14.1</b> Sigma Notation</a></li>
<li class="chapter" data-level="14.2" data-path="series.html"><a href="series.html#infinite-series"><i class="fa fa-check"></i><b>14.2</b> Infinite Series</a></li>
<li class="chapter" data-level="14.3" data-path="series.html"><a href="series.html#power-series"><i class="fa fa-check"></i><b>14.3</b> Power Series</a></li>
<li class="chapter" data-level="14.4" data-path="series.html"><a href="series.html#taylor-series"><i class="fa fa-check"></i><b>14.4</b> Taylor Series</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="series.html"><a href="series.html#linearisation"><i class="fa fa-check"></i><b>14.4.1</b> Linearisation</a></li>
<li class="chapter" data-level="14.4.2" data-path="series.html"><a href="series.html#taylor-polynomials"><i class="fa fa-check"></i><b>14.4.2</b> Taylor Polynomials</a></li>
<li class="chapter" data-level="14.4.3" data-path="series.html"><a href="series.html#taylor-series-1"><i class="fa fa-check"></i><b>14.4.3</b> Taylor Series</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="integration.html"><a href="integration.html"><i class="fa fa-check"></i><b>15</b> Integration</a>
<ul>
<li class="chapter" data-level="15.1" data-path="integration.html"><a href="integration.html#indefinite-integrals"><i class="fa fa-check"></i><b>15.1</b> Indefinite Integrals</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="integration.html"><a href="integration.html#standard-integrals"><i class="fa fa-check"></i><b>15.1.1</b> Standard Integrals</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="integration.html"><a href="integration.html#definite-integrals"><i class="fa fa-check"></i><b>15.2</b> Definite Integrals</a></li>
<li class="chapter" data-level="15.3" data-path="integration.html"><a href="integration.html#integration-by-substitution"><i class="fa fa-check"></i><b>15.3</b> Integration by Substitution</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="further-integration-techniques.html"><a href="further-integration-techniques.html"><i class="fa fa-check"></i><b>16</b> Further Integration Techniques</a>
<ul>
<li class="chapter" data-level="16.1" data-path="further-integration-techniques.html"><a href="further-integration-techniques.html#integrals-of-trigonometric-and-hyperbolic-functions"><i class="fa fa-check"></i><b>16.1</b> Integrals of trigonometric and hyperbolic functions</a></li>
<li class="chapter" data-level="16.2" data-path="further-integration-techniques.html"><a href="further-integration-techniques.html#integrals-of-rational-functions-using-partial-fractions"><i class="fa fa-check"></i><b>16.2</b> Integrals of rational functions using partial fractions</a></li>
<li class="chapter" data-level="16.3" data-path="further-integration-techniques.html"><a href="further-integration-techniques.html#integration-by-parts"><i class="fa fa-check"></i><b>16.3</b> Integration by Parts</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="differential-equations.html"><a href="differential-equations.html"><i class="fa fa-check"></i><b>17</b> Differential Equations</a>
<ul>
<li class="chapter" data-level="17.1" data-path="differential-equations.html"><a href="differential-equations.html#linear-or-nonlinear-odes"><i class="fa fa-check"></i><b>17.1</b> Linear or Nonlinear ODEs</a></li>
<li class="chapter" data-level="17.2" data-path="differential-equations.html"><a href="differential-equations.html#separable-first-order-odes"><i class="fa fa-check"></i><b>17.2</b> Separable First Order ODEs</a></li>
<li class="chapter" data-level="17.3" data-path="differential-equations.html"><a href="differential-equations.html#linear-first-order-odes"><i class="fa fa-check"></i><b>17.3</b> Linear first order ODEs</a></li>
<li class="chapter" data-level="17.4" data-path="differential-equations.html"><a href="differential-equations.html#linear-second-order-odes"><i class="fa fa-check"></i><b>17.4</b> Linear Second Order ODEs</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="differential-equations.html"><a href="differential-equations.html#homogeneous-equation-with-constant-coefficients"><i class="fa fa-check"></i><b>17.4.1</b> Homogeneous equation with constant coefficients</a></li>
<li class="chapter" data-level="17.4.2" data-path="differential-equations.html"><a href="differential-equations.html#inhomogeneous-equation-with-constant-coefficients"><i class="fa fa-check"></i><b>17.4.2</b> Inhomogeneous equation with constant coefficients</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="probability-fundamentals.html"><a href="probability-fundamentals.html"><i class="fa fa-check"></i><b>18</b> Probability Fundamentals</a>
<ul>
<li class="chapter" data-level="18.1" data-path="probability-fundamentals.html"><a href="probability-fundamentals.html#sample-space-and-events"><i class="fa fa-check"></i><b>18.1</b> Sample space and events</a></li>
<li class="chapter" data-level="18.2" data-path="probability-fundamentals.html"><a href="probability-fundamentals.html#counting"><i class="fa fa-check"></i><b>18.2</b> Counting</a></li>
<li class="chapter" data-level="18.3" data-path="probability-fundamentals.html"><a href="probability-fundamentals.html#permutations-and-combinations"><i class="fa fa-check"></i><b>18.3</b> Permutations and Combinations</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="probability-fundamentals.html"><a href="probability-fundamentals.html#permutations"><i class="fa fa-check"></i><b>18.3.1</b> Permutations</a></li>
<li class="chapter" data-level="18.3.2" data-path="probability-fundamentals.html"><a href="probability-fundamentals.html#combinations"><i class="fa fa-check"></i><b>18.3.2</b> Combinations</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="probability-fundamentals.html"><a href="probability-fundamentals.html#probabilities"><i class="fa fa-check"></i><b>18.4</b> Probabilities</a></li>
<li class="chapter" data-level="18.5" data-path="probability-fundamentals.html"><a href="probability-fundamentals.html#conditional-probability"><i class="fa fa-check"></i><b>18.5</b> Conditional Probability</a></li>
<li class="chapter" data-level="18.6" data-path="probability-fundamentals.html"><a href="probability-fundamentals.html#independence"><i class="fa fa-check"></i><b>18.6</b> Independence</a></li>
<li class="chapter" data-level="18.7" data-path="probability-fundamentals.html"><a href="probability-fundamentals.html#law-of-total-probability"><i class="fa fa-check"></i><b>18.7</b> Law of Total Probability</a></li>
<li class="chapter" data-level="18.8" data-path="probability-fundamentals.html"><a href="probability-fundamentals.html#bayes-theorem"><i class="fa fa-check"></i><b>18.8</b> Bayes’ Theorem</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>19</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="19.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#bernoulli-trials"><i class="fa fa-check"></i><b>19.1</b> Bernoulli trials</a></li>
<li class="chapter" data-level="19.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#binomial-distribution"><i class="fa fa-check"></i><b>19.2</b> Binomial Distribution</a></li>
<li class="chapter" data-level="19.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#cumulative-distribution-functions"><i class="fa fa-check"></i><b>19.3</b> Cumulative Distribution Functions</a></li>
<li class="chapter" data-level="19.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#poisson-distribution"><i class="fa fa-check"></i><b>19.4</b> Poisson distribution</a></li>
<li class="chapter" data-level="19.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#expectation-and-variance"><i class="fa fa-check"></i><b>19.5</b> Expectation and Variance</a>
<ul>
<li class="chapter" data-level="19.5.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#expectation"><i class="fa fa-check"></i><b>19.5.1</b> Expectation</a></li>
<li class="chapter" data-level="19.5.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>19.5.2</b> Variance and Standard Deviation</a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#summary-of-discrete-distributions"><i class="fa fa-check"></i><b>19.6</b> Summary of Discrete Distributions</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html"><i class="fa fa-check"></i><b>20</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="20.1" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#uniform-distribution"><i class="fa fa-check"></i><b>20.1</b> Uniform distribution</a></li>
<li class="chapter" data-level="20.2" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#cumulative-distribution-function"><i class="fa fa-check"></i><b>20.2</b> Cumulative Distribution Function</a></li>
<li class="chapter" data-level="20.3" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#expectation-and-variance-1"><i class="fa fa-check"></i><b>20.3</b> Expectation and Variance</a></li>
<li class="chapter" data-level="20.4" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#normal-distribution"><i class="fa fa-check"></i><b>20.4</b> Normal Distribution</a></li>
<li class="chapter" data-level="20.5" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#standard-normal-distribution-tables"><i class="fa fa-check"></i><b>20.5</b> Standard Normal Distribution Tables</a></li>
<li class="chapter" data-level="20.6" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#the-law-of-large-numbers"><i class="fa fa-check"></i><b>20.6</b> The Law of Large Numbers</a></li>
<li class="chapter" data-level="20.7" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#central-limit-theorem"><i class="fa fa-check"></i><b>20.7</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="exercise-set-1.html"><a href="exercise-set-1.html"><i class="fa fa-check"></i>Exercise Set 1</a></li>
<li class="chapter" data-level="21" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>21</b> Statistics</a>
<ul>
<li class="chapter" data-level="21.1" data-path="statistics.html"><a href="statistics.html#frequency"><i class="fa fa-check"></i><b>21.1</b> Frequency</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="statistics.html"><a href="statistics.html#tables"><i class="fa fa-check"></i><b>21.1.1</b> Tables</a></li>
<li class="chapter" data-level="21.1.2" data-path="statistics.html"><a href="statistics.html#graphs"><i class="fa fa-check"></i><b>21.1.2</b> Graphs</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="statistics.html"><a href="statistics.html#measures-of-central-tendency"><i class="fa fa-check"></i><b>21.2</b> Measures of central tendency</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="statistics.html"><a href="statistics.html#mean"><i class="fa fa-check"></i><b>21.2.1</b> Mean</a></li>
<li class="chapter" data-level="21.2.2" data-path="statistics.html"><a href="statistics.html#mode"><i class="fa fa-check"></i><b>21.2.2</b> Mode</a></li>
<li class="chapter" data-level="21.2.3" data-path="statistics.html"><a href="statistics.html#median"><i class="fa fa-check"></i><b>21.2.3</b> Median</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="statistics.html"><a href="statistics.html#measures-of-dispersion"><i class="fa fa-check"></i><b>21.3</b> Measures of Dispersion</a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="statistics.html"><a href="statistics.html#range"><i class="fa fa-check"></i><b>21.3.1</b> Range</a></li>
<li class="chapter" data-level="21.3.2" data-path="statistics.html"><a href="statistics.html#interquartile-range"><i class="fa fa-check"></i><b>21.3.2</b> Interquartile Range</a></li>
<li class="chapter" data-level="21.3.3" data-path="statistics.html"><a href="statistics.html#variance-and-standard-deviation-1"><i class="fa fa-check"></i><b>21.3.3</b> Variance and Standard Deviation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="exercise-set-2.html"><a href="exercise-set-2.html"><i class="fa fa-check"></i>Exercise Set 2</a></li>
<li class="chapter" data-level="" data-path="exercise-set-3.html"><a href="exercise-set-3.html"><i class="fa fa-check"></i>Exercise Set 3</a></li>
<li class="chapter" data-level="" data-path="exercise-set-4.html"><a href="exercise-set-4.html"><i class="fa fa-check"></i>Exercise Set 4</a></li>
<li class="chapter" data-level="" data-path="exercise-set-5.html"><a href="exercise-set-5.html"><i class="fa fa-check"></i>Exercise Set 5</a></li>
<li class="chapter" data-level="" data-path="exercise-set-6.html"><a href="exercise-set-6.html"><i class="fa fa-check"></i>Exercise Set 6</a></li>
<li class="chapter" data-level="" data-path="exercise-set-7.html"><a href="exercise-set-7.html"><i class="fa fa-check"></i>Exercise Set 7</a></li>
<li class="chapter" data-level="" data-path="exercise-set-8.html"><a href="exercise-set-8.html"><i class="fa fa-check"></i>Exercise Set 8</a></li>
<li class="chapter" data-level="" data-path="exercise-set-9.html"><a href="exercise-set-9.html"><i class="fa fa-check"></i>Exercise Set 9</a></li>
<li class="chapter" data-level="" data-path="exercise-set-10.html"><a href="exercise-set-10.html"><i class="fa fa-check"></i>Exercise Set 10</a></li>
<li class="chapter" data-level="" data-path="exercise-set-11.html"><a href="exercise-set-11.html"><i class="fa fa-check"></i>Exercise Set 11</a></li>
<li class="chapter" data-level="" data-path="exercise-set-12.html"><a href="exercise-set-12.html"><i class="fa fa-check"></i>Exercise Set 12</a></li>
<li class="chapter" data-level="" data-path="exercise-set-13.html"><a href="exercise-set-13.html"><i class="fa fa-check"></i>Exercise Set 13</a></li>
<li class="chapter" data-level="" data-path="exercise-set-14.html"><a href="exercise-set-14.html"><i class="fa fa-check"></i>Exercise Set 14</a></li>
<li class="chapter" data-level="" data-path="exercise-set-15.html"><a href="exercise-set-15.html"><i class="fa fa-check"></i>Exercise Set 15</a></li>
<li class="chapter" data-level="" data-path="notation.html"><a href="notation.html"><i class="fa fa-check"></i>Notation</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="" data-path="exercise-set-16-1.html"><a href="exercise-set-16-1.html"><i class="fa fa-check"></i>Exercise Set 16</a></li>
<li class="chapter" data-level="" data-path="exercise-set-16-2.html"><a href="exercise-set-16-2.html"><i class="fa fa-check"></i>Exercise Set 16</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mathematics for Scientists and Engineers</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="exercise-set-7-answers" class="section level1 unlisted unnumbered hasAnchor">
<h1>Exercise Set 7 Answers<a href="exercise-set-7-answers.html#exercise-set-7-answers" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<ol style="list-style-type: decimal">
<li><p>Write down the <span class="math inline">\(2\times 2\)</span> matrix <span class="math inline">\(R_\pi\)</span> that rotates a vector anticlockwise by <span class="math inline">\(\pi\)</span>. Apply this to a vector <span class="math inline">\(\mathbf{v}=\left(\begin{smallmatrix}v_1\\v_2\end{smallmatrix}\right)\)</span>.</p>
<p>Answers:
The matrix <span class="math inline">\(R_\theta\)</span> for anticlockwise rotation by angle <span class="math inline">\(\theta\)</span> is
<span class="math display">\[
R_\theta = \begin{pmatrix}\cos \theta &amp; - \sin \theta \\ \sin\theta &amp; \cos\theta\end{pmatrix}\]</span>
So the matrix that rotates a vector anticlockwise by <span class="math inline">\(\pi\)</span> is
<span class="math display">\[R_\pi = \begin{pmatrix}-1 &amp; 0 \\ 0 &amp; -1\end{pmatrix}\]</span>
Applying this to a vector:
<span class="math display">\[\begin{pmatrix}-1 &amp; 0 \\ 0 &amp; -1\end{pmatrix}\begin{pmatrix}v_1\\v_2\end{pmatrix} = \begin{pmatrix}-v_1\\-v_2\end{pmatrix}\]</span></p></li>
<li><p>Write down the <span class="math inline">\(2\times 2\)</span> matrix <span class="math inline">\(M_x\)</span> that reflects a vector in the <span class="math inline">\(x\)</span>-axis. Similarly write down the <span class="math inline">\(2\times 2\)</span> matrix <span class="math inline">\(M_y\)</span> that reflects a vector in the <span class="math inline">\(y\)</span>-axis. Multiply these two matrices to find the transformation that first reflects in the <span class="math inline">\(x\)</span>-axis and then reflects in the <span class="math inline">\(y\)</span>-axis. Compare this to the matrix <span class="math inline">\(R_\pi\)</span>.</p>
<p>Answers:</p>
<p><span class="math display">\[M_x = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; -1\end{pmatrix}\]</span>
<span class="math display">\[M_y = \begin{pmatrix} -1 &amp; 0 \\0 &amp; 1\end{pmatrix}\]</span>
<span class="math display">\[M_xM_y = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; -1\end{pmatrix}\begin{pmatrix} -1 &amp; 0 \\0 &amp; 1\end{pmatrix} = \begin{pmatrix}-1 &amp; 0 \\ 0 &amp; -1\end{pmatrix} = R_\pi\]</span></p></li>
<li><p>Note that <span class="math inline">\(R^2_\theta=R_{2\theta}\)</span> (why?). Use this to find the “double angle identity” for <span class="math inline">\(\cos\)</span> and <span class="math inline">\(\sin\)</span>. Can you find other trigonometric identities using <span class="math inline">\(R_\theta\)</span>?</p>
<p>Answers:</p>
<p><span class="math inline">\(R^2_\theta=R_\theta R_\theta\)</span>, that is, apply <span class="math inline">\(R_\theta\)</span> twice: this is the same as rotating by <span class="math inline">\(2\theta\)</span>.</p>
<p><span class="math display">\[R_{2\theta} = R_\theta^2 = R_\theta R_\theta\\
\begin{pmatrix}\cos (2\theta) &amp; -\sin(2\theta) \\ \sin(2\theta) &amp; \cos(2\theta)\end{pmatrix} = \begin{pmatrix}\cos \theta &amp; - \sin \theta \\ \sin\theta &amp; \cos\theta\end{pmatrix}\begin{pmatrix}\cos \theta &amp; - \sin \theta \\ \sin\theta &amp; \cos\theta\end{pmatrix}\\
\begin{pmatrix}\cos (2\theta) &amp; -\sin(2\theta) \\ \sin(2\theta) &amp; \cos(2\theta)\end{pmatrix} = \begin{pmatrix} \cos^2(\theta) - \sin^2(\theta) &amp; -2\cos(\theta)\sin(\theta) \\ 2\cos(\theta)\sin(\theta) &amp; \cos^2(\theta) - \sin^2(\theta)\end{pmatrix}\]</span>
Where each entry gives the double angle formula for <span class="math inline">\(\sin\)</span> and <span class="math inline">\(\cos\)</span>.</p>
<p>The general sum and difference identities for <span class="math inline">\(\sin\)</span> and <span class="math inline">\(\cos\)</span> can be derived by noting that <span class="math inline">\(R_{a+b} = R_a R_b\)</span> and <span class="math inline">\(R_{a-b} = R_a R_{-b}\)</span>.</p>
<p>Similarly, any identity for positive integer multiples <span class="math inline">\(n\theta\)</span> can be derived from <span class="math inline">\(R_{n\theta}=R^n_{\theta}\)</span>.</p></li>
<li><p>For each of the following pairs of matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, find (when possible), <span class="math inline">\(A+B\)</span>, <span class="math inline">\(A-B\)</span>, <span class="math inline">\(A^2\)</span>, <span class="math inline">\(B^2\)</span>, <span class="math inline">\(AB\)</span>, <span class="math inline">\(BA\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(A = \begin{pmatrix} 2 &amp; 3 \\ 4 &amp; 1 \end{pmatrix}\qquad B = \begin{pmatrix} -1 &amp; 2 \\ -2 &amp; 0 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(A = \begin{pmatrix} 4 &amp; -5 \\ 6 &amp; 1 \\ 0 &amp; 1 \end{pmatrix}\qquad B = \begin{pmatrix} 5 &amp; 2 &amp; -3 \\ 1 &amp; 3 &amp; -1 \\ 2 &amp; 2 &amp; -1 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(A = \begin{pmatrix} 1 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1\\ 1 &amp; 0 &amp; 1 \end{pmatrix} \qquad B = \begin{pmatrix} 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 0 \\ 1 &amp; 1 &amp; 0 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(A = \begin{pmatrix} -1 &amp; 1 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 1 &amp; 1\\ 1 &amp; 0 &amp; 1 &amp; 0\\ 1 &amp; 1 &amp; 1 &amp; -1 \end{pmatrix} \qquad B = \begin{pmatrix} 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 0 \\ 1 &amp; 1 &amp; 0 \\ 1 &amp; -1 &amp; 1 \end{pmatrix}\)</span>.</li>
</ol>
<p>Answers:</p>
<ol style="list-style-type: lower-alpha">
<li>We have
<span class="math display">\[\begin{align*}
&amp;A + B = \begin{pmatrix} 1 &amp; 5 \\ 2 &amp; 1 \end{pmatrix}, \qquad
A - B = \begin{pmatrix} 3 &amp; 1 \\ 6 &amp; 1 \end{pmatrix}, \\
&amp;A^2 = \begin{pmatrix} 16 &amp; 9 \\ 12 &amp; 13 \end{pmatrix}, \qquad
B^2 = \begin{pmatrix} -3 &amp; -2 \\ 2 &amp; -4 \end{pmatrix},\\
&amp;AB = \begin{pmatrix} -8 &amp; 4 \\ -6 &amp; 8\end{pmatrix}, \qquad
BA = \begin{pmatrix} 6 &amp; -1 \\ -4 &amp; -6 \end{pmatrix}.
\end{align*}\]</span></li>
<li>Because <span class="math inline">\(A\)</span> is a <span class="math inline">\(3\times 2\)</span> and <span class="math inline">\(B\)</span> is a <span class="math inline">\(3\times 3\)</span> matrix, <span class="math inline">\(A + B\)</span>, <span class="math inline">\(A - B\)</span>, <span class="math inline">\(A^2\)</span> and <span class="math inline">\(AB\)</span> are not defined. We have
<span class="math display">\[\begin{align*}
B^2 = \begin{pmatrix} 21 &amp; 10 &amp; -14 \\ 6 &amp;  9 &amp;  -5 \\ 10 &amp;  8 &amp;  -7 \end{pmatrix}, \qquad
BA = \begin{pmatrix} 32 &amp; -26 \\ 22 &amp;  -3 \\ 20 &amp;  -9 \end{pmatrix}.
\end{align*}\]</span></li>
<li>We have
<span class="math display">\[\begin{align*}
&amp;A + B = \begin{pmatrix} 1 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 \\ 2 &amp; 1 &amp; 1 \end{pmatrix}, \qquad
A - B = \begin{pmatrix} 1 &amp; 1 &amp; -1 \\ -1 &amp; 0 &amp; 1 \\ 0 &amp; -1 &amp; 1 \end{pmatrix}, \\
&amp;A^2 = \begin{pmatrix} 1 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 \\ 2 &amp; 1 &amp; 1 \end{pmatrix}, \qquad
B^2 = \begin{pmatrix} 1 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 1 \end{pmatrix}, \\
&amp;AB = \begin{pmatrix} 1 &amp; 0 &amp; 1 \\ 1 &amp; 1 &amp; 0 \\ 1 &amp; 1 &amp; 1 \end{pmatrix}, \qquad
BA = \begin{pmatrix} 1 &amp; 0 &amp; 1 \\ 1 &amp; 1 &amp; 0 \\ 1 &amp; 1 &amp; 1 \end{pmatrix}.
\end{align*}\]</span></li>
<li>Because <span class="math inline">\(A\)</span> is a <span class="math inline">\(4\times 4\)</span> and <span class="math inline">\(B\)</span> is a <span class="math inline">\(4\times 3\)</span> matrix, <span class="math inline">\(A + B\)</span>, <span class="math inline">\(A - B\)</span>, <span class="math inline">\(B^2\)</span>, and <span class="math inline">\(BA\)</span> are not defined. We have
<span class="math display">\[\begin{align*}
A^2 = \begin{pmatrix} 3 &amp; 0 &amp; 1 &amp; -2\\ 1 &amp; 2 &amp; 2 &amp; 0\\ 0 &amp; 1 &amp; 1 &amp; 1\\ 0 &amp; 0 &amp; 1 &amp; 1 \end{pmatrix}, \qquad
AB = \begin{pmatrix} 2 &amp; -1 &amp; 0\\ 2 &amp; 0 &amp; 2\\ 1 &amp; 1 &amp; 1\\ 1 &amp; 2 &amp; 0 \end{pmatrix}.
\end{align*}\]</span></li>
</ol></li>
<li><p>Find two <span class="math inline">\(3 \times 3\)</span> matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> such that <span class="math inline">\(AB=BA\)</span>. Now find two <span class="math inline">\(3 \times 3\)</span> matrices such that <span class="math inline">\(AB\neq BA\)</span>.</p>
<p>Answers:</p>
<p>Two diagonal matrices will always commute:
<span class="math display">\[
\begin{pmatrix}a &amp; 0 &amp; 0 \\ 0 &amp; b &amp; 0 \\ 0 &amp; 0 &amp; c\end{pmatrix}\begin{pmatrix}d &amp; 0 &amp; 0 \\ 0 &amp; e &amp; 0 \\ 0 &amp; 0 &amp; f\end{pmatrix} = \begin{pmatrix}d &amp; 0 &amp; 0 \\ 0 &amp; e &amp; 0 \\ 0 &amp; 0 &amp; f\end{pmatrix} \begin{pmatrix}a &amp; 0 &amp; 0 \\ 0 &amp; b &amp; 0 \\ 0 &amp; 0 &amp; c\end{pmatrix} = \begin{pmatrix}ad &amp; 0 &amp; 0 \\ 0 &amp; be &amp; 0 \\ 0 &amp; 0 &amp;cf\end{pmatrix}\]</span>
but there are also non-diagonal matrices that commute.</p>
<p>Two matrices that do not commute are
<span class="math display">\[A = \begin{pmatrix}0 &amp; 0 &amp; a \\ 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0\end{pmatrix}, \quad B = \begin{pmatrix}0 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 0\\b &amp; 0 &amp; 0\end{pmatrix}\]</span>
<span class="math display">\[AB = \begin{pmatrix}ab &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; 0 \\  0 &amp; 0 &amp; 0 \end{pmatrix} \neq BA = \begin{pmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; ab\end{pmatrix}\]</span></p></li>
<li><p>For any two numbers <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, if <span class="math inline">\(ab=0\)</span> then at least one of <span class="math inline">\(a\)</span> or <span class="math inline">\(b\)</span> must be <span class="math inline">\(0\)</span>. Does an analagous result hold for matrices? That is, if <span class="math inline">\(AB=0_{n\times m}\)</span> must at least one of the matrices <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> be the zero matrix?</p>
<p>Answers:</p>
<p>A similar result does not hold for matrices, neither <span class="math inline">\(A\)</span> nor <span class="math inline">\(B\)</span> must be zero if <span class="math inline">\(AB=0_{n\times m}\)</span>. This occurs when the columns of <span class="math inline">\(B\)</span> are in the <em>null space</em> of <span class="math inline">\(A\)</span>, that is to say, they are mapped to zero. For instance:
<span class="math display">\[\begin{pmatrix} a &amp; b &amp; 0 \\ c &amp; d &amp; 0 \\ e &amp; f &amp; 0\end{pmatrix}\begin{pmatrix}0 &amp; 0 \\ 0 &amp; 0 \\g &amp; h\end{pmatrix} = \begin{pmatrix} 0 &amp; 0 \\ 0 &amp; 0 \\ 0 &amp; 0 \end{pmatrix}\]</span></p></li>
<li><p>Determine whether the following matrices are <em>invertible</em> or <em>singular</em> by computing their determinants. If they are invertible, find the inverse.</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\begin{pmatrix} 2 &amp; 1 \\ 1 &amp; 1 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} 6 &amp; 3 \\ -4 &amp; -2 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} 4 &amp; -28 &amp; 48 \\ -27 &amp; 162 &amp; -216 \\ 32 &amp; -160 &amp; 192 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} \cos(\theta) &amp; -\sin(\theta) \\ \sin(\theta) &amp; \cos(\theta)\end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} 1 &amp; 3 &amp; -5 \\ -2 &amp; 1 &amp; 4 \\ 1 &amp; 2 &amp; -4 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} 1 &amp; -1 &amp; 4 \\ 2 &amp; 3 &amp; 3 \\ 3 &amp; 1 &amp; 8 \end{pmatrix}\)</span></li>
</ol>
<p>Answers:</p>
<ol style="list-style-type: lower-alpha">
<li><p>We have <span class="math inline">\(\det(A) = 2\times 1 - 1\times 1 = 1\)</span>, so using the formula for the inverse of a <span class="math inline">\(2\times 2\)</span> matrix:
<span class="math display">\[
A^{-1} = \begin{pmatrix} 1 &amp; -1 \\ -1 &amp; 2 \end{pmatrix}.
\]</span>
Alternatively, using the Gaussian elmination method
<span class="math display">\[
\left(\begin{array}{cc|cc}
2 &amp; 1 &amp; 1 &amp; 0 \\
1 &amp; 1 &amp; 0 &amp; 1
\end{array}\right),
\]</span>
we perform the EROs <span class="math inline">\(R_1 \to R_1 - R_2\)</span> and <span class="math inline">\(R_2 \to R_2 - R_1\)</span> to obtain
<span class="math display">\[
\left(\begin{array}{cc|cc}
1 &amp; 0 &amp; 1 &amp; -1 \\
0 &amp; 1 &amp; -1 &amp; 2
\end{array}\right),
\]</span>
as required.</p></li>
<li><p>We have <span class="math inline">\(\det(A) = 0\)</span>, so the matrix is singular. Alternatively, using the Gaussian elmination method
<span class="math display">\[
\left(\begin{array}{cc|cc}
6  &amp; 3  &amp; 1 &amp; 0 \\
-4 &amp; -2 &amp; 0 &amp; 1
\end{array}\right),
\]</span>
we perform the EROs <span class="math inline">\(R_1 \to \frac{1}{6}R_1\)</span> and then <span class="math inline">\(R_2 \to R_2 + 4R_1\)</span> to obtain
<span class="math display">\[
\left(\begin{array}{cc|cc}
1 &amp; \frac{1}{2} &amp; \frac{1}{6} &amp; 0 \\
0 &amp; 0           &amp; \frac{4}{6} &amp; 1
\end{array}\right),
\]</span>
which has leading entries in the solution vectors, hence shows that the system of equations is inconsistent, and therefore that <span class="math inline">\(A\)</span> is singular.</p></li>
<li><p>We have the augmented matrix
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
4   &amp; -28  &amp; 48   &amp; 1 &amp; 0 &amp; 0\\
-27 &amp; 162  &amp; -216 &amp; 0 &amp; 1 &amp; 0\\
32  &amp; -160 &amp; 192  &amp; 0 &amp; 0 &amp; 1
\end{array}\right).
\]</span>
Performing the EROs <span class="math inline">\(R_1 \to 27\times 8\times R_1\)</span>, <span class="math inline">\(R_2 \to -32 R_2\)</span> and <span class="math inline">\(R_3 \to 27 R_3\)</span> gives
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
864 &amp; -6048 &amp; 10368 &amp; 216 &amp; 0   &amp; 0\\
864 &amp; -5184 &amp; 6912  &amp; 0   &amp; -32 &amp; 0\\
864 &amp; -4320 &amp; 5184  &amp; 0   &amp; 0   &amp; 27
\end{array}\right).
\]</span>
Then, performing <span class="math inline">\(R_2 \to R_2 - R_1\)</span> and <span class="math inline">\(R_3 \to R_3 - R_1\)</span> gives
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
864  &amp; -6048 &amp; 10368 &amp; 216  &amp; 0   &amp; 0\\
0    &amp; 864   &amp; -3456 &amp; -216 &amp; -32 &amp; 0\\
0    &amp; 1728  &amp; -5184 &amp; -216 &amp; 0   &amp; 27
\end{array}\right).
\]</span>
Then, performing <span class="math inline">\(R_3 \to R_3 + 2R_2\)</span> and <span class="math inline">\(R_1 \to R_1 + 7R_3\)</span> gives
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
864  &amp; 0   &amp; 13824 &amp; -1296 &amp; -224 &amp; 0\\
0    &amp; 864 &amp; -3456 &amp; -216  &amp; -32  &amp; 0\\
0    &amp; 0   &amp; 1728  &amp; 216   &amp; 64   &amp; 27
\end{array}\right).
\]</span>
Then, performing <span class="math inline">\(R_1 \to R_1 + 8R_3\)</span> and <span class="math inline">\(R_2 \to R_2 + 2R_3\)</span> gives
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
864  &amp; 0   &amp; 0    &amp; 432 &amp; 288 &amp; 216\\
0    &amp; 864 &amp; 0    &amp; 216 &amp; 96  &amp; 54\\
0    &amp; 0   &amp; 1728 &amp; 216 &amp; 64  &amp; 27
\end{array}\right).
\]</span>
Finally, performing <span class="math inline">\(R_1 \to \frac{1}{864} R_1\)</span>, <span class="math inline">\(R_2 \to \frac{1}{864} R_2\)</span> and <span class="math inline">\(R_3 \to \frac{1}{1728} R_3\)</span> gives
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
1 &amp; 0 &amp; 0 &amp; \frac{1}{2} &amp; \frac{1}{3}  &amp; \frac{1}{4}\\
0 &amp; 1 &amp; 0 &amp; \frac{1}{4} &amp; \frac{1}{9}  &amp; \frac{1}{16}\\
0 &amp; 0 &amp; 1 &amp; \frac{1}{8} &amp; \frac{1}{27} &amp; \frac{1}{64}
\end{array}\right)
\]</span>
and we read of
<span class="math display">\[
A^{-1} = \begin{pmatrix}
\frac{1}{2} &amp; \frac{1}{3}  &amp; \frac{1}{4}\\
\frac{1}{4} &amp; \frac{1}{9}  &amp; \frac{1}{16}\\
\frac{1}{8} &amp; \frac{1}{27} &amp; \frac{1}{64}
\end{pmatrix}.
\]</span></p></li>
<li><p>We have <span class="math inline">\(\det(A) = \cos^2 \theta + \sin^2 \theta = 1\)</span>, so
<span class="math display">\[
A^{-1} = \begin{pmatrix} \cos(\theta) &amp; \sin(\theta) \\ -\sin(\theta) &amp; \cos(\theta) \end{pmatrix}.
\]</span>
Alternatively, using the Gaussian elmination method
<span class="math display">\[
\left(\begin{array}{cc|cc}
\cos(\theta) &amp; -\sin(\theta) &amp; 1 &amp; 0 \\
\sin(\theta) &amp; \cos(\theta)  &amp; 0 &amp; 1
\end{array}\right),
\]</span>
we perform the EROs <span class="math inline">\(R_1 \to \cos(\theta)R_1\)</span>, <span class="math inline">\(R_2 \to \sin(\theta)R_2\)</span> to obtain
<span class="math display">\[
\left(\begin{array}{cc|cc}
\cos^2(\theta) &amp; -\cos(\theta)\sin(\theta) &amp; \cos(\theta) &amp; 0 \\
\sin^2(\theta) &amp; \cos(\theta)\sin(\theta)  &amp; 0            &amp; \sin(\theta)
\end{array}\right),
\]</span>
and then <span class="math inline">\(R_1 \to R_1 + R_2\)</span> to obtain
<span class="math display">\[
\left(\begin{array}{cc|cc}
1              &amp; 0                        &amp; \cos(\theta) &amp; \sin(\theta) \\
\sin^2(\theta) &amp; \cos(\theta)\sin(\theta) &amp; 0            &amp; \sin(\theta)
\end{array}\right),
\]</span>
and then <span class="math inline">\(R_2 \to R_2 - \sin^2(\theta)R_1\)</span> and <span class="math inline">\(R_2 \to \frac{1}{\sin(\theta)\cos(\theta)}R_2\)</span> to arrive at
<span class="math display">\[
\left(\begin{array}{cc|cc}
1 &amp; 0 &amp; \cos(\theta)  &amp; \sin(\theta)\\
0 &amp; 1 &amp; -\sin(\theta) &amp; \frac{\sin(\theta)(1 - \sin^2(\theta))}{\sin(\theta)\cos(\theta)}
\end{array}\right),
\]</span>
which, by substituting <span class="math inline">\(1 = \sin^2(\theta) + \cos^2(\theta)\)</span> second entry of the fourth columns, is equal to
<span class="math display">\[
\left(\begin{array}{cc|cc}
1 &amp; 0 &amp; \cos(\theta)  &amp; \sin(\theta)\\
0 &amp; 1 &amp; -\sin(\theta) &amp; \cos(\theta)
\end{array}\right),
\]</span>
as required.</p>
<p>Note that <span class="math inline">\(A\)</span> is the rotation anticlockwise by an angle <span class="math inline">\(\theta\)</span> and <span class="math inline">\(A^{-1}\)</span> is simply rotation <em>clockwise</em> by the angle <span class="math inline">\(\theta\)</span>, i.e. the matrix <span class="math inline">\(R_{-\theta}\)</span> where one uses the facts that <span class="math inline">\(\cos(-\theta)=\cos(\theta)\)</span> and <span class="math inline">\(\sin(-\theta)=-\sin(\theta)\)</span>.</p></li>
<li><p>We have the augmented matrix
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
1  &amp; 3 &amp; -5 &amp; 1 &amp; 0 &amp; 0 \\
-2 &amp; 1 &amp; 4  &amp; 0 &amp; 1 &amp; 0 \\
1  &amp; 2 &amp; -4 &amp; 0 &amp; 0 &amp; 1
\end{array}\right).
\]</span>
We perform EROs <span class="math inline">\(R_2 \to R_2 + 2R_1\)</span> and <span class="math inline">\(R_3 \to R_3 - R_1\)</span> to obtain
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
1 &amp; 3  &amp; -5 &amp; 1  &amp; 0 &amp; 0 \\
0 &amp; 7  &amp; -6 &amp; 2  &amp; 1 &amp; 0 \\
0 &amp; -1 &amp; 1  &amp; -1 &amp; 0 &amp; 1
\end{array}\right)
\]</span>
Swap the second and third rows, i.e. perform ERO <span class="math inline">\(R_2 \leftrightarrow R_3\)</span>, and the perform <span class="math inline">\(R_2 \to -R_2\)</span> to have
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
1 &amp; 3 &amp; -5 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; -1 &amp; 1 &amp; 0 &amp; -1 \\
0 &amp; 7 &amp; -6 &amp; 2 &amp; 1 &amp; 0
\end{array}\right).
\]</span>
Then, perform <span class="math inline">\(R_3 \to R_3 - 7R_2\)</span> and <span class="math inline">\(R_1 \to R_1 - 3R_2\)</span> to obtain
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
1 &amp; 0 &amp; -2 &amp; -2 &amp; 0 &amp; 3 \\
0 &amp; 1 &amp; -1 &amp; 1  &amp; 0 &amp; -1 \\
0 &amp; 0 &amp; 1  &amp; -5 &amp; 1 &amp; 7
\end{array}\right).
\]</span>
Then, perform <span class="math inline">\(R_1 \to R_1 + 2R_3\)</span> and <span class="math inline">\(R_2 \to R_2 + R_3\)</span> to obtain
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
1 &amp; 0 &amp; 0 &amp; -12 &amp; 2 &amp; 17 \\
0 &amp; 1 &amp; 0 &amp; -4  &amp; 1 &amp; 6 \\
0 &amp; 0 &amp; 1 &amp; -5  &amp; 1 &amp; 7
\end{array}\right).
\]</span>
So
<span class="math display">\[
A^{-1} = \begin{pmatrix} -12 &amp; 2 &amp; 17 \\ -4  &amp; 1 &amp; 6\\ -5  &amp; 1 &amp; 7 \end{pmatrix}.
\]</span></p></li>
<li><p>We have the augmented matrix
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
1 &amp; -1 &amp; 4 &amp; 1 &amp; 0 &amp; 0 \\
2 &amp; 3  &amp; 3 &amp; 0 &amp; 1 &amp; 0 \\
3 &amp; 1  &amp; 8 &amp; 0 &amp; 0 &amp; 1
\end{array}\right).
\]</span>
We perform EROs <span class="math inline">\(R_2 \to R_2 - 2R_1\)</span> and <span class="math inline">\(R_3 \to R_3 - 3R_1\)</span> to obtain
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
1 &amp; -1 &amp; 4  &amp; 1  &amp; 0 &amp; 0 \\
0 &amp; 5  &amp; -5 &amp; -2 &amp; 1 &amp; 0 \\
0 &amp; 4  &amp; -4 &amp; -3 &amp; 0 &amp; 1
\end{array}\right),
\]</span>
Then, we perform <span class="math inline">\(R_3 \to R_3 - \frac{4}{5}R_2\)</span> to obtain
<span class="math display">\[
\left(\begin{array}{ccc|ccc}
1 &amp; -1 &amp; 4  &amp; 1            &amp; 0            &amp; 0 \\
0 &amp; 5  &amp; -5 &amp; -2           &amp; 1            &amp; 0 \\
0 &amp; 0  &amp; 0  &amp; -\frac{7}{5} &amp; -\frac{4}{5} &amp; 1
\end{array}\right),
\]</span>
which is in echelon form with (at least one) leading entries in the solution vectors, thus shows that the system of equations is inconsistent, therefore the matrix is singular.</p></li>
</ol></li>
<li><p>Find the eigenvalues and eigenvectors of each of the following matrices <span class="math inline">\(A\)</span>. Determine whether the matrix is diagonalisable and, if so, find the matrices <span class="math inline">\(D\)</span> and <span class="math inline">\(P\)</span> in the diagonalisation <span class="math inline">\(D=P^{-1}AP\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\begin{pmatrix} 1 &amp; 0 \\ 2 &amp; 2 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} 1 &amp; 2 \\ 0 &amp; 1 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} 1 &amp; 2 \\ 2 &amp; -2 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} 1 &amp; -2 &amp; -1 \\ 2 &amp; 6 &amp; 2 \\ -1 &amp; -2 &amp; 1 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} -2 &amp; 1 &amp; 1 \\ -11 &amp; 4 &amp; 5 \\ -1 &amp; 1 &amp; 0 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} 2 &amp; \sqrt 2 &amp; 0 \\ \sqrt 2 &amp; 2 &amp; \sqrt 2 \\ 0 &amp; \sqrt 2 &amp; 2 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} 1 &amp; -1 &amp; -1 \\ 1 &amp; -1 &amp; 0 \\ 1 &amp; 0 &amp; -1 \end{pmatrix}\)</span></li>
<li><span class="math inline">\(\begin{pmatrix} 5 &amp; 5 &amp; 1 \\ -2 &amp; -1 &amp; 0 \\ 1 &amp; 1 &amp; 1 \end{pmatrix}\)</span>.</li>
</ol>
<p>Answers:</p>
<p>In the following, we always let <span class="math inline">\(B_{\lambda} = \lambda I - A\)</span> and denote the characteristic polynomial <span class="math inline">\(p_{A}(\lambda) = \det(\lambda I - A)\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>The characteristic polynomial <span class="math inline">\(p_{A}(\lambda)\)</span> of <span class="math inline">\(A\)</span> is defined by
<span class="math display">\[
p_{A}(\lambda) = \begin{vmatrix} \lambda - 1 &amp; 0 \\ -2 &amp; \lambda - 2 \end{vmatrix}
= (\lambda-1)(\lambda-2).
\]</span>
Thus, the eigenvalues are <span class="math inline">\(\lambda_1 = 1\)</span> and <span class="math inline">\(\lambda_2 = 2\)</span>.
For <span class="math inline">\(\lambda_1 = 1\)</span>, substitute <span class="math inline">\(\lambda = \lambda_1 = 1\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{1}\mathbf{x} = \mathbf{0}\)</span>, that is
<span class="math display">\[
\begin{pmatrix} 0 \\ 0 \end{pmatrix}
= \begin{pmatrix} 0 &amp; 0 \\ -2 &amp; -1 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix}
= \begin{pmatrix} 0 \\ -2x -y \end{pmatrix}.
\]</span>
Thus, <span class="math inline">\(y = -2x\)</span> (with <span class="math inline">\(x\)</span> arbitrary) and the set of eigenvectors corresponding to the eigenvalue <span class="math inline">\(\lambda_1 = 1\)</span> is given by
<span class="math display">\[
\begin{pmatrix} \alpha \\ -2\alpha \end{pmatrix} \colon \alpha \neq 0.
\]</span>
For <span class="math inline">\(\lambda_2 = 2\)</span>, substitute <span class="math inline">\(\lambda = \lambda_2 = 2\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{2}\mathbf{x} = \mathbf{0}\)</span>, that is
<span class="math display">\[
\begin{pmatrix} 0 \\ 0 \end{pmatrix}
= \begin{pmatrix} 1 &amp; 0 \\ -2 &amp; 0 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}
= \begin{pmatrix} x \\ -2x \end{pmatrix},
\]</span>
so the solution is <span class="math inline">\(x = 0\)</span>, with <span class="math inline">\(y\)</span> arbitrary. The set of eigenvectors corresponding to the eigenvalue <span class="math inline">\(\lambda_2 = 2\)</span> is
<span class="math display">\[
\begin{pmatrix} 0 \\ \beta \end{pmatrix} \colon \beta \neq 0
\]</span>
Taking <span class="math inline">\(\alpha = \beta = 1\)</span>, we have the eigenvectors
<span class="math display">\[
\begin{pmatrix} 1 \\ -2 \end{pmatrix} \qquad\text{and} \qquad
\begin{pmatrix} 0 \\ 1 \end{pmatrix}
\]</span>
corresponding to the eigenvalues <span class="math inline">\(\lambda_1 = 1\)</span> and <span class="math inline">\(\lambda_2 = 2\)</span>, respectively. Let
<span class="math display">\[
P = \begin{pmatrix} 1 &amp; 0 \\ -2 &amp; 1 \end{pmatrix},
\]</span>
the matrix whose columns are the eigenvectors listed above. Then we have
<span class="math display">\[
D = \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 2 \end{pmatrix}.
\]</span></p></li>
<li><p>We have
<span class="math display">\[
p_{A}(\lambda) = \begin{vmatrix} \lambda - 1 &amp; -2 \\ 0 &amp; \lambda - 1 \end{vmatrix}
= (\lambda - 1)^2.
\]</span>
so the only eigenvalue is <span class="math inline">\(\lambda = \lambda_{1,2} = 1\)</span>. To find the eigenvectors, we solve
<span class="math display">\[
\begin{pmatrix} 0 \\ 0 \end{pmatrix}
= \begin{pmatrix} 0 &amp; -2 \\ 0 &amp; 0 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix}
= \begin{pmatrix} -2y \\ 0 \end{pmatrix}.
\]</span>
Thus, we have <span class="math inline">\(y = 0\)</span> and the eigenvectors are given by the set
<span class="math display">\[
\begin{pmatrix} \alpha \\ 0 \end{pmatrix} \colon \alpha \neq 0.
\]</span>
Since there is a repeated eigenvalue <span class="math inline">\(\lambda_{1,2} = 1\)</span> and there does not exists a set of two linearly independent eigenvectors for <span class="math inline">\(\lambda_{1,2}\)</span>, <span class="math inline">\(A\)</span> is not diagonalisable.</p></li>
<li><p>We have
<span class="math display">\[\begin{align*}
  p_{A}(\lambda) =\det(\lambda I - A)
  &amp;= \begin{vmatrix} \lambda-1 &amp; -2 \\ -2 &amp; \lambda+2 \end{vmatrix} \\
  &amp;= (\lambda-1)(\lambda+2)-4 \\
  &amp;= \lambda^2+\lambda-6 \\
  &amp;= (\lambda+3)(\lambda-2),
  \end{align*}\]</span>
hence, the eigenvalues are <span class="math inline">\(\lambda_1 = -3\)</span> and <span class="math inline">\(\lambda_2 = 2\)</span>.
For <span class="math inline">\(\lambda_1 = -3\)</span>, substitute <span class="math inline">\(\lambda = \lambda_1 = -3\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{-3}\mathbf{x} = \mathbf{0}\)</span>, that is
<span class="math display">\[
  \begin{pmatrix} 0 \\ 0 \end{pmatrix}
  = \begin{pmatrix} -4 &amp; -2 \\ -2 &amp; -1 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}.
  \]</span>
We note that the top row is twice the bottom row, the solutions satisfy <span class="math inline">\(y = -2x\)</span>. We take <span class="math inline">\(x = \alpha\)</span> to be arbitrary, whence the set of eigenvectors corresponding to the eigenvalue <span class="math inline">\(\lambda_1 = -3\)</span> is
<span class="math display">\[
  \begin{pmatrix} \alpha \\ -2\alpha \end{pmatrix} \colon \alpha \neq 0
  \]</span>
For <span class="math inline">\(\lambda_2 = 2\)</span>, substitute <span class="math inline">\(\lambda = \lambda_2 = 2\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{2}\mathbf{x} = \mathbf{0}\)</span>, that is
<span class="math display">\[
  \begin{pmatrix} 0 \\ 0 \end{pmatrix}
  = \begin{pmatrix} 1 &amp; -2 \\ -2 &amp; 4 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}.
  \]</span>
Again, we note that the bottom row is <span class="math inline">\(-2\)</span> times the top row, thus solutions satisfy <span class="math inline">\(x = 2y\)</span>. We take <span class="math inline">\(y = \beta\)</span> to be arbitrary, whence the set of eigenvectors corresponding to the eigenvalue <span class="math inline">\(\lambda_2 = 2\)</span> is
<span class="math display">\[
  \begin{pmatrix} 2\beta\\ \beta \end{pmatrix} \colon \beta \neq 0.
  \]</span>
Taking <span class="math inline">\(\alpha = \beta = 1\)</span>, we have the eigenvectors
<span class="math display">\[
  \begin{pmatrix} 1 \\ -2 \end{pmatrix} \qquad\text{and}\qquad
  \begin{pmatrix} 2 \\ 1 \end{pmatrix}
  \]</span>
corresponding to the eigenvalues <span class="math inline">\(\lambda_1 = -3\)</span> and <span class="math inline">\(\lambda_2 = 2\)</span>, respectively. Let
<span class="math display">\[
  P = \begin{pmatrix} 1 &amp; 2 \\ -2 &amp; 1 \end{pmatrix},
  \]</span>
then we have
<span class="math display">\[
  D= \begin{pmatrix} -3 &amp; 0 \\ 0 &amp; 2 \end{pmatrix}.
  \]</span></p></li>
<li><p>We have
<span class="math display">\[\begin{align*}
p_{A}(\lambda) = \det(\lambda I - A)
&amp;= \begin{vmatrix} \lambda-1 &amp; 2 &amp; 1 \\ -2 &amp; \lambda - 6 &amp; -2 \\ 1 &amp; 2 &amp; \lambda -1 \end{vmatrix} \\
&amp;= (\lambda-2)^2(\lambda-4)
\end{align*}\]</span>
hence, the eigenvalues are <span class="math inline">\(\lambda_{1,2} = 2\)</span> and <span class="math inline">\(\lambda_3 = 4\)</span> (note that there are only two distinct eigenvalues).
For <span class="math inline">\(\lambda_{1,2} = 2\)</span>, substitute <span class="math inline">\(\lambda = \lambda_{1,2} = 2\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{-3}\mathbf{x} = \mathbf{0}\)</span>, that is
<span class="math display">\[
\begin{pmatrix} 0 \\ 0\\ 0 \end{pmatrix}
= \begin{pmatrix} 1 &amp; 2 &amp; 1 \\ -2 &amp; -4 &amp; -2 \\ 1 &amp; 2 &amp; 1 \end{pmatrix} \begin{pmatrix} x \\ y \\ z \end{pmatrix}.
\]</span>
Here the second and third rows are multiples of the first row, so the general solution to the above system of equations is <span class="math inline">\(x + 2y + z = 0\)</span>. We can take <span class="math inline">\(y = \alpha\)</span> and <span class="math inline">\(z = \beta\)</span> to be arbitrary, and get the set of corresponding eigenvectors
<span class="math display">\[
\begin{pmatrix} -2\alpha-\beta \\ \alpha \\ \beta \end{pmatrix} \colon \text{$\alpha, \beta$ not both equal to zero.}
\]</span>
In particular, note that
<span class="math display">\[
\mathbf{v}_1 = \begin{pmatrix} -2 \\ 1 \\ 0 \end{pmatrix} \qquad\text{and}\qquad
\mathbf{v}_2 = \begin{pmatrix} -1 \\ 0 \\ 1 \end{pmatrix}
\]</span>
are two linearly independent eigenvectors corresponding to the eigenvalue <span class="math inline">\(\lambda_{1,2} = 2\)</span>, where we take <span class="math inline">\((\alpha,\beta) = (1,0)\)</span> to get <span class="math inline">\(\mathbf{v}_1\)</span> and <span class="math inline">\((\alpha,\beta) = (0,1)\)</span> to get <span class="math inline">\(\mathbf{v}_2\)</span>.
For <span class="math inline">\(\lambda_3 = 4\)</span>, substitute <span class="math inline">\(\lambda = \lambda_3 = 4\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{4}\mathbf{x} = \mathbf{0}\)</span>, that is
<span class="math display">\[
\begin{pmatrix} 0 \\ 0 \\ 0\end{pmatrix}
= \begin{pmatrix} 3 &amp; 2 &amp; 1 \\ -2 &amp; -2 &amp; -2 \\ 1 &amp; 2 &amp; 3\end{pmatrix} \begin{pmatrix} x \\ y \\ z \end{pmatrix}.
\]</span>
Applying EROs <span class="math inline">\(R_1 \to R_1 - 3R_3\)</span> and <span class="math inline">\(R_2 \to R_2 + 2R_3\)</span> gives
<span class="math display">\[
\begin{pmatrix} 0 &amp; -4 &amp; -8 \\ 0 &amp; 2 &amp; 4 \\ 1 &amp; 2 &amp; 3 \end{pmatrix}.
\]</span>
Then, applying <span class="math inline">\(R_1 \leftrightarrow R_3\)</span>, <span class="math inline">\(R_2 \to \frac{1}{2}R_2\)</span> and <span class="math inline">\(R_3 \to -\frac{1}{4}R_3\)</span> gives
<span class="math display">\[
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 0 &amp; 1 &amp; 2 \\ 0 &amp; 1 &amp; 2 \end{pmatrix},
\]</span>
and performing <span class="math inline">\(R_3 \to R_3 - R_2\)</span> and <span class="math inline">\(R_1 \to R_1 - 2R_2\)</span>, we arrive at the reduced echelon form
<span class="math display">\[
\begin{pmatrix} 1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; 2 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}.
\]</span>
There is no leading entry in the third column of the matrix of coefficients, so we may take <span class="math inline">\(z = \gamma\)</span> to be arbitrary and hence read off the the set of eigenvectors corresponding to the eigenvalue <span class="math inline">\(\lambda_3 = 4\)</span> as
<span class="math display">\[
\begin{pmatrix} \gamma \\ -2 \gamma \\ \gamma \end{pmatrix} \colon \gamma \neq 0.
\]</span>
In particular, taking <span class="math inline">\(\gamma = 1\)</span>, we get the eigenvector
<span class="math display">\[
\mathbf{v}_3 = \begin{pmatrix} 1 \\ -2 \\ 1 \end{pmatrix}.
\]</span>
We define the matrix <span class="math inline">\(P\)</span> by
<span class="math display">\[
P = (\mathbf{v}_1 \ \mathbf{v}_2\ \mathbf{v}_3) = \begin{pmatrix} -2 &amp; -1 &amp; 1\\ 1 &amp; 0 &amp; -2 \\ 0 &amp; 1 &amp; 1 \end{pmatrix},
\]</span>
then
<span class="math display">\[
D = \begin{pmatrix} 2 &amp; 0 &amp; 0 \\ 0 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 4 \end{pmatrix}
\]</span>
Note: In this example, we are able to diagonalise the <span class="math inline">\(3 \times 3\)</span> matrix <span class="math inline">\(A\)</span> even though it only had two distinct eigenvalues. This is because we can find two linearly independent eigenvectors corresponding to one of the eigenvalues.</p></li>
<li><p>We have
<span class="math display">\[\begin{align*}
p_{A}(\lambda) &amp;= \det(\lambda I - A)
&amp;= \begin{vmatrix} \lambda+2 &amp; -1 &amp; -1 \\ 11 &amp; \lambda -4 &amp; -5 \\ 1 &amp; -1 &amp; \lambda \end{vmatrix}\\
&amp;= (\lambda+1)(\lambda-1)(\lambda-2),
\end{align*}\]</span>
hence the eigenvalues of <span class="math inline">\(A\)</span> are <span class="math inline">\(\lambda_1 = -1\)</span>, <span class="math inline">\(\lambda_2 = 1\)</span>, and <span class="math inline">\(\lambda_3 = 2\)</span>.
For <span class="math inline">\(\lambda_1 = -1\)</span>, we substitute <span class="math inline">\(\lambda = \lambda_1 = -1\)</span> into the matrix <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{-1}\mathbf{x} = \mathbf{0}\)</span>. The augmented matrix is
<span class="math display">\[
\begin{pmatrix} 1 &amp; -1 &amp; -1 \\ 11 &amp; -5 &amp; -5 \\ 1 &amp; -1 &amp; -1 \end{pmatrix}
\]</span>
We perform EROs as follows:
<span class="math display">\[\begin{align*}
\text{$R_2 \to R_2 - 11R_1$ and $R_3 \to R_3 - R_1$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; -1 &amp; -1\\ 0 &amp; 6 &amp; 6 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}; \\
\text{$R_2 \to \frac{1}{6}R_2$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; -1 &amp; -1 \\ 0 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}; \\
\text{$R_1 \to R_1 + R_2$ and $R_3 \to R_3 - R_1$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}.
\end{align*}\]</span>
There is no leading entry in the last column so we take <span class="math inline">\(z = \alpha\)</span> to be arbitrary. The set of eigenvectors corresponding to the eigenvalue <span class="math inline">\(\lambda_1 = -1\)</span> is thus given by
<span class="math display">\[
\alpha \begin{pmatrix} 0 \\ -1 \\ 1 \end{pmatrix} \colon \alpha \neq 0.
\]</span>
For <span class="math inline">\(\lambda_2 = 1\)</span>, we substitute <span class="math inline">\(\lambda = \lambda_2 = 1\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{1}\mathbf{x} = \mathbf{0}\)</span>. We have the augmented matrix
<span class="math display">\[
\begin{pmatrix} 3 &amp; -1 &amp; -1 \\ 11 &amp; -3 &amp; -5 \\ 1 &amp; -1 &amp; 1 \\ \end{pmatrix},
\]</span>
which we bring into reduced echelon form as follows:
<span class="math display">\[\begin{align*}
\text{$R_1 \leftrightarrow R_3$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; -1 &amp; 1 \\ 11 &amp; -3 &amp; -5 \\ 3 &amp; -1 &amp; -1 \end{pmatrix}; \\
\text{$R_2 \to R_2 - 11R_1$ and $R_3 \to R_3 - 3R_1$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; -1 &amp; 1 \\ 0 &amp; 8 &amp; -16 \\ 0 &amp; 2 &amp; -4 \end{pmatrix}; \\
\text{$R_2 \to R_2 - 11R_1$ and $R_3 \to R_3 - R_1$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; -1 &amp; 1 \\ 0 &amp; 1 &amp; -2 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}; \\
\text{$R_1 \to R_1 + R_2$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; -2 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}.
\end{align*}\]</span>
There is no leading entry in the last column so we take <span class="math inline">\(z = \beta\)</span> to be arbitrary. The set of eigenvectors corresponding to the eigenvalue <span class="math inline">\(\lambda_2 = 1\)</span> is thus given by
<span class="math display">\[
\beta \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix} \colon \beta \neq 0.
\]</span>
For <span class="math inline">\(\lambda_3 = 2\)</span>, we substitute <span class="math inline">\(\lambda = \lambda_3 = 2\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{3}\mathbf{x} = \mathbf{0}\)</span>. We have the augmented matrix
<span class="math display">\[
\begin{pmatrix} 4 &amp; -1 &amp; -1 \\ 11 &amp; -2 &amp; -5 \\ 1 &amp; -1 &amp; 2 \end{pmatrix}
\]</span>
which we transform into reduced echelon form via the following process:
<span class="math display">\[\begin{align*}
\text{$R_1 \leftrightarrow R_3$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; -1 &amp; 2 \\ 11 &amp; -2 &amp; -5 \\ 4 &amp; -1 &amp; -1 \end{pmatrix}; \\
\text{$R_2 \to R_2 - 11R_1$ and $R_3 \to R_3 - 4R_1$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; -1 &amp; 2 \\ 0 &amp; 9 &amp; -27 \\ 0 &amp; 3 &amp; -9 \end{pmatrix}; \\
\text{$R_2 \to \frac{1}{9}R_2$ and $R_3 \to R_3 - 3R_2$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; -1 &amp; 2 \\ 0 &amp; 1 &amp; -3 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}; \\
\text{$R_1 \to R_1 + R_2$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; -3 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}.
\end{align*}\]</span>
Again, there is no leading entry in the last column, thus, taking <span class="math inline">\(z = \gamma\)</span>, we read off that the set eigenvectors corresponding to <span class="math inline">\(\lambda_3 = 2\)</span> is given by
<span class="math display">\[
\gamma \begin{pmatrix} 1 \\ 3 \\ 1 \end{pmatrix} \colon \gamma\neq 0.
\]</span>
Let
<span class="math display">\[
P = (\mathbf{v}_1 \ \ \mathbf{v}_2 \ \ \mathbf{v}_3) = \begin{pmatrix} 0 &amp; 1 &amp; 1 \\ -1 &amp; 2 &amp; 3 \\ 1 &amp; 1 &amp; 1 \end{pmatrix},
\]</span>
where, for <span class="math inline">\(\alpha = \beta = \gamma = 1\)</span>, <span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2\)</span>, and <span class="math inline">\(\mathbf{v}_3\)</span> are eigenvectors corresponding to the eigenvalues <span class="math inline">\(\lambda_1\)</span>, <span class="math inline">\(\lambda_2\)</span> and <span class="math inline">\(\lambda_3\)</span>, respectively. Then
<span class="math display">\[
P^{-1}AP = D,
\]</span>
where
<span class="math display">\[
D = \begin{pmatrix} -1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 2 \end{pmatrix}.
\]</span></p></li>
<li><p>We have
<span class="math display">\[\begin{align*}
p_{A}(\lambda) = \det(\lambda I - A)
&amp;= \begin{vmatrix} \lambda-2 &amp; -\sqrt{2} &amp; 0 \\ - \sqrt{2} &amp; \lambda -2 &amp; - \sqrt{2} \\ 0 &amp; - \sqrt{2} &amp; \lambda - 2 \end{vmatrix} \\
&amp;= (\lambda-2)\begin{vmatrix} \lambda -2 &amp; -\sqrt{2} \\ -\sqrt{2} &amp; \lambda -2  \end{vmatrix}
+ \sqrt{2} \begin{vmatrix} -\sqrt{2} &amp; - \sqrt{2} \\ 0 &amp; \lambda-2 \end{vmatrix} \\
&amp;= (\lambda-2)\left[(\lambda-2)^2-2\right] + \sqrt{2} \left[-\sqrt{2} (\lambda-2) \right] \\
&amp;= (\lambda-2)\left[ \lambda^2 - 4 \lambda\right] \\
&amp;= \lambda(\lambda-2)(\lambda-4),
\end{align*}\]</span>
so the eigenvalues are <span class="math inline">\(\lambda_1=0\)</span>, <span class="math inline">\(\lambda_2=2\)</span>, and <span class="math inline">\(\lambda_3=4\)</span>.
For <span class="math inline">\(\lambda_1 = 0\)</span>, we substitute <span class="math inline">\(\lambda = \lambda_1 = 0\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{0}\mathbf{x} = \mathbf{0}\)</span>. We have the augmented matrix
<span class="math display">\[
\begin{pmatrix} -2 &amp; - \sqrt{2} &amp; 0 \\ -\sqrt{2} &amp; -2 &amp; -\sqrt{2} \\ 0 &amp; -\sqrt{2} &amp; -2 \end{pmatrix}
\]</span>
which we bring into reduced echelon form as follows:
<span class="math display">\[\begin{align*}
\text{$R_1 \leftrightarrow R_2$} \colon\quad
&amp; \begin{pmatrix} - \sqrt{2} &amp; - 2 &amp; -\sqrt{2} \\ -2 &amp; -\sqrt{2} &amp; 0 \\ 0 &amp; -\sqrt{2} &amp; -2 \end{pmatrix};\\
\text{$R_1 \to -\frac{1}{\sqrt{2}}R_1$ and $R_2 \to R_2 + 2R_1$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; \sqrt{2} &amp; 1 \\ 0 &amp; \sqrt{2} &amp; 2 \\ 0 &amp; -\sqrt{2} &amp; -2 \end{pmatrix}; \\
\text{$R_1 \to R_1 - R_2$ and $R_3 \to R_3 + R_2$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; 0 &amp; -1 \\ 0 &amp; \sqrt{2} &amp; 2 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}; \\
\text{$R_2 \to \frac{1}{\sqrt{2}}R_2$} \colon\quad
&amp; \begin{pmatrix}  1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; \sqrt{2} \\ 0 &amp; 0 &amp; 0 \end{pmatrix}
\end{align*}\]</span>
Thus, the eigenvectors corresponding to the eigenvalue <span class="math inline">\(\lambda_1=0\)</span> are given by as the set
<span class="math display">\[
\alpha \begin{pmatrix} 1 \\ -\sqrt{2} \\ 1 \end{pmatrix} \colon \alpha \neq 0.
\]</span>
Note, that this example shows that it is possible for an eigen to be zero, even though eigen are prohibited from being zero. Note also, that for any eigenvector <span class="math inline">\(\mathbf{x}\)</span> corresponding to a zero eigenvalue, we have <span class="math inline">\(A\mathbf{x} = \mathbf{0}\)</span>.
For <span class="math inline">\(\lambda_2 = 2\)</span>, we substitute <span class="math inline">\(\lambda = \lambda_2 =2\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_2\mathbf{x} = \mathbf{0}\)</span>. We have the augmented matrix
<span class="math display">\[
\begin{pmatrix} 0 &amp; -\sqrt{2} &amp; 0 \\ -\sqrt{2} &amp; 0 &amp; -\sqrt{2} \\ 0 &amp; - \sqrt{2} &amp; 0 \end{pmatrix},
\]</span>
which, applying EROs <span class="math inline">\(R_1 \leftrightarrow R_2\)</span> and <span class="math inline">\(R_3 \to R_3 - R_2\)</span> we transform to
<span class="math display">\[
\begin{pmatrix} -\sqrt{2} &amp; 0 &amp; -\sqrt{2} \\ 0 &amp; - \sqrt{2} &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{pmatrix},
\]</span>
and, performing <span class="math inline">\(R_i \to -\frac{1}{\sqrt{2}}R_i\)</span>, for <span class="math inline">\(i=1,2\)</span>, to
<span class="math display">\[
\begin{pmatrix} 1 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}.
\]</span>
Thus, the set of eigenvectors corresponding to the eigenvalue <span class="math inline">\(\lambda_2 = 2\)</span>, is given as
<span class="math display">\[
\beta \begin{pmatrix} -1 \\0 \\ 1 \end{pmatrix} \colon \beta \neq 0.
\]</span>
For <span class="math inline">\(\lambda_3=4\)</span>, we substitute <span class="math inline">\(\lambda = \lambda_3 = 4\)</span> into the matrix <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_4\mathbf{x} = \mathbf{0}\)</span>. We get the augmented matrix
<span class="math display">\[
\begin{pmatrix} 2 &amp; - \sqrt{2} &amp; 0\\ - \sqrt{2} &amp; 2 &amp; -\sqrt{2} \\ 0 &amp; -\sqrt{2} &amp; 2 \end{pmatrix}
\]</span>
which, applying EROs, can be transformed into REF as follows:
<span class="math display">\[\begin{align*}
\text{$R_1 \leftrightarrow R_2$} \colon\quad
&amp; \begin{pmatrix} -\sqrt{2} &amp; 2 &amp; -\sqrt{2} \\ 2 &amp; -\sqrt{2} &amp; 0 \\ 0 &amp; -\sqrt{2} &amp; 2 \end{pmatrix} \\
\text{$R_2 \to R_2 + \sqrt{2}R_1$} \colon\quad
&amp; \begin{pmatrix} -\sqrt{2} &amp; 2 &amp; -\sqrt{2} \\ 0 &amp; \sqrt{2} &amp; - 2 \\ 0 &amp; -\sqrt{2} &amp; 2 \end{pmatrix} \\
\text{$R_3 \to R_3 + R_2$ and $R_1 \to -\frac{1}{\sqrt{2}} R_1$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; -\sqrt{2} &amp; 1 \\ 0 &amp; \sqrt{2} &amp; - 2 \\ 0 &amp; 0 &amp; 0 \end{pmatrix} \\
\text{$R_1 \to R_1 + R_2$ and $R_2 \to \frac{1}{\sqrt{2}} R_2$} \colon\quad
&amp; \begin{pmatrix} 1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; -\sqrt{2} \\ 0 &amp; 0 &amp; 0 \end{pmatrix}.
\end{align*}\]</span>
Thus, the eigenvectors corresponding to the eigenvalue <span class="math inline">\(\lambda_3=4\)</span> are given by as the set
<span class="math display">\[
\gamma \begin{pmatrix} 1 \\ \sqrt{2} \\ 1  \end{pmatrix} \colon \gamma \neq 0.
\]</span>
Using <span class="math inline">\(\alpha = \beta = \gamma = 1\)</span> in the above sets to obtain particular eigenvectors <span class="math inline">\(\mathbf{v}_1, \mathbf{v}_2\)</span> and <span class="math inline">\(\mathbf{v}_3\)</span>, respectively, define the matrix <span class="math inline">\(P\)</span> by
<span class="math display">\[
P = (\mathbf{v}_1 \ \ \mathbf{v}_2 \ \ \mathbf{v}_3)
= \begin{pmatrix} 1 &amp; -1  &amp; 1 \\ -\sqrt{2} &amp; 0 &amp; \sqrt{2} \\ 1 &amp; 1 &amp; 1 \end{pmatrix}.
\]</span>
Then,
<span class="math display">\[
P^{-1}AP = D,
\]</span>
where
<span class="math display">\[
D = \begin{pmatrix} 0 &amp; 0 &amp; 0 \\ 0 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 4 \end{pmatrix}.
\]</span></p></li>
<li><p>We have
<span class="math display">\[\begin{align*}
p_{A}(\lambda) = \det(\lambda I - A)
&amp;= \begin{vmatrix} \lambda-1 &amp; 1 &amp; 1 \\ -1 &amp; \lambda+1 &amp; 0 \\ -1 &amp; 0 &amp; \lambda +1 \end{vmatrix}\\
&amp;= (\lambda-1) \begin{vmatrix} \lambda +1 &amp; 0 \\ 0 &amp; \lambda+1 \end{vmatrix}
- \begin{vmatrix} -1 &amp; 0 \\ -1 &amp; \lambda+1 \end{vmatrix}
+ \begin{vmatrix} -1 &amp; \lambda+1 \\ -1 &amp; 0 \end{vmatrix} \\
&amp;= (\lambda-1)(\lambda+1)^2 + (\lambda+1) + (\lambda+1) \\
&amp;= (\lambda+1)(\lambda^2+1),
\end{align*}\]</span>
thus the eigenvalues are <span class="math inline">\(\lambda_1 = -1\)</span>, <span class="math inline">\(\lambda_2 = i\)</span> and <span class="math inline">\(\lambda_3 = -i\)</span> (where <span class="math inline">\(i^2=-1\)</span>).
For <span class="math inline">\(\lambda_1 = -1\)</span>, we substitute <span class="math inline">\(\lambda = \lambda_1 = -1\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{-1}\mathbf{x} = \mathbf{0}\)</span>. We have the augmented matrix
<span class="math display">\[
\begin{pmatrix} -2 &amp; 1 &amp; 1 \\ -1 &amp; 0 &amp; 0 \\ -1 &amp; 0 &amp; 0 \end{pmatrix},
\]</span>
which we transform into reduced echelon form via <span class="math inline">\(R_3 \to R_3 - R_2\)</span>, <span class="math inline">\(R_1 \to R_1 - 2R_2\)</span> and <span class="math inline">\(R_1 \leftrightarrow R_2\)</span> to obtain
<span class="math display">\[
\begin{pmatrix} -1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 0 \end{pmatrix},
\]</span>
and thus find the set of eigenvectors
<span class="math display">\[
\alpha \begin{pmatrix} 0 \\ -1 \\ 1 \end{pmatrix} \colon \alpha \neq 0
\]</span>
corresponding to <span class="math inline">\(\lambda_1 = -1\)</span>.
For <span class="math inline">\(\lambda_2 = i\)</span>, we substitute <span class="math inline">\(\lambda = \lambda_2 = i\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{i}\mathbf{x} = \mathbf{0}\)</span>. We have the augmented matrix
<span class="math display">\[
\begin{pmatrix} i-1 &amp; 1 &amp; 1 \\ -1 &amp; i+1 &amp; 0 \\ -1 &amp; 0 &amp; i+1 \end{pmatrix}.
\]</span>
First, performing <span class="math inline">\(R_1 \leftrightarrow R_2\)</span>, <span class="math inline">\(R_2 \to R_2 + (i-1)R_1\)</span> and <span class="math inline">\(R_3 \to R_3 - R_1\)</span> gives
<span class="math display">\[
\begin{pmatrix} -1 &amp; i+1 &amp; 0 \\ 0 &amp; 1 + (i+1)(i-1) &amp; 1 \\ 0 &amp; -i-1 &amp; i+1 \end{pmatrix}
= \begin{pmatrix} -1 &amp; i+1 &amp; 0 \\ 0 &amp; -1 &amp; 1 \\ 0 &amp; -(i+1) &amp; i+1 \end{pmatrix},
\]</span>
and applying <span class="math inline">\(R_3 \to R_3 - (i+1)R_2\)</span> and <span class="math inline">\(R_1 \to R_1 + (i+1)R_2\)</span> gives
<span class="math display">\[
\begin{pmatrix} -1 &amp; 0 &amp; (i+1) \\ 0 &amp; -1 &amp; 1 \\ 0 &amp; 0 &amp; 0 \end{pmatrix},
\]</span>
which is in REF and thus we find the set of eigenvectors
<span class="math display">\[
\beta \begin{pmatrix} (i+1) \\ 1 \\ 1 \end{pmatrix} \colon \beta \neq 0
\]</span>
corresponding to <span class="math inline">\(\lambda_2 = i\)</span>.
For <span class="math inline">\(\lambda_3 = -i\)</span>, we substitute <span class="math inline">\(\lambda = \lambda_3 = -i\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{-i}\mathbf{x} = \mathbf{0}\)</span>. We have the augmented matrix
<span class="math display">\[
\begin{pmatrix} -i-1 &amp; 1 &amp; 1 \\ -1 &amp; -i+1 &amp; 0 \\ -1 &amp; 0 &amp; -i+1 \end{pmatrix}.
\]</span>
First, performing <span class="math inline">\(R_1 \leftrightarrow R_2\)</span>, <span class="math inline">\(R_2 \to R_2 - (i+1)R_1\)</span> and <span class="math inline">\(R_3 \to R_3 - R_1\)</span> gives
<span class="math display">\[
\begin{pmatrix} -1 &amp; -(i-1) &amp; 0 \\ 0 &amp; 1 + (i+1)(i-1) &amp; 1 \\ 0 &amp; i-1 &amp; -i+1 \end{pmatrix}
= \begin{pmatrix} -1 &amp; -(i-1) &amp; 0 \\ 0 &amp; -1 &amp; 1 \\ 0 &amp; i-1 &amp; -(i-1) \end{pmatrix},
\]</span>
and applying <span class="math inline">\(R_3 \to R_3 + (i-1)R_2\)</span> and <span class="math inline">\(R_1 \to R_1 - (i-1)R_2\)</span> gives
<span class="math display">\[
\begin{pmatrix} -1 &amp; 0 &amp; -(i-1) \\ 0 &amp; -1 &amp; 1 \\ 0 &amp; 0 &amp; 0 \end{pmatrix},
\]</span>
which is in REF and thus we find the set of eigenvectors
<span class="math display">\[
\gamma \begin{pmatrix} -(i-1) \\ 1 \\ 1 \end{pmatrix} \colon \gamma \neq 0
\]</span>
corresponding to <span class="math inline">\(\lambda_3 = -i\)</span>.
Setting <span class="math inline">\(\alpha = \beta = \gamma = 1\)</span>, we find that the matrix
<span class="math display">\[
P = \begin{pmatrix} 0 &amp; i+1 &amp; -i+1 \\ -1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 1 \end{pmatrix}
\]</span>
satisfies
<span class="math display">\[
P^{-1}AP = D,
\]</span>
where
<span class="math display">\[
D = \begin{pmatrix} -1 &amp; 0 &amp; 0 \\ 0 &amp; i &amp; 0 \\ 0 &amp; 0 &amp; -i \end{pmatrix}.
\]</span></p></li>
<li><p>We have
<span class="math display">\[\begin{align*}
p_{A}(\lambda) = \det(\lambda I - A)
&amp;= \begin{vmatrix} \lambda-5 &amp; -5 &amp; -1 \\ 2 &amp; \lambda+1 &amp; 0 \\ -1 &amp; -1 &amp; \lambda-1 \end{vmatrix}\\
&amp;= (\lambda-5)\begin{vmatrix} \lambda+1 &amp; 0 \\ -1 &amp; \lambda-1 \end{vmatrix}
- (-5) \begin{vmatrix} 2 &amp; 0 \\ -1 &amp; \lambda-1 \end{vmatrix} \\
&amp;\phantom{={}} + (-1) \begin{vmatrix} 2 &amp; \lambda+1 \\ -1 &amp; -1 \end{vmatrix} \\
&amp;= (\lambda-5)(\lambda+1)(\lambda-1) + 5(2(\lambda-1)) - (-2 + \lambda + 1) \\
&amp;= (\lambda-1)\big((\lambda-5)(\lambda+1) + 10 - 1\big) \\
&amp;= (\lambda-1)\big(\lambda^2 - 4\lambda + 4\big) \\
&amp;= (\lambda-1)(\lambda - 2)^2,
\end{align*}\]</span>
thus the eigenvalues are <span class="math inline">\(\lambda_1 = 1\)</span>, <span class="math inline">\(\lambda_{2,3} = 2\)</span>.
For <span class="math inline">\(\lambda_1 = 1\)</span>, we substitute <span class="math inline">\(\lambda = \lambda_1 = 1\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{1}\mathbf{x} = \mathbf{0}\)</span>. We have the augmented matrix
<span class="math display">\[
\begin{pmatrix} -4 &amp; -5 &amp; -1 \\ 2 &amp; 2 &amp; 0 \\ -1 &amp; -1 &amp; 0 \end{pmatrix}.
\]</span>
Applying EROs <span class="math inline">\(R_1 \to R_1 + 2R_2\)</span> and <span class="math inline">\(R_3 \to R_3 + \frac{1}{2}R_2\)</span> gives
<span class="math display">\[
\begin{pmatrix} 0 &amp; -1 &amp; -1 \\ 2 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 0 \end{pmatrix}.
\]</span>
Performing <span class="math inline">\(R_1 \leftrightarrow R_2\)</span>, <span class="math inline">\(R_1 \to R_1 + 2R_2\)</span> and <span class="math inline">\(R_1 \to \frac{1}{2}R_1\)</span> and <span class="math inline">\(R_2 \to -R_2\)</span> gives
<span class="math display">\[
\begin{pmatrix} 1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 0 \end{pmatrix},
\]</span>
which is in REF and thus we find the set of eigenvectors
<span class="math display">\[
\alpha\begin{pmatrix} 1 \\ -1 \\ 1 \end{pmatrix} \colon \alpha \neq 0
\]</span>
corresponding to <span class="math inline">\(\lambda_1 = 1\)</span>.
For <span class="math inline">\(\lambda_{2,3} = 2\)</span>, we substitute <span class="math inline">\(\lambda = \lambda_{2,3} = 2\)</span> into <span class="math inline">\(B_{\lambda}\)</span> and solve <span class="math inline">\(B_{2}\mathbf{x} = \mathbf{0}\)</span>. We have the augmented matrix
<span class="math display">\[
\begin{pmatrix} -3 &amp; -5 &amp; -1 \\ 2 &amp; 3 &amp; 0 \\ -1 &amp; -1 &amp; 1 \end{pmatrix}.
\]</span>
Performing <span class="math inline">\(R_1\leftrightarrow R_3\)</span>, <span class="math inline">\(R_2 \to R_2 + 2R_1\)</span> and <span class="math inline">\(R_3 \to R_3 - 3R_1\)</span>, we have
<span class="math display">\[
\begin{pmatrix} -1 &amp; -1 &amp; 1 \\ 0 &amp; 1 &amp; 2 \\ 0 &amp; -2 &amp; -4 \end{pmatrix},
\]</span>
and further, performing <span class="math inline">\(R_3 \to R_3 + 2R_2\)</span>, <span class="math inline">\(R_1 \to -R_1\)</span> and <span class="math inline">\(R_1 \to R_1 - R_2\)</span> gives
<span class="math display">\[
\begin{pmatrix} 1 &amp; 0 &amp; -3 \\ 0 &amp; 1 &amp; 2 \\ 0 &amp; 0 &amp; 0 \end{pmatrix},
\]</span>
which is in REF and thus we find the set of eigenvectors
<span class="math display">\[
\beta\begin{pmatrix} 3 \\ -2 \\ 1 \end{pmatrix} \colon \beta \neq 0
\]</span>
corresponding to <span class="math inline">\(\lambda_{2,3} = 2\)</span>.
This shows that there are only two linearly independent eigenvectors, hence <span class="math inline">\(A\)</span> is not diagonalisable.</p></li>
</ol></li>
<li><p>For the matrices in a. and d. in the previous question, find a formula for <span class="math inline">\(A^n\)</span>.</p>
<p>Answers:</p>
<p>First, note that <span class="math inline">\(P^{-1}AP = D\)</span> and thus <span class="math inline">\(A = PDP^{-1}\)</span>. Then,
<span class="math display">\[\begin{align*}
A^2 &amp;= \left(PDP^{-1}\right)^2 \\
&amp;= \left(PDP^{-1}\right)\left(PDP^{-1}\right) \\
&amp;= PDP^{-1}PDP^{-1} \\
&amp;= PD I_n DP^{-1} \\
&amp;= P D^{2} P^{-1}.
\end{align*}\]</span>
and more generally <span class="math inline">\(A^n = P D^{n} P^{-1}\)</span>.</p>
<p>Now for a.
<span class="math display">\[\begin{align*}
A^n &amp;= \begin{pmatrix} 1 &amp; 0 \\ -2 &amp; 1 \end{pmatrix}
\begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 2^n \end{pmatrix}
\begin{pmatrix} 1 &amp; 0 \\ 2 &amp; 1\end{pmatrix} \\
&amp;= \begin{pmatrix} 1 &amp; 0 \\ -2 &amp; 2^n \end{pmatrix}
\begin{pmatrix} 1 &amp; 0 \\ 2 &amp; 1 \end{pmatrix} \\
&amp;= \begin{pmatrix} 1 &amp; 0 \\ 2^{n+1}-2 &amp; 2^n \end{pmatrix}.
\end{align*}\]</span></p>
<p>For d., first compute <span class="math inline">\(P^{-1}\)</span> using Gaussian elimination. Starting with the augmented matrix
<span class="math display">\[\left(\begin{array}{rrr|rrr}
2  &amp; -1 &amp; 1  &amp; 1 &amp; 0 &amp; 0 \\
-1 &amp; 0  &amp; -2 &amp; 0 &amp; 1 &amp; 0 \\
0  &amp; 1  &amp; 1  &amp; 0 &amp; 0 &amp; 1
\end{array}\right).\]</span>
Applying <span class="math inline">\(R_1 \leftrightarrow R_2\)</span> gives
<span class="math display">\[\left(\begin{array}{rrr|rrr}
-1 &amp; 0  &amp; -2 &amp; 0 &amp; 1 &amp; 0 \\
2  &amp; -1 &amp; 1  &amp; 1 &amp; 0 &amp; 0 \\
0  &amp; 1  &amp; 1  &amp; 0 &amp; 0 &amp; 1
\end{array}\right),\]</span>
performing <span class="math inline">\(R_2 \to R_2 + 2R_1\)</span> gives
<span class="math display">\[\left(\begin{array}{rrr|rrr}
-1 &amp; 0  &amp; -2 &amp; 0 &amp; 1 &amp; 0 \\
0  &amp; -1 &amp; -3 &amp; 1 &amp; 2 &amp; 0 \\
0  &amp; 1  &amp; 1  &amp; 0 &amp; 0 &amp; 1
\end{array}\right),\]</span>
performing <span class="math inline">\(R_3 \to R_3 + R_2\)</span> gives
<span class="math display">\[\left(\begin{array}{rrr|rrr}
-1 &amp; 0  &amp; -2 &amp; 0 &amp; 1 &amp; 0 \\
0  &amp; -1 &amp; -3 &amp; 1 &amp; 2 &amp; 0 \\
0  &amp; 0  &amp; -2 &amp; 1 &amp; 2 &amp; 1
\end{array}\right),\]</span>
performing <span class="math inline">\(R_1 \to -R_1\)</span>, <span class="math inline">\(R_2 \to -R_2\)</span> and <span class="math inline">\(R_3 \to -\frac{1}{2}R_3\)</span> gives
<span class="math display">\[\left(\begin{array}{rrr|rrr}
1 &amp; 0 &amp; 2 &amp; 0            &amp; -1 &amp; 0 \\
0 &amp; 1 &amp; 3 &amp; -1           &amp; -2 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; -\frac{1}{2} &amp; -1 &amp; -\frac{1}{2}
\end{array}\right),\]</span>
and with <span class="math inline">\(R_2 \to R_2 - 3R_3\)</span> and <span class="math inline">\(R_1 \to R_1 - 2R_3\)</span> we arrive at
<span class="math display">\[\left(\begin{array}{rrr|rrr}
1 &amp; 0 &amp; 0 &amp; 1            &amp; 1  &amp; 1 \\
0 &amp; 1 &amp; 0 &amp; \frac{1}{2}  &amp; 1  &amp; \frac{3}{2} \\
0 &amp; 0 &amp; 1 &amp; -\frac{1}{2} &amp; -1 &amp; -\frac{1}{2}
\end{array}\right).\]</span>
We deduce that
<span class="math display">\[
P^{-1} = \frac{1}{2} \begin{pmatrix} 2 &amp; 2 &amp; 2 \\ 1 &amp; 2 &amp; 3 \\ -1 &amp; -2 &amp; -1 \end{pmatrix}.
\]</span>
We have
<span class="math display">\[
D^n = \begin{pmatrix} 2^n &amp; 0 &amp; 0\\ 0 &amp; 2^n &amp; 0 \\ 0 &amp; 0 &amp; 4^n \end{pmatrix},
\]</span>
and so
<span class="math display">\[\begin{align*}
A^n &amp;= P D^n P^{-1} \\
&amp;=\frac{1}{2} \begin{pmatrix}
2^{n+2}-2^n-4^n &amp;2^{n+2}-2^{n+1}-2^{2 n+1} &amp; 2^{n+2}-3\times 2^n-4^n \\
-2^{n+1}+2^{2 n+1} &amp;-2^{n+1}+2^{2 n+2} &amp;-2^{n+1}+2^{2 n+1} \\
2^n-4^n &amp; 2^{n+1}-2^{2 n+1} &amp; 3\times 2^n-4^n
\end{pmatrix}.
\end{align*}\]</span></p></li>
<li><p><em>Linear Difference Equations</em>. A population of Wildebeest can be classified into two life stages: juvenile and adult. Each year <span class="math inline">\(60\%\)</span> of the juveniles survive to become adults, adults give birth on average to <span class="math inline">\(0.5\)</span> juvelines and <span class="math inline">\(70\%\)</span> of adults survive the year. If there are <span class="math inline">\(200\)</span> juveniles and <span class="math inline">\(200\)</span> adults in one year, what is the long term population of juveniles and adults? What is the long term ratio of juveniles to adults? Hint: write this as a matrix equation and use diagonalisation (save some time and use a computer to find the eigenvalues and eigenvectors for this question).</p>
<p>How about in the case when the adult survival rate increases to <span class="math inline">\(80\%\)</span>? In this case also give the long term growth rate of the juvenile and adult populations. What happens in the case that the adult survival rate drops to <span class="math inline">\(60\%\)</span>?</p>
<p>Answers:</p>
<p>Let <span class="math inline">\(x_1(n)\)</span> denote the population of juveniles and <span class="math inline">\(x_2(n)\)</span> the population of adults in year <span class="math inline">\(n\)</span>. Then we can formulate this as the coupled system of linear difference equations:
<span class="math display">\[
\begin{pmatrix}
x_1(n)\\
x_2(n)
\end{pmatrix}
=
\begin{pmatrix}
0&amp;0.5\\
0.6&amp;0.7
\end{pmatrix}
\begin{pmatrix}
x_1(n-1)\\
x_2(n-1)
\end{pmatrix}.
\]</span>
Let
<span class="math display">\[
\mathbf{x}(n)=
\begin{pmatrix}
x_1(n)\\
x_2(n)
\end{pmatrix}
\quad \text{and} \quad A=
\begin{pmatrix}
0&amp;0.5\\
0.6&amp;0.7
\end{pmatrix}
\]</span>
then the solution is
<span class="math display">\[
\mathbf{x}(n)=A^n\mathbf{x}(0).
\]</span>
If the matrix <span class="math inline">\(A\)</span> is diagonalisable, then we can find <span class="math inline">\(A^n\)</span> by diagonalisation. We find that <span class="math inline">\(A\)</span> has eigenvalues <span class="math inline">\(\lambda_1=1\)</span> and <span class="math inline">\(\lambda_2=-\frac{3}{10}\)</span> with corresponding eigenvectors
<span class="math display">\[\mathbf{v}_1=\begin{pmatrix}1\\2\end{pmatrix},\quad \mathbf{v}_2\begin{pmatrix}1\\-3/5\end{pmatrix}.\]</span>
So
<span class="math display">\[
A^n=\frac{1}{13}
\begin{pmatrix}
1&amp;1\\
2&amp;-\frac{3}{5}
\end{pmatrix}
\begin{pmatrix}
1&amp;0\\
0&amp;-\frac{3}{10}
\end{pmatrix}^n
\begin{pmatrix}
3&amp;5\\
10&amp;-5
\end{pmatrix}
\]</span>
and
<span class="math display" id="eq:vecwildebeest">\[\begin{align}
\mathbf{x}(n)&amp;=\frac{1}{13}\times 1^n \times (3x_1(0)+5x_2(0))
\begin{pmatrix}
1\\
2
\end{pmatrix}
\\
&amp;+\frac{1}{13}\times\left(-\frac{3}{10}\right)^n\times(10x_1(0)-5x_2(0))
\begin{pmatrix}
1\\
-\frac{3}{5}
\end{pmatrix}\tag{21.1}
\end{align}\]</span>
or writing each population separately
<span class="math display">\[
\begin{aligned}
x_1(n)&amp;=\frac{1}{13}(3x_1(0)+5x_2(0))+\frac{1}{13}\left(-\frac{3}{10}\right)^n(10x_1(0)-5x_2(0))\\
x_2(n)&amp;=\frac{2}{13}(3x_1(0)+5x_2(0))+\frac{1}{13}\left(-\frac{3}{10}\right)^n\left( -\frac{3}{5}\right)(10x_1(0)-5x_2(0)).
\end{aligned}
\]</span></p>
<p>From <a href="exercise-set-7-answers.html#eq:vecwildebeest">(21.1)</a> we can see that in the long term the populations settle down to:
<span class="math display" id="eq:asymp">\[\begin{equation}
\lim\limits_{n\to\infty}\mathbf{x}(n)=\frac{1}{13}(3x_1(0)+5x_2(0))
\begin{pmatrix}
1\\
2
\end{pmatrix}\tag{21.2}
\end{equation}\]</span>
that is,
<span class="math display">\[\begin{align*}
\lim\limits_{n\to\infty}x_1(n)&amp;=\frac{1}{13}(3x_1(0)+5x_2(0))\approx 123,\\
\lim\limits_{n\to\infty}x_2(n)&amp;=\frac{2}{13}(3x_1(0)+5x_2(0))\approx 246.
\end{align*}\]</span>
From <a href="exercise-set-7-answers.html#eq:asymp">(21.2)</a> the long term ratio of juveniles to adults is
<span class="math display">\[
\lim\limits_{n\to\infty}\frac{x_1(n)}{x_2(n)}=\frac{1}{2}
\]</span>
i.e. <span class="math inline">\(1:2\)</span>.</p>
<p>Now when the survival rate increases to 80% the matrix <span class="math inline">\(A\)</span> becomes
<span class="math display">\[
A=
\begin{pmatrix}
0&amp;0.5\\
0.6&amp;0.8
\end{pmatrix}
\]</span>
which is still diagonalisable and has eigenvalues and corresponding eigenvectors
<span class="math display">\[\begin{align*}
\lambda_1=\frac{1}{10} (4 + \sqrt{46})\approx 1.08,\quad &amp; \quad\lambda_2=\frac{1}{10} (4 - \sqrt{46})\approx-0.28,\\
\mathbf{v}_1=
\begin{pmatrix}
\frac{1}{6}(-4 + \sqrt{46})\\
1
\end{pmatrix},\quad
&amp;
\quad \mathbf{v}_2=\begin{pmatrix}
\frac{1}{6}(-4 - \sqrt{46})\\
1
\end{pmatrix}.
\end{align*}\]</span>
If we let <span class="math inline">\(\mathcal{P}=(\mathbf{v}_1,\mathbf{v}_2)\)</span> and write
<span class="math display">\[
\mathbf{x}(0)_\mathcal{P}=\begin{pmatrix}
\mu_1\\
\mu_2
\end{pmatrix}
\]</span>
then
<span class="math display">\[
\mathbf{x}(n)=\mu_1\lambda_1^n\mathbf{v}_1+\mu_2\lambda_2^n\mathbf{v}_2.
\]</span>
Since <span class="math inline">\(|\lambda_1|&gt;1\)</span> and <span class="math inline">\(|\lambda_2|&lt;1\)</span>, for large <span class="math inline">\(n\)</span>
<span class="math display">\[
\mathbf{x}(n)\approx\mu_1\lambda_1^nv_1
\]</span>
and hence both <span class="math inline">\(x_1(n)\to\infty\)</span> and <span class="math inline">\(x_2(n)\to \infty\)</span>, with the long term ratio <span class="math inline">\(x_1:x_2\)</span> being <span class="math inline">\(\frac{1}{6}(-4 + \sqrt{46}):1\)</span>, or approximately <span class="math inline">\(1:2.2\)</span>.</p>
<p>In the case that the adult survival rate drops to 60%, we have
<span class="math display">\[
A=
\begin{pmatrix}
0&amp;0.5\\
0.6&amp;0.6
\end{pmatrix}
\]</span>
which is diagonalisable and has eigenvalues and corresponding eigenvectors
<span class="math display">\[\begin{align*}
\lambda_1=\frac{1}{10} (3 + \sqrt{39})\approx 0.92,\quad &amp; \quad\lambda_2=\frac{1}{10} (3 - \sqrt{39})\approx-0.32,\\
\mathbf{v}_1=
\begin{pmatrix}
\frac{1}{6}(-3 + \sqrt{39})\\
1
\end{pmatrix},\quad
&amp;
\quad \mathbf{v}_2=\begin{pmatrix}
\frac{1}{6}(-3 - \sqrt{39})\\
1
\end{pmatrix}.
\end{align*}\]</span>
If we let <span class="math inline">\(\mathcal{P}=(\mathbf{v}_1,\mathbf{v}_2)\)</span> and write
<span class="math display">\[
\mathbf{x}(0)_\mathcal{P}=\begin{pmatrix}
\mu_1\\
\mu_2
\end{pmatrix}
\]</span>
then
<span class="math display">\[
\mathbf{x}(n)=\mu_1\lambda_1^nv_1+\mu_2\lambda_2^nv_2,
\]</span>
but now since both <span class="math inline">\(|\lambda_1|&lt;1\)</span> and <span class="math inline">\(|\lambda_2|&lt;1\)</span>,
<span class="math display">\[
\lim\limits_{n\to\infty}x(n)=\lim\limits_{n\to\infty}\begin{pmatrix}
x_1(n)\\
x_2(n)
\end{pmatrix}
=
\begin{pmatrix}
0\\
0
\end{pmatrix}
\]</span>
and the population dies out.</p></li>
</ol>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="exercise-set-7.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exercise-set-8.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/maths-sci-eng/maths-sci-eng.github.io/edit/master/33-exercises07_ans.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["maths-notes.pdf", "maths-notes.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
